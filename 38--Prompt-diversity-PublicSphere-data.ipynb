{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2288.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 640, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2288.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 1992, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2288.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_28128\\1977079471.py\", line 6, in <module>\n",
      "    import src\n",
      "  File \"c:\\Users\\sstolwi\\Github\\TWON-Metrics\\src\\__init__.py\", line 1, in <module>\n",
      "    from .hf_classify import HFClassify\n",
      "  File \"c:\\Users\\sstolwi\\Github\\TWON-Metrics\\src\\hf_classify.py\", line 5, in <module>\n",
      "    import torch\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\torch\\__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\torch\\functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\torch\\nn\\__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\torch\\nn\\modules\\__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import typing\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import config\n",
    "import src\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"sjoerdAzure.env\")  # Load environment variables from .env file\n",
    "import time\n",
    "import tqdm\n",
    "#from tqdm import tqdm          #run these lines to run the ADA progress bar\n",
    "#tqdm.pandas()\n",
    "import json\n",
    "import numpy as np\n",
    "import logging\n",
    "import re\n",
    "#import cltrier_lib as lib\n",
    "\n",
    "import yaml\n",
    "pd.set_option('display.max_colwidth', 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up helper variables and functions:\n",
    "CFG = config.Config()\n",
    "\n",
    "def load_json(path: str):\n",
    "    with open(path, encoding='utf-8') as fp:\n",
    "        return json.load(fp)\n",
    "    \n",
    "#set option variables:\n",
    "\n",
    "#set options to low temperature (0,1):\n",
    "options_low_str = \"\"\"\n",
    "seed: 42\n",
    "temperature: 0.1\n",
    "\"\"\"\n",
    "\n",
    "options_low = yaml.safe_load(options_low_str)\n",
    "\n",
    "MODELsmall: str = 'llama3.1:8b-instruct-q6_K' # options: 'gemma:7b-instruct-q6_K', 'gemma2:27b-instruct-q6_K', 'llama3.1:8b-instruct-q6_K', 'llama3.1:70b-instruct-q6_K', 'mistral:7b-instruct-v0.3-q6_K', 'mistral-large:123b-instruct-2407-q6_K', 'mixtral:8x7b-instruct-v0.1-q6_K', 'mixtral:8x22b-instruct-v0.1-q6_K', 'phi3:14b-medium-128k-instruct-q6_K' or 'qwen2:72b-instruct-q6_K'\n",
    "MODELlarge: str = 'llama3.1:70b-instruct-q6_K' # options: 'gemma:7b-instruct-q6_K', 'gemma2:27b-instruct-q6_K', 'llama3.1:8b-instruct-q6_K', 'llama3.1:70b-instruct-q6_K', 'mistral:7b-instruct-v0.3-q6_K', 'mistral-large:123b-instruct-2407-q6_K', 'mixtral:8x7b-instruct-v0.1-q6_K', 'mixtral:8x22b-instruct-v0.1-q6_K', 'phi3:14b-medium-128k-instruct-q6_K' or 'qwen2:72b-instruct-q6_K'\n",
    "MODELgpt4o = \"nf-gpt-4o-2024-08-06\" # in principe is er nu van elk model een nf (no filter) en een normale versie beschikbaar, de no filter versies zijn alleen voor onderzoekers beschikbaar voor analyze van content die niet door de filter heen zou komen.\n",
    "MODELgpt4T = \"nf-gpt-4-turbo\" # Can be gpt-35-turbo, gpt-4-turbo, gpt-4 or Meta-Llama-3-8B-Instruct.\n",
    "MODELgpt4 = \"nf-gpt-4\" # Can be gpt-35-turbo, gpt-4-turbo, gpt-4 or Meta-Llama-3-8B-Instruct.\n",
    "\n",
    "options_zero_str = \"\"\"\n",
    "seed: 42\n",
    "temperature: 0\n",
    "\"\"\"\n",
    "options_zero = yaml.safe_load(options_zero_str)\n",
    "\n",
    "temperature_0 : int = 0\n",
    "SEED: int = 42\n",
    "MAX10: int = 10\n",
    "TOPP1: int = 1\n",
    "\n",
    "\n",
    "options_large_str = \"\"\"\n",
    "seed: 42\n",
    "temperature: 0\n",
    "num_predict: 2000\n",
    "\"\"\"\n",
    "options_large = yaml.safe_load(options_large_str)\n",
    "\n",
    "#load environment variables:\n",
    "api_key = os.environ.get('sjoerd_key')\n",
    "\n",
    "#setttings:\n",
    "api_endpoint = \"https://ai-research-proxy.azurewebsites.net/chat/completions\"\n",
    "api_endpoint_embed = \"https://ai-research-proxy.azurewebsites.net/embeddings\"\n",
    "####### API REQUEST FORMATTING ######\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer \" + api_key\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ada_embedding(text):\n",
    "    retry_count = 0\n",
    "    max_retries = 10\n",
    "    while retry_count < max_retries:\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                url=api_endpoint_embed,\n",
    "                headers=headers,\n",
    "                json={\n",
    "                    \"model\": \"text-embedding-ada-002\",\n",
    "                    \"input\": text,\n",
    "                }\n",
    "            )\n",
    "            if response.status_code == 200:\n",
    "                return response.json()['data'][0]['embedding']\n",
    "            elif response.status_code == 429:\n",
    "                retry_count += 1\n",
    "                wait_time = 1 + (3 * retry_count * retry_count)\n",
    "                print(f\"Rate limit exceeded. Retrying in {wait_time} seconds...\")\n",
    "                print(response.text)\n",
    "                time.sleep(wait_time)\n",
    "            elif response.status_code == 500:\n",
    "                retry_count += 1\n",
    "                wait_time = 20\n",
    "                print(f\"Failed to connect to API. Status code: {response.status_code}. Retrying in {wait_time} seconds...\")\n",
    "                print(response.text)\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                print(f\"Failed to connect to API. Status code: {response.status_code}\")\n",
    "                print(response.text)\n",
    "                break\n",
    "        except requests.exceptions.RequestException as e:   \n",
    "            print(f\"Failed to connect to API: {e}\")\n",
    "            retry_count += 1\n",
    "            wait_time = 60\n",
    "            print(f\"Retrying in {wait_time} seconds...\")\n",
    "            time.sleep(wait_time)        \n",
    "\n",
    "def convert_to_int(value):\n",
    "    if isinstance(value, list):\n",
    "        return np.nan\n",
    "    try:\n",
    "        return int(value)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset: pd.DataFrame = pd.read_csv('data/publicsphere/full_data.csv')\n",
    "dataset_claim_embeds = pd.read_parquet(f'{CFG.report_dir}/pubsphere.claim_embed.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Time_comment           parsed_datetime\n",
      "0  2017-11-16T09:14:09.000Z 2017-11-16 09:14:09+00:00\n",
      "1  2019-08-12T20:22:06.000Z 2019-08-12 20:22:06+00:00\n",
      "2                2019-03-26 2019-03-26 00:00:00+00:00\n",
      "3  2018-10-03T05:44:24.000Z 2018-10-03 05:44:24+00:00\n",
      "4  2018-08-28T05:38:51.000Z 2018-08-28 05:38:51+00:00\n"
     ]
    }
   ],
   "source": [
    "# Parse datetime values\n",
    "dataset['parsed_datetime'] = pd.to_datetime(dataset['Time_comment'], errors='coerce', utc=True)\n",
    "\n",
    "# Fill NaT values for date-only entries\n",
    "dataset['parsed_datetime'] = dataset['parsed_datetime'].fillna(pd.to_datetime(dataset['Time_comment'], format='%Y-%m-%d', errors='coerce', utc=True))\n",
    "\n",
    "\n",
    "print(dataset.loc[:, ['Time_comment', 'parsed_datetime']].head(5))\n",
    "\n",
    "dataset.loc[:, 'dataset_index'] = dataset.index\n",
    "YT_input = dataset[dataset['Platform'] == 1]\n",
    "X_input = dataset[dataset['Platform'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showName\n",
      "NBC News                                201\n",
      "The Daily Show with Trevor Noah         188\n",
      "The Late Show with Stephen Colbert      186\n",
      "Hardball with Chris Matthews            177\n",
      "Real Time with Bill Maher               172\n",
      "Hannity                                 171\n",
      "Tucker Carlson Tonight                  155\n",
      "Fox News                                152\n",
      "Late Night with Seth Meyers             148\n",
      "Face the Nation                         128\n",
      "60 Minutes                              125\n",
      "CBS Evening News                        116\n",
      "ABC News                                109\n",
      "LastWeekTonight                         106\n",
      "The 11th Hour                           101\n",
      "CNN                                      94\n",
      "Anderson Cooper 360                      89\n",
      "TuckerCarlson                            82\n",
      "hardball                                 81\n",
      "AC360                                    79\n",
      "Hardball with Chris Matthews (MSNBC)     59\n",
      "Tucker Carlson Tonight (FoxNews)         58\n",
      "Full Frontal with Samantha Bee           57\n",
      "Hannity (FoxNews)                        57\n",
      "Anderson Cooper 360 (CNN)                54\n",
      "World News Tonight                       51\n",
      "RealTimers                               39\n",
      "MSNBC                                    37\n",
      "ABC Nightline                            36\n",
      "LateNightSeth                            35\n",
      "World News Tonight With David Muir       35\n",
      "Full Frontal with Samantha Bee           34\n",
      "patriotact                               34\n",
      "TheDailyShow                             34\n",
      "colbertlateshow                          33\n",
      "FullFrontalSamB                          33\n",
      "Late Night with Seth Meyers              33\n",
      "Daily Show                               32\n",
      "Late Show with Colbert                   32\n",
      "Patriot Act with Hasan Minhaj            32\n",
      "Real Time with Bill Maher                31\n",
      "ABCWorldNews                             31\n",
      "NewsHour                                 30\n",
      "Last week Tonight                        30\n",
      "NBCNews                                  29\n",
      "CBS Evening News                         27\n",
      "CBSEveningNews                           27\n",
      "NightLine                                27\n",
      "FaceTheNation                            27\n",
      "MeetThePress                             26\n",
      "Patriot Act                              26\n",
      "11thHour                                 26\n",
      "60Minutes                                25\n",
      "Meet The Press                           25\n",
      "Name: count, dtype: int64\n",
      "videoTitle\n",
      "Anderson Cooper lays out questions surrounding Mueller report                           23\n",
      "'Hannity' panel on the important questions Mueller needs to answer                      23\n",
      "Sanders: Bolton is a guy who likes war                                                  22\n",
      "AOC's chief of staff resigns amid multiple controversies                                20\n",
      "\"Haley: Airstrikes \"\"crippled\"\" Syria’s chemical weapons program  \"                     20\n",
      "                                                                                        ..\n",
      "Billy Eichner Talks Working with Lin-Manuel Miranda on Difficult People                  1\n",
      "Hillary Clinton Responds To Mueller Statement During Commencement Address | NBC News     1\n",
      "One Week Older: Kidnap Him To Jail                                                       1\n",
      "How did an Oklahoma woman start hunting with eagles in Mongolia?                         1\n",
      "Extended interview: Iranian Foreign Minister Javad Zarif                                 1\n",
      "Name: count, Length: 1137, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#showname and videoTitle make most sense to group by:\n",
    "print(dataset_claim_embeds['showName'].value_counts())\n",
    "print(dataset_claim_embeds['videoTitle'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the rows in the dataset that have the a videoTitle with more than 20 comments:   \n",
    "selectedvideos = dataset_claim_embeds[dataset_claim_embeds['videoTitle'].isin(dataset_comment_embeds['videoTitle'].value_counts()[dataset_comment_embeds['videoTitle'].value_counts() >= 20].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_claim: str = \\\n",
    "    \"\"\"\n",
    "        Instruction:\n",
    "\n",
    "        You are a text annotation assistant. Analyze a social media comment enclosed in chevrons <..>. Identify and list the claims within this comment. Claims can be related to events, issues, opinions or concerns.\n",
    "        Claims are defined as the main assertion or conclusion of an argument.\n",
    "        You summarize each claim into a short simple sentence.\n",
    "\n",
    "        Response format:\n",
    "\n",
    "        You provide only the list of claims, separated by commas, without any additional text or explanations. If no claims can be identified, return an empty list [].\n",
    "\n",
    "        Response format template:\n",
    "        \n",
    "        [\"claim 1\", \"claim 2\", ... \"claim x\"]\n",
    "\t\"\"\"\n",
    "\n",
    "#note updated on 30-12-2024:\n",
    "SYSTEM_expansion: str = \\\n",
    "    \"\"\"\n",
    "        # Instruction\\n\\nRephrase a social media post to reflect its meaning within the context of a conversation thread:\\n\\n1. You'll receive a thread in chevrons `<...>` and a target post in double chevrons `<<...>>`.\\n2. If the post is clear without context, repeat it as-is.\\n3. If the post depends on context, expand it to include necessary details.\\n4. Respond with only the expanded post. \\n5. If the post does not refer to context provided in the thread, or if in doubt, respond with the exact target post as you received it. If no target post was presented reply with an empty list [] \\n\\n## Example\\n\\n**Input**:\\n- Thread: <'Comment 1', 'Comment 2', 'Comment 3'>\\n- Target reply: `<<This is so relatable!>>`\\n\\n**Output**:\\n- '[context from previous comments] is so relatable!'\\n\\n**Text:\n",
    "    \"\"\"\n",
    "\n",
    "SYSTEM_claim_new: str = \\\n",
    "    \"\"\"\n",
    "        # Instruction\n",
    "\n",
    "        Identify whether a claim adds new information (2), expands on information (1) or does not add new information (0) with respect to preceding claims. New information is present (2) if the claim introduces a new argument or perspective. \n",
    "        A claim expands on an existing argument or perspective (1) if it strongly related to it, or it provides additional context or examples to an argument or perspective in a preceding claim, or if it provides a sub-argument (parent-child relation). \n",
    "        If the claim is very similar to a preceding claim or does not add any perspective or argument, assign a value of 0. Follow these steps:\n",
    "\n",
    "\n",
    "        Follow these steps:\n",
    "\n",
    "        1. You will receive a target claim in double chevrons <<...>> along with the preceding claims in single chevrons <...>.\n",
    "        2. Identify if new information is presented in the target claim with respect to the preceding posts. \n",
    "        4. If in doubt, assign a value of 0.\n",
    "\n",
    "        Respond with only the predicted class (0 or 1 or 2) of the request. Do not include any additional text or explanations.\n",
    "        Class:\n",
    "\t\"\"\"\n",
    "\n",
    "SYSTEM_claim_simscore: str = \\\n",
    "    \"\"\"\n",
    "        # Instruction\n",
    "\n",
    "        Identify degree of similarity of the information presented in a claim with respect to preceding claims in a thread on an integer scale of 1 (completely dissimilar) to 10 (identical). A score of 5 indicates that the claims share context or topic, but otherwise present different information. \n",
    "        Follow these steps:\n",
    "\n",
    "        1. You will receive a target claim in double chevrons <<...>> along with a JSON containing the preceding claims and their claim_index enclosed in single chevrons <...>.\n",
    "        2. Determine the most similar claim to the target claim in the preceding claims in terms of the information they present.. If only one preceding claim is provided pick this claim as the most similar claim.\n",
    "        3. Find the claim_index of this most similar claim. If you can't decide which claim is most similar, pick a preceding comment at random.\n",
    "        4. Identify the degree of similarity of the target claim with respect to that claim on a range of 1-10. \n",
    "        5. If no target claim is porvided or only '[]' return an empty list [] as value for both the most_similar_claim_index and the similarity_score, if you can't decide on the similarity score return an empty list for that value. If no preceding claims are provided or only an empty string '', return an empty list [] as value for both the most_similar_claim_index and the similarity_score.\n",
    "        6. Always and only respond with the claim_index and similarity score.\n",
    "\n",
    "        Response format in JSON:\n",
    "\n",
    "        [\n",
    "            {\n",
    "                \"most_similar_claim_index\": \"1\",\n",
    "                \"similarity_score\": \"1\"\t\n",
    "            }\n",
    "        ]\n",
    "\t\"\"\"\n",
    "\n",
    "SYSTEM_post_simscore: str = \\\n",
    "    \"\"\"\n",
    "        # Instruction \n",
    "        \n",
    "        Identify degree of similarity of the information presented in a social media comment with respect to preceding comments in a thread on an integer scale of 1 (completely dissimilar) to 10 (identical). A score of 5 indicates that the comments share context or topic, but otherwise present different information. \n",
    "        Follow these steps:\n",
    "        \n",
    "        1. You will receive a target comment in double chevrons <<...>> along with a JSON containing the preceding comments and their comment_index enclosed in single chevrons <...>.\n",
    "        2. Determine the most similar comment to the target comment in the preceding comments in terms of the information they present. If only one preceding comment is provided pick this comment as the most similar comment.\n",
    "        3. Find the comment_index of this most similar comment. If you can't decide which comment is most similar, pick a preceding comment at random.\n",
    "        4. Identify the degree of similarity of the target comment with respect to that comment on a range of 1-10. \n",
    "        5. If no target comment is provided or only '[]' return an empty list [] as value for both the most_similar_comment_index and the similarity_score, if you can't decide on the similarity score return an empty list for that value.\n",
    "        6. Always and only respond with the comment_index and similarity score.\n",
    "        \n",
    "        Response format in JSON:\n",
    "        \n",
    "        [\n",
    "            {\n",
    "                \"most_similar_comment_index\": \"1\",\n",
    "                \"similarity_score\": \"1\"\t\n",
    "            }\n",
    "        ]\n",
    "\t\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "classifying political_post: 100%|██████████| 3862/3862 [17:10<00:00,  3.75it/s]\n"
     ]
    }
   ],
   "source": [
    "#find out which posts are political, and which are not:\n",
    "predictions: typing.Dict[str, pd.Series] = {\n",
    "    label: (\n",
    "        src.PromptClassify\n",
    "        .from_json(path)\n",
    "        (dataset_claim_embeds[\"commentText\"], MODELsmall, options=options_zero)\n",
    "    )\n",
    "    for label, path in CFG.prompt_classify_files.items() if label in ['political_post']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "political_post\n",
      "political        2546\n",
      "non-political    1155\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#join to the dataset:\n",
    "for label, preds in predictions.items():\n",
    "    print(preds.value_counts())\n",
    "    print(\"-\" * 42)\n",
    "    # Convert Series to DataFrame\n",
    "    preds_df = preds.to_frame()\n",
    "    # Rename the column in preds_df to include the label\n",
    "    preds_df.columns = [f'Llama31_{label}_8b']\n",
    "    dataset_claim_embeds = dataset_claim_embeds.join(preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_claim_embeds.loc[:, 'Llama31_political_fill_8b'] = dataset_claim_embeds.loc[:, 'Llama31_political_post_8b'].fillna('non-political')\n",
    "dataset_claim_embeds.loc[:, 'Llama31_political_fill_8b_score'] = dataset_claim_embeds.loc[:, 'Llama31_political_post_8b'].map({'non-political': 0, 'political': 1}).fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data:\n",
    "dataset_claim_embeds.to_parquet(f'{CFG.report_dir}/pubsphere.claim_embed.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data:\n",
    "dataset_claim_embeds = pd.read_parquet(f'{CFG.report_dir}/pubsphere.claim_embed.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['StartDate',\n",
       " 'RecordedDate',\n",
       " 'IPAddress',\n",
       " 'Finished',\n",
       " 'Coder',\n",
       " 'ID',\n",
       " 'Mark_ID',\n",
       " 'Genre',\n",
       " 'topiccode',\n",
       " 'Platform',\n",
       " 'Anonymity',\n",
       " 'Anonymity_9_TEXT',\n",
       " 'codable',\n",
       " 'Interaction',\n",
       " 'Acknowledgement',\n",
       " 'TopicRelevance',\n",
       " 'Reasoning',\n",
       " 'BackgroundInfo',\n",
       " 'ExternalEvidence',\n",
       " 'ExternalEvidence_1_TEXT',\n",
       " 'Opinion',\n",
       " 'disagreement',\n",
       " 'Ideologicaldirection',\n",
       " 'Name_calling',\n",
       " 'Vulgarity',\n",
       " 'Attack_reputation',\n",
       " 'Question_Intelligenc',\n",
       " 'All_caps_function',\n",
       " 'Sarcasm_to_criticize',\n",
       " 'Individual_right',\n",
       " 'discrimination',\n",
       " 'Invoke_violence',\n",
       " 'Tone',\n",
       " 'INTERACTIVITY_DUMMY',\n",
       " 'RATIONALITY_DUMMY',\n",
       " 'HAS_OPINION_DUMMY',\n",
       " 'LIBERAL_NEUTRAL_CONSERVATIVE',\n",
       " 'LIBERAL_DUMMY',\n",
       " 'CONSERVATIVE_DUMMY',\n",
       " 'NAMECALLING_DUMMY',\n",
       " 'VULGAR_DUMMY',\n",
       " 'NAMECALLING_VULGAR_DUMMY',\n",
       " 'INCIVILITY_ORDINAL',\n",
       " 'INCIVILITY_DUMMY',\n",
       " 'INTOLERANCE_DUMMY',\n",
       " 'filter_$',\n",
       " 'IMPOLITENESS_DUMMY',\n",
       " 'commentText',\n",
       " 'showName',\n",
       " 'genre',\n",
       " 'Time_comment',\n",
       " 'likeCount_comment',\n",
       " 'entities',\n",
       " 'place',\n",
       " 'retweet_count',\n",
       " 'platform',\n",
       " 'retweeted',\n",
       " 'language',\n",
       " 'source',\n",
       " 'in_reply_to_status_id_str',\n",
       " 'in_reply_to_user_id_str',\n",
       " 'in_reply_to_screen_name',\n",
       " 'is_quote_status',\n",
       " 'videoTitle',\n",
       " 'description',\n",
       " 'Time_video',\n",
       " 'channelTitle',\n",
       " 'channelId',\n",
       " 'viewCount',\n",
       " 'dislikeCount_video',\n",
       " 'likeCount_video',\n",
       " 'date_difference',\n",
       " 'commentCount_video',\n",
       " 'replyCount_comment',\n",
       " 'topic',\n",
       " 'subscribers',\n",
       " 'HATELIST_FOCUSED_DUMMY',\n",
       " 'Time_comment_year',\n",
       " 'Time_video_year',\n",
       " 'interactivity_acknowledgement',\n",
       " 'political_ideology',\n",
       " 'rationality_external_evidence',\n",
       " 'rationality_topic_relevance',\n",
       " 'political_negativity',\n",
       " 'rationality_background_info',\n",
       " 'rationality_reasoning',\n",
       " 'sentiment',\n",
       " 'offensive',\n",
       " 'topics',\n",
       " 'emotions',\n",
       " 'irony',\n",
       " 'hate',\n",
       " 'topiccodeSTR',\n",
       " 'claim_run1',\n",
       " 'claim_optdef',\n",
       " 'claim_optdef_embed_MXBAI',\n",
       " 'claim_optlow',\n",
       " 'claim_optlow_MXBAI',\n",
       " 'tfidf_embed_post',\n",
       " 'embed_MXBAI_post',\n",
       " 'cosine_similarity_post_claim_MXBAI',\n",
       " 'cosine_low_high_MXBAI',\n",
       " 'tfidf_embed_post_svd',\n",
       " 'Llama31_political_post_8b',\n",
       " 'Llama31_political_fill_8b',\n",
       " 'Llama31_political_fill_8b_score']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_claim_embeds.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"That's a vicious insult!!! What did a box of rocks ever do to you that you would slander it like that? I represent the coalition for mineral rights. Minerals have rights to.\", 'I agree.  Maybe he was sending a message to his mistress.', 'President Trump made 8,158 false or misleading claims in his first two years ... besides his entire life, businesses, deals, have been a lie as well  .... should he apologize?', 'NPC-90210-RockTheVote   Heâ€™s getting his oil checked!', \"Gee, someone is upset that they are trying to give Fox a run for their money.  Don't worry Sierra, Fox still controls that niche.\", \"What are they being false about?  It's a fact that the military assets are being moved.\", 'Bernie is the most consistent and most  trustworthy progressive. Feel the Bern!', \"USA Freedom Patriots made the Internet. \\xa0Why don't you go back to fucking donkeys.\", \"What I seriously don't get and leaves me shaking my head in frustration:\\n the USA doesn't want Iran to have nuclear weapons - which is understandable - so they made an agreement which Iran has never broken _once,_ then they  pull out of this agreement and start sanctioning Iran and every country which trades with them harshly - in order to archieve that Iran doesn't build nuclear weapons.\\nIn the process they hurt their already fragile relationships of their allies within the EU by dictating and threatening their governments. \\nIran is still upholding the Deal with Europe though and not building nw, and now Trump says that this country is such a great danger that they might invade? And there are people cheering to this decision? \\nWho pulled out of the deal in the first place? How do the people that want war not see that the USA is on the bad side of history here?\", 'Tulsi 2020! She is the only candidate in either party who is willing to stand up for people worldwide with her track record of service for our country and opposing the loss of human life and financial resources that mark regime change wars.', 'Hello? Why is the main player left out of this discussion. I can understand Bernie not mentioning Israel but Anderson? On second thought, I CAN understand it.', \"The Representatives should do what they think is right IMPEACH --regardless of their expected response from the Senate.  They should allow Americans to do what is right to the Senators who choose to  defend Trump rather than the country and the Constitution despite Mueller's findings and report.  The House should not abdicate its power to spineless Senators.  Let the Senators face consequences of their action come 2020 and   future elections.\", '@Joseph King You didnt read the report didya, Joe?', 'Are U really surprised. I’m not \\nOur own government rigged it.  He’s there because out government put him there.', 'Blah blah blah.      Blah,     hilarious..Anderson for once tell it as is.. we all can see clearly..\\nA Democrat asking Mueller questions...fairy dust on a cake....', 'Rod rosenstein wrote a memo recommended to fire James Comey!!!', \"I wouldn't have waited after the tankers were struck. When you were growing up, if somebody came up to you and sucker punched you, would you put them on notice or would you have broken their nose? At a minimum, I would have sank a ship!\", \"@Cranjis McBasketball He's not wrong. The radical left (not moderate liberals) are trying to fuck this country to death. The decent center-leftists are the umbrella under which these people are hiding.\", 'There are behaviors that thoughtful gentlemen and leaders employ. Even when firing someone. Our president is neither an \"officer nor a gentleman.\" Sadly.', \"@ClassicalMMAChef \\nI get it!  You can't read.  Understood.  Just send me $500 and I'll ship you Hooked On Phonics!  It may help, but probably not. You've clearly dedicated your life to being as stupid as you possibly can, and I applaud that.  It must be a lot of work to still be struggling to graduate kindergarten.\", \"It's scary that some people still don't understand that we are a Constitutional Republic.\", \"Well why the fuck would you prosecute yourself?  That's a shitty use of power when you could have at the least drugs, sex, and money with that kind of control.\", 'Too be fair we in Europe are full of homophobic and mysoginistic crimes thanks to a refugee influx x.x', \"A lot of people are projecting her to be Secretary of Defense or Foreign Affairs which I can see why. But from what I've seen so far she would be a great president as well.\", 'Does anyone Remember the \\nConstitution of America?\\n\\nNo more Wars you Trump ??', 'Margie Nelsen   Do you mean pray for the lying draft dodger and traitor?', 'Mostly the GOP and most of his misinformed and ignorant base. I think it’s intentional and very unpatriotic.', \"@k b John Dowd, not McGhan was the Trump lawyer assigned to work with Mueller. Here's his take and he's just as stupid as i am-  https://www.youtube.com/watch?v=S1o8Ze4J81A\\nOr maybe we're both traitors to the U.S.  Cummings in the video above is blowing out his backside.  If the dems impeach they well be slaughtered in trial by the Senate. they won't impeach because they know this already and they are at least as stupid as I am.\", 'one thing proved for certain; the swamp is alive and well and full of fat barr creatures', \"Yeah. Democrats are so mature. Read all of their immature, vile rants on our Presidents FB page. It's like all they think about all day everyday is our Presidents penis.\", '@hepwo91222 you still hung up on the nunes memo?! holy shit~!!! how long ago was that immediately disproved?', 'Army force?\\nNeed to be teached a lesson?', \"Let's look at the middle East. Iran knows it has no win eith America. If America makes any move on Iran, what do you think there response will be? When you have nothing to lose, you go out with a big bang. \\nIran will light Israel up with the very language trump used on lighting them up.\", 'if we where not in everyones business just like all the other countries we wouldve been dead long time ago dont be so stupid I hate how people who have no clue make statements', 'We have been there for sometime, and nothing has changed. Bring our men and women home. You go and help them.', \"THANK YOU. The fear mongering and brain washing is horrific. It's not perfect in Canada, (there are always some people). However the big difference is that our PM Trudeau is embracing the refugees, and is promoting acceptance and equality. \\nI'm so scared for those refugees entering America now. I hope that more of them get to come to Canada. We would love to have you.\", 'Please explain what\\'s good about this guy. BTW, it\\'s \"countries.\" 45ers can\\'t spell. They\\'re illiterate like their president.', '+ZenRules - you have made that mistake in Afghanistan and out came Bin Laden. Assad was responsible to create IS, he supported them in war in iraq against your troops, he later was against htem but then released IS members out of jail. Assad never fought IS and IS fought against FSA and Kurds. Without Assad - no IS, that is the truth.', 'doug mckay So is it okay for you if one day native american and australia want their land back and kick out white people with guns and mortars because thousand years ago it is their land', \"They also used Australian passports and they weren't happy about it. The Australians called in the Israeli ambassador for a please explain.\", 'At least Obama wasn’t pen pals with Kim Jong Un while he murders his people in public executions.', '@Mary Murdock I thought he might be corrupt from envelope at funeral and just not saying much ,and Ryan PENCE letter before election,about a article 9 I BELEIVE not sure but close MAGA BLESS OUR PRESIDENT DONALD Trump and his family', 'Trump and GOP 2020.', \"@EL OEL so you're just going to ignore shillary sold 20% of american uranium to a russian company for $145 million paid into the clinton foundation?\", 'She would destroy him', 'John Bolton will not learn any lesson unless Israel is attacked by Iranians', \"@ILLMATIC2222 Yes, because he didn't cut spending as well.\", 'Syrian rebellion was not organised by west or saudi arab... It happened due to Assads brutality against protesters... Assads brutality made him unacceptable to Syrian people...all rebels are not jihadist...jihad can also be for freedom..christians dont think crusaders were terrorists', '@Antonio DeJesus In fact, this whole investigation has become a massive clown show. Not a single shred of evidence to suggest the Trump campaign colluded with the Russians has arisen after months of investigating by multiple congressional committees. What we do know is that the Hillary Clinton campaign actually funded the effort that led to the Trump dossier, compiled by former British spook Christopher Steele. During the 2016 election, the Clinton crew retained the services of research firm Fusion GPS, who then hired Steele to gather information on this opposition research file. The same documents that were used to obtain a FISA warrant against former foreign policy adviser to Trump, Carter Page. Yeah, a partisan piece of opposition research from a political campaign was used to secure a warrant to spy on someone who had worked on the opposing campaign—all of this under the Obama DOJ mind you. In fact, as this investigation has moved on, we see less about Trump-Russia and more about the endless trip-ups at the FBI, namely the unacceptable levels of bias among top officials involved in some of the most sensitive investigations conducted by the bureau.', 'Not a single one of those people you mentioned has been verified as a Russian agent. Not. one. Yes, Manafort and Flynn have had to or are under pressure to register as foreign agents- but neither of them are with Russia. They\\'re UKRAINE AND TURKEY. And yes, there are questions of their ties with those countries being beneficial to Russia- but holy shit. You can\\'t even get that right.\\n\\nAnd yes, that is what Bush technically was referencing in those statements- but to use such polarizing language, in face of the nature of the Bush administration and US policy and everything else, was utterly deranged, and was endlessly derided as one of the most embodying statements of the horrors of the Bush administration. But now? Maher OPENLY SAID he wants the democrats to use the SAME LANGUAGE- and directly REFERENCING BUSH. And there is every fucking reason to view Maher\\'s statement in the same light. I wouldn\\'t even really know where to begin on how utterly psychotic the left has been over Russia, but a really good one recently is Maxine Waters, on TV, saying PUTIN came up with \"Crooked Hillary\" and \"lock her up.\" YES- ideas that have been around for years now in conservative circles were the work of PUTIN!!!\\n\\nAlso- Bill Clinton\\'s impeachment calls came from various things, such as- lying under oath about it, doing it in the WH while married and to a girl less than half his age, and of course, the pressure of all the other accusations that came out against him.\\n\\nBut yeah, I do think Bush was worse than that.\\n\\nAnd still nothing about all of the other shit you Russia hysterics support while claiming to care about TREASON!!!\\n\\nAlso:\\n\\n\"Stuart Penman Also, the chicago tribune is a conservative media, I would not trust a single word that is poorly written on its right-wing pages\"\\n\\nYou linked to fucking Salon.', 'Keep up the great work, you are not a cop hater, you are a patriot,  and a libertarian.', 'Christians will not replace us!!!', \"@Diane Hooper I'm probably older than you and he's the most unstable I've even seen.\", 'Thanks for the Liberal Slant.  CBS.', 'Chuck the schmuck Schumer, a creep all day long, news all day long!!! And Nancy pa crazy,!! She looks like the Crypt Keeper!!', 'Bad day for the Hamas terrorist bastard.', 'Date night with Trump', \"That's all TRUMP DOES, is LIE!\", 'I hate reporters like this lady...', \"@Trump's a pathological liar Prove me wrong < Mmmmm. Are you stupid because you're liberal or are you liberal because you're stupid?\", 'YOU KEEP TALKING TRUMP......KEEP DIGGING YOUR OWN HOLE, YOU HAVE BEEN DOING THIS SINCE THE START............SO CONTINUE.............', \"believe me that's not gonna be happen ever... at least not for Syria\", \"@BartJ583 or because comey doesn't know how to do his job\", 'Are you saying you\\'re willing to risk countless billions of dollars.. American lives.. another endless war over Israel... possibly ww3 just to \"appear\" strong for a moment in time?', 'Credible reporting?\\nI choose... NO.\\nSedition charges will put most of CCCPNN  \" reporters \" in Gitmo.', 'If you want to see white male privilege, delusion and denial see 15:00', '@Zquadfather you sound like an Antifa punk!!!', 'We The People are not white supremacists, WE ARE RIGHT SUPREMACISTS. We have the RIGHT to believe in our CREATOR, our country, our countrymen, our leader, our constitution, our rule of LAW. We look like all the people you see world wide. You corrupt devil, and self, and money worshipers are the WRONG supremacists. You believe in lawlessness, drugs, alcohol, child molestation, drug trafficking, people trafficking, extortion, bribes. You have 4 rules, lie, cheat, steal. Audit EVERY city in this country and get this corrupt trash out of it. Your climate change is coming and is real. It is called the lake of FIRE. Know this. And enjoy that.@ROB112  You got it.', 'Matthew “Trump Deranged” Rodriguez  ?? ????? and ?', \"Can't anyone have him evaluated for mental incompetence...Not a Dr. Picked by him...???\", '@NPC Unit #84740695 what was so bad about the interview ? because Trump exposed himself as an idiot ...again ?', 'Bill you gotta stop wagging your finger at liberal \"purists\" and Russian \"hacking\". Let\\'s take your argument all the way to its conclusion shall we? If Russia had not exposed things Hillary actually said and actually did; she could have lied her way into office and gotten away with cheating the real liberal in the race? I will concede that she is the \"lesser of two evils\", sure. But as you carry on about how unethical and dishonest Trump\\'s ties with Russia might be; how can your argument be that the solution is/was to give a pass to proven unethical and dishonest behavior of his opponent? Your analysis that Trump is the problem is incorrect. He is a symptom. The problem is that America is tired of corporate establishment and corruption and that is the embodiment of Hillary. It was for that reason that a snake oil salesman baboon fuck like Trump was even given a chance in the first place. Did we learn nothing eight years ago when the electorate was so tired of \"politics as usual\" that they went out in droves voting for a black guy with a Muslim name that people questioned if he was born in Kenya with almost no political experience and lied through his teeth and we bought it with a catch phrase \"yes we can\" which apparently meant \"yes we can remove the public option\" and \"yes we can bail out Wall Street and kick 10 million people out of their homes\" and \"yes we can support Nafta and TPP\" and \"yes we can bomb the Middle East non stop and include more countries to bomb\" and \"yes we can extend the tax cut on dividends\" and \"yes we can keep the minimum wage low and create more minimum wage jobs with no benefits\" and \"yes we can make the banks even bigger\" and \"yes we can continue the income inequality and make the gap even larger\" and \"yes we can continue the drug war and continue to explode the prisons with disproportionately black non-violent offenders\". Give it a rest Bill. People didn\\'t vote for Obama in Michigan, Ohio, Wisconsin, and Pennsylvania TWICE and then suddenly become racist. They voted for Trump on the off chance we wasn\\'t lying and would be something different. Just like they voted for Obama. And who the fuck are you to call those people misguided when I believed in \"hope\" and \"change\" and it was all lies and you, almost 9 years later, still can\\'t even see that? Hillary didn\\'t lose because of racism. Or misogyny. Or Comey letters. Or Russia. She lost for one simple reason; because of Hillary. Because she stood there and told people that have been getting fucked non-stop for decades that she was going to keep doing the same thing because it\\'s been doing great! If it was truly about winning the election; the Dems would have ran Bernie and won by 20 points. But it\\'s not. It\\'s about keeping the corruption going even if that means rolling the dice and losing to a clown. Because it was her turn and it was her right to be President? That Republican-in-a-pant-suit that\\'s cool with gay marriage and you can shove that up your collective asses, Bill. Does that make me a \"purist\" Bill?', 'The United Satan of America, in reality, is a parasite and an extortionist with its currency backed by nothing but pure tyranny!', 'All they want is to hide all their criminal activity! They are afraid of Trump!', 'I am a pagan. Last I looked this is fucking America and I have the right to FREEDOM OF RELIGION, BITCH', \"He backed down from attacking iran because putin told him to back down and to save donald con-chump's face putin sent the north seas flotilla to back up the bombers already in venezuela and cuba.\", '+Pllotrcm Being conservative is not a bad thing at all. Most soldiers, people who risk their lives to protect yours, are conservative because that mindset believes in protecting each other. Nationalism is why we have a Constitution that allows all of the freedoms that Americans enjoy. Nationalist economics is just another way of saying \"we want our own people to be able to succeed and feed their families.\" Communism and Capitalism are not the same things, but Communism and Totalitarianism are the same things. Capitalism is the only system that humans have created that is capable of giving equal opportunity to all people. All other systems are biased against subsections of society. No one can deny that conservatives are very partisan, as are progressives.', '@Eugene Osborn It\\'s even worse when you weight the impeachable offences. Slick Willy committed perjury... about a blowjob. Nixon ran a conspiracy in which the \"Plumbers\" broke into the DNC offices to steal information. The Orange Sphincter has committed at least two counts of Conspiracy to Violate Campaign Finance Laws... probably a lot more of which we\\'re not aware, yet... Conspiracy to Defraud the U.S.... Obstruction of Justice... and TRE45ON... the TRE45ON, by itself, outweighs everything the all Democrats have done, combined.', \"@MightyDragon i agree trump probably cares more deeply than any potus sense Kennedy. He's like Goldwater extreme for liberty. And he is effective. But as a liberal I disagree w his viewpoint on 70% of stuff. Please admit he says and does stupid stuff. I agree he is a wrench in a broken system. And we do need to stop and figure stuff out before we go full new world order.  Can you see that Trump has tendency to fascist racist rhetoric, sometimes. He is no dictator,  but it seems that way. Do you understand why liberals see that?\", \"America will pay for its sin's\", 'They need to investigate just like a Democrat would if it were Trump.   We need to put these socialist on their heels', '@Stella Sirman this is how dictatorships start', 'Impeach. I agree with Romney. trump is a traitor and a lying sack of sht.', 'the longer the collective stay silent, the more complicit they become', 'CONGRATULATIONS AMERICA YOU HAVE A RAPIST AS A PRESIDENT!!', 'Is it racist of CNN not listening to Van Jones saying it was a big nothing burger?', 'Either solidarity confinement or with the general population.', \"Russia didn't make me vote for Trump, Hillary did.\", '@Gary Anthony McLoughlin TX cuts were for billionaires', 'Demoncraps and illegal are above the law unlike us red blooded Americans.', 'Trump is among them because he knew John Bolton and Mike Pompeo history and he still put them in charge.', 'Another war for the antichrist gews.iran is on the list because there not enslaved by the gewish central banksters.out of 208 countries there were 10 countries not enslaved now were down to just a few countries left iran is one of them.jewliani is a lier just like every one on this devil box..iran refused the enslavement under the gew banksters.good luck iran.', 'Allows law enforcement to use surveillance against more crimes of terror. Before the Patriot Act, courts could permit law enforcement to conduct electronic surveillance to investigate many ordinary, non-terrorism crimes, such as drug crimes, mail fraud, and passport fraud. Agents also could obtain wiretaps to investigate some, but not all, of the crimes that terrorists often commit. The Act enabled investigators to gather information when looking into the full range of terrorism-related crimes, including: chemical-weapons offenses, the use of weapons of mass destruction, killing Americans abroad, and terrorism financing.', '#Yang2020', '*Waiting US Attack SHIA IRAN & SHIA SYIRA KUFFAR* ????', '@Logical Conservative not seeing the hamburger one except on conservative \\'news\\'. \"A fraction of a percent\" hahahaha.  The only joke I\\'m seeing is you and your pathetic attempt at denial... err I mean logic.', \"@Frederic Bastiat \\nFirst off, you are absolutely wrong in your assumptions, that anyone besides trump's people leaked something.  trump and his pals that he gave jobs to, have been giving national security information to everyone they can.\", \"I bet you Trudeau looks his barber in the eyes when he's getting trimmed up...\", 'Mueller is evil, deceitful and unethical. He has lost all his prestige, and his respect and yet totally unashamed...\\n> his licence must be revoked... and so be debarred as said by diGenova...', 'I am happy with my stock market now...Democrats are bunch of parasites.', 'Prejury  charges coming soon. See my comment. You will find it legally binding.', 'Science is a trick of Satan to take away your guns and end Christmas.', 'The only \"Green\" in Cortez\\' \"new green deal\" was the green dollars she and her crooked campaign manager were stealing. He\\'s gonna have to sell her out to save himself.', 'Zionist super fascist apartheid regime terrorists are not just ruining our country, but the entire world', 'Good propaganda for the warmongers', 'Thanks Tulsi for being anti war, we here at msnbc are profiting of all the wars so we cant actually be against them or we get fired', \"Who else is tired of Republicans like Rudy telling sociopaths like Biden and Hussein to be ashamed of themselves?  It's embarrassing they pretend they don't realize shaming isn't the answer, imprisoning them for weaponizing the executive branch and breaking the law is the answer.\", 'Sweet! (☆^ー^☆) hopefully we can go in and take soms more oil ? America is great ?? we can take whatever we want :D', 'So you want to talk about lies?? LMAO. \"OOOK\" you attack his poor grasp of communication and exploit it. Meanwhile causing ACTUAL divide and real problems with BIG lies.... Trying to get us to care and take notice about some pointless Symantecs. You created more hate and violence in leftist fenatisicm by insisting he is some evil racist, than he ever did trying do promote boarder security.... Hes a bit of a fuk up ih a few ways for sure....but nothing on the mass scale of manipulation and social division that you and the rest of the George Orwell, erm i mean Soros media, have brought to fruition.', 'You can hear the mockingbirds as the flock from the deepstate offices to the studios at the mainstrwam news. \"Caw caw\" to just straight Caca', 'You lost me with this video, shame... thought this show is smarter than to join in propaganda', 'Just more evidence that we have an idiot in the White House.  That the Trumptards will never see.', \"Yes...there it is, no collision or obstruction. He brilliantly counter the interviewer. It's the alternate version broken down that's barely reveal on MSM with few exceptions like today. Lol. Other bureaucrats and politicians who are lawyers are racking their  rains for different narrative or National Enquirer story to oppose and hate this President. Unfortunately for many of us the wording is all legalese talk common only to lawyers. Rudy layed it out despite interference from the interviewer. Rudy did the same thing with Jake Trapper with CNN.\\nPeople shouldn't worry too much it's a means to their end and also entertainment. Problem is people believe or think they're being or playing a part with the government and they're not. Everyone take care of your families and seek a higher spiritual realm, nothing to do with religion....Peace\", \"@Beachdudeca You miss the point!   It doesn't matter whether Trump was actively working WITH Russia, or not!    He clearly is compromised by his own conflicts of interest!    He wants to build a Trump Tower in Moscow!    He can't do that without the blessings of Putin!    Therefore, he isn't going to say or do anything against Putin!   That is unacceptable in a President of the United States!   And, on the other side of the coin, Putin knows that Trump needs his blessings AND that helping Trump into office would allow Trump to DO things to EARN his blessings - like lifting sanctions on Russia!   These things make it imperitive that Trump be removed from office!    How can you be so gullible and stupid as to not see this as clearly as I do?\", 'Just go back and watch this arsehole during the Iraq invasion in 2003 he was basically having an orgasm he loved it, tucker carlson is the  only voice of sanity', 'Pay  attention snowflakes and demonrats . These guys do not agree  completely . They remain civil .', 'Why are the real news giving this P.O.S. air time? Better off showing reruns of romper room.', \"@YS S I didn't say they were.  Clinton was interviewed for about 12 hours and they found no wrong doing.  Don't care about Flynn.  Yes - illegal aliens are above the law - if they come from Mars.\", \"@Gilberto TX USAThe caravan is hype. They stopped talking about it after the election, really you are being conned. The wall is also bullshit, Border Protection themselves said surveillance is much more effective than any wall. Trump himself doesn't believe in the wall anymore but is just pushing it because he thinks it gets him votes. Apparently by your post it does.\", 'TheChiefEng- \"Last time I looked, I did not find a country called USA in that part of the world.\"  Look again . . . it\\'s called Israel.  And there is no doubt who the real terrorists in the World are:  Trump and Netanyahu.', 'american news networks are a joke..', 'The FBI bias has along with some of the media and bad democrat has destroyed the USA.', 'The average & leading Westerners don\\'t mind letting the whole World\\'s dirty people molest their girls & terize them, even in their own nations as long as hatred for other cultures can be bred or generated..whose better and best people are sought to be devalued and mistreated their whole lives by Westerners who don\\'t like seeing higher quality foreignors that they need to abuse and treat like Jesus, Bruce Lee, or Martin Luther King jr....also..on boats....& on private jets paid by American dollars....w. armed bodyguards & private jets standing by, -but..it is only Iran & those who don\\'t respect dishonourable behaviour, -who never hurt them in any way, that are treated like, -& considered as \"threats\" that have to be starved to death, beaten, & broken for their whole lives similar to how Jesus was treated and his Palestinian people are still treated today by the illegal immigrant land thieves sent by Westerners & armed with the Nukes that they constantly blame and terrorize others for supposedly trying to develop, who pretend to be Jewish & religious, -when they\\'re not claiming to be \"secular\", -since the leading Westerners, & their profiteering cronies, expect anyone more civilized, worthy, intelligent, attractive, & decent than themselves to simply not be allowed to exist....lol   They should give up their COWARD-NUKES that can never have any real or positive use, learn how to wash themselves, & agree to have their programs monitored if they\\'re serious, truthful, or claiming to be so good as they act like they are....accusing others for all your own actions & cowardly ways or existence only proves who\\'s wrong and unworthy!      https://www.youtube.com/watch?v=zIbQWW3HUhE      https://www.youtube.com/watch?v=ILy8CYpo_RA', 'OMG the dude is in total denial of FACTS that Rudy is giving him. Literally does not compute!', \"For sure they've committed a crime. It's always ironic how they pretend that's the way to have money out of politics and all that crap, when they're really just the exact same. Pathetic New Green Deal aside, these people are crazy.\", 'The report would of never seen the light of day if the GOP still controlled the house.', 'They made money with all the stuff they got from Manafort lol', \"Dedalus69 \\nYou still don't get it, aren't you?   Sure, according to you, Cohen sent to prison for 3 yrs with NO CRIME, isn't it?   If you don't see any problem, you are either being AMORAL, or have a sociopathic trait.  Only sociopath could defend other Sociopathic criminal.\", 'Fake news fake news fake news all bullshit!!!!!!    CNN sucks.  CNN doesn’t care about America!!!!! Look at the numbers, unemployment rate all time low!!!!', '\"Innocent until proven guilty... and dont worry, you WILL be found guilty\"', \"Are you people aware of the fact that we can all look into this on our own? This is why the public doesn't trust the mainstream media. You are all disgusting, America hating, bias hacks. How bout you people start reporting things that actually affect the American people. You know, news?\", \"He's gonna kill brown people jus like Obama and Bush did..\\n#DeathToUSA\", '@Duece Momm funny how you democrats started the KKK', 'Damage a great nation, just for ratings. THIS, is CNN', \"Democrats will never win again with this kind of mentality. I'm sure it makes them feel better though, especially since there's a particularly bad boogeymen man on the other side right now.\", \"Liberals got their a@@ KIcked this week! LOL It's a wrap, Trump has 4 more years. I now believe the fake news chant. Can not spin it, Liberals are dirty and evil spirited.\", '@Meh Gusta\\nThey have left the cities. Over 9 million Syrians have fled the country.', \"I shouldn't have to be...accusations should be substantiated...but libtwats never do.\", 'Amazing Hasan, he really hits the issue head on.', '@Justin Little sorry he was rased ny kkk daddy you open your eves', \"@David tinch No. Like I said in three original comment.  CNN and their fascist followers call them lies.  Normal people understand he exaggerates to make a point.  Like everybody does in the real world.  You lost.  Get over it.  Or don't.  Whatever.\", 'Uneducated are at least not CORRUPT IVY LEAGUE SCUMBAGS! Nice going with the educated Dems and their Mueller Bomb... eeeehhhheeeheeheeeh.\\nGood luck with that Huge Brain of yours! I have a BBA. .. btw.', \"Don't worry Barr will do the job and that's what Democrats need to worry about!\", 'NO. You wanna know what\\'s HYPOCRISY? In 2007 when Bush was president and the conservative media (led by Ann Coulter) said there was no need to pull out of Afghanistan because things were going \"swimmingly\" (Coulter\\'s own words). Then six months after Obama became president, suddenly the Teabaggers were saying Afghanistan was a disaster, that it was \"Obama\\'s Vietnam\" (again, Coulter\\'s own words).', \"@AJ \\nTrump fires the guy who violated all the rules to make Trump president, and you think it isn't fishy. Alrighty then.\", 'Watch and see. It is not easy to identify them, besides all of them cover each others back.\\nFor President Trump, only time and working with them can tell. \\nDont you worry,POTUS is smart and he gets things done, sometimes the preparation time is longer than the real act.', \"There need to be psychometric tests for all public servants. There are psychopaths and serial killers in suits who get off on murdering thousands and thousands of people. I think Bolton is one. Remember 'war lite'? Yeah right. Total freaking disaster. Then after they totally mess up the region and create hundreds of thousands of refugees they will start complaining about immigration.\", 'This is just Fake news and CNN is just bullsh/t.', 'First Unindited felon president in history a new record', 'It must be so hard for these professional adults to take orders from this petty imbecilic child', '@RC Hobbyist Extreme rightttttttt...', '@Pragm Aticamente \\nI already know why some former Obama voters voted for Trump. And I would never call the 2016 voters \"White Supremacists\" or \"NeoNazis\". In 2016, you could have all kinds of reasons why you would vote for Trump, and a lot of people thought he would change in office, that his disgusting behaviour on the stump was just a persona to win votes. -->\\n\\nBut the 2019 Trump supporters are just that - \"White Supremacists.\" There are no doubts about who Trump is anymore. Also, keep in mind that \"White Supremacist\" is not a synonym for \"NeoNazi\" or \"KKK-member\". A White Supremacist is simply someone who thinks that white people are a little better at running things. That is all. Some of them are raging racists to be sure, but most are just narrow-minded.\\n.', '@Mr. Autistic Atheist ye yes horrible cuntry ...they don have a right to exist ....we don need no stinking iran ...syria is over .....we get to bomb a new cuntry ....SOMEBODY new for Israel!!!!!!', 'So are republicans blind or what? I mean did we not read the same report .. that report was pretty damn bad. Like did you people not read it because it shows clear obstruction of justice at the least .. this was more clear than oj', 'What has Trump done to obstruct anything, how has he tried to impede anything.\\xa0 The truth about what really happened https://www.youtube.com/watch?v=P4gx6KfZCss', 'Donald Trump plays tennis and he is a lard arse.', 'Janet Masiello Well when he puts people down who are in the military it is a shame. He also said that his military school gave him military experience? How funny is that? And people bought it.', 'Anyone still supporting Donald Trumpolini today should have their voting privileges revoked. #idiocracy', \"18 years is long enough. I loath Trump as a person but if we withdraw before the 2020 elections I'll vote for him\", 'My guess would be Beto wants the weed legal true?', 'I feel like she understands a lot more than most Democrats she knows Israel pressures us into foreign wars against Islamic nations.', \"@karen doyle You can fix a typo, good for you. Here's a biscuit. Keep at it since spell check seems to be nonexistent (you must be Betsy's star pupil). You generate typos faster than Tiny spouts out lies. Don't be too stupid. Tiny hates competition.\", 'Let’s bomb the chemical compound and release the chemicals. You think we are stupid.', \"WAR!.....................WHAT IS IT GOOD FOR? ..........ABSOLUTELY NOTHIN'!\", 'If Christians conservatives see Jesus  as a refugee they would probably reject him.', '@edgar valderrama and as of today you can add article 3 of the Articles of impeachment to the list.', 'Tracy Cohee you’re misinformed sweetie. This is why voting should be left to the adults. This Russir thing wouldn’t be as big a deal had the president not lied every step of the way. Had he just said “yeah I met a couple of people a couple of times but then I stopped for the election” he could have saved face.... but he lied about having ever spoken, thought, heard, mentioned any of the above. “Leave Flynn alone” there is your smoking gun. The president directed Comey to not investigate Flynn... do you recall? This was before the rest of the world knew Flynn was a guilty foreign agent. This would imply that the president KNEW about what Flynn had done and tried to influence an investigation. Then he Fired Comey.... hmmmm odd to say the least. The writing is all over the wall honey.', 'But the enviroment everything thats humans are doing is wrong THIS MUST BE STOPEd', \"Do you know how many children the USA have murdered in Iraq, Afghanistan, Libya, Syria, Vietnam ? Conservative estimates are around 2 million.\\nBut that's OK because America did it, and they are always right.\", 'Hasan making Internet great again with these dam amazing episodes', 'Does anyone else think the whole story isn\\'t being covered here?\\nHere are the issues: China\\'s supply chain, tariffs, currency manipulation, intellectual property theft, WTO status...Trump administration approach:\"blunt big stick tariffs\" to negotiate all this crap you just brought up. \\n\\nWhen I see fake Nike\\'s and Rolex watches coming out of China I can\\'t make any connection with US businesses being there at all. Lindsay said, \"...you are required to have a Chinese business partner when you do business in China, then they steal all of your stuff.\" Now, how did he lead into this conversation? It\\'s a global economy: He\\'s happy we are there doing business, lots of customers.\\n\\nLet me offer one small anecdotal example: I want a widget made for my, I dunno, Toe Jam Depilator. China can bid on making them, beats everyone else and what happens next? My Toe Jam device shows up in America under a different name, by a different company and now I\\'m losing out. I know, get Trump to use tariffs to protect me in the future. Make any sense to you? What about Apple I-phones? Their parts, in piecemeal fashion, are made all over the damned globe and assembled where ever that happens. Trump\\'s solution: Make the whole phone here in the US. Okay, let\\'s get that ball rolling, snicker, snicker.\\n\\nIn other words, make up your mind. Do business with China and deal with all the permutations of unfair practices or go to war with China, using tariffs, and see who wins. Who wins or loses? Depends on who we vote in or out in 2020. China is literally and figuratively banking on it: We luv you long time America! Bye, see you soon! Snicker, snicker.\\n\\nLet\\'s not even get into the deficit when tax cuts to the rich (not just the 1%, corporations too) amounts to someone peeing in your face while calling it rain. Especially when \"entitlements\" are pet peeves of the Republican party, not defense spending, lobbyists or the healthcare act they keep wanting to repeal or hobble.', \"@Harman Virk That's scary. This dumbass is teaching the next generation...\", 'Bashar Alassad are fucking you in every time', \"That is the white helmets job, to drop the chemical bottles at the same place of the Assad's air strikes.\", 'Looks like we have better internet connectivity in India than in USA', \"In your dreams, bubba. Trump won by a mere 11,000 votes in Michigan. In 2020 he'll be out on his portly ass.\", '@Richard Owens it does matter,  that\\'s the entire point of this investigation... \" you have nothing!\"', 'Trump is a great president.', \"Iran will be suffered an international attack from the west if refuses to release the UK's tankers.\", \"I am not so sure any more.  When I look back at some of the actions he has taken...   I just cannot decide whether the President's actions are accidental or purposeful.  I am not seeing any benefit to his actions, and all we are getting is the negative.  My mind is starting to change on him.  I never thought that I would say that.\", 'Mr Cummings IS truly a blessing, I hope people PAY ATTENTION & CARE!!!!', 'Look at all these people in the comment section being outraged and screaming for change, but we all know they won\"t go out and vote or protest to make a difference cause \"what can one person do\" and...\"OH, A VIDEO WHERE A GUY GAVE A CAT A HUMAN VOICE! Thats funny!\" *click*\\n\\nAmericans are just too lazy to ever change anything.\\n\\nAnd before you type an angry response, proving me right, use that energy to go out and vote, protest and educate.', 'Just let it go. You already lost credibility with this report proving nothing happened.. Just report the facts or else youll lose even more people to Trump in 2020. Stop proving Trump right!!', \"@Jeremy that would be great cause you'd be the first to go\", \"@andrew chambers proving again that trump supporters are hateful people. Nice people don't want to see anyone's tears.\", '@The Mean Arena \"normal\" law enforcement already has military equipment', 'Ups! Original link was censored, but not worries go to this site:_x000D_\\nchange punt org/p/free-julian-assange-before-it-s-too-late-stop-usa-extradition_x000D_\\nor go to my Channel- playlist:  Trump - \"I LOVE WikiLeaks”!! _x000D_\\nand sign the petition. If you wish to help Assange further copy the original link of the petition, from my playlist, and posted it again please. _x000D_\\nSpread the Word S.V.P. Thank you. _x000D_\\nUnited in Solidarity for Julian Assange.', \"@Justin Little Backatcha. Stop supporting Putin's Puppet in the White House. The coward and dictator wannabe who cozies up to murdurous dictators because he wants to join the club. And spits in the fsce of our old allies and friends. Who has no respect for our Constitution and system of governmemt. Who operates like a mafia don installing he\\nenchmen and threatening those who speak up against him. You support Trump? You are a treasonous rat.\", 'yea in trumps favor', 'muttley hehehe yet you ignore Hillary who confessed to colluding. ??\\u200d♂️', 'HANNITY IS ONE OF THE #1 PRODUCERS OF HATE SPEECH! FACT!', '@Lindsay Johnston I got as much faith in congress as I have in the FBI which is zero%.', 'Why USA drone was too close on Iranian border ? \\nAre Iranian drones coming close to USA borders?. Keep away and will be safe\\nWhat a bullying crap', 'Fox is literally brainwashing people. It is literally state tv. Trump is compromised and he show why again yesterday', 'Wow liberal tears', \"@CNendExactly! He'll have a guest on there that starts to make a great point, then he interrupts them and shuts it down. So irritating!\", 'just because youre not guilty of treason doesnt mean youre not guilty of treason? do dems just like losing elections?', '@Recluse Spider Search on YouTube Clinton Foundation Oversight, you will find it.  It started today.  I agree, but true crimes are hidden fake crimes are on CNN.  NOT cool.', 'if you actually take time to watch the actual hearing you can easily see how biased mule face is by how concise all his answers are when answering democrats compared to how dodgy he gets when answering republicans.', 'Hey blockhead Hannity, maybe you can share a cell with your penpal manafart', 'Donald Trump Benjamin Netanyahu John Bolton and the fake prince of saudia Arabia should be standing in front of a firing squad...', 'When Nancy Pelosi flies on military junkets she send her liquor bill to the taxpayers.  The self importance of our deep state knows no bounds!', 'except trump does not have permission to concoct his own stories  at cnn  like he did with the enquirer..', 'Gabbard/Harris or Harris/Gabbard ticket would be one good looking one! :)', 'hagar2025 blood sucking corporations and a greedy government', 'Arrogant, psychopathic, and narcissistic describes Trump perfectly, sweety. I always love coming to Fox News comments, I always leave with a renewed sense of confidence of who the ones on the wrong side of history a are.. confused people like you.', 'Im disappointed in americans.  I thought law, order and good sense would somehow prevail.   Now it depends on 2020 and the people.   \\nIm concerned the gop and trump will cheat again and keep trump in office. Maybe even for a third term.  Why not?  Whos going to stop them?  Adam schiff?', \"Why don't you ask them why the rich gulf states next door won't take them in\\n\\nGo on...ask them\", 'You were too stupid to realize that he ALWAYS was a warmonger?', \"It's the congress' job to get rid of 45 not mueller. Heck democracy in the US is failing and you expect mueller to sacrifice his job and for what? These people even got a molesting drunken in the highest authority next to the president and the senate. Nixon resigned cause a couple of people did the right thing and didn't protect him. This time it's different. No one of real importance is talking and he's handing out pardons like sweets! He's even talking about pardoning himself in advance and nobody's standing up to him. It looks as if he CAN get away with murder. Why are you picking on mueller he's not Jesus and doesn't have to pay for other people's sins!\", \"Jim Myers  -  That's exactly what he will do.  Staying in office is his ONLY chance at not going to jail.  That's all that matters to him.  What better way to make that happen then by making his stay at the WH permanent?\", '@Michael Armstrong How so? Burden of proof is on the person dismissing the claims :)', \"Don't put him in jail,send him to the battle front. He will turn to a mouse.\", 'CNN is disgusting...but...2nd Amendment...it is better this way, despite their nastiness.', \"THIS IS FAKE NEWS.\\nTHERE WERE THOUSANDS OF PEOPLE IN LONDON WHO MARCHED IN HIS FAVOUR. THERE WERE ONLY SMALL GROUPS PROTESTING WHO WERE ORGANIZED.\\nTHE CAMERAS ZOOMED IN TO MAKE IT LOOK BIGGER THAN IT ACTUALLY WAS.\\nONE BUSINESSMAN EVEN CHANGED HIS PUB'S NAME TO TRUMPS ARMS.\\nCNN IS WELL KNOWN TO BRING FAKE ANTI TRUMP PROPAGANDA.\\nTRUMP RULES\", \"@Mike Rogers Obstruction of Justice .... Oh, I forgot you are so retarded you can't define what obstruction means... No worries, you'll learn !\", 'These Dems are totally deranged and they will not win! If they did, they would tear up this country so bad it would not be recognizable anymore?', \"Can anyone believe that Trump, who knows the best words, would know of and be able to use the word 'proportionality' in a grammatically correct manner?  Someone else told him the reason not to attack Iran.  Trump is not in control of the government it is the people who manipulate Trump that are really in control.\", 'Unbelievable your statement is ,the president of the USA is worrying about 1minor aspect happening in the country while over 300 million people are dependent of him yet his cherry picking and macro-managing the company (USA) he supposed to run,his actions and taught process is evidence in an ongoing criminal investigation subjecting him,the man is clearly not fit to serve.', \"What make him to decide apart from Trumb. Trumb I's the president. It like he is apove the president.\", \"No they wanted Hillary that actually helped Russia build it's fancy new ICBMs now with more decoy warheads just in case defense systems are more capable.\\nGo Hillary!\", 'Lol, How would you feel if you found out that Trump made a living screwing over contractors like yourself?', \"Hoooold on @Aussie Jim, distinguishing between Communism, Socialism, and Fascism is a matter of details these folks can not be bothered with. They wouldn't know a narcissistic, Fascists, autocrat if he held a rally in their backyard and shunned The Free Press, Separate but Equal Branches, and First Amendment Rights of Free Speech. Whoops, just read your last sentence or two. Carry on.\", \"Someone got to police the world. Iran should stop enriching uranium and threatening the US. They should also get out of Yemen, stop fighting proxy wars etc... Iran has been taken over by extreme religious nutjobs. Checl the country out in the 70's. It was a complete different place.\", 'I’m not going come here and sing Trump’s praises but you guys realize Maher is going Alex Jones/rush limbaugh on you, right?  This video is a nonsensical rant against a failed messiah, nothing more than a therapeutic exercise. \\n\\nLet’s put to rest the conspiracy theories and get back to the issues.', 'This is nothing like Irak, because the allied forces only targeted chemical plant, and there is no sign of intervention in the civil war...', 'Mueller is a Republican.  Should have guess so much!', 'From 5:25 -- Extra good stuff.  As a \"cherry on top\" it should put an END to automatic \"the honorable/Your honor\" BULLSHIT that we are coerced to lay upon \"high-level\" \"legal\" \"experts\"!!!  I\\'ve HAD it!  I\\'m just \"doing my time\" until my deliverance from this horseshit, dumbass \"Earthly plane\".  That\\'s it!', \"I'm reading many of these comments. Many Fake News polluted minds here.\", \"If it's true what you say, why not release the full report without being redacted? After all one thing is clear, he who owns nothing, fears nothing. It is clear that there was something in that report and that's why they don't want to disclose it.\", '@EveryDaffodil53 Warrmonger scum!', '@Trump for Prison 2020 LOL LOL LOL', \"+Vince Miller   Your welcome.  I'm a republican but was rooting for Tulsi the whole time.\", 'So Trump is guilty of at least one charge Cohen went to jail for.', 'Back ground checks ate getting Americans killed. End all background checks. Open carry your AR-15 to to Wal-Mart.', 'This is probably the only case where I can accept the term \"toxic masculinity\". Not in the feminazi sense of \"OMG, he has his knees APART!\", but the common sense of a testosterone overdosing, overly aggressive, hyper masculine, degenerate skinhead neo-nazi.', 'Publicly Exterminate Trump', 'Trump lying PoS', 'It would have cost less to just fly a B-52 over the targets and carpet bomb the living daylights out of them.', 'That drone is a long way from the US.....just wondering what would have happened if a Iranian drone was flying near the US coast. ie...it deserved to be shot', 'They know because 17 US intelligence agencies say it was Russia. It may also be worth noting that all the Republicans agree with them (with the possible exception of trump)', '@Helen Russell\\n\"Being French is a state of genetics.\"\\nOkay, I\\'m out.\\nFrance, of all places. Who invented the Nation as the community of all people within their borders, and had quite a revolution about that sort of thing.\\nRegarding your African-ness: Swap \"English\" for \"quasi-Dutch\", and you get the textbook definition of an Afrikaaner (i.e. a white South African) - who are just that, African.\\n(Incidentally, about half of Africa _are_ Christians.)', '@Achish of Ziklag ,. Israeli is a nationality, not a race or a religion.\\nGet an education, fool...lol', \"Y'all couldn't get John Dickerson to interview Trump?\", '@David J  You have nothing, little liberal beta male. Your precious Mueller report FAILED and now you little soy boys are crying like school girls. Loser.', 'Wow!  So many NPCs in the comment section.  Orange man bad', 'Our federal government is INSANELY corrupt!', \"State bars are self-regulating and have numerous professional responsibility rules to ensure transparency and accountability. Arguably, some district attorney offices have better systems and guiding principles primarily based on state law and district attorneys. I enjoy this show and enjoyed this episode but it would've been better had John Oliver at least mentioned the overwhelming % of cases that are properly handled, and discussed which states tend to make more blunders.\", 'Tulsi is fantastic and much more qualified than Biden and all the other hacks...why is america putting her down for being honest??', 'why must war??', 'Trump IS a Dope and his cult is as Fucked up.', \"Aaaaand as per Bobby Mueller's SOP he immediately walked back his claims the moment he was questioned about them in the following hearing...this is what happens when you stuff words in to the mouth of an OBVIOUSLY senile old man LMAO he probably forgets what is is he has said the moment his breath runs out.\", 'Wow, it just keeps coming out...and Trump is supposed to be the leader of the free world ??? what a disgusting piece of work', 'colquitt74  You are so confused. His days are numbered? So are you implying he will get impeached? Ok what facts do you have? The same that has been reported? None. Stealing money? Again what are you talking about? It is his right as elected president to claim a national emergency and allocate funds as he sees fit. It’s in his power. You claim “ he know” so now you know what  the man knows and thinks? You have no clue what he hasn’t done for the military. Have you served during his term?  Probably not.', 'He doesnt trust the Senate, because he knows that they have been bought.\\n\\nTrum cant be bought. He does the buying. \\n\\nViva DT.', 'Trump 2020', 'When we actually had a decent president. You must miss Obama. ?', 'I find it funny that CNN is calling some a liar. Trump said that he only saw a small crowd of protesters. Which could be true because the British Royalty has been keeping Trump way from the protest. CNN doesn’t show video of the supporters', \"Have you seen this you tube video? 'House Oversight Hearing: Financial Investigators Testify on Clinton Foundation Corruption_x000D_\\nI billion  in fraudulent activities found by forensic financial investigators.\", 'In Iran it’s legal for a man to marry a child!', \"His job is not to clear...........it's to find guilt........and he didn't.  CBS needs to educate their reporters.\", \"Again, I reiterate, it is the Taliban's fault. The war could have been avoided if they took him down themselves.\\nAnd who said I trained \\xa0and armed extremists? I'm not American, or even European.\\n\\nAmerica has done a lot of bad things, including the way they handled Afghanistan, but bin Laden is the one who started it (it was even his intention to lure them into Afghanistan).\\n\\nBy the way, the Taliban wasn't around in the 1980s; they popped up in the early 1990s, due to the constant rivalry of rebel groups, and the endless quarreling over territory. Please do your research before making so-called arguments.\\n\\nYou're brainwashed due to your anti-American attitude. I'm older than that, and have upgraded from black-and-white to color.\", 'I think Kushner was s girl before he married Ivanka. Sure looks like it. Who knows? Maybe he still is.', \"The Democrats and their MSM mouthpiece won't let it go, lol\", 'MAGA', 'Muellers garbage report is based on a garbage dossier! What can you expect?\\nGarbage produces garbage. Period', 'Can someone please mention ONE thing in the US, that is not utterly corrupted and screwed up - by either money or reactionary extremism?', 'And TRUMP WINS AGAIN!!!', 'Rudy Is like any cheap trickster lawyer. Always  framing twisted arguments!', 'Knegrodamus great again', 'Adam is one articulate believable and sincere Democrat. We are with Adam.', 'Texas thinks they are ranch hands but instead they got the ranch.', \"The fact that Schieffer still can't- or won't pronounce Ocasio properly is just more proof he's still  just a right-wing  mediasaurus who should retire.\", '@Randy Jordan \\nI will wait for the Mueller report on whether there was a conspiracy or not between Trump and Russians.  That\\'s the only report that matters to me and many Americans.\\n\"Russia, if you\\'re listening, I hope you are able to find the 30,000 emails that are missing.\" Can you tell me who made that request to Russia on July 27, 2016?\\nAlso, did the Russians try to hack Hillary Clinton\\'s email the same day after getting that request?\\nI don\\'t expect you to answer both those questions. \\nIf you do respond, I expect that you will resort to deflections and/or some form of Whataboutism.', \"Someone with a caring heart needs to enlighten Bernie Sanders to the wonderful relief of a thorough colon cleansing.  He's backed-up and packed-up to the extent his brain is having major difficulties in making decisions that are compatable at helping the working class people thrive.\", \"Don't need to watch Alex Jones or Infowars anymore. All you have to do is tune into main stream media and it's conspiracy central.\", 'NOTHING will happen NOTHING - all this is just to keep the mindless Americans occupied', \"The Democrats are so petty.  They are so eager to find fault that they'll spin anything Trump does into a national security threat.\", \"B Bhima: You do know better than to say that. I know you do, and you know you do. CNN doesn't lie at anything like the pace, or with anything near the contempt, that Trump does. \\nYou do know this. \\nYou're disgusting. Anyone who supports Trump is a disgusting subhuman. There's simply no way to objectively defend Trump. It's impossible to do it. He's a menace-- a sociopath. \\nYou really should consider yourself.\", 'Trump is a conman,grifter,money launderer,tax fraud,and a pedophile and child rapist.\\nHe is not my president.', \"Once again CBS shows its true nature - A MOUTHPIECE FOR THE DNC! Mueller didn't clear Trump of wrongdoing because THAT WASN'T HIS JOB!  But of course CBS will try to SPIN it into something nefarious. I expect nothing else from them.....\", \"@Vagabond Jay We have laws we expect Americans to follow.  The immigration laws are proof we don't support our have open boarders.  If people came follow laws, why signs anyone follow any laws?\", '@Based lvl 9000 Ultra Chad Boomer freak , trumputin', 'John Oliver: a court jester and in no way a satirist, here  using clueless celebrities to brainwash American people into thinking Assad is the bad guy, while their own taxpayer money is used to pay for Al Qaeda and ISIS to tear up a beautiful, peaceful country. WAKE UP AMERICA and stop being brainwashed with this inane garbage!\\n\\nAND LIBERAL SCUM! IT IS YOUR PRESIDENT OBAMA WHO DRONES INNOCENTS TO DEATH!\\n\\nLiberals are SCUM!', 'Representative Gabbard\\'s support of an \"assault style weapons ban\" is not acceptable.', 'Under the watch of Donald Trump Mike Pence, AG Wm. Barr, Sen. Mitch McConnell, John Bolton, and Elliott Abrams we quite possibly could be led to the very edge of World War 3 if not to otherwize actualize something truly catastrophic for Humanity', 'Joseph Nordenbrock Bernie was corrupted when he said nothing about not getting the delegates when he ran. Hillary got the majority. Bernie Sanders? Silence. Not one word.', 'Campaigning for regime change. \\nProjecting about Crimes against Humanity - the USA are the reason people are starving around the world, selling their kidneys to feed their families, USA did that!', 'T Haze what’s your obsession with Iran? Do you love their support of terrorism? The insane laws they implement on their people? The fact they are involved in every conflict in the region?', \"It's too late for CNN and they know it.  Brand destroyed.\", \"He did not clear Trump of wrongdoing because he found no wrongdoing. Mueller himself said he didn't have evidence worthy to bring to a court.\", \"I don't think Mueller even wrote the report.  So, collusion is only a crime in unfair business practices to restrain trade. So, this was ten pounds of air. None event ! Will never believe anything out of government media complex.\", 'Stop killing inocent people!', \"Sucks to be wrong Bill.  Nine months ago you were talking to Ben Shapiro about how you were convinced about collusion.  Adam Schiff also kept telling us that he had all of this evidence about collusion so I guess the little pencil neck congressman must be feeling like you now.  Sucks to be so wrong.  Hey, why don't you get Ben Shapiro back on your show.\", 'For once, you have to agree with Bernie ...', 'ya it was a hoot watching 9/11 unfold..  pollard, uss liberty,  etc..', 'Let our President speak, finish his words. RESPECT OUR PRESIDENT!', 'american politicians are a cancer to their own people', \"TRUMP BRING EVERYONE HOME AND QUIT BEING THE WORLD'S POLICEMAN GEEZ WAKE UP TRUMP ---PROTECT OUR GRID AND GET RID OF THESE DAMN CHEMTRAILS THAT IS KILLING EVERYTHING IN OUR WORLD---COME BACK TO GOD OR HE WILL MAKE THE FINAL DECISION\", 'Trump is the American version of Wallace Souza', 'Oh look, more liberal bias news!', '@xXmlg420yoloswag69Xx Well, he liked the poor and hated the rich, he advocated to pay taxes to the Romans and even had a tax collector as a disciple, I mean, in Tea Party terms, he had it coming.', 'Geoff Forgie yea tell those spoiled prilvedged few of ALL races that you ain’t special, you ain’t important, YOU ARE NOT THE FUTURE, so stop acting like you should receive special treatment, or did your democratic parents spoil you like that?', 'There’s no trusting trump, Bolton or Pompeo.', '5000 people protested... pathetic', 'just line the straight with ships and subs. What are they gonna do, throw their head rags at warships?', 'justice', \"tr?mp & the republiCONs as usual want WAR. With Iran, North Korea & China. Think about it when ever republiCUNTs are in the W.H. there's always a war, billions wasted & too many people killed on both sides. Wars in the middle east creates more terrorist's too btw !\", \"They tried to set Trump up? Wow, now that's breaking news!\", \"Fake news.  Anti American what's wrong with you. Msm wants war. Disgusting.\", 'There have been no lies to apologize for, you tendentious moron. As Mueller himself states in his report, it does NOT exonerate the President.', \"@John Bold...well said!\\nIf lamestream media such as FOX, CNN and MSNBC did their jobs...these criminal wars by the Demlicans & Republicrats would have been over years ago if the dumb'd down public even had a clue what was taking place at the hands of American Imperialism.\\nFact if they hadn't all been Bush Dubya's useful idiots back in 2003...we wouldn't be having this discussion and the world would be a much better place.\", \"Wow... He'll of a prospective from the great mind of congress leaders... \\n\\nI never had any idea that is this complicated...\", 'sam zen rebuild .. you mean economic colonialism', '@C J trump has had power for years now. Where is the doom and gloom? I was promised all sorts of evil, where is it?', 'Two words explain why so many Republicans currently oppose interventionism.   RON PAUL.', 'If war breaks out, send Hannity in first.', 'Fake passports????? SPY SHIT!!!!', 'This is absolutely hilarious cnn is probably going bankrupt.does anybody understand what he is saying?', 'lock hem up', 'anderson cooper the guy who knows the answer to the question,who do you have to blow to get a job here at cnn', '@Feeds Ravens \\n\\n\\nYou almost had a point and then resorted to willful ignorance and or lies.', 'MATT GAETZ ROCKS. the other 3 including Tchitface are Dummies, Warmongers and Liars. China are the new Silent Colonialist.', \"Thanks for leading and showing us the way! I'm in Denver CO and the only option is Comcast. Coax cable is good service with low latency (30 ms to any coast or border). But gosh we hate not having any option or recourse against a truly horrible Comcast. Voters are passing municipal broadband laws. Even with the most disastrous rollout, it could never be WORSE than Comcast lol. I'll be vacationing in Switzerland this summer -- see you soon :)\", 'If you go to war with them in court, they will destroy you...', 'Nothing ever happens to a Democrat.   We see the beginning then dropped', \"For all the guns and weapons America has, y'all sure do get frightened easily.\", \"He is not getting worse, he's exactly like he's always been. He was not sharp on the apprentice, he was edited and coached. This is the first time in his life he's not being edited by people trying to make him look good. That's all. And it's why he thinks the press is being mean to him now.\", 'ALL LIES! FAKE FOX NEWS AND PROPAGANDA!', 'Yes he had lied 10000+times. Boy', 'Debra Smith TRUMP 2020', \"@David Moser lol you are the one thats 2 stupid to see thru cnn's bs idiot! 2 years of nothingburgers and you still believe this dying channel\", \"@Alexis but I definitely agree,we need universal health care,Israel has it, yet we're forced to send them 38 billion tax payer dollars a year and WE don't even have that!\", 'The only way to debunk this lunatic is to get his stinking derrière out of office!', 'YOU ARE FAKE NEWS FAKE NEWS YOU ARE FAKE NEWS FAKE NEWS FAKE NEWS FAKE NEWS FAKE NEWS FAKE NEWS FAKE NEWS YOU ARE FAKE NEWS OF THE FIRST ORDER!??????', 'John Oliver RIP off!', 'Wars are fought mainly for secular reasons; power, money, resources, territories. It\\'s the oldest story in the book. There is no \"truth to come out\" because I just told it to you.', \"@Yugioh Pokemon I don't believe anyone anymore (Irak had atomic bomb )\", 'M B There was, however, several attempts made, as well as obstruction of justice, and other conspiracy charges that can be brought because the report did not in any way exonerate him in its search for evidence of innocence.', \"The cafe owner here in North TX who is an American born muslim of Albanian decent gave my wife a free piece of Baklava cheese cake when she found out we had our first child recently, we chat often, she teats all her employees who all of them are not muslim great, she has Christmas trees and decorations currently in her cafe. Sorry I don't a lot of Muslims..but the ones I do seem pretty nice. I assuming you didn't watch the vid or just part of it. The process is long and every one of them that I've seen interviews with said they have not problem with how our culture is or any need to change it. Which, I might add... even IF there were many more.. how exactly would they so quickly turn everything over in our culture?  I'm not a fan of Hillary, but the plan was not for a population of millions. Seriously if it has to be just women, children and widows with husbands on special instances then so be it. If they can't all come here but go to places closer to home..then so be it.  But I don't have a shred of aggression to anyone, them or anyone else until someone shows me aggression as well.\", 'I wonder where Lady justice stands on this matter? Fascinating! Will\\nthe end justify the beginning ?', '@OneTruth Given then just end it and DONT LIE.', \"Wow Memo, nobody cares about CNN? That's been a fact since the witch hunt faceplanted. The right wing comes here during commercials!!!!! You whining asshats are extra laughs after we get real news during PRIME TIME!!!!!!! How's your little circle jerk politiclub doing these days? Still slaying the tweenies online? ROFFLMFAO@UUUU!\", \"@Marcus \\n?  How about you take a hike beings you can't handle truth. You democrats seem to be having NOT very good days. ?\", '@hepwo91222 getting hundreds of millions of dollars from the Deutsche bank, a bank infamous for money laundering, is suspicious. Especially after the US banks refused to lend you money after defaulting on nearly a billion dollars worth of debt', \"Now CNN cares about campaign finance laws? Hillary's dossier payments of millions of dollars to Steele was never reported and clearly were designed to influence the election? I wonder when they will report on this? Never obviously\", \"@Stoned Again You must be a troll. Europe would be speaking German or Russian if the United States didn't save your asses. Because this statement is so absurd you must be ignorant or a troll. My guess is you're a troll.\", '@catalinacurio Mueller is a traitor and will be hung!', 'Donnie Dotardo only fools his sycophantic base! \\nanyone with even one foot in reality knows Spanky McBonespurs is the original Bait and Switch artist!', \"@Guts Repeating mistaken family stories is hardly a crime. That's much more than Trump can claim.\", '@Based lvl 9000 Ultra Chad Boomer you are so predictive, pure hate always is and what happened to your Mother? BERNIE2020 this time.', 'Well it seems to Russians ran their own candidate. And he won.', 'Perhaps Mueller could not \"declare tRump exonerated\" but neither could Barr - - but he did, several times, on tv --- which is why Mueller was forced to go on tv and SAY that tRump was not exonerated.\\nMueller has no conflicts of interest with tRump, only the felons occupying sensitive positions in our government, he definitely has problems with them, IT\\'S HIS JOB, FOR AN FBI AGENT TO HAVE PROBLEMS WITH CRIMINALS.', \"surprisingly he's not a democrat.\", 'Wow. Great news for the country. Rats leaving a sinking ship. I hope there are arrests.', 'My God! Trump makes me feel disgust the likes I’ve never felt before!', '@Inez Dills Indeed, Trump is a dirty little traitor.  I agree 100% Inez.', \"Go ahead America, start this war. But don't complain when millions more refugees invade your country and Europe. Maybe that's the agenda after all?\", 'TIME FOR DEMOCRAT SCUM BAGS GET OVER THE RUSSIAN COLLUSION THEY CREATED THEY ARE ONLY PUSHING THEIR FAKE COLLUSION STORY TO DEVERT THEIR MISCONDUCT OF CRIMINAL CRIMES OF TREASON HOPEFULLY TRUMP WILL NOW HAVE AG BARR START INDICTING THEM ALL & FACE JUSTICE AT THE END OFF A ROPE...', 'CNN never lies. LOL. His visit to the UK was a success. The protest against him was not huge, just people who do not work.', \"Robert Honer the intelligence agencies have nothing, there is zero proof, nada, nothing, that the Russians interfere with the democratic process of our country. At best you could say the Wikileaks emails were given to them by Russia but again they agencies can't prove it either. At the end of they day the voter makes the decision, and you cannot blame that on Russian interference.\", \"@G.T.O. Momma Thank you, I am independent though thats why i don't trust either side because of the political stuff going on, but everyone has their own opinions or believe in the left or right\", \"If I don't vote for Trump, In voting for Gabbard.\", '@Bryan Kay Omar never said she felt pride for a terrorist organization, that is a complete and total lie. They have all repeatedly expressed their love for the United States, and if you want to talk about somebody\\'s \"hateful content of character\" look at Trump bullying everybody on Twitter. I have never seen such an angry and argumentative person fling so many hated-filled rants and insults out into the world. Go away, bot.', 'Isnt Anderson Cooper ashamed of how he covered this?', 'Susan Pelsue you mean tulsi being Hindu and America pretending to be Christian ?', 'Wow the media just won’t stop—they are activists, not journalists. This is ridiculous. Trump has been completely exonerated—never collided with Russia. Fact. Can’t obstruct a crime you haven’t committed. \\nThis is so unfair and dishonest of the media and democrats. They will receive the consequences on November 8th, 2020', 'Why do you waste your time on these democratic cuntz', 'President Trump Was Put Into Office By The LORD To Throttle the Enemies of Israel, and the U.S.', 'Well, ABC is one of the Five Crime Families of Fake News.', 'Playbackjunkie he is out for his own EGO. If you don’t see that then you’re in denial.', 'Hannity has shown himself to be a warmonger of the worst kind.  Guiliani is completely corrupt -- you cannot believe  word he says. The Pentagon knows that the US will lose against Iran.', \"Don't be fooled. What Trump is doing now seems more of an escape plan in progress. He fumbled North Korean nuclear negotiations, the economy, strained relationships with almost the globe, imagration policy, devided the nation and has not told the truth about anything. There is much more negative than positive. My point is, what better way to escape prosecution than to play crazy with the world? Think about it! It may be hard for rational people. Trump has proven to all he is clearly not a rational person.\", 'Liberals are incorrigible', \"King Kong well it's the amount sanctions you put on them.\", \"I care as much about the Democratic Party server getting hacked as the Democrats care about my computer getting hacked.  I don't see any reason for a 30 million dollar investigation.  Let them buy an anti-virus program the same as the rest of us.\", '\"For over two years America has had a crazy person in the White House and for over two years the Democrats have done fuck all about it...\"\\n\\nThat being correct then that\\'s the whole video, Bill.', 'Funny how the comment section has more balls then the news for truth!!!!!!!', 'Just when you thought CNN hit rock bottom. They find a shovel waiting for them.', 'Maybe someone needs to look at Mueller\\'s income over the last 2 years and see if his \"paycheck\" jumped. ....', 'These are white on white crimes. Nothing to see here!', 'Bill need to call us to the streets so we can battle \"them!\"', 'Well Anderson by the comments it looks like about 25% of people still agree with you!! The Democrats failed because that is what they are good at. I mean just look at all of the great legislation they have passed in the last 50 years. They have gotten nothing at all done for the middle class for a half of a century. While the Republicans have made this country a state run by the companies. Time to put in someone who will get things done for the middle class like Tulsi Gabbard.', \"Andrew Smith: yeah oh right answered really well already but I don't see why we should force anyone to fit in a place which is already as diverse as heck and is supposed to celebrate differences. And as the video stated they do not even get to pick where they will be placed so rejecting them for that is just silly.\", '@Wadley Jred \\n\"I don\\'t know Matt Whitaker\".', \"China has been undermining our country from within for a LONG time!! You cant go shopping without seeing 90% of the goods being from China! Quit importing this crap! America needs to start making our own goods again! Look into how China has worked with the Mexican drug lords to fund MS 13 that now control parts of California. Remember. You have millionaire politicians who got rich on a 170,000 a year. HOW? They're getting paid off by China! Feinstein, Harris, Waters, etc. allowing China to acquire California. Watch The Common Sense Show on you tube.\", 'Damn Its so fucking sad that Iranians are kicking our asses .USA  we should go to war !! . Fuck this terrorists', \"Hasan is right now the best thing that Netflix has .... Hasan would like to hear from you abt the social media applications like Snapchat Instagram tiktok etc just to let the world know abt it's consequences\", 'When did it become that prosecutors job to clear people. It is their job to find guilt not innocence. The Mueller report is not based on any legal precedence. The Mueller team made up their own rules and pass them off as following the law but missed the fundamental truth that \"EVERYONE IS INNOCENT UNTIL PROVEN GUILTY.\"', 'John...  When you decide to recognize that the Prosecutors in the Office of the District Attorney are clients  - their crimes against the public cannot be prosecuted because of attorney client privilege.  Rule 1.6 Confidentiality of Information is the cause of the problem... but, lawyers must keep that CONFIDENTIAL.\\n\\nTime to unblock me, eh?  www.work2bdone.com/live', 'ABC is owned by the Bilderberg Group.', \"What crimes...yes there were some shady individuals but what evidence of collusion was there? Isn't that what Mueller was investigating? Right?Trump didn't exactly get anything but the bottom of the barrel as everyone didn't figure him to win...remember? \\n\\nHow long was Manafort on the Trump team?\\nWhat exactly did Popa D do?\\nFlynn lol...he was set up and somebody leaked info on him from spies?\\n\\nStefan Halper, go look him up. Where is he lol?\", 'I really wonder who most Democrats would vote for next year if not her, is there really a more appealing or likable candidate at this point? I think some say she is too unconventional and outside the box, but that is not necessarily a bad thing, we do need someone new and different for a change.', 'We also have a shitty company here in Morocco called Maroc Telecom it is the only company that provides broadband internet connection so they get set the prices as high as they want and their customer service is terrible .\\n#FuckYouMarocTelecom', \"YOU WANT TO TALK ABOUT LIARS...?\\xa0\\xa0\\xa0 CNN IS THE BIGGEST LYING ASS PROPAGANDA\\xa0 NETWORK IN THIS COUNTRY.... CNN WILL CEASE TO EXIST SOON AFTER WILLIAM H BARR KO'S HILLARY CLINTON AND HER COMEY CABAL...BHAHAHAHAHAHAHAHAHAHAHAHAHAHAHAHAHAHA\\xa0\\xa0 ....BHAHAHAHAHAHAHAHAHAHA\\xa0\\xa0 BHAHAHAHAHAHAHAHAHA\", 'The so called ‘chosen one’ (AND compliant GOP) gave huge tax cuts to rich, wants to buy Greenland, build a wall, and have Americans living pay check to paycheck to pay for it.  And as an added bonus, take away Medicare and Medicaid.  He’s more the anti-Christ.', \"Dear Republicans,\\n\\nWe don't care what you think about us ruining the country.\\n\\nSigned,\\n\\nThe Republicans you voted for.\", 'Fuck the drone', '@Genghis Khan Sounds awesome', 'A criminal family in office?', 'Obama had an AG that said he was his \"wing man \", not one complaint from anyone.', 'Look in ur reply and u see a persn says:  “ same here in iran” .... and u can tell in both sides are some certain current whom need war!!!!', 'If only he would get bone spurs in his thumbs.', 'Americas favorite mobster. fake mayor fake urine colored president. neonaziconn...................', 'I recently graduated law school in Germany, and here the system is similiarly fucked up. At least you have to have a certain grade to be able to become a judge or a DA and they are not elected. But what my feeling is, that most people that do become judges and DAs are kind of weird and like the power they have just a little too much. The people that actually are aware how many lives the can and will ruin with that job, don\\'t do this job for THAT EXACT reason.\\n\\nAlso you are obligated by the law in Germany as a DA to bring forward any exculpating evidence. But it is not really taken all that serious. There is a joke going around in the DA that it is \"the most objective public institution in the world\", but everybody says it with a knowing smirk.. also I witnessed a rare case in court where the guy was found innocent and the police guy, who has to lead the accused in and out of the court room got all excited and joked \"aren\\'t acquittals illegal?!\"\\n\\nThe good thing here is, that at least we don\\'t have the death penalty, so at least nobody dies because of it..', \"Well I apologize for not practicing the best grammar online, especially since my it's not even the language i was brought up with. I wont argue on that.\\n\\nBut you're forgetting that the Taliban and the Alqaeda is essentially the same 'group'. They were created - organized, funded and trained - by the US government at the time of the cold war. Well you know the murricans they hate being 2nd best so they were scared of the communists invading the middle east. So they created OBL and so on.\\n\\nUm well let me 'reiterate', bashar didnt kill more people - civies or military - than his father. If anyone it's the so called 'revolutionists'. Anyways these statistics are always cloudy in the time of war lets agree to that.\\xa0\\n\\nBut what I can't have is people watching cnn or fox and call syria's president a shitty and despicable cold blooded killer whilst leaving people like netanyahu and obama roam free without a second glance.\", \"@Roman Hoax And Trump isn't a liar? lololololololololololololol\", '@ElPocho DelMundo i agree with you there is no false word in the report no collusion no obstruction by trump, but it does show that the DNC and hillary accepted money from Russia for the campaign,  and that comey did not interrogated hillay about the emails, and mccabe and lorreta lynch told comey to let her go. Read the mueller report, and before you tell me it is redacted, so is the FISA REPORT,   AND FISA WARRANT,', 'Fuck you cnn soon you will be gone.', 'Notice that when Trump is speaking to the media it’s beside a noisy chopper which means ‘I’m a very busy person’ or with a bunch of people behind him like his rallies which means, ‘look how many people support me. It’s sad and pathetic behaviour.', '@C\\'est la vie \\nWhen did any of those \"dictatorships\" go Pirate, for instance ?  What business of yours is it ?', '\"No more Russia investigation \" also Trump lol ?', 'Lies lies lies are from cnn ???', \"Mueller didn't clear the president of wrongdoing because he didn't do anything wrong. Stupid people cannot understand this very simple idea. Mueller carefully uses his words to make the stupid people believe he's saying the president is guilty of something.\", 'Trump is looking ill.', 'AND LOCK HER UP!!!1', 'POLY GRAPH ALL AGENTS CIA AND FBI  WHATS UP NOW WRAY', 'this program tonight, was a hatchet job, you are suppose to be neutral.  There is only one United States. The president represent all of us, like him or not.   The forces that can not destroy this country by force,  are working to tear us apart.  We are tire of all the negativism.  I have yet to hear anything positive about Trump presidency  from your network.', 'The christian right have no morals just like it\\'s leader and Trump is holding on to his ace in the hole for his souless base \"Roe vs Wade and the legalization of weed.', 'Is Beto actually saying they wanna start impeaching Trump now so they can start investigating why they are impeaching him??!', '@spikethompson2000 Wisdom is needed. In 15 or 20 years she should run again.', '@Scorp308\\xa0There are not really many good options in Syria right now, but doing nothing or supporting Assad/ISIS are the worst possible choices.', 'Congressman Matt Gaetz is the smartest guy in that panel, %100 agree with him, president Trump made the smartest and best decision.', \"As a German it is always funny to see how both the right and the left in the USA use merkel. To make it clear: either she gets elected or someone to the left. She is a conservative in Germany. The alt right is polling at 8%, so don't use us as an example of your faulty systems. If the Russians would hack us it would mean a shift further to the left. Please get that!\", \"Trump is a fool . He doesn't know what he is doing or what he wants to do.\", 'Hey Bill those whoops and clapping from your audience mirror the MILLIONS of people around the world that are yelling at the screen and applauding in agreement with what you are saying... how does this fucking two bit conman get away with this shit? !  It’s COWARDICE plain and simple.', \"Just a continuation of the clown crap show. Isn't this a form of obstuction?\\nAccording to them obstruction is a crime. So more projection.\", \"The rest of the world ain't living in chains lmfao. majority of the world lives under the same rules as USA, give or take a few religious countries or rules, etc.\\n\\nOnly difference is the wealth of the country and living standards. But US isn't doing too well in that aspect either lol\", 'Jay Grewe Blaming Bush and Congress for his woes. “During Obama’s first term, he blamed Bush for the economy, for the botched Operation Fast and Furious, for the massive deficits, for our plummeting national wealth, for our problems in the Middle East -- for just about everything that went wrong.\\nWar on coal and oil. “Obama forced more than 200 coal-fired plants to shut down over a five year period.”\\nCut funding to fight aids. “This inexplicable decision had a devastating effect on Africa, where most AIDS deaths occur.”\\nNominating John Brennan as CIA director. Brennan has gone on to be President Trump’s critic.\\nDACA via executive order. Obama went around Congress to give amnesty to some 800,000 younger illegal immigrants.\\nAssault on the press. The Committee to Protect Journalists, said of Obama’s media attacks, “In the Obama administration’s Washington, government officials are increasingly afraid to talk to the press. Those suspected of discussing, with reporters, anything that the government has classified as secret are subject to investigation, including lie-detector tests and scrutiny of their telephone and e-mail records.”', '@J Ch \\nFirst off, do you mean Iraq?  If so, exactly how much oil did we actually take?  Despite being there longer than we should have ever been there, the answer is NONE.  So get your facts straight before bloviating about things you clearly know nothing about.  And Venezuela?  What \"invasion\" are you referencing, exactly?  North Korea?  Gee, I don\\'t know, maybe the fact that the regime was testing ICBMs with our name on it sort of prompted a lot of that.  And if you think that by \"controlling\" the Koreas, we could somehow \"control\" China, you are nuts.  Oh but we are the ones who are naive...says the person who couldn\\'t even keep Iran and Iraq straight?  Please.\\n\\n...but for the sake of the argument, let\\'s say the U.S. accounted for all of the negativity it has brought the world with military actions and such, to your point.  Let\\'s not forget who sits on the other side of the scale, the side that I\\'d argue is much heavier, that being all of the protection we have provided to so many countries who would be extremely hard pressed to defend themselves.  So have your little anti-American tirade but at least be intellectually honest about it.  There\\'s is criticism to be had, for sure, but to act like the U.S. has not served the world well in MANY regards is to overlook a staggering amount of history.', \"He throws red meat to his base like they're a pack of wild dogs.\", 'Love how MSNBC by this title seem to be trying to create a Tulsi vs Biden moment by ignoring the other important things she said and just concentrating on Biden.......but unfortunately for them Tulsi does not play those games.....she is not Cory Booker she actually has class.', '@James Gray since when? and whats about the other resources america needs from other nations?', 'Senator Sanders is the voice of SANITY.  Listen to him, and make HIM the next USA President.', \"Look at Dan go! If Fox doesn't let this function as his on-air audition, they're nuts. Nice job, Mr. B! ?\", '@WanderfalkeAT I don\\'t think they run a conspiracy, it\\'s like Noam Chomsky said to a reporter: \"if you didn\\'t believe what you said, you wouldn\\'t be sitting here\". You should watch his lectures on the media and read Manufacturing Consent. Pretty good stuff! I get what you are saying though.', 'The drone story was made up by the same people that made up the weapons of mass destruction story that started the war with Iraq.  There is nothing the press loves more than a good old fashioned war.', \"This could have been easily swept under the rug if Trump hadn't put her in the spotlight LOL.\", 'The United States invasion of Afghanistan occurred after the September 11 attacks in late 2001, supported by close US allies.  Its public aims were to dismantle al-Qaeda, and to deny it a safe base of operations in Afghanistan by removing the Taliban from power.\\nnow trump and graham \"negotiate\" with taliban for our surrender and withdrawal. yea amerika!', '@Teeveepicksures seeing as how there never was collusion some folks have legitimate questions...', 'The Syrian crisis is a horrible thing, but has anyone noticed the situation’s strange components?\\n\\nAl Assad- Syria- is against Daesh (ISIS) and the rebels who had rose up against him.  Putin- Russia- is aligned with al Assad to combat Daesh, but so is the U.S.  but, the U.S. is against al Assad.\\n\\nSo, basically, Russia and the U.S. are both against ISIS, but Russia is aligned with the Syrian government, and the U.S. is against the Syrian government for attacking the countries civilians.']\n"
     ]
    }
   ],
   "source": [
    "#find threads with most political posts:\n",
    "#select the rows in the dataset that are in a thread with more political posts than cutoff:   \n",
    "# Define the cutoff value\n",
    "cutoff_value = 8\n",
    "\n",
    "# Group by 'thread_title' and count the number of political posts\n",
    "thread_counts = dataset_claim_embeds.groupby('videoTitle')['Llama31_political_fill_8b_score'].sum()\n",
    "\n",
    "# Filter the threads based on the cutoff value\n",
    "pol_threads = thread_counts[thread_counts > cutoff_value].index\n",
    "\n",
    "# Select the posts in the filtered threads\n",
    "pol_posts = dataset_claim_embeds[dataset_claim_embeds['videoTitle'].isin(pol_threads)]\n",
    "\n",
    "# Display the filtered posts\n",
    "print(pol_posts.loc[pol_posts['Llama31_political_fill_8b_score'] == 1, 'commentText'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2014-06-09T23:18:16.000Z\n",
       "1    2014-06-10T00:26:36.000Z\n",
       "2    2014-06-10T14:26:16.000Z\n",
       "3    2014-06-12T01:40:55.000Z\n",
       "4    2014-06-16T08:09:41.000Z\n",
       "Name: Time_comment, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pol_posts.sort_values(by='Time_comment').reset_index(drop=False).Time_comment.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "#Expand the polposts to include the thread context:\n",
    "chunked_result: typing.List[pd.DataFrame] = []\n",
    "GROUPER='videoTitle'\n",
    "#sort data by Time_comment\n",
    "sort_pol_posts = pol_posts.sort_values(by='Time_comment').reset_index(drop=False)\n",
    "groupeddata = sort_pol_posts.loc[sort_pol_posts.Llama31_political_fill_8b == 'political',:].groupby(GROUPER)\n",
    "for group, df in tqdm.tqdm(groupeddata):\n",
    "    df['preceding_index'] = df.index.to_series().shift(1)\n",
    "    for index, row in df.iterrows():\n",
    "        if pd.isna(row['preceding_index']):\n",
    "            chunked_result.append(\n",
    "                pd.DataFrame(\n",
    "                    data=[[index, row['commentText']]],\n",
    "                    columns=['index', 'post_expansion']\n",
    "                )\n",
    "            )\n",
    "        if pd.notna(row['preceding_index']):\n",
    "            threadset = int(row['preceding_index'])\n",
    "            try: \n",
    "                chunked_result.append(\n",
    "                    pd.DataFrame(\n",
    "                        data=[[index,\n",
    "                            requests.post(\n",
    "                                'https://inf.cl.uni-trier.de/',\n",
    "                                json={\n",
    "                                    'model': MODELlarge,\n",
    "                                    'system': SYSTEM_expansion,\n",
    "                                    'prompt': f'\"Thread\":\\n<{df[\"commentText\"][:threadset].to_list()}>, \"Target reply\":<<{df[\"commentText\"][index]}>>',\n",
    "                                    'options': options_zero\n",
    "                                    }).json()['response']                       \n",
    "                        ]],\n",
    "                        columns=['index','post_expansion']\n",
    "                    )\n",
    "                )\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"invalid json response, skipping to next batch\")\n",
    "\n",
    "expanded_posts = pd.concat(chunked_result, ignore_index=True)\n",
    "print(expanded_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_posts = pd.concat(chunked_result, ignore_index=True)\n",
    "print(expanded_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_posts.set_index(expanded_posts['index'], inplace=True)\n",
    "sort_pol_posts = sort_pol_posts.join(expanded_posts['post_expansion'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_pol_posts.loc[10:, ['commentText', 'post_expansion', 'videoTitle']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data:\n",
    "sort_pol_posts.to_parquet(f'{CFG.report_dir}/pubsphere_pol_posts.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply generalized claim mining to get a list of claims:\n",
    "chunked_result: typing.List[pd.DataFrame] = []\n",
    "for index, row in tqdm.tqdm(sort_pol_posts.iterrows()):\n",
    "    try: \n",
    "        chunked_result.append(\n",
    "            pd.DataFrame(\n",
    "                data=[\n",
    "                    requests.post(\n",
    "                        'https://inf.cl.uni-trier.de/',\n",
    "                        json={\n",
    "                            'model': MODELsmall,\n",
    "                            'system': SYSTEM_claim,\n",
    "                            'prompt': f'The following set of social media posts are replies to a news- or infotainment-post. '\n",
    "                                    + f'Check whether your answer strictly adheres to the specified format. \\n\"Posts\":\\n<{row[\"commentText\"]}>',\n",
    "                            'options': options_zero\n",
    "                            }).json()['response']                       \n",
    "                ],\n",
    "                columns=['claims']\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    except json.JSONDecodeError:\n",
    "        print(\"invalid json response, skipping to next batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_df = pd.concat(chunked_result, ignore_index=True)\n",
    "print(claim_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#and what if we apply GPT4o to the same data:\n",
    "# dataset_claim_embeds[\"commentText\"] -> get political_post\n",
    "# -> get post_expansion for political posts\n",
    "# -> get claims for post_expansion\n",
    "# -> find diversity in claims and posts through SYSTEM_claim_simscore\n",
    "# -> get ADA embeddings for posts and claims\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3862it [37:18,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      index political_post\n",
      "0         0  non-political\n",
      "1         1  non-political\n",
      "2         2      political\n",
      "3         3  non-political\n",
      "4         4  non-political\n",
      "...     ...            ...\n",
      "3857   3857  non-political\n",
      "3858   3858  non-political\n",
      "3859   3859  non-political\n",
      "3860   3860  non-political\n",
      "3861   3861      political\n",
      "\n",
      "[3862 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#get political posts:\n",
    "#classify messages using gpt4o:\n",
    "run1 = ['political_post']\n",
    "  \n",
    "chunked_result: typing.List[pd.DataFrame] = []\n",
    "\n",
    "for label, path in CFG.prompt_classify_files.items():\n",
    "    if label in run1: \n",
    "        template = load_json(path).get('template')\n",
    "        classes = load_json(path).get('classes')\n",
    "        for index, row in tqdm.tqdm(dataset_claim_embeds[\"commentText\"].items()):\n",
    "            retry_count = 0\n",
    "            max_retries = 10\n",
    "            \n",
    "            while retry_count < max_retries:\n",
    "                try: \n",
    "                    response = requests.post(\n",
    "                            url=api_endpoint,\n",
    "                            headers=headers,\n",
    "                            json={\n",
    "                                'model': MODELgpt4o,\n",
    "                                'messages': [\n",
    "                                    {\n",
    "                                        \"role\": \"system\",\n",
    "                                        \"content\": template\n",
    "                                    },\n",
    "                                    {\n",
    "                                        \"role\": \"user\",\n",
    "                                        \"content\": template.format(text=row)\n",
    "                                    }\n",
    "                                ],\n",
    "                                'temperature': temperature_0,  \n",
    "                                'seed': SEED,\n",
    "                                \"max_tokens\": MAX10\n",
    "                            }\n",
    "                        )  \n",
    "\n",
    "                    if response.status_code == 200:\n",
    "                        data_response = response.json()\n",
    "                        chunked_result.append(\n",
    "                        pd.DataFrame(\n",
    "                            data=[[index, classes.get(data_response[\"choices\"][0][\"message\"][\"content\"], None)]],                                \n",
    "                            columns=['index', label]\n",
    "                            )\n",
    "                        )\n",
    "                        break  # Exit the retry loop on success\n",
    "                    elif response.status_code == 429:\n",
    "                        retry_count += 1\n",
    "                        wait_time = 1 + (3 * retry_count * retry_count)\n",
    "                        print(f\"Rate limit exceeded. Retrying in {wait_time} seconds...\")\n",
    "                        print(response.text)\n",
    "                        time.sleep(wait_time)\n",
    "                    elif response.status_code == 500:\n",
    "                        retry_count += 1\n",
    "                        wait_time = 20\n",
    "                        print(f\"Failed to connect to API. Status code: {response.status_code}. Retrying in {wait_time} seconds...\")\n",
    "                        print(response.text)\n",
    "                        time.sleep(wait_time)\n",
    "                    else:\n",
    "                        print(f\"Failed to connect to API. Status code: {response.status_code}\")\n",
    "                        print(response.text)\n",
    "                        break\n",
    "                except requests.exceptions.RequestException as e:   \n",
    "                    print(f\"Failed to connect to API: {e}\")\n",
    "                    retry_count += 1\n",
    "                    wait_time = 60\n",
    "                    print(f\"Retrying in {wait_time} seconds...\")\n",
    "                    time.sleep(wait_time)                 \n",
    "                \n",
    "\n",
    "\n",
    "classifications1 = pd.concat(chunked_result, ignore_index=True)\n",
    "print(classifications1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "political_post_gpt4o = classifications1.loc[:, [\"index\", \"political_post\"]].dropna()\n",
    "political_post_gpt4o.set_index('index', drop=True, inplace=True)\n",
    "dataset_claim_embeds = dataset_claim_embeds.join(political_post_gpt4o, rsuffix='_gpt4o')\n",
    "\n",
    "dataset_claim_embeds = dataset_claim_embeds.rename(columns={\n",
    "    'political_post': 'political_post_gpt4o'\n",
    "})\n",
    "dataset_claim_embeds.loc[:, 'political_post_gpt4o_dum'] = dataset_claim_embeds.loc[:, 'political_post_gpt4o'].map({\"political\": 1, \"non-political\":0}).fillna(0).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartDate</th>\n",
       "      <th>RecordedDate</th>\n",
       "      <th>IPAddress</th>\n",
       "      <th>Finished</th>\n",
       "      <th>Coder</th>\n",
       "      <th>ID</th>\n",
       "      <th>Mark_ID</th>\n",
       "      <th>Genre</th>\n",
       "      <th>topiccode</th>\n",
       "      <th>Platform</th>\n",
       "      <th>...</th>\n",
       "      <th>tfidf_embed_post</th>\n",
       "      <th>embed_MXBAI_post</th>\n",
       "      <th>cosine_similarity_post_claim_MXBAI</th>\n",
       "      <th>cosine_low_high_MXBAI</th>\n",
       "      <th>tfidf_embed_post_svd</th>\n",
       "      <th>Llama31_political_post_8b</th>\n",
       "      <th>Llama31_political_fill_8b</th>\n",
       "      <th>Llama31_political_fill_8b_score</th>\n",
       "      <th>political_post_gpt4o</th>\n",
       "      <th>political_post_gpt4o_dum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/30/2021 13:03:17</td>\n",
       "      <td>5/30/2021 13:04:17</td>\n",
       "      <td>62.194.51.29</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgyPHwv8G0cDE6-wEgl4AaABAg.8_0ZjJKSJty8_0kXGkAd2U</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.40566757321357727, -0.032418690621852875, -0.5345820188522339, 0.25060492753982544, 0.3237237...</td>\n",
       "      <td>0.960095</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>non-political</td>\n",
       "      <td>non-political</td>\n",
       "      <td>0</td>\n",
       "      <td>non-political</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/11/2021 10:34:05</td>\n",
       "      <td>10/11/2021 10:36:46</td>\n",
       "      <td>213.127.109.191</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Ugx2WXq9UdV8mPPjejJ4AaABAg.8yHCKV0Boe58yYRxEQEF45</td>\n",
       "      <td>282</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.49942252039909363, -0.22240903973579407, -0.4247226417064667, 0.18189606070518494, -0.0185961...</td>\n",
       "      <td>0.957984</td>\n",
       "      <td>0.991973</td>\n",
       "      <td>[0.9999999959466253]</td>\n",
       "      <td>political</td>\n",
       "      <td>political</td>\n",
       "      <td>1</td>\n",
       "      <td>non-political</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9/9/2021 18:49:48</td>\n",
       "      <td>9/9/2021 18:51:32</td>\n",
       "      <td>213.127.110.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1110578710648890000</td>\n",
       "      <td>372</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.6132397651672363, -0.3024018704891205, -0.6756535172462463, 0.33316466212272644, 0.2613784670...</td>\n",
       "      <td>0.967763</td>\n",
       "      <td>0.996136</td>\n",
       "      <td>[1.0000000354648362]</td>\n",
       "      <td>political</td>\n",
       "      <td>political</td>\n",
       "      <td>1</td>\n",
       "      <td>political</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6/6/2021 16:12:46</td>\n",
       "      <td>6/6/2021 16:16:16</td>\n",
       "      <td>213.127.76.145</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgwUPFScjJ0MCeaP2F54AaABAg.8lvp3fc9Euf8lvvgsUgEgV</td>\n",
       "      <td>769</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.27884048223495483, -0.3008716404438019, -0.48076391220092773, 0.6041528582572937, 0.336594045...</td>\n",
       "      <td>0.952258</td>\n",
       "      <td>0.992674</td>\n",
       "      <td>[0.9999999904984119]</td>\n",
       "      <td>political</td>\n",
       "      <td>political</td>\n",
       "      <td>1</td>\n",
       "      <td>non-political</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6/13/2021 13:25:49</td>\n",
       "      <td>6/13/2021 13:27:28</td>\n",
       "      <td>213.127.82.232</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgwWKCWtSJdFvjGHvTp4AaABAg.8kUC5dGrQ2H8kUDRihE2f3</td>\n",
       "      <td>1206</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.5210463404655457, 0.03200243413448334, -0.37679624557495117, 0.37940096855163574, 0.320245444...</td>\n",
       "      <td>0.977981</td>\n",
       "      <td>0.992789</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>non-political</td>\n",
       "      <td>non-political</td>\n",
       "      <td>0</td>\n",
       "      <td>non-political</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             StartDate         RecordedDate        IPAddress  Finished  Coder  \\\n",
       "0   5/30/2021 13:03:17   5/30/2021 13:04:17     62.194.51.29         1      6   \n",
       "1  10/11/2021 10:34:05  10/11/2021 10:36:46  213.127.109.191         1      6   \n",
       "2    9/9/2021 18:49:48    9/9/2021 18:51:32    213.127.110.0         1      6   \n",
       "3    6/6/2021 16:12:46    6/6/2021 16:16:16   213.127.76.145         1      6   \n",
       "4   6/13/2021 13:25:49   6/13/2021 13:27:28   213.127.82.232         1      6   \n",
       "\n",
       "                                                  ID  Mark_ID  Genre  \\\n",
       "0  UgyPHwv8G0cDE6-wEgl4AaABAg.8_0ZjJKSJty8_0kXGkAd2U      119      0   \n",
       "1  Ugx2WXq9UdV8mPPjejJ4AaABAg.8yHCKV0Boe58yYRxEQEF45      282      1   \n",
       "2                                1110578710648890000      372      2   \n",
       "3  UgwUPFScjJ0MCeaP2F54AaABAg.8lvp3fc9Euf8lvvgsUgEgV      769      0   \n",
       "4  UgwWKCWtSJdFvjGHvTp4AaABAg.8kUC5dGrQ2H8kUDRihE2f3     1206      0   \n",
       "\n",
       "   topiccode  Platform  ...  \\\n",
       "0          0         1  ...   \n",
       "1          2         1  ...   \n",
       "2          4         2  ...   \n",
       "3          0         1  ...   \n",
       "4          0         1  ...   \n",
       "\n",
       "                                                                                      tfidf_embed_post  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                                                                      embed_MXBAI_post  \\\n",
       "0  [0.40566757321357727, -0.032418690621852875, -0.5345820188522339, 0.25060492753982544, 0.3237237...   \n",
       "1  [0.49942252039909363, -0.22240903973579407, -0.4247226417064667, 0.18189606070518494, -0.0185961...   \n",
       "2  [0.6132397651672363, -0.3024018704891205, -0.6756535172462463, 0.33316466212272644, 0.2613784670...   \n",
       "3  [0.27884048223495483, -0.3008716404438019, -0.48076391220092773, 0.6041528582572937, 0.336594045...   \n",
       "4  [0.5210463404655457, 0.03200243413448334, -0.37679624557495117, 0.37940096855163574, 0.320245444...   \n",
       "\n",
       "   cosine_similarity_post_claim_MXBAI  cosine_low_high_MXBAI  \\\n",
       "0                            0.960095               1.000000   \n",
       "1                            0.957984               0.991973   \n",
       "2                            0.967763               0.996136   \n",
       "3                            0.952258               0.992674   \n",
       "4                            0.977981               0.992789   \n",
       "\n",
       "   tfidf_embed_post_svd  Llama31_political_post_8b  Llama31_political_fill_8b  \\\n",
       "0                 [1.0]              non-political              non-political   \n",
       "1  [0.9999999959466253]                  political                  political   \n",
       "2  [1.0000000354648362]                  political                  political   \n",
       "3  [0.9999999904984119]                  political                  political   \n",
       "4                 [1.0]              non-political              non-political   \n",
       "\n",
       "   Llama31_political_fill_8b_score  political_post_gpt4o  \\\n",
       "0                                0         non-political   \n",
       "1                                1         non-political   \n",
       "2                                1             political   \n",
       "3                                1         non-political   \n",
       "4                                0         non-political   \n",
       "\n",
       "  political_post_gpt4o_dum  \n",
       "0                        0  \n",
       "1                        0  \n",
       "2                        1  \n",
       "3                        0  \n",
       "4                        0  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_claim_embeds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data:\n",
    "dataset_claim_embeds.to_parquet(f'{CFG.report_dir}/pubsphere.claim_embed.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"That's a vicious insult!!! What did a box of rocks ever do to you that you would slander it like that? I represent the coalition for mineral rights. Minerals have rights to.\", 'I agree.  Maybe he was sending a message to his mistress.', 'President Trump made 8,158 false or misleading claims in his first two years ... besides his entire life, businesses, deals, have been a lie as well  .... should he apologize?', 'NPC-90210-RockTheVote   Heâ€™s getting his oil checked!', \"Gee, someone is upset that they are trying to give Fox a run for their money.  Don't worry Sierra, Fox still controls that niche.\", \"What are they being false about?  It's a fact that the military assets are being moved.\", 'Bernie is the most consistent and most  trustworthy progressive. Feel the Bern!', 'Dennis Manson Only wimps, perverts, and lazy men vote Democrat.  Which ones are you?', 'Melania\\'s body language is so stiff. I do not like her at all. What\\'s with \"be best\"?', \"USA Freedom Patriots made the Internet. \\xa0Why don't you go back to fucking donkeys.\", \"What I seriously don't get and leaves me shaking my head in frustration:\\n the USA doesn't want Iran to have nuclear weapons - which is understandable - so they made an agreement which Iran has never broken _once,_ then they  pull out of this agreement and start sanctioning Iran and every country which trades with them harshly - in order to archieve that Iran doesn't build nuclear weapons.\\nIn the process they hurt their already fragile relationships of their allies within the EU by dictating and threatening their governments. \\nIran is still upholding the Deal with Europe though and not building nw, and now Trump says that this country is such a great danger that they might invade? And there are people cheering to this decision? \\nWho pulled out of the deal in the first place? How do the people that want war not see that the USA is on the bad side of history here?\", 'Tulsi 2020! She is the only candidate in either party who is willing to stand up for people worldwide with her track record of service for our country and opposing the loss of human life and financial resources that mark regime change wars.', 'Hello? Why is the main player left out of this discussion. I can understand Bernie not mentioning Israel but Anderson? On second thought, I CAN understand it.', \"The Representatives should do what they think is right IMPEACH --regardless of their expected response from the Senate.  They should allow Americans to do what is right to the Senators who choose to  defend Trump rather than the country and the Constitution despite Mueller's findings and report.  The House should not abdicate its power to spineless Senators.  Let the Senators face consequences of their action come 2020 and   future elections.\", '@Joseph King You didnt read the report didya, Joe?', 'Are U really surprised. I’m not \\nOur own government rigged it.  He’s there because out government put him there.', 'Blah blah blah.      Blah,     hilarious..Anderson for once tell it as is.. we all can see clearly..\\nA Democrat asking Mueller questions...fairy dust on a cake....', 'Rod rosenstein wrote a memo recommended to fire James Comey!!!', \"I wouldn't have waited after the tankers were struck. When you were growing up, if somebody came up to you and sucker punched you, would you put them on notice or would you have broken their nose? At a minimum, I would have sank a ship!\", \"@Cranjis McBasketball He's not wrong. The radical left (not moderate liberals) are trying to fuck this country to death. The decent center-leftists are the umbrella under which these people are hiding.\", 'There are behaviors that thoughtful gentlemen and leaders employ. Even when firing someone. Our president is neither an \"officer nor a gentleman.\" Sadly.', \"@ClassicalMMAChef \\nI get it!  You can't read.  Understood.  Just send me $500 and I'll ship you Hooked On Phonics!  It may help, but probably not. You've clearly dedicated your life to being as stupid as you possibly can, and I applaud that.  It must be a lot of work to still be struggling to graduate kindergarten.\", \"If it's sound-proof so we don't have to hear that rotten pumpkin-man's yelling, then all the better.\", \"It's scary that some people still don't understand that we are a Constitutional Republic.\", \"Well why the fuck would you prosecute yourself?  That's a shitty use of power when you could have at the least drugs, sex, and money with that kind of control.\", 'Too be fair we in Europe are full of homophobic and mysoginistic crimes thanks to a refugee influx x.x', \"A lot of people are projecting her to be Secretary of Defense or Foreign Affairs which I can see why. But from what I've seen so far she would be a great president as well.\", 'Does anyone Remember the \\nConstitution of America?\\n\\nNo more Wars you Trump ??', 'Margie Nelsen   Do you mean pray for the lying draft dodger and traitor?', 'Mostly the GOP and most of his misinformed and ignorant base. I think it’s intentional and very unpatriotic.', \"@k b John Dowd, not McGhan was the Trump lawyer assigned to work with Mueller. Here's his take and he's just as stupid as i am-  https://www.youtube.com/watch?v=S1o8Ze4J81A\\nOr maybe we're both traitors to the U.S.  Cummings in the video above is blowing out his backside.  If the dems impeach they well be slaughtered in trial by the Senate. they won't impeach because they know this already and they are at least as stupid as I am.\", 'one thing proved for certain; the swamp is alive and well and full of fat barr creatures', \"@Fortis Fortuna Adiuvat .... I've never been for a deficit. You don't have a clue who I am ?\", \"Yeah. Democrats are so mature. Read all of their immature, vile rants on our Presidents FB page. It's like all they think about all day everyday is our Presidents penis.\", 'What I learned today: Vladimir Putin looks uncannily like Wolf Blitzer when you put him in a beard and glasses.\\n\\n\\n\\n\\n\\nOh and remember, licking doorknobs is illegal on other planets.', '@hepwo91222 you still hung up on the nunes memo?! holy shit~!!! how long ago was that immediately disproved?', 'Army force?\\nNeed to be teached a lesson?', \"Let's look at the middle East. Iran knows it has no win eith America. If America makes any move on Iran, what do you think there response will be? When you have nothing to lose, you go out with a big bang. \\nIran will light Israel up with the very language trump used on lighting them up.\", 'if we where not in everyones business just like all the other countries we wouldve been dead long time ago dont be so stupid I hate how people who have no clue make statements', 'We have been there for sometime, and nothing has changed. Bring our men and women home. You go and help them.', \"THANK YOU. The fear mongering and brain washing is horrific. It's not perfect in Canada, (there are always some people). However the big difference is that our PM Trudeau is embracing the refugees, and is promoting acceptance and equality. \\nI'm so scared for those refugees entering America now. I hope that more of them get to come to Canada. We would love to have you.\", 'Please explain what\\'s good about this guy. BTW, it\\'s \"countries.\" 45ers can\\'t spell. They\\'re illiterate like their president.', '+ZenRules - you have made that mistake in Afghanistan and out came Bin Laden. Assad was responsible to create IS, he supported them in war in iraq against your troops, he later was against htem but then released IS members out of jail. Assad never fought IS and IS fought against FSA and Kurds. Without Assad - no IS, that is the truth.', 'doug mckay So is it okay for you if one day native american and australia want their land back and kick out white people with guns and mortars because thousand years ago it is their land', \"They also used Australian passports and they weren't happy about it. The Australians called in the Israeli ambassador for a please explain.\", 'At least Obama wasn’t pen pals with Kim Jong Un while he murders his people in public executions.', '@Mary Murdock I thought he might be corrupt from envelope at funeral and just not saying much ,and Ryan PENCE letter before election,about a article 9 I BELEIVE not sure but close MAGA BLESS OUR PRESIDENT DONALD Trump and his family', 'Trump and GOP 2020.', \"@EL OEL so you're just going to ignore shillary sold 20% of american uranium to a russian company for $145 million paid into the clinton foundation?\", 'She would destroy him', 'John Bolton will not learn any lesson unless Israel is attacked by Iranians', \"@ILLMATIC2222 Yes, because he didn't cut spending as well.\", 'Syrian rebellion was not organised by west or saudi arab... It happened due to Assads brutality against protesters... Assads brutality made him unacceptable to Syrian people...all rebels are not jihadist...jihad can also be for freedom..christians dont think crusaders were terrorists', '@L they do. They\\'re just trying to bride their way and taking the black/brown vote for their party. Notice, also they\\'re the same ones who cheer when innocent black kids dies, claiming black people for killing the most and \"killing\" 80% + white individuals aka painting black people as the enemy and them as the victims, and the same one\\'s who support trump when he said black people are stupid and can\\'t lead a nation', '@Antonio DeJesus In fact, this whole investigation has become a massive clown show. Not a single shred of evidence to suggest the Trump campaign colluded with the Russians has arisen after months of investigating by multiple congressional committees. What we do know is that the Hillary Clinton campaign actually funded the effort that led to the Trump dossier, compiled by former British spook Christopher Steele. During the 2016 election, the Clinton crew retained the services of research firm Fusion GPS, who then hired Steele to gather information on this opposition research file. The same documents that were used to obtain a FISA warrant against former foreign policy adviser to Trump, Carter Page. Yeah, a partisan piece of opposition research from a political campaign was used to secure a warrant to spy on someone who had worked on the opposing campaign—all of this under the Obama DOJ mind you. In fact, as this investigation has moved on, we see less about Trump-Russia and more about the endless trip-ups at the FBI, namely the unacceptable levels of bias among top officials involved in some of the most sensitive investigations conducted by the bureau.', 'Not a single one of those people you mentioned has been verified as a Russian agent. Not. one. Yes, Manafort and Flynn have had to or are under pressure to register as foreign agents- but neither of them are with Russia. They\\'re UKRAINE AND TURKEY. And yes, there are questions of their ties with those countries being beneficial to Russia- but holy shit. You can\\'t even get that right.\\n\\nAnd yes, that is what Bush technically was referencing in those statements- but to use such polarizing language, in face of the nature of the Bush administration and US policy and everything else, was utterly deranged, and was endlessly derided as one of the most embodying statements of the horrors of the Bush administration. But now? Maher OPENLY SAID he wants the democrats to use the SAME LANGUAGE- and directly REFERENCING BUSH. And there is every fucking reason to view Maher\\'s statement in the same light. I wouldn\\'t even really know where to begin on how utterly psychotic the left has been over Russia, but a really good one recently is Maxine Waters, on TV, saying PUTIN came up with \"Crooked Hillary\" and \"lock her up.\" YES- ideas that have been around for years now in conservative circles were the work of PUTIN!!!\\n\\nAlso- Bill Clinton\\'s impeachment calls came from various things, such as- lying under oath about it, doing it in the WH while married and to a girl less than half his age, and of course, the pressure of all the other accusations that came out against him.\\n\\nBut yeah, I do think Bush was worse than that.\\n\\nAnd still nothing about all of the other shit you Russia hysterics support while claiming to care about TREASON!!!\\n\\nAlso:\\n\\n\"Stuart Penman Also, the chicago tribune is a conservative media, I would not trust a single word that is poorly written on its right-wing pages\"\\n\\nYou linked to fucking Salon.', 'Keep up the great work, you are not a cop hater, you are a patriot,  and a libertarian.', 'Christians will not replace us!!!', \"@Diane Hooper I'm probably older than you and he's the most unstable I've even seen.\", 'Thanks for the Liberal Slant.  CBS.', 'Chuck the schmuck Schumer, a creep all day long, news all day long!!! And Nancy pa crazy,!! She looks like the Crypt Keeper!!', 'Bad day for the Hamas terrorist bastard.', 'Date night with Trump', \"That's all TRUMP DOES, is LIE!\", 'I hate reporters like this lady...', \"@Trump's a pathological liar Prove me wrong < Mmmmm. Are you stupid because you're liberal or are you liberal because you're stupid?\", 'YOU KEEP TALKING TRUMP......KEEP DIGGING YOUR OWN HOLE, YOU HAVE BEEN DOING THIS SINCE THE START............SO CONTINUE.............', \"believe me that's not gonna be happen ever... at least not for Syria\", \"@BartJ583 or because comey doesn't know how to do his job\", 'Are you saying you\\'re willing to risk countless billions of dollars.. American lives.. another endless war over Israel... possibly ww3 just to \"appear\" strong for a moment in time?', 'Credible reporting?\\nI choose... NO.\\nSedition charges will put most of CCCPNN  \" reporters \" in Gitmo.', \"@socal rocks \\nNo what you're smelling is George Soros dick after ass fucking Anderson Cooper .\", 'If you want to see white male privilege, delusion and denial see 15:00', '@Zquadfather you sound like an Antifa punk!!!', 'We The People are not white supremacists, WE ARE RIGHT SUPREMACISTS. We have the RIGHT to believe in our CREATOR, our country, our countrymen, our leader, our constitution, our rule of LAW. We look like all the people you see world wide. You corrupt devil, and self, and money worshipers are the WRONG supremacists. You believe in lawlessness, drugs, alcohol, child molestation, drug trafficking, people trafficking, extortion, bribes. You have 4 rules, lie, cheat, steal. Audit EVERY city in this country and get this corrupt trash out of it. Your climate change is coming and is real. It is called the lake of FIRE. Know this. And enjoy that.@ROB112  You got it.', 'Matthew “Trump Deranged” Rodriguez  ?? ????? and ?', \"Can't anyone have him evaluated for mental incompetence...Not a Dr. Picked by him...???\", '@NPC Unit #84740695 what was so bad about the interview ? because Trump exposed himself as an idiot ...again ?', 'Yep, and we should start boycotting their sponsors, really kick them when their down.', 'Bill you gotta stop wagging your finger at liberal \"purists\" and Russian \"hacking\". Let\\'s take your argument all the way to its conclusion shall we? If Russia had not exposed things Hillary actually said and actually did; she could have lied her way into office and gotten away with cheating the real liberal in the race? I will concede that she is the \"lesser of two evils\", sure. But as you carry on about how unethical and dishonest Trump\\'s ties with Russia might be; how can your argument be that the solution is/was to give a pass to proven unethical and dishonest behavior of his opponent? Your analysis that Trump is the problem is incorrect. He is a symptom. The problem is that America is tired of corporate establishment and corruption and that is the embodiment of Hillary. It was for that reason that a snake oil salesman baboon fuck like Trump was even given a chance in the first place. Did we learn nothing eight years ago when the electorate was so tired of \"politics as usual\" that they went out in droves voting for a black guy with a Muslim name that people questioned if he was born in Kenya with almost no political experience and lied through his teeth and we bought it with a catch phrase \"yes we can\" which apparently meant \"yes we can remove the public option\" and \"yes we can bail out Wall Street and kick 10 million people out of their homes\" and \"yes we can support Nafta and TPP\" and \"yes we can bomb the Middle East non stop and include more countries to bomb\" and \"yes we can extend the tax cut on dividends\" and \"yes we can keep the minimum wage low and create more minimum wage jobs with no benefits\" and \"yes we can make the banks even bigger\" and \"yes we can continue the income inequality and make the gap even larger\" and \"yes we can continue the drug war and continue to explode the prisons with disproportionately black non-violent offenders\". Give it a rest Bill. People didn\\'t vote for Obama in Michigan, Ohio, Wisconsin, and Pennsylvania TWICE and then suddenly become racist. They voted for Trump on the off chance we wasn\\'t lying and would be something different. Just like they voted for Obama. And who the fuck are you to call those people misguided when I believed in \"hope\" and \"change\" and it was all lies and you, almost 9 years later, still can\\'t even see that? Hillary didn\\'t lose because of racism. Or misogyny. Or Comey letters. Or Russia. She lost for one simple reason; because of Hillary. Because she stood there and told people that have been getting fucked non-stop for decades that she was going to keep doing the same thing because it\\'s been doing great! If it was truly about winning the election; the Dems would have ran Bernie and won by 20 points. But it\\'s not. It\\'s about keeping the corruption going even if that means rolling the dice and losing to a clown. Because it was her turn and it was her right to be President? That Republican-in-a-pant-suit that\\'s cool with gay marriage and you can shove that up your collective asses, Bill. Does that make me a \"purist\" Bill?', 'The United Satan of America, in reality, is a parasite and an extortionist with its currency backed by nothing but pure tyranny!', 'All they want is to hide all their criminal activity! They are afraid of Trump!', 'I am a pagan. Last I looked this is fucking America and I have the right to FREEDOM OF RELIGION, BITCH', \"He backed down from attacking iran because putin told him to back down and to save donald con-chump's face putin sent the north seas flotilla to back up the bombers already in venezuela and cuba.\", '+Pllotrcm Being conservative is not a bad thing at all. Most soldiers, people who risk their lives to protect yours, are conservative because that mindset believes in protecting each other. Nationalism is why we have a Constitution that allows all of the freedoms that Americans enjoy. Nationalist economics is just another way of saying \"we want our own people to be able to succeed and feed their families.\" Communism and Capitalism are not the same things, but Communism and Totalitarianism are the same things. Capitalism is the only system that humans have created that is capable of giving equal opportunity to all people. All other systems are biased against subsections of society. No one can deny that conservatives are very partisan, as are progressives.', \"Truckers weren't the only ones lied to, but were certainly part of a majority of who fell for it.\", '@Eugene Osborn It\\'s even worse when you weight the impeachable offences. Slick Willy committed perjury... about a blowjob. Nixon ran a conspiracy in which the \"Plumbers\" broke into the DNC offices to steal information. The Orange Sphincter has committed at least two counts of Conspiracy to Violate Campaign Finance Laws... probably a lot more of which we\\'re not aware, yet... Conspiracy to Defraud the U.S.... Obstruction of Justice... and TRE45ON... the TRE45ON, by itself, outweighs everything the all Democrats have done, combined.', \"@MightyDragon i agree trump probably cares more deeply than any potus sense Kennedy. He's like Goldwater extreme for liberty. And he is effective. But as a liberal I disagree w his viewpoint on 70% of stuff. Please admit he says and does stupid stuff. I agree he is a wrench in a broken system. And we do need to stop and figure stuff out before we go full new world order.  Can you see that Trump has tendency to fascist racist rhetoric, sometimes. He is no dictator,  but it seems that way. Do you understand why liberals see that?\", \"America will pay for its sin's\", 'They need to investigate just like a Democrat would if it were Trump.   We need to put these socialist on their heels', '@Stella Sirman this is how dictatorships start', 'Impeach. I agree with Romney. trump is a traitor and a lying sack of sht.', 'the longer the collective stay silent, the more complicit they become', 'CONGRATULATIONS AMERICA YOU HAVE A RAPIST AS A PRESIDENT!!', 'Is it racist of CNN not listening to Van Jones saying it was a big nothing burger?', 'Either solidarity confinement or with the general population.', \"Russia didn't make me vote for Trump, Hillary did.\", '@Gary Anthony McLoughlin TX cuts were for billionaires', 'Demoncraps and illegal are above the law unlike us red blooded Americans.', 'Trump is among them because he knew John Bolton and Mike Pompeo history and he still put them in charge.', 'I wish Kellyanne Conway would disappear from television/youtube all together. I am tired of listening to her alternative facts, what I really mean is lies.', 'Another war for the antichrist gews.iran is on the list because there not enslaved by the gewish central banksters.out of 208 countries there were 10 countries not enslaved now were down to just a few countries left iran is one of them.jewliani is a lier just like every one on this devil box..iran refused the enslavement under the gew banksters.good luck iran.', 'Allows law enforcement to use surveillance against more crimes of terror. Before the Patriot Act, courts could permit law enforcement to conduct electronic surveillance to investigate many ordinary, non-terrorism crimes, such as drug crimes, mail fraud, and passport fraud. Agents also could obtain wiretaps to investigate some, but not all, of the crimes that terrorists often commit. The Act enabled investigators to gather information when looking into the full range of terrorism-related crimes, including: chemical-weapons offenses, the use of weapons of mass destruction, killing Americans abroad, and terrorism financing.', '1. why is the rest of the world praising the US? Why is the rest of the world (Britain and France) the first ones to do what we did\\n2. it was the syrian army we did the chemical attacks', '#Yang2020', '*Waiting US Attack SHIA IRAN & SHIA SYIRA KUFFAR* ????', '@Logical Conservative not seeing the hamburger one except on conservative \\'news\\'. \"A fraction of a percent\" hahahaha.  The only joke I\\'m seeing is you and your pathetic attempt at denial... err I mean logic.', \"@Frederic Bastiat \\nFirst off, you are absolutely wrong in your assumptions, that anyone besides trump's people leaked something.  trump and his pals that he gave jobs to, have been giving national security information to everyone they can.\", \"I bet you Trudeau looks his barber in the eyes when he's getting trimmed up...\", 'Mueller is evil, deceitful and unethical. He has lost all his prestige, and his respect and yet totally unashamed...\\n> his licence must be revoked... and so be debarred as said by diGenova...', 'I am happy with my stock market now...Democrats are bunch of parasites.', 'Prejury  charges coming soon. See my comment. You will find it legally binding.', 'Science is a trick of Satan to take away your guns and end Christmas.', 'The only \"Green\" in Cortez\\' \"new green deal\" was the green dollars she and her crooked campaign manager were stealing. He\\'s gonna have to sell her out to save himself.', 'Zionist super fascist apartheid regime terrorists are not just ruining our country, but the entire world', 'Good propaganda for the warmongers', 'Thanks Tulsi for being anti war, we here at msnbc are profiting of all the wars so we cant actually be against them or we get fired', \"Who else is tired of Republicans like Rudy telling sociopaths like Biden and Hussein to be ashamed of themselves?  It's embarrassing they pretend they don't realize shaming isn't the answer, imprisoning them for weaponizing the executive branch and breaking the law is the answer.\", '@TheLogical Lowdown yet your president is controlled by zionists jews? ironic aint it.', 'Sweet! (☆^ー^☆) hopefully we can go in and take soms more oil ? America is great ?? we can take whatever we want :D', 'So you want to talk about lies?? LMAO. \"OOOK\" you attack his poor grasp of communication and exploit it. Meanwhile causing ACTUAL divide and real problems with BIG lies.... Trying to get us to care and take notice about some pointless Symantecs. You created more hate and violence in leftist fenatisicm by insisting he is some evil racist, than he ever did trying do promote boarder security.... Hes a bit of a fuk up ih a few ways for sure....but nothing on the mass scale of manipulation and social division that you and the rest of the George Orwell, erm i mean Soros media, have brought to fruition.', 'You can hear the mockingbirds as the flock from the deepstate offices to the studios at the mainstrwam news. \"Caw caw\" to just straight Caca', 'You lost me with this video, shame... thought this show is smarter than to join in propaganda', 'Just more evidence that we have an idiot in the White House.  That the Trumptards will never see.', \"Yes...there it is, no collision or obstruction. He brilliantly counter the interviewer. It's the alternate version broken down that's barely reveal on MSM with few exceptions like today. Lol. Other bureaucrats and politicians who are lawyers are racking their  rains for different narrative or National Enquirer story to oppose and hate this President. Unfortunately for many of us the wording is all legalese talk common only to lawyers. Rudy layed it out despite interference from the interviewer. Rudy did the same thing with Jake Trapper with CNN.\\nPeople shouldn't worry too much it's a means to their end and also entertainment. Problem is people believe or think they're being or playing a part with the government and they're not. Everyone take care of your families and seek a higher spiritual realm, nothing to do with religion....Peace\", \"@Beachdudeca You miss the point!   It doesn't matter whether Trump was actively working WITH Russia, or not!    He clearly is compromised by his own conflicts of interest!    He wants to build a Trump Tower in Moscow!    He can't do that without the blessings of Putin!    Therefore, he isn't going to say or do anything against Putin!   That is unacceptable in a President of the United States!   And, on the other side of the coin, Putin knows that Trump needs his blessings AND that helping Trump into office would allow Trump to DO things to EARN his blessings - like lifting sanctions on Russia!   These things make it imperitive that Trump be removed from office!    How can you be so gullible and stupid as to not see this as clearly as I do?\", 'Just go back and watch this arsehole during the Iraq invasion in 2003 he was basically having an orgasm he loved it, tucker carlson is the  only voice of sanity', 'Pay  attention snowflakes and demonrats . These guys do not agree  completely . They remain civil .', 'Why are the real news giving this P.O.S. air time? Better off showing reruns of romper room.', \"@YS S I didn't say they were.  Clinton was interviewed for about 12 hours and they found no wrong doing.  Don't care about Flynn.  Yes - illegal aliens are above the law - if they come from Mars.\", \"@Gilberto TX USAThe caravan is hype. They stopped talking about it after the election, really you are being conned. The wall is also bullshit, Border Protection themselves said surveillance is much more effective than any wall. Trump himself doesn't believe in the wall anymore but is just pushing it because he thinks it gets him votes. Apparently by your post it does.\", 'TheChiefEng- \"Last time I looked, I did not find a country called USA in that part of the world.\"  Look again . . . it\\'s called Israel.  And there is no doubt who the real terrorists in the World are:  Trump and Netanyahu.', 'american news networks are a joke..', 'The FBI bias has along with some of the media and bad democrat has destroyed the USA.', 'The average & leading Westerners don\\'t mind letting the whole World\\'s dirty people molest their girls & terize them, even in their own nations as long as hatred for other cultures can be bred or generated..whose better and best people are sought to be devalued and mistreated their whole lives by Westerners who don\\'t like seeing higher quality foreignors that they need to abuse and treat like Jesus, Bruce Lee, or Martin Luther King jr....also..on boats....& on private jets paid by American dollars....w. armed bodyguards & private jets standing by, -but..it is only Iran & those who don\\'t respect dishonourable behaviour, -who never hurt them in any way, that are treated like, -& considered as \"threats\" that have to be starved to death, beaten, & broken for their whole lives similar to how Jesus was treated and his Palestinian people are still treated today by the illegal immigrant land thieves sent by Westerners & armed with the Nukes that they constantly blame and terrorize others for supposedly trying to develop, who pretend to be Jewish & religious, -when they\\'re not claiming to be \"secular\", -since the leading Westerners, & their profiteering cronies, expect anyone more civilized, worthy, intelligent, attractive, & decent than themselves to simply not be allowed to exist....lol   They should give up their COWARD-NUKES that can never have any real or positive use, learn how to wash themselves, & agree to have their programs monitored if they\\'re serious, truthful, or claiming to be so good as they act like they are....accusing others for all your own actions & cowardly ways or existence only proves who\\'s wrong and unworthy!      https://www.youtube.com/watch?v=zIbQWW3HUhE      https://www.youtube.com/watch?v=ILy8CYpo_RA', 'OMG the dude is in total denial of FACTS that Rudy is giving him. Literally does not compute!', \"For sure they've committed a crime. It's always ironic how they pretend that's the way to have money out of politics and all that crap, when they're really just the exact same. Pathetic New Green Deal aside, these people are crazy.\", 'The report would of never seen the light of day if the GOP still controlled the house.', 'They made money with all the stuff they got from Manafort lol', \"Dedalus69 \\nYou still don't get it, aren't you?   Sure, according to you, Cohen sent to prison for 3 yrs with NO CRIME, isn't it?   If you don't see any problem, you are either being AMORAL, or have a sociopathic trait.  Only sociopath could defend other Sociopathic criminal.\", 'Kamala asked a non specific question and she is rude and arrogant.', \"You said it best, but at this rate I believe Trump supporters do not care about morality. No individual is innocent of all things but a person's character means something.\", 'Fake news fake news fake news all bullshit!!!!!!    CNN sucks.  CNN doesn’t care about America!!!!! Look at the numbers, unemployment rate all time low!!!!', '\"Innocent until proven guilty... and dont worry, you WILL be found guilty\"', \"Are you people aware of the fact that we can all look into this on our own? This is why the public doesn't trust the mainstream media. You are all disgusting, America hating, bias hacks. How bout you people start reporting things that actually affect the American people. You know, news?\", \"He's gonna kill brown people jus like Obama and Bush did..\\n#DeathToUSA\", '@Duece Momm funny how you democrats started the KKK', 'why are people who voted for trump so stupid?', 'Trump tweets sound like the way Stephen Miller talks... hmmm...', 'Damage a great nation, just for ratings. THIS, is CNN', \"Democrats will never win again with this kind of mentality. I'm sure it makes them feel better though, especially since there's a particularly bad boogeymen man on the other side right now.\", \"Trump learned how to answer questions off-the-cuff from that 'The Iraq and such' lady.\", \"Liberals got their a@@ KIcked this week! LOL It's a wrap, Trump has 4 more years. I now believe the fake news chant. Can not spin it, Liberals are dirty and evil spirited.\", '@Dana Herron wow, when you put it that way I get it now. How am I, Just a lowly bafoon to question your higher understanding and intelligence. You do have a much deeper grasp of world issues than I. I see now that I was wrong and why you didnt bother wasting any time giving any explanations as insulting people will do the job and they will understand why they are wrong. I really appreciate your words. I am going to go get lost now and try to lose my passive aggresiveness and my moral high ground on the way. Thank you for pointing out my pompous demeanor as well. Thats gonna get gone too. I hope to come back equally as intelligent and wise as you. Thanks again comrade.', '@Meh Gusta\\nThey have left the cities. Over 9 million Syrians have fled the country.', \"I shouldn't have to be...accusations should be substantiated...but libtwats never do.\", 'Amazing Hasan, he really hits the issue head on.', '@Justin Little sorry he was rased ny kkk daddy you open your eves', \"@David tinch No. Like I said in three original comment.  CNN and their fascist followers call them lies.  Normal people understand he exaggerates to make a point.  Like everybody does in the real world.  You lost.  Get over it.  Or don't.  Whatever.\", 'Uneducated are at least not CORRUPT IVY LEAGUE SCUMBAGS! Nice going with the educated Dems and their Mueller Bomb... eeeehhhheeeheeheeeh.\\nGood luck with that Huge Brain of yours! I have a BBA. .. btw.', \"Don't worry Barr will do the job and that's what Democrats need to worry about!\", 'NO. You wanna know what\\'s HYPOCRISY? In 2007 when Bush was president and the conservative media (led by Ann Coulter) said there was no need to pull out of Afghanistan because things were going \"swimmingly\" (Coulter\\'s own words). Then six months after Obama became president, suddenly the Teabaggers were saying Afghanistan was a disaster, that it was \"Obama\\'s Vietnam\" (again, Coulter\\'s own words).', \"@AJ \\nTrump fires the guy who violated all the rules to make Trump president, and you think it isn't fishy. Alrighty then.\", 'Kamala ? harris', 'Watch and see. It is not easy to identify them, besides all of them cover each others back.\\nFor President Trump, only time and working with them can tell. \\nDont you worry,POTUS is smart and he gets things done, sometimes the preparation time is longer than the real act.', \"There need to be psychometric tests for all public servants. There are psychopaths and serial killers in suits who get off on murdering thousands and thousands of people. I think Bolton is one. Remember 'war lite'? Yeah right. Total freaking disaster. Then after they totally mess up the region and create hundreds of thousands of refugees they will start complaining about immigration.\", 'This is just Fake news and CNN is just bullsh/t.', 'First Unindited felon president in history a new record', 'It must be so hard for these professional adults to take orders from this petty imbecilic child', '@RC Hobbyist Extreme rightttttttt...', '@Pragm Aticamente \\nI already know why some former Obama voters voted for Trump. And I would never call the 2016 voters \"White Supremacists\" or \"NeoNazis\". In 2016, you could have all kinds of reasons why you would vote for Trump, and a lot of people thought he would change in office, that his disgusting behaviour on the stump was just a persona to win votes. -->\\n\\nBut the 2019 Trump supporters are just that - \"White Supremacists.\" There are no doubts about who Trump is anymore. Also, keep in mind that \"White Supremacist\" is not a synonym for \"NeoNazi\" or \"KKK-member\". A White Supremacist is simply someone who thinks that white people are a little better at running things. That is all. Some of them are raging racists to be sure, but most are just narrow-minded.\\n.', '@Mr. Autistic Atheist ye yes horrible cuntry ...they don have a right to exist ....we don need no stinking iran ...syria is over .....we get to bomb a new cuntry ....SOMEBODY new for Israel!!!!!!', 'So are republicans blind or what? I mean did we not read the same report .. that report was pretty damn bad. Like did you people not read it because it shows clear obstruction of justice at the least .. this was more clear than oj', 'What has Trump done to obstruct anything, how has he tried to impede anything.\\xa0 The truth about what really happened https://www.youtube.com/watch?v=P4gx6KfZCss', 'Donald Trump plays tennis and he is a lard arse.', 'Janet Masiello Well when he puts people down who are in the military it is a shame. He also said that his military school gave him military experience? How funny is that? And people bought it.', 'Schiff needs his damn ass kicked real nice like .mama wont recognize her twat son anymore.\\n   He deserves the absolute worse', 'Anyone still supporting Donald Trumpolini today should have their voting privileges revoked. #idiocracy', \"18 years is long enough. I loath Trump as a person but if we withdraw before the 2020 elections I'll vote for him\", 'My guess would be Beto wants the weed legal true?', 'I feel like she understands a lot more than most Democrats she knows Israel pressures us into foreign wars against Islamic nations.', '@Max Covfefe should not be no prison time.\\nNeeds the rope time at the National Gallows Mall.', \"@karen doyle You can fix a typo, good for you. Here's a biscuit. Keep at it since spell check seems to be nonexistent (you must be Betsy's star pupil). You generate typos faster than Tiny spouts out lies. Don't be too stupid. Tiny hates competition.\", 'Let’s bomb the chemical compound and release the chemicals. You think we are stupid.', 'Iran can pin point their ballistic missiles and blow your sick head.Mr.Rudy Giuliani .Rudy you are rascal and a cheap shot.', \"WAR!.....................WHAT IS IT GOOD FOR? ..........ABSOLUTELY NOTHIN'!\", 'If Christians conservatives see Jesus  as a refugee they would probably reject him.', 'Liberal Privilege is stronger than white privilege.  Just look st smollett.  Spread if u agree', '@edgar valderrama and as of today you can add article 3 of the Articles of impeachment to the list.', 'Tracy Cohee you’re misinformed sweetie. This is why voting should be left to the adults. This Russir thing wouldn’t be as big a deal had the president not lied every step of the way. Had he just said “yeah I met a couple of people a couple of times but then I stopped for the election” he could have saved face.... but he lied about having ever spoken, thought, heard, mentioned any of the above. “Leave Flynn alone” there is your smoking gun. The president directed Comey to not investigate Flynn... do you recall? This was before the rest of the world knew Flynn was a guilty foreign agent. This would imply that the president KNEW about what Flynn had done and tried to influence an investigation. Then he Fired Comey.... hmmmm odd to say the least. The writing is all over the wall honey.', 'rastaewabeach hey didn’t you all rush worshippers say that when Obama was president?  Hypocrite much', 'But the enviroment everything thats humans are doing is wrong THIS MUST BE STOPEd', \"Do you know how many children the USA have murdered in Iraq, Afghanistan, Libya, Syria, Vietnam ? Conservative estimates are around 2 million.\\nBut that's OK because America did it, and they are always right.\", 'Hasan making Internet great again with these dam amazing episodes', 'Does anyone else think the whole story isn\\'t being covered here?\\nHere are the issues: China\\'s supply chain, tariffs, currency manipulation, intellectual property theft, WTO status...Trump administration approach:\"blunt big stick tariffs\" to negotiate all this crap you just brought up. \\n\\nWhen I see fake Nike\\'s and Rolex watches coming out of China I can\\'t make any connection with US businesses being there at all. Lindsay said, \"...you are required to have a Chinese business partner when you do business in China, then they steal all of your stuff.\" Now, how did he lead into this conversation? It\\'s a global economy: He\\'s happy we are there doing business, lots of customers.\\n\\nLet me offer one small anecdotal example: I want a widget made for my, I dunno, Toe Jam Depilator. China can bid on making them, beats everyone else and what happens next? My Toe Jam device shows up in America under a different name, by a different company and now I\\'m losing out. I know, get Trump to use tariffs to protect me in the future. Make any sense to you? What about Apple I-phones? Their parts, in piecemeal fashion, are made all over the damned globe and assembled where ever that happens. Trump\\'s solution: Make the whole phone here in the US. Okay, let\\'s get that ball rolling, snicker, snicker.\\n\\nIn other words, make up your mind. Do business with China and deal with all the permutations of unfair practices or go to war with China, using tariffs, and see who wins. Who wins or loses? Depends on who we vote in or out in 2020. China is literally and figuratively banking on it: We luv you long time America! Bye, see you soon! Snicker, snicker.\\n\\nLet\\'s not even get into the deficit when tax cuts to the rich (not just the 1%, corporations too) amounts to someone peeing in your face while calling it rain. Especially when \"entitlements\" are pet peeves of the Republican party, not defense spending, lobbyists or the healthcare act they keep wanting to repeal or hobble.', \"@Harman Virk That's scary. This dumbass is teaching the next generation...\", 'Bashar Alassad are fucking you in every time', \"That is the white helmets job, to drop the chemical bottles at the same place of the Assad's air strikes.\", 'Pelosi was just wondering when she was going to get another bump', 'Looks like we have better internet connectivity in India than in USA', \"In your dreams, bubba. Trump won by a mere 11,000 votes in Michigan. In 2020 he'll be out on his portly ass.\", '@Richard Owens it does matter,  that\\'s the entire point of this investigation... \" you have nothing!\"', \"Adam and eve rode dinosaurs and the atmosphere is a Chinese conspiracy to take away your guns and end Christmas. Obstruction of justice isn't a crime if you say it fast.\", 'Trump is a great president.', \"Iran will be suffered an international attack from the west if refuses to release the UK's tankers.\", \"I am not so sure any more.  When I look back at some of the actions he has taken...   I just cannot decide whether the President's actions are accidental or purposeful.  I am not seeing any benefit to his actions, and all we are getting is the negative.  My mind is starting to change on him.  I never thought that I would say that.\", 'Mr Cummings IS truly a blessing, I hope people PAY ATTENTION & CARE!!!!', 'You just need to read the history of the jews. How no culture or civilisation anywhere at any time in history liked them. Since the year 250 A.D., the jews have (by their own records and count), been expelled from 109 countries.  Let\\'s see, 109 countries, 109 people\\'s courts, 109 guilty verdicts, and 109 cries of persecution. Jews have claimed over and over at every opportunity that they have been \"innocent victims of anti-Semitism\" time and time again. That they\\'re always portrayed  as being  \"liars, crooks, thieves, hoarders, deceivers\". \\n\\nThe people of the United States have been sheep, and the jewish wolves have been devouring us since the establishment of the Federal Reserve in 1913. JFK, the USS Liberty, Robert Kennedy, Johnathon Pollard, stealing nuclear material from the US,  9/11, Afghanistan, Iraq, Libya and Syria. They have been shafting America with the help of duel citizenship & controlling high government positions that puts israels interests FIRST, making us go to wars.', 'Look at all these people in the comment section being outraged and screaming for change, but we all know they won\"t go out and vote or protest to make a difference cause \"what can one person do\" and...\"OH, A VIDEO WHERE A GUY GAVE A CAT A HUMAN VOICE! Thats funny!\" *click*\\n\\nAmericans are just too lazy to ever change anything.\\n\\nAnd before you type an angry response, proving me right, use that energy to go out and vote, protest and educate.', 'Just let it go. You already lost credibility with this report proving nothing happened.. Just report the facts or else youll lose even more people to Trump in 2020. Stop proving Trump right!!', \"@Jeremy that would be great cause you'd be the first to go\", \"@andrew chambers proving again that trump supporters are hateful people. Nice people don't want to see anyone's tears.\", '@The Mean Arena \"normal\" law enforcement already has military equipment', 'Ups! Original link was censored, but not worries go to this site:_x000D_\\nchange punt org/p/free-julian-assange-before-it-s-too-late-stop-usa-extradition_x000D_\\nor go to my Channel- playlist:  Trump - \"I LOVE WikiLeaks”!! _x000D_\\nand sign the petition. If you wish to help Assange further copy the original link of the petition, from my playlist, and posted it again please. _x000D_\\nSpread the Word S.V.P. Thank you. _x000D_\\nUnited in Solidarity for Julian Assange.', \"@Justin Little Backatcha. Stop supporting Putin's Puppet in the White House. The coward and dictator wannabe who cozies up to murdurous dictators because he wants to join the club. And spits in the fsce of our old allies and friends. Who has no respect for our Constitution and system of governmemt. Who operates like a mafia don installing he\\nenchmen and threatening those who speak up against him. You support Trump? You are a treasonous rat.\", 'Israel has been riding Americans like a horse for long long time for her interests', 'yea in trumps favor', 'muttley hehehe yet you ignore Hillary who confessed to colluding. ??\\u200d♂️', 'HANNITY IS ONE OF THE #1 PRODUCERS OF HATE SPEECH! FACT!', '@Lindsay Johnston I got as much faith in congress as I have in the FBI which is zero%.', 'Why USA drone was too close on Iranian border ? \\nAre Iranian drones coming close to USA borders?. Keep away and will be safe\\nWhat a bullying crap', 'Fox is literally brainwashing people. It is literally state tv. Trump is compromised and he show why again yesterday', 'Wow liberal tears', \"@CNendExactly! He'll have a guest on there that starts to make a great point, then he interrupts them and shuts it down. So irritating!\", \"@Rod Brewster  bro it's hard to take anything you say seriously since you believe in silly Russian hoax. They been illegally spying on the man for 2 years they have no evidence of a crime let alone trump commenting 1.\\nThey have mountains of evidence of them illegally spying on him!!!\\nPs. I'm black so calling me a racist isn't going to help with your delusion my friend.\", 'just because youre not guilty of treason doesnt mean youre not guilty of treason? do dems just like losing elections?', '@Recluse Spider Search on YouTube Clinton Foundation Oversight, you will find it.  It started today.  I agree, but true crimes are hidden fake crimes are on CNN.  NOT cool.', 'Libtards. Libtards everywhere.', 'if you actually take time to watch the actual hearing you can easily see how biased mule face is by how concise all his answers are when answering democrats compared to how dodgy he gets when answering republicans.', 'Hey blockhead Hannity, maybe you can share a cell with your penpal manafart', 'Donald Trump Benjamin Netanyahu John Bolton and the fake prince of saudia Arabia should be standing in front of a firing squad...', 'When Nancy Pelosi flies on military junkets she send her liquor bill to the taxpayers.  The self importance of our deep state knows no bounds!', 'except trump does not have permission to concoct his own stories  at cnn  like he did with the enquirer..', 'Gabbard/Harris or Harris/Gabbard ticket would be one good looking one! :)', 'hagar2025 blood sucking corporations and a greedy government', 'Arrogant, psychopathic, and narcissistic describes Trump perfectly, sweety. I always love coming to Fox News comments, I always leave with a renewed sense of confidence of who the ones on the wrong side of history a are.. confused people like you.', 'Im disappointed in americans.  I thought law, order and good sense would somehow prevail.   Now it depends on 2020 and the people.   \\nIm concerned the gop and trump will cheat again and keep trump in office. Maybe even for a third term.  Why not?  Whos going to stop them?  Adam schiff?', \"Why don't you ask them why the rich gulf states next door won't take them in\\n\\nGo on...ask them\", 'You were too stupid to realize that he ALWAYS was a warmonger?', \"It's the congress' job to get rid of 45 not mueller. Heck democracy in the US is failing and you expect mueller to sacrifice his job and for what? These people even got a molesting drunken in the highest authority next to the president and the senate. Nixon resigned cause a couple of people did the right thing and didn't protect him. This time it's different. No one of real importance is talking and he's handing out pardons like sweets! He's even talking about pardoning himself in advance and nobody's standing up to him. It looks as if he CAN get away with murder. Why are you picking on mueller he's not Jesus and doesn't have to pay for other people's sins!\", 'Fascism (/ˈfæʃɪzəm/) is a form of radical, right-wing, authoritarian ultranationalism, characterized by dictatorial power, forcible suppression of opposition, and strong regimentation of society and of the economy, which came to prominence in early 20th-century Europe.', \"Jim Myers  -  That's exactly what he will do.  Staying in office is his ONLY chance at not going to jail.  That's all that matters to him.  What better way to make that happen then by making his stay at the WH permanent?\", '@Michael Armstrong How so? Burden of proof is on the person dismissing the claims :)', \"Don't put him in jail,send him to the battle front. He will turn to a mouse.\", 'CNN is disgusting...but...2nd Amendment...it is better this way, despite their nastiness.', \"THIS IS FAKE NEWS.\\nTHERE WERE THOUSANDS OF PEOPLE IN LONDON WHO MARCHED IN HIS FAVOUR. THERE WERE ONLY SMALL GROUPS PROTESTING WHO WERE ORGANIZED.\\nTHE CAMERAS ZOOMED IN TO MAKE IT LOOK BIGGER THAN IT ACTUALLY WAS.\\nONE BUSINESSMAN EVEN CHANGED HIS PUB'S NAME TO TRUMPS ARMS.\\nCNN IS WELL KNOWN TO BRING FAKE ANTI TRUMP PROPAGANDA.\\nTRUMP RULES\", \"@Mike Rogers Obstruction of Justice .... Oh, I forgot you are so retarded you can't define what obstruction means... No worries, you'll learn !\", 'These Dems are totally deranged and they will not win! If they did, they would tear up this country so bad it would not be recognizable anymore?', \"Can anyone believe that Trump, who knows the best words, would know of and be able to use the word 'proportionality' in a grammatically correct manner?  Someone else told him the reason not to attack Iran.  Trump is not in control of the government it is the people who manipulate Trump that are really in control.\", 'Unbelievable your statement is ,the president of the USA is worrying about 1minor aspect happening in the country while over 300 million people are dependent of him yet his cherry picking and macro-managing the company (USA) he supposed to run,his actions and taught process is evidence in an ongoing criminal investigation subjecting him,the man is clearly not fit to serve.', \"What make him to decide apart from Trumb. Trumb I's the president. It like he is apove the president.\", \"No they wanted Hillary that actually helped Russia build it's fancy new ICBMs now with more decoy warheads just in case defense systems are more capable.\\nGo Hillary!\", 'Lol, How would you feel if you found out that Trump made a living screwing over contractors like yourself?', \"Hoooold on @Aussie Jim, distinguishing between Communism, Socialism, and Fascism is a matter of details these folks can not be bothered with. They wouldn't know a narcissistic, Fascists, autocrat if he held a rally in their backyard and shunned The Free Press, Separate but Equal Branches, and First Amendment Rights of Free Speech. Whoops, just read your last sentence or two. Carry on.\", \"Someone got to police the world. Iran should stop enriching uranium and threatening the US. They should also get out of Yemen, stop fighting proxy wars etc... Iran has been taken over by extreme religious nutjobs. Checl the country out in the 70's. It was a complete different place.\", 'I’m not going come here and sing Trump’s praises but you guys realize Maher is going Alex Jones/rush limbaugh on you, right?  This video is a nonsensical rant against a failed messiah, nothing more than a therapeutic exercise. \\n\\nLet’s put to rest the conspiracy theories and get back to the issues.', 'This is nothing like Irak, because the allied forces only targeted chemical plant, and there is no sign of intervention in the civil war...', 'Mueller is a Republican.  Should have guess so much!', 'From 5:25 -- Extra good stuff.  As a \"cherry on top\" it should put an END to automatic \"the honorable/Your honor\" BULLSHIT that we are coerced to lay upon \"high-level\" \"legal\" \"experts\"!!!  I\\'ve HAD it!  I\\'m just \"doing my time\" until my deliverance from this horseshit, dumbass \"Earthly plane\".  That\\'s it!', \"I'm reading many of these comments. Many Fake News polluted minds here.\", 'Theres a few states doing well.lots of states that are in poverty..\\nSo the unemployment stats must be bullshit...', \"If it's true what you say, why not release the full report without being redacted? After all one thing is clear, he who owns nothing, fears nothing. It is clear that there was something in that report and that's why they don't want to disclose it.\", '@EveryDaffodil53 Warrmonger scum!', '@Trump for Prison 2020 LOL LOL LOL', \"+Vince Miller   Your welcome.  I'm a republican but was rooting for Tulsi the whole time.\", '@jessica cisneros you leftist have turned into Fucken rude disrespectful human beings which brings the bad out in us level headed folks', 'So Trump is guilty of at least one charge Cohen went to jail for.', 'Back ground checks ate getting Americans killed. End all background checks. Open carry your AR-15 to to Wal-Mart.', 'This is probably the only case where I can accept the term \"toxic masculinity\". Not in the feminazi sense of \"OMG, he has his knees APART!\", but the common sense of a testosterone overdosing, overly aggressive, hyper masculine, degenerate skinhead neo-nazi.', 'Publicly Exterminate Trump', 'Trump lying PoS', 'It would have cost less to just fly a B-52 over the targets and carpet bomb the living daylights out of them.', 'That drone is a long way from the US.....just wondering what would have happened if a Iranian drone was flying near the US coast. ie...it deserved to be shot', 'They know because 17 US intelligence agencies say it was Russia. It may also be worth noting that all the Republicans agree with them (with the possible exception of trump)', '@Helen Russell\\n\"Being French is a state of genetics.\"\\nOkay, I\\'m out.\\nFrance, of all places. Who invented the Nation as the community of all people within their borders, and had quite a revolution about that sort of thing.\\nRegarding your African-ness: Swap \"English\" for \"quasi-Dutch\", and you get the textbook definition of an Afrikaaner (i.e. a white South African) - who are just that, African.\\n(Incidentally, about half of Africa _are_ Christians.)', '@Achish of Ziklag ,. Israeli is a nationality, not a race or a religion.\\nGet an education, fool...lol', \"Y'all couldn't get John Dickerson to interview Trump?\", '@David J  You have nothing, little liberal beta male. Your precious Mueller report FAILED and now you little soy boys are crying like school girls. Loser.', 'Wow!  So many NPCs in the comment section.  Orange man bad', 'Our federal government is INSANELY corrupt!', \"State bars are self-regulating and have numerous professional responsibility rules to ensure transparency and accountability. Arguably, some district attorney offices have better systems and guiding principles primarily based on state law and district attorneys. I enjoy this show and enjoyed this episode but it would've been better had John Oliver at least mentioned the overwhelming % of cases that are properly handled, and discussed which states tend to make more blunders.\", 'Tulsi is fantastic and much more qualified than Biden and all the other hacks...why is america putting her down for being honest??', 'why must war??', 'Trump IS a Dope and his cult is as Fucked up.', \"Aaaaand as per Bobby Mueller's SOP he immediately walked back his claims the moment he was questioned about them in the following hearing...this is what happens when you stuff words in to the mouth of an OBVIOUSLY senile old man LMAO he probably forgets what is is he has said the moment his breath runs out.\", 'Wow, it just keeps coming out...and Trump is supposed to be the leader of the free world ??? what a disgusting piece of work', 'colquitt74  You are so confused. His days are numbered? So are you implying he will get impeached? Ok what facts do you have? The same that has been reported? None. Stealing money? Again what are you talking about? It is his right as elected president to claim a national emergency and allocate funds as he sees fit. It’s in his power. You claim “ he know” so now you know what  the man knows and thinks? You have no clue what he hasn’t done for the military. Have you served during his term?  Probably not.', 'He doesnt trust the Senate, because he knows that they have been bought.\\n\\nTrum cant be bought. He does the buying. \\n\\nViva DT.', 'Trump 2020', 'When we actually had a decent president. You must miss Obama. ?', 'I find it funny that CNN is calling some a liar. Trump said that he only saw a small crowd of protesters. Which could be true because the British Royalty has been keeping Trump way from the protest. CNN doesn’t show video of the supporters', \"Have you seen this you tube video? 'House Oversight Hearing: Financial Investigators Testify on Clinton Foundation Corruption_x000D_\\nI billion  in fraudulent activities found by forensic financial investigators.\", 'In Iran it’s legal for a man to marry a child!', 'That Liberals lap this garbage up reveals just how Unintelligent they are', \"His job is not to clear...........it's to find guilt........and he didn't.  CBS needs to educate their reporters.\", \"Again, I reiterate, it is the Taliban's fault. The war could have been avoided if they took him down themselves.\\nAnd who said I trained \\xa0and armed extremists? I'm not American, or even European.\\n\\nAmerica has done a lot of bad things, including the way they handled Afghanistan, but bin Laden is the one who started it (it was even his intention to lure them into Afghanistan).\\n\\nBy the way, the Taliban wasn't around in the 1980s; they popped up in the early 1990s, due to the constant rivalry of rebel groups, and the endless quarreling over territory. Please do your research before making so-called arguments.\\n\\nYou're brainwashed due to your anti-American attitude. I'm older than that, and have upgraded from black-and-white to color.\", 'I think Kushner was s girl before he married Ivanka. Sure looks like it. Who knows? Maybe he still is.', \"The Democrats and their MSM mouthpiece won't let it go, lol\", 'MAGA', 'Muellers garbage report is based on a garbage dossier! What can you expect?\\nGarbage produces garbage. Period', 'Can someone please mention ONE thing in the US, that is not utterly corrupted and screwed up - by either money or reactionary extremism?', 'And TRUMP WINS AGAIN!!!', 'Rudy Is like any cheap trickster lawyer. Always  framing twisted arguments!', 'Knegrodamus great again', 'Adam is one articulate believable and sincere Democrat. We are with Adam.', 'Texas thinks they are ranch hands but instead they got the ranch.', \"The fact that Schieffer still can't- or won't pronounce Ocasio properly is just more proof he's still  just a right-wing  mediasaurus who should retire.\", '@Randy Jordan \\nI will wait for the Mueller report on whether there was a conspiracy or not between Trump and Russians.  That\\'s the only report that matters to me and many Americans.\\n\"Russia, if you\\'re listening, I hope you are able to find the 30,000 emails that are missing.\" Can you tell me who made that request to Russia on July 27, 2016?\\nAlso, did the Russians try to hack Hillary Clinton\\'s email the same day after getting that request?\\nI don\\'t expect you to answer both those questions. \\nIf you do respond, I expect that you will resort to deflections and/or some form of Whataboutism.', \"Someone with a caring heart needs to enlighten Bernie Sanders to the wonderful relief of a thorough colon cleansing.  He's backed-up and packed-up to the extent his brain is having major difficulties in making decisions that are compatable at helping the working class people thrive.\", \"Don't need to watch Alex Jones or Infowars anymore. All you have to do is tune into main stream media and it's conspiracy central.\", 'NOTHING will happen NOTHING - all this is just to keep the mindless Americans occupied', \"The Democrats are so petty.  They are so eager to find fault that they'll spin anything Trump does into a national security threat.\", \"B Bhima: You do know better than to say that. I know you do, and you know you do. CNN doesn't lie at anything like the pace, or with anything near the contempt, that Trump does. \\nYou do know this. \\nYou're disgusting. Anyone who supports Trump is a disgusting subhuman. There's simply no way to objectively defend Trump. It's impossible to do it. He's a menace-- a sociopath. \\nYou really should consider yourself.\", 'Trump is a conman,grifter,money launderer,tax fraud,and a pedophile and child rapist.\\nHe is not my president.', \"Once again CBS shows its true nature - A MOUTHPIECE FOR THE DNC! Mueller didn't clear Trump of wrongdoing because THAT WASN'T HIS JOB!  But of course CBS will try to SPIN it into something nefarious. I expect nothing else from them.....\", \"Why is tucker still on? That's funny to me! At least the left uses comedy.\", \"@Vagabond Jay We have laws we expect Americans to follow.  The immigration laws are proof we don't support our have open boarders.  If people came follow laws, why signs anyone follow any laws?\", '@Based lvl 9000 Ultra Chad Boomer freak , trumputin', 'John Oliver: a court jester and in no way a satirist, here  using clueless celebrities to brainwash American people into thinking Assad is the bad guy, while their own taxpayer money is used to pay for Al Qaeda and ISIS to tear up a beautiful, peaceful country. WAKE UP AMERICA and stop being brainwashed with this inane garbage!\\n\\nAND LIBERAL SCUM! IT IS YOUR PRESIDENT OBAMA WHO DRONES INNOCENTS TO DEATH!\\n\\nLiberals are SCUM!', 'Representative Gabbard\\'s support of an \"assault style weapons ban\" is not acceptable.', 'Under the watch of Donald Trump Mike Pence, AG Wm. Barr, Sen. Mitch McConnell, John Bolton, and Elliott Abrams we quite possibly could be led to the very edge of World War 3 if not to otherwize actualize something truly catastrophic for Humanity', 'Joseph Nordenbrock Bernie was corrupted when he said nothing about not getting the delegates when he ran. Hillary got the majority. Bernie Sanders? Silence. Not one word.', 'Campaigning for regime change. \\nProjecting about Crimes against Humanity - the USA are the reason people are starving around the world, selling their kidneys to feed their families, USA did that!', 'T Haze what’s your obsession with Iran? Do you love their support of terrorism? The insane laws they implement on their people? The fact they are involved in every conflict in the region?', \"It's too late for CNN and they know it.  Brand destroyed.\", \"He did not clear Trump of wrongdoing because he found no wrongdoing. Mueller himself said he didn't have evidence worthy to bring to a court.\", 'Why does trump try to make us believe that he reads???', \"I don't think Mueller even wrote the report.  So, collusion is only a crime in unfair business practices to restrain trade. So, this was ten pounds of air. None event ! Will never believe anything out of government media complex.\", 'Stop killing inocent people!', 'Thats true, getting tired seeing those jews and arabs controlling us.', 'working pepole voted because trump stimulated the economy buy grabing it by the pussy.?', \"Sucks to be wrong Bill.  Nine months ago you were talking to Ben Shapiro about how you were convinced about collusion.  Adam Schiff also kept telling us that he had all of this evidence about collusion so I guess the little pencil neck congressman must be feeling like you now.  Sucks to be so wrong.  Hey, why don't you get Ben Shapiro back on your show.\", 'For once, you have to agree with Bernie ...', \"I wander why in America the cia and fbi call the death by pillow a suicide and this must be exactly how these jews killed an American republican judge because humanity knows how these jew imbreeding practices leave there race of animals unable to learn anything new and continue to use there exact same terrorist plans for thousands of years which must be trained into these jews from childhood because of all there kuru amongst there race there ability to learn anything new is no longer possible much like there latest little jew monster they call HOGG whom is just another disposable mossad agent in brainwashing or mk survivor whom was kidnapped as a baby for the jewish zionist poop packing jesuit pope infiltrator and his fellow queens in the vatican and there UK pedophile parliament of the newer SES and sERCO terrorist organizations around the world and israel. Just question the queens queen in canada they call justin trudeau castro who is definitely a queen of all queens and a perfect zionist nazi science experiment creation where they created a fake human female with the IQ and body of a mentally challenged lgbtdpfag liberal which can survive with only six percent of a brain compared to most pigs today at her BC pig farm which was exposed for junket betting torturing of innocent babies, women and children to impress her canibalistic and pedophile zionist jew associates from astana Kazakhstan, saudi arabia, fake brittain and israel. God bless all humanity and expose all of these greedy enemies of humanity or also known as the khozar satanic jewish race and may they all suffer ten fold the pain and agony they do to God's creations for a buck.\", 'ya it was a hoot watching 9/11 unfold..  pollard, uss liberty,  etc..', 'Let our President speak, finish his words. RESPECT OUR PRESIDENT!', 'american politicians are a cancer to their own people', 'Garry Miller ... He will leave office with an ample pension and healthcare coverage.  Things that even a one-termer of Capitol Hill will receive.  That’s obscene.  Let them save for their retirement, and pay for their healthcare - like nearly every other citizen has to do.  These are well-to-do individuals:  physicians, attorneys, business execs.', \"TRUMP BRING EVERYONE HOME AND QUIT BEING THE WORLD'S POLICEMAN GEEZ WAKE UP TRUMP ---PROTECT OUR GRID AND GET RID OF THESE DAMN CHEMTRAILS THAT IS KILLING EVERYTHING IN OUR WORLD---COME BACK TO GOD OR HE WILL MAKE THE FINAL DECISION\", 'Trump is the American version of Wallace Souza', 'Oh look, more liberal bias news!', '@xXmlg420yoloswag69Xx Well, he liked the poor and hated the rich, he advocated to pay taxes to the Romans and even had a tax collector as a disciple, I mean, in Tea Party terms, he had it coming.', 'Pelosi thinks she is as powerful as the President and way ahead of the VP; she’s drunk with power.  Too bad she had to be behind the Prez; I had a little trouble blocking out her ugly puss.', 'Geoff Forgie yea tell those spoiled prilvedged few of ALL races that you ain’t special, you ain’t important, YOU ARE NOT THE FUTURE, so stop acting like you should receive special treatment, or did your democratic parents spoil you like that?', 'There’s no trusting trump, Bolton or Pompeo.', 'How can a MAN decide what women can and cannot do with their bodies. This guy looks like an asshole.', '5000 people protested... pathetic', 'I don\\'t... for two main reason.  First, the character limit... I don\\'t want diplomacy \"Squeezed down\".  Second... I could be wrong about this, but I don\\'t imagine twitter is set up to national security standards.  They set themselves up for teenage girls to discuss which singing stars are \"Da bomb\\'.  How hackproof are they to outside Governments?', 'just line the straight with ships and subs. What are they gonna do, throw their head rags at warships?', 'justice', \"tr?mp & the republiCONs as usual want WAR. With Iran, North Korea & China. Think about it when ever republiCUNTs are in the W.H. there's always a war, billions wasted & too many people killed on both sides. Wars in the middle east creates more terrorist's too btw !\", \"They tried to set Trump up? Wow, now that's breaking news!\", \"Fake news.  Anti American what's wrong with you. Msm wants war. Disgusting.\", 'There have been no lies to apologize for, you tendentious moron. As Mueller himself states in his report, it does NOT exonerate the President.', \"@John Bold...well said!\\nIf lamestream media such as FOX, CNN and MSNBC did their jobs...these criminal wars by the Demlicans & Republicrats would have been over years ago if the dumb'd down public even had a clue what was taking place at the hands of American Imperialism.\\nFact if they hadn't all been Bush Dubya's useful idiots back in 2003...we wouldn't be having this discussion and the world would be a much better place.\", \"Wow... He'll of a prospective from the great mind of congress leaders... \\n\\nI never had any idea that is this complicated...\", 'sam zen rebuild .. you mean economic colonialism', '@C J trump has had power for years now. Where is the doom and gloom? I was promised all sorts of evil, where is it?', 'Two words explain why so many Republicans currently oppose interventionism.   RON PAUL.', 'If war breaks out, send Hannity in first.', 'Fake passports????? SPY SHIT!!!!', 'This is absolutely hilarious cnn is probably going bankrupt.does anybody understand what he is saying?', 'lock hem up', 'anderson cooper the guy who knows the answer to the question,who do you have to blow to get a job here at cnn', \"Carter Page's tell is his raised eyebrows just before he answers.\", \"@dogmeat jesus transgender people are not a priority in national defense besides let's be honest if a man with 2 balls thinks he is a woman ..obviously there is a screw loose .\", 'Helly looks more insane than Killary and boy that language of hate she has', '@Feeds Ravens \\n\\n\\nYou almost had a point and then resorted to willful ignorance and or lies.', 'MATT GAETZ ROCKS. the other 3 including Tchitface are Dummies, Warmongers and Liars. China are the new Silent Colonialist.', \"Thanks for leading and showing us the way! I'm in Denver CO and the only option is Comcast. Coax cable is good service with low latency (30 ms to any coast or border). But gosh we hate not having any option or recourse against a truly horrible Comcast. Voters are passing municipal broadband laws. Even with the most disastrous rollout, it could never be WORSE than Comcast lol. I'll be vacationing in Switzerland this summer -- see you soon :)\", 'If you go to war with them in court, they will destroy you...', 'Nothing ever happens to a Democrat.   We see the beginning then dropped', \"For all the guns and weapons America has, y'all sure do get frightened easily.\", \"He is not getting worse, he's exactly like he's always been. He was not sharp on the apprentice, he was edited and coached. This is the first time in his life he's not being edited by people trying to make him look good. That's all. And it's why he thinks the press is being mean to him now.\", 'ALL LIES! FAKE FOX NEWS AND PROPAGANDA!', 'Yes he had lied 10000+times. Boy', 'Debra Smith TRUMP 2020', \"@David Moser lol you are the one thats 2 stupid to see thru cnn's bs idiot! 2 years of nothingburgers and you still believe this dying channel\", \"@Alexis but I definitely agree,we need universal health care,Israel has it, yet we're forced to send them 38 billion tax payer dollars a year and WE don't even have that!\", 'The only way to debunk this lunatic is to get his stinking derrière out of office!', 'YOU ARE FAKE NEWS FAKE NEWS YOU ARE FAKE NEWS FAKE NEWS FAKE NEWS FAKE NEWS FAKE NEWS FAKE NEWS FAKE NEWS YOU ARE FAKE NEWS OF THE FIRST ORDER!??????', 'John Oliver RIP off!', 'Wars are fought mainly for secular reasons; power, money, resources, territories. It\\'s the oldest story in the book. There is no \"truth to come out\" because I just told it to you.', \"@Yugioh Pokemon I don't believe anyone anymore (Irak had atomic bomb )\", 'M B There was, however, several attempts made, as well as obstruction of justice, and other conspiracy charges that can be brought because the report did not in any way exonerate him in its search for evidence of innocence.', \"The cafe owner here in North TX who is an American born muslim of Albanian decent gave my wife a free piece of Baklava cheese cake when she found out we had our first child recently, we chat often, she teats all her employees who all of them are not muslim great, she has Christmas trees and decorations currently in her cafe. Sorry I don't a lot of Muslims..but the ones I do seem pretty nice. I assuming you didn't watch the vid or just part of it. The process is long and every one of them that I've seen interviews with said they have not problem with how our culture is or any need to change it. Which, I might add... even IF there were many more.. how exactly would they so quickly turn everything over in our culture?  I'm not a fan of Hillary, but the plan was not for a population of millions. Seriously if it has to be just women, children and widows with husbands on special instances then so be it. If they can't all come here but go to places closer to home..then so be it.  But I don't have a shred of aggression to anyone, them or anyone else until someone shows me aggression as well.\", 'I wonder where Lady justice stands on this matter? Fascinating! Will\\nthe end justify the beginning ?', '@OneTruth Given then just end it and DONT LIE.', \"Wow Memo, nobody cares about CNN? That's been a fact since the witch hunt faceplanted. The right wing comes here during commercials!!!!! You whining asshats are extra laughs after we get real news during PRIME TIME!!!!!!! How's your little circle jerk politiclub doing these days? Still slaying the tweenies online? ROFFLMFAO@UUUU!\", \"@Marcus \\n?  How about you take a hike beings you can't handle truth. You democrats seem to be having NOT very good days. ?\", '@hepwo91222 getting hundreds of millions of dollars from the Deutsche bank, a bank infamous for money laundering, is suspicious. Especially after the US banks refused to lend you money after defaulting on nearly a billion dollars worth of debt', \"Now CNN cares about campaign finance laws? Hillary's dossier payments of millions of dollars to Steele was never reported and clearly were designed to influence the election? I wonder when they will report on this? Never obviously\", \"@Stoned Again You must be a troll. Europe would be speaking German or Russian if the United States didn't save your asses. Because this statement is so absurd you must be ignorant or a troll. My guess is you're a troll.\", 'artty Ę - then your government are retarded last 70 years. Going around telling people you are bringing democracy to the country´s you attack. And then you tell me you do not have democracy in America. Now i think of it your right and i am wrong. America is a police state controlled by fascist corporations. Land of the free my ass. Rather land of the slaves and cowards', '@catalinacurio Mueller is a traitor and will be hung!', 'Donnie Dotardo only fools his sycophantic base! \\nanyone with even one foot in reality knows Spanky McBonespurs is the original Bait and Switch artist!', \"@Guts Repeating mistaken family stories is hardly a crime. That's much more than Trump can claim.\", 'IDIOT DEMOCRAT LOSERS,.... they go zero original ideas for anything ,..', '@Based lvl 9000 Ultra Chad Boomer you are so predictive, pure hate always is and what happened to your Mother? BERNIE2020 this time.', 'Well it seems to Russians ran their own candidate. And he won.', 'Perhaps Mueller could not \"declare tRump exonerated\" but neither could Barr - - but he did, several times, on tv --- which is why Mueller was forced to go on tv and SAY that tRump was not exonerated.\\nMueller has no conflicts of interest with tRump, only the felons occupying sensitive positions in our government, he definitely has problems with them, IT\\'S HIS JOB, FOR AN FBI AGENT TO HAVE PROBLEMS WITH CRIMINALS.', \"surprisingly he's not a democrat.\", 'Is this the new talking point ROTFL??? Is this the best you got? What no more Russia Russia Russia Stormy Stormy Stormy LMAO you are desperate now. Just give it up you are done! Trump 2020 SnowFlakes HAHAHA', 'Wow. Great news for the country. Rats leaving a sinking ship. I hope there are arrests.', 'My God! Trump makes me feel disgust the likes I’ve never felt before!', '@Inez Dills Indeed, Trump is a dirty little traitor.  I agree 100% Inez.', \"Go ahead America, start this war. But don't complain when millions more refugees invade your country and Europe. Maybe that's the agenda after all?\", 'TIME FOR DEMOCRAT SCUM BAGS GET OVER THE RUSSIAN COLLUSION THEY CREATED THEY ARE ONLY PUSHING THEIR FAKE COLLUSION STORY TO DEVERT THEIR MISCONDUCT OF CRIMINAL CRIMES OF TREASON HOPEFULLY TRUMP WILL NOW HAVE AG BARR START INDICTING THEM ALL & FACE JUSTICE AT THE END OFF A ROPE...', 'CNN never lies. LOL. His visit to the UK was a success. The protest against him was not huge, just people who do not work.', \"Robert Honer the intelligence agencies have nothing, there is zero proof, nada, nothing, that the Russians interfere with the democratic process of our country. At best you could say the Wikileaks emails were given to them by Russia but again they agencies can't prove it either. At the end of they day the voter makes the decision, and you cannot blame that on Russian interference.\", \"@G.T.O. Momma Thank you, I am independent though thats why i don't trust either side because of the political stuff going on, but everyone has their own opinions or believe in the left or right\", \"If I don't vote for Trump, In voting for Gabbard.\", '@Bryan Kay Omar never said she felt pride for a terrorist organization, that is a complete and total lie. They have all repeatedly expressed their love for the United States, and if you want to talk about somebody\\'s \"hateful content of character\" look at Trump bullying everybody on Twitter. I have never seen such an angry and argumentative person fling so many hated-filled rants and insults out into the world. Go away, bot.', '@Dan Dettmann \\n\\nand \"YouTube\" ?\\nWant me to come over and read you \"Fear\" or the \"Mueller Report\" as you fall asleep?  There in audio format but I\\'ll do it.', 'Isnt Anderson Cooper ashamed of how he covered this?', 'Susan Pelsue you mean tulsi being Hindu and America pretending to be Christian ?', 'Wow the media just won’t stop—they are activists, not journalists. This is ridiculous. Trump has been completely exonerated—never collided with Russia. Fact. Can’t obstruct a crime you haven’t committed. \\nThis is so unfair and dishonest of the media and democrats. They will receive the consequences on November 8th, 2020', 'Why do you waste your time on these democratic cuntz', 'President Trump Was Put Into Office By The LORD To Throttle the Enemies of Israel, and the U.S.', 'Kamala is a straight killer. Drop the mic ?', 'Well, ABC is one of the Five Crime Families of Fake News.', \"It's not just Pelosi feeding the media.  Dems or their operatives feed info or talking points to the media, NYT &WaPo. Then the press goes hog wild with it, trashing Republicans and making the most outrageous accusations. Then, when the info comes up in hearings, the dems read the news reports AND enter them into the Congressional record.  Quite the racket!\", 'Playbackjunkie he is out for his own EGO. If you don’t see that then you’re in denial.', 'Hannity has shown himself to be a warmonger of the worst kind.  Guiliani is completely corrupt -- you cannot believe  word he says. The Pentagon knows that the US will lose against Iran.', \"I'm glad people are beginning to think CNN should have it's license to broadcast news revoked. There's no place in America for unbridled lies and propaganda.  Displaced CNN workers can go work in Cuba or N. Korea.\", \"Don't be fooled. What Trump is doing now seems more of an escape plan in progress. He fumbled North Korean nuclear negotiations, the economy, strained relationships with almost the globe, imagration policy, devided the nation and has not told the truth about anything. There is much more negative than positive. My point is, what better way to escape prosecution than to play crazy with the world? Think about it! It may be hard for rational people. Trump has proven to all he is clearly not a rational person.\", 'Liberals are incorrigible', \"King Kong well it's the amount sanctions you put on them.\", \"I care as much about the Democratic Party server getting hacked as the Democrats care about my computer getting hacked.  I don't see any reason for a 30 million dollar investigation.  Let them buy an anti-virus program the same as the rest of us.\", '\"For over two years America has had a crazy person in the White House and for over two years the Democrats have done fuck all about it...\"\\n\\nThat being correct then that\\'s the whole video, Bill.', 'Funny how the comment section has more balls then the news for truth!!!!!!!', 'Just when you thought CNN hit rock bottom. They find a shovel waiting for them.', \"How can we get them to stop illegal immigration? It would save us billions. I am not going to buy health care for Latino kids that aren't even Americans.\", 'Maybe someone needs to look at Mueller\\'s income over the last 2 years and see if his \"paycheck\" jumped. ....', 'These are white on white crimes. Nothing to see here!', 'Bill need to call us to the streets so we can battle \"them!\"', 'Well Anderson by the comments it looks like about 25% of people still agree with you!! The Democrats failed because that is what they are good at. I mean just look at all of the great legislation they have passed in the last 50 years. They have gotten nothing at all done for the middle class for a half of a century. While the Republicans have made this country a state run by the companies. Time to put in someone who will get things done for the middle class like Tulsi Gabbard.', \"Andrew Smith: yeah oh right answered really well already but I don't see why we should force anyone to fit in a place which is already as diverse as heck and is supposed to celebrate differences. And as the video stated they do not even get to pick where they will be placed so rejecting them for that is just silly.\", 'I really can\\'t stand it when these places call themselves\"news stations\". They aren\\'t...They are politically biased, agenda driven and opinion based shows. There\\'s no actual journalism or news there..', '@Wadley Jred \\n\"I don\\'t know Matt Whitaker\".', 'Is Kudlow drunk ?', \"China has been undermining our country from within for a LONG time!! You cant go shopping without seeing 90% of the goods being from China! Quit importing this crap! America needs to start making our own goods again! Look into how China has worked with the Mexican drug lords to fund MS 13 that now control parts of California. Remember. You have millionaire politicians who got rich on a 170,000 a year. HOW? They're getting paid off by China! Feinstein, Harris, Waters, etc. allowing China to acquire California. Watch The Common Sense Show on you tube.\", 'Damn Its so fucking sad that Iranians are kicking our asses .USA  we should go to war !! . Fuck this terrorists', \"Hasan is right now the best thing that Netflix has .... Hasan would like to hear from you abt the social media applications like Snapchat Instagram tiktok etc just to let the world know abt it's consequences\", 'When did it become that prosecutors job to clear people. It is their job to find guilt not innocence. The Mueller report is not based on any legal precedence. The Mueller team made up their own rules and pass them off as following the law but missed the fundamental truth that \"EVERYONE IS INNOCENT UNTIL PROVEN GUILTY.\"', 'John...  When you decide to recognize that the Prosecutors in the Office of the District Attorney are clients  - their crimes against the public cannot be prosecuted because of attorney client privilege.  Rule 1.6 Confidentiality of Information is the cause of the problem... but, lawyers must keep that CONFIDENTIAL.\\n\\nTime to unblock me, eh?  www.work2bdone.com/live', 'ABC is owned by the Bilderberg Group.', \"What crimes...yes there were some shady individuals but what evidence of collusion was there? Isn't that what Mueller was investigating? Right?Trump didn't exactly get anything but the bottom of the barrel as everyone didn't figure him to win...remember? \\n\\nHow long was Manafort on the Trump team?\\nWhat exactly did Popa D do?\\nFlynn lol...he was set up and somebody leaked info on him from spies?\\n\\nStefan Halper, go look him up. Where is he lol?\", 'I really wonder who most Democrats would vote for next year if not her, is there really a more appealing or likable candidate at this point? I think some say she is too unconventional and outside the box, but that is not necessarily a bad thing, we do need someone new and different for a change.', 'We also have a shitty company here in Morocco called Maroc Telecom it is the only company that provides broadband internet connection so they get set the prices as high as they want and their customer service is terrible .\\n#FuckYouMarocTelecom', \"YOU WANT TO TALK ABOUT LIARS...?\\xa0\\xa0\\xa0 CNN IS THE BIGGEST LYING ASS PROPAGANDA\\xa0 NETWORK IN THIS COUNTRY.... CNN WILL CEASE TO EXIST SOON AFTER WILLIAM H BARR KO'S HILLARY CLINTON AND HER COMEY CABAL...BHAHAHAHAHAHAHAHAHAHAHAHAHAHAHAHAHAHA\\xa0\\xa0 ....BHAHAHAHAHAHAHAHAHAHA\\xa0\\xa0 BHAHAHAHAHAHAHAHAHA\", 'The so called ‘chosen one’ (AND compliant GOP) gave huge tax cuts to rich, wants to buy Greenland, build a wall, and have Americans living pay check to paycheck to pay for it.  And as an added bonus, take away Medicare and Medicaid.  He’s more the anti-Christ.', \"Dear Republicans,\\n\\nWe don't care what you think about us ruining the country.\\n\\nSigned,\\n\\nThe Republicans you voted for.\", 'Fuck the drone', '@Genghis Khan Sounds awesome', 'A criminal family in office?', 'Obama had an AG that said he was his \"wing man \", not one complaint from anyone.', 'I love Kamala Harris', 'Look in ur reply and u see a persn says:  “ same here in iran” .... and u can tell in both sides are some certain current whom need war!!!!', 'If only he would get bone spurs in his thumbs.', 'Americas favorite mobster. fake mayor fake urine colored president. neonaziconn...................', 'I’m sad we had to see mooch face', 'Little bitch ass liberals stfu', 'I recently graduated law school in Germany, and here the system is similiarly fucked up. At least you have to have a certain grade to be able to become a judge or a DA and they are not elected. But what my feeling is, that most people that do become judges and DAs are kind of weird and like the power they have just a little too much. The people that actually are aware how many lives the can and will ruin with that job, don\\'t do this job for THAT EXACT reason.\\n\\nAlso you are obligated by the law in Germany as a DA to bring forward any exculpating evidence. But it is not really taken all that serious. There is a joke going around in the DA that it is \"the most objective public institution in the world\", but everybody says it with a knowing smirk.. also I witnessed a rare case in court where the guy was found innocent and the police guy, who has to lead the accused in and out of the court room got all excited and joked \"aren\\'t acquittals illegal?!\"\\n\\nThe good thing here is, that at least we don\\'t have the death penalty, so at least nobody dies because of it..', \"Well I apologize for not practicing the best grammar online, especially since my it's not even the language i was brought up with. I wont argue on that.\\n\\nBut you're forgetting that the Taliban and the Alqaeda is essentially the same 'group'. They were created - organized, funded and trained - by the US government at the time of the cold war. Well you know the murricans they hate being 2nd best so they were scared of the communists invading the middle east. So they created OBL and so on.\\n\\nUm well let me 'reiterate', bashar didnt kill more people - civies or military - than his father. If anyone it's the so called 'revolutionists'. Anyways these statistics are always cloudy in the time of war lets agree to that.\\xa0\\n\\nBut what I can't have is people watching cnn or fox and call syria's president a shitty and despicable cold blooded killer whilst leaving people like netanyahu and obama roam free without a second glance.\", \"@Roman Hoax And Trump isn't a liar? lololololololololololololol\", '@ElPocho DelMundo i agree with you there is no false word in the report no collusion no obstruction by trump, but it does show that the DNC and hillary accepted money from Russia for the campaign,  and that comey did not interrogated hillay about the emails, and mccabe and lorreta lynch told comey to let her go. Read the mueller report, and before you tell me it is redacted, so is the FISA REPORT,   AND FISA WARRANT,', \"@Ol’ Yeller lol the imaginary emails that where in the hard drive she acid tone?? Democrats r a fucking pieces of shit.. They didn't even clap when trump mentioned a las for bidding abortion up until birth\", 'Fuck you cnn soon you will be gone.', 'Notice that when Trump is speaking to the media it’s beside a noisy chopper which means ‘I’m a very busy person’ or with a bunch of people behind him like his rallies which means, ‘look how many people support me. It’s sad and pathetic behaviour.', '@C\\'est la vie \\nWhen did any of those \"dictatorships\" go Pirate, for instance ?  What business of yours is it ?', '\"No more Russia investigation \" also Trump lol ?', 'Lies lies lies are from cnn ???', \"Mueller didn't clear the president of wrongdoing because he didn't do anything wrong. Stupid people cannot understand this very simple idea. Mueller carefully uses his words to make the stupid people believe he's saying the president is guilty of something.\", 'Trump is looking ill.', 'AND LOCK HER UP!!!1', 'POLY GRAPH ALL AGENTS CIA AND FBI  WHATS UP NOW WRAY', 'this program tonight, was a hatchet job, you are suppose to be neutral.  There is only one United States. The president represent all of us, like him or not.   The forces that can not destroy this country by force,  are working to tear us apart.  We are tire of all the negativism.  I have yet to hear anything positive about Trump presidency  from your network.', 'The christian right have no morals just like it\\'s leader and Trump is holding on to his ace in the hole for his souless base \"Roe vs Wade and the legalization of weed.', 'Is Beto actually saying they wanna start impeaching Trump now so they can start investigating why they are impeaching him??!', '@spikethompson2000 Wisdom is needed. In 15 or 20 years she should run again.', '@Scorp308\\xa0There are not really many good options in Syria right now, but doing nothing or supporting Assad/ISIS are the worst possible choices.', 'Congressman Matt Gaetz is the smartest guy in that panel, %100 agree with him, president Trump made the smartest and best decision.', \"As a German it is always funny to see how both the right and the left in the USA use merkel. To make it clear: either she gets elected or someone to the left. She is a conservative in Germany. The alt right is polling at 8%, so don't use us as an example of your faulty systems. If the Russians would hack us it would mean a shift further to the left. Please get that!\", \"Trump is a fool . He doesn't know what he is doing or what he wants to do.\", \"CNN, MSNBC, and usually can lump CBS in there too,  propagates COMMUNIST and Socialist propaganda.  'Nuff said.\", 'Hey Bill those whoops and clapping from your audience mirror the MILLIONS of people around the world that are yelling at the screen and applauding in agreement with what you are saying... how does this fucking two bit conman get away with this shit? !  It’s COWARDICE plain and simple.', \"Just a continuation of the clown crap show. Isn't this a form of obstuction?\\nAccording to them obstruction is a crime. So more projection.\", \"1) This is a waste of government resources.\\n\\n2) This is preventing our country (USA) from addressing the important issues: taking care of its citizens. \\n\\n3) Much (all?) of this could have been avoided if Trump had released his tax returns early in the campaign. But since he didn't, more and more suspicion grew about *why* he didn't, and what he could be hiding (too many to list, but two top issues: a Russian connection and that he's a weak businessman). And until he releases his tax returns, he feels free to spew off crazy-talk.\\n\\n4) We need to pass a law: *every* government candidate MUST release their tax returns in order to be listed on a voting ballot. Zero excuses allowed. And this must be repeated at each election, not just the first one. How can we inititate this? \\n--> Write to your political representatives.\", \"what you blind fools fail to recognize is that because we didn't want the career criminal hills in office, doesn't mean we love and deify everything trump does. that is STUPID.\", \"The rest of the world ain't living in chains lmfao. majority of the world lives under the same rules as USA, give or take a few religious countries or rules, etc.\\n\\nOnly difference is the wealth of the country and living standards. But US isn't doing too well in that aspect either lol\", 'Jay Grewe Blaming Bush and Congress for his woes. “During Obama’s first term, he blamed Bush for the economy, for the botched Operation Fast and Furious, for the massive deficits, for our plummeting national wealth, for our problems in the Middle East -- for just about everything that went wrong.\\nWar on coal and oil. “Obama forced more than 200 coal-fired plants to shut down over a five year period.”\\nCut funding to fight aids. “This inexplicable decision had a devastating effect on Africa, where most AIDS deaths occur.”\\nNominating John Brennan as CIA director. Brennan has gone on to be President Trump’s critic.\\nDACA via executive order. Obama went around Congress to give amnesty to some 800,000 younger illegal immigrants.\\nAssault on the press. The Committee to Protect Journalists, said of Obama’s media attacks, “In the Obama administration’s Washington, government officials are increasingly afraid to talk to the press. Those suspected of discussing, with reporters, anything that the government has classified as secret are subject to investigation, including lie-detector tests and scrutiny of their telephone and e-mail records.”', '@J Ch \\nFirst off, do you mean Iraq?  If so, exactly how much oil did we actually take?  Despite being there longer than we should have ever been there, the answer is NONE.  So get your facts straight before bloviating about things you clearly know nothing about.  And Venezuela?  What \"invasion\" are you referencing, exactly?  North Korea?  Gee, I don\\'t know, maybe the fact that the regime was testing ICBMs with our name on it sort of prompted a lot of that.  And if you think that by \"controlling\" the Koreas, we could somehow \"control\" China, you are nuts.  Oh but we are the ones who are naive...says the person who couldn\\'t even keep Iran and Iraq straight?  Please.\\n\\n...but for the sake of the argument, let\\'s say the U.S. accounted for all of the negativity it has brought the world with military actions and such, to your point.  Let\\'s not forget who sits on the other side of the scale, the side that I\\'d argue is much heavier, that being all of the protection we have provided to so many countries who would be extremely hard pressed to defend themselves.  So have your little anti-American tirade but at least be intellectually honest about it.  There\\'s is criticism to be had, for sure, but to act like the U.S. has not served the world well in MANY regards is to overlook a staggering amount of history.', 'All hail The Clan of The White Shrews, their manifesto was written on a cocktail napkins on a slow Tuesday night after the Margaritas were mixed, page one calls for baby sacrifices across the nation, then a replacement of dead American babies by poor third world urchins trucked in by the thousands. Your financial irresponsibility means your money must be confiscated and spent for you, luckily, feeling generous the White Shrews will make sure the poor urchins are nourished on your tax dollars and trained to be good victim Democrat Socialist voters, the borders will open wider and wider, our lives will be enriched and guided by the White Shrews cocktail napkins.', \"He throws red meat to his base like they're a pack of wild dogs.\", 'Love how MSNBC by this title seem to be trying to create a Tulsi vs Biden moment by ignoring the other important things she said and just concentrating on Biden.......but unfortunately for them Tulsi does not play those games.....she is not Cory Booker she actually has class.', '@James Gray since when? and whats about the other resources america needs from other nations?', 'Senator Sanders is the voice of SANITY.  Listen to him, and make HIM the next USA President.', \"Look at Dan go! If Fox doesn't let this function as his on-air audition, they're nuts. Nice job, Mr. B! ?\", '@WanderfalkeAT I don\\'t think they run a conspiracy, it\\'s like Noam Chomsky said to a reporter: \"if you didn\\'t believe what you said, you wouldn\\'t be sitting here\". You should watch his lectures on the media and read Manufacturing Consent. Pretty good stuff! I get what you are saying though.', 'The drone story was made up by the same people that made up the weapons of mass destruction story that started the war with Iraq.  There is nothing the press loves more than a good old fashioned war.', \"This could have been easily swept under the rug if Trump hadn't put her in the spotlight LOL.\", 'The United States invasion of Afghanistan occurred after the September 11 attacks in late 2001, supported by close US allies.  Its public aims were to dismantle al-Qaeda, and to deny it a safe base of operations in Afghanistan by removing the Taliban from power.\\nnow trump and graham \"negotiate\" with taliban for our surrender and withdrawal. yea amerika!', '@Teeveepicksures seeing as how there never was collusion some folks have legitimate questions...', 'The Syrian crisis is a horrible thing, but has anyone noticed the situation’s strange components?\\n\\nAl Assad- Syria- is against Daesh (ISIS) and the rebels who had rose up against him.  Putin- Russia- is aligned with al Assad to combat Daesh, but so is the U.S.  but, the U.S. is against al Assad.\\n\\nSo, basically, Russia and the U.S. are both against ISIS, but Russia is aligned with the Syrian government, and the U.S. is against the Syrian government for attacking the countries civilians.']\n"
     ]
    }
   ],
   "source": [
    "#find threads with most POTENTIAL political posts:\n",
    "#select the rows in the dataset that are in a thread with more political posts than cutoff:   \n",
    "# Define the cutoff value\n",
    "cutoff_value = 8\n",
    "\n",
    "dataset_claim_embeds['either_political'] = dataset_claim_embeds[['Llama31_political_fill_8b_score', 'political_post_gpt4o_dum']].max(axis=1)\n",
    "\n",
    "# Group by 'thread_title' and count the number of political posts\n",
    "thread_counts = dataset_claim_embeds.groupby('videoTitle')['either_political'].sum()\n",
    "\n",
    "# Filter the threads based on the cutoff value\n",
    "pol_threads_either = thread_counts[thread_counts > cutoff_value].index\n",
    "\n",
    "# Select the posts in the filtered threads\n",
    "pol_posts_either = dataset_claim_embeds[dataset_claim_embeds['videoTitle'].isin(pol_threads_either)]\n",
    "\n",
    "# Display the filtered posts\n",
    "print(pol_posts_either.loc[pol_posts_either['either_political'] == 1, 'commentText'].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['StartDate',\n",
       " 'RecordedDate',\n",
       " 'IPAddress',\n",
       " 'Finished',\n",
       " 'Coder',\n",
       " 'ID',\n",
       " 'Mark_ID',\n",
       " 'Genre',\n",
       " 'topiccode',\n",
       " 'Platform',\n",
       " 'Anonymity',\n",
       " 'Anonymity_9_TEXT',\n",
       " 'codable',\n",
       " 'Interaction',\n",
       " 'Acknowledgement',\n",
       " 'TopicRelevance',\n",
       " 'Reasoning',\n",
       " 'BackgroundInfo',\n",
       " 'ExternalEvidence',\n",
       " 'ExternalEvidence_1_TEXT',\n",
       " 'Opinion',\n",
       " 'disagreement',\n",
       " 'Ideologicaldirection',\n",
       " 'Name_calling',\n",
       " 'Vulgarity',\n",
       " 'Attack_reputation',\n",
       " 'Question_Intelligenc',\n",
       " 'All_caps_function',\n",
       " 'Sarcasm_to_criticize',\n",
       " 'Individual_right',\n",
       " 'discrimination',\n",
       " 'Invoke_violence',\n",
       " 'Tone',\n",
       " 'INTERACTIVITY_DUMMY',\n",
       " 'RATIONALITY_DUMMY',\n",
       " 'HAS_OPINION_DUMMY',\n",
       " 'LIBERAL_NEUTRAL_CONSERVATIVE',\n",
       " 'LIBERAL_DUMMY',\n",
       " 'CONSERVATIVE_DUMMY',\n",
       " 'NAMECALLING_DUMMY',\n",
       " 'VULGAR_DUMMY',\n",
       " 'NAMECALLING_VULGAR_DUMMY',\n",
       " 'INCIVILITY_ORDINAL',\n",
       " 'INCIVILITY_DUMMY',\n",
       " 'INTOLERANCE_DUMMY',\n",
       " 'filter_$',\n",
       " 'IMPOLITENESS_DUMMY',\n",
       " 'commentText',\n",
       " 'showName',\n",
       " 'genre',\n",
       " 'Time_comment',\n",
       " 'likeCount_comment',\n",
       " 'entities',\n",
       " 'place',\n",
       " 'retweet_count',\n",
       " 'platform',\n",
       " 'retweeted',\n",
       " 'language',\n",
       " 'source',\n",
       " 'in_reply_to_status_id_str',\n",
       " 'in_reply_to_user_id_str',\n",
       " 'in_reply_to_screen_name',\n",
       " 'is_quote_status',\n",
       " 'videoTitle',\n",
       " 'description',\n",
       " 'Time_video',\n",
       " 'channelTitle',\n",
       " 'channelId',\n",
       " 'viewCount',\n",
       " 'dislikeCount_video',\n",
       " 'likeCount_video',\n",
       " 'date_difference',\n",
       " 'commentCount_video',\n",
       " 'replyCount_comment',\n",
       " 'topic',\n",
       " 'subscribers',\n",
       " 'HATELIST_FOCUSED_DUMMY',\n",
       " 'Time_comment_year',\n",
       " 'Time_video_year',\n",
       " 'interactivity_acknowledgement',\n",
       " 'political_ideology',\n",
       " 'rationality_external_evidence',\n",
       " 'rationality_topic_relevance',\n",
       " 'political_negativity',\n",
       " 'rationality_background_info',\n",
       " 'rationality_reasoning',\n",
       " 'sentiment',\n",
       " 'offensive',\n",
       " 'topics',\n",
       " 'emotions',\n",
       " 'irony',\n",
       " 'hate',\n",
       " 'topiccodeSTR',\n",
       " 'claim_run1',\n",
       " 'claim_optdef',\n",
       " 'claim_optdef_embed_MXBAI',\n",
       " 'claim_optlow',\n",
       " 'claim_optlow_MXBAI',\n",
       " 'tfidf_embed_post',\n",
       " 'embed_MXBAI_post',\n",
       " 'cosine_similarity_post_claim_MXBAI',\n",
       " 'cosine_low_high_MXBAI',\n",
       " 'tfidf_embed_post_svd',\n",
       " 'Llama31_political_post_8b',\n",
       " 'Llama31_political_fill_8b',\n",
       " 'Llama31_political_fill_8b_score',\n",
       " 'political_post_gpt4o',\n",
       " 'political_post_gpt4o_dum',\n",
       " 'either_political']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_claim_embeds.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YT_input_sort = YT_input.sort_values(by='parsed_datetime').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 368.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   dataset_index  \\\n",
      "0            196   \n",
      "\n",
      "                                                                                           commentText  \\\n",
      "0  No, the industry is worse! If you to took a biologylesson you would learn that the biodiversity ...   \n",
      "\n",
      "   preceding_index  \n",
      "0              NaN  \n",
      "   dataset_index  \\\n",
      "0            190   \n",
      "\n",
      "                                                                                           commentText  \\\n",
      "0  i saw the show. it was amazing. go see it, you wont regret it! and i love the little sound clips...   \n",
      "\n",
      "   preceding_index  \n",
      "0              NaN  \n",
      "   dataset_index           commentText  preceding_index\n",
      "0            398  she looks like coal.              NaN\n",
      "   dataset_index  \\\n",
      "0            177   \n",
      "\n",
      "                                                      commentText  \\\n",
      "0  the only solution for it...... hire a rapist..... just kidding   \n",
      "\n",
      "   preceding_index  \n",
      "0              NaN  \n",
      "   dataset_index  \\\n",
      "0            185   \n",
      "\n",
      "                                                                                           commentText  \\\n",
      "0  WTH? Social behavior of the rich. Some of these losers are wanna be rich and either in legal doo...   \n",
      "\n",
      "   preceding_index  \n",
      "0              NaN  \n",
      "   dataset_index  \\\n",
      "0            176   \n",
      "\n",
      "                                                                                           commentText  \\\n",
      "0  what about the health ramifications of getting shot in the face? is everyone going to wear bulle...   \n",
      "\n",
      "   preceding_index  \n",
      "0              NaN  \n",
      "   dataset_index  \\\n",
      "0            245   \n",
      "\n",
      "                                                                                           commentText  \\\n",
      "0  Hahah Gerald Fraas, who appears to have signed up for youtube an hour ago, completely misses the...   \n",
      "\n",
      "   preceding_index  \n",
      "0              NaN  \n",
      "   dataset_index                              commentText  preceding_index\n",
      "0            464               omg they got mike!!!!lolÂ               NaN\n",
      "1            465  the beek didn't even apologize. amazing              0.0\n",
      "\"Thread\":\n",
      "<['omg they got mike!!!!lolÂ\\xa0']>, \"Target reply\":<<the beek didn't even apologize. amazing>>\n",
      "   dataset_index  \\\n",
      "0            188   \n",
      "\n",
      "                                                                                        commentText  \\\n",
      "0  Don't date men that kiss and tell girls, they will hurt you.  A jealous man is not trust worthy.   \n",
      "\n",
      "   preceding_index  \n",
      "0              NaN  \n",
      "   dataset_index  \\\n",
      "0            395   \n",
      "1            396   \n",
      "\n",
      "                                                                                           commentText  \\\n",
      "0                                                                         @killalthedon21Â  get a life   \n",
      "1  @Amanda TorresÂ Omfg. Obviously but if you had a background in any type of history class you'd k...   \n",
      "\n",
      "   preceding_index  \n",
      "0              NaN  \n",
      "1              0.0  \n",
      "\"Thread\":\n",
      "<['@killalthedon21Â\\xa0 get a life']>, \"Target reply\":<<@Amanda TorresÂ Omfg. Obviously but if you had a background in any type of history class you'd know that a lot of Irish people were distinguished from whites on the basis that they had been separated in terms of ethnicity. I'm not sure if that's the case with the initial poster but many irish referred to themselves as white but apart of an \"irish\" ethnic group. Thanks for trying to educate me though, move along.Â >>\n",
      "   dataset_index          commentText  preceding_index\n",
      "0            186  go mitt Romney 2012              NaN\n",
      "   dataset_index                                  commentText  preceding_index\n",
      "0            250                                        First              NaN\n",
      "1            251  how do you get on hunger games not on X box              0.0\n",
      "\"Thread\":\n",
      "<['First']>, \"Target reply\":<<how do you get on hunger games not on X box>>\n",
      "   dataset_index  \\\n",
      "0            331   \n",
      "1            330   \n",
      "\n",
      "                                                                                           commentText  \\\n",
      "0  She looks like a pron star I don't Â but to me she has like a porn star vibe about her like she'...   \n",
      "1                                                         If your criteria begins and ends with \"hot\".   \n",
      "\n",
      "   preceding_index  \n",
      "0              NaN  \n",
      "1              0.0  \n",
      "\"Thread\":\n",
      "<[\"She looks like a pron star I don't Â\\xa0but to me she has like a porn star vibe about her like she's someone you'll see on bang bus.\"]>, \"Target reply\":<<If your criteria begins and ends with \"hot\".>>\n",
      "   dataset_index  \\\n",
      "0            347   \n",
      "\n",
      "                                                                                           commentText  \\\n",
      "0  @TheJohny815   true. dinosaurs microscopic organisms, neanderthals and other pre-historic humans...   \n",
      "\n",
      "   preceding_index  \n",
      "0              NaN  \n",
      "   dataset_index  \\\n",
      "0            345   \n",
      "\n",
      "                                                                                           commentText  \\\n",
      "0  No she didn't. They suggested it was a black man (cause they found out it was on day 2 of the in...   \n",
      "\n",
      "   preceding_index  \n",
      "0              NaN  \n",
      "   dataset_index                  commentText  preceding_index\n",
      "0            450  Is 1:37 the new 60 minutes               NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Expand the polposts of all YT comments to include the thread context:\n",
    "chunked_result: typing.List[pd.DataFrame] = []\n",
    "GROUPER='videoTitle'\n",
    "#sort data by Time_comment\n",
    "YT_input_sort = YT_input.sort_values(by='parsed_datetime').reset_index(drop=False)\n",
    "groupeddata = YT_input_sort[:20].groupby(GROUPER)\n",
    "for group, df in tqdm.tqdm(groupeddata):\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.loc[:, 'preceding_index'] = df.index.to_series().shift(1)\n",
    "    print(df.loc[:, ['dataset_index', 'commentText', 'preceding_index']])\n",
    "    for index, row in df.iterrows():\n",
    "        if pd.isna(row['preceding_index']):\n",
    "            chunked_result.append(\n",
    "                pd.DataFrame(\n",
    "                    data=[[row['dataset_index'], row['commentText']]],\n",
    "                    columns=['index', 'post_expansion']\n",
    "                )\n",
    "            )\n",
    "        if pd.notna(row['preceding_index']):\n",
    "            #threadset = int(row['preceding_index'])\n",
    "            print(f'\"Thread\":\\n<{df[\"commentText\"][:index].to_list()}>, \"Target reply\":<<{df[\"commentText\"].iloc[index]}>>')\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1137 [00:12<58:41,  3.11s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 24 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 24 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/1137 [01:02<1:43:27,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/1137 [02:20<4:02:37, 12.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 26 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 26 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 33/1137 [03:16<57:27,  3.12s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 48/1137 [05:15<1:50:35,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 51/1137 [05:46<2:01:21,  6.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 6 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 83/1137 [08:06<25:16,  1.44s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 6 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 127/1137 [10:10<23:09,  1.38s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 11 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 11 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 165/1137 [11:16<12:21,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 172/1137 [11:23<11:41,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 14 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 14 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 173/1137 [11:44<48:36,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 186/1137 [13:27<1:09:32,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 22 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 22 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 191/1137 [13:58<1:08:55,  4.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 7 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 225/1137 [15:51<23:49,  1.57s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 20 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 20 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 292/1137 [18:26<06:28,  2.18it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 297/1137 [18:29<06:50,  2.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 312/1137 [20:05<28:22,  2.06s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 30 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 30 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 319/1137 [20:47<52:52,  3.88s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 340/1137 [22:28<15:30,  1.17s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 22 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 22 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 360/1137 [24:41<24:42,  1.91s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 21 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 21 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 365/1137 [25:09<37:04,  2.88s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 396/1137 [26:56<11:23,  1.08it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 15 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 15 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 396/1137 [27:08<11:23,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 436/1137 [29:18<12:02,  1.03s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 9 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 437/1137 [29:29<30:07,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 441/1137 [29:39<28:36,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 481/1137 [31:18<15:30,  1.42s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 14 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 14 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 503/1137 [33:29<35:17,  3.34s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 25 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 25 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 530/1137 [34:25<09:13,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 25 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 25 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 532/1137 [34:57<41:11,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 578/1137 [37:08<10:52,  1.17s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 585/1137 [37:20<12:04,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 594/1137 [39:01<51:21,  5.67s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 25 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 25 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 596/1137 [39:32<1:10:35,  7.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 5 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 619/1137 [41:24<19:12,  2.23s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 14 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 14 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 621/1137 [41:44<40:28,  4.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 635/1137 [43:26<19:05,  2.28s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 24 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 24 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 637/1137 [43:54<53:15,  6.39s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 664/1137 [45:34<17:31,  2.22s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 14 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 14 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 668/1137 [46:05<39:41,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 741/1137 [49:09<25:14,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 7 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 745/1137 [49:17<19:04,  2.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 761/1137 [51:25<27:49,  4.44s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 9 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 794/1137 [52:36<07:07,  1.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 800/1137 [52:44<06:18,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 818/1137 [54:16<16:13,  3.05s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 822/1137 [54:57<29:51,  5.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 854/1137 [56:23<03:04,  1.54it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 39 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 39 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 866/1137 [58:55<19:21,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 15 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 15 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 873/1137 [59:13<13:37,  3.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 898/1137 [1:00:55<05:53,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 10 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 928/1137 [1:03:01<05:24,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 22 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 22 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 952/1137 [1:04:44<08:31,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 20 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 20 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 20 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 976/1137 [1:06:47<05:35,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 22 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 22 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 980/1137 [1:07:16<09:15,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 1003/1137 [1:08:58<03:18,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 20 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 20 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 1008/1137 [1:09:34<07:19,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 1020/1137 [1:11:19<10:50,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 19 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 19 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1051/1137 [1:13:34<03:24,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 13 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 13 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 1062/1137 [1:14:02<02:47,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 1091/1137 [1:15:51<00:48,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 17 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 17 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 1121/1137 [1:16:54<00:31,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 12 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 12 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1137/1137 [1:18:42<00:00,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      index  \\\n",
      "0      2936   \n",
      "1      3573   \n",
      "2      2864   \n",
      "3      3098   \n",
      "4      3861   \n",
      "...     ...   \n",
      "3127   3787   \n",
      "3128   1746   \n",
      "3129   1552   \n",
      "3130   3035   \n",
      "3131   2362   \n",
      "\n",
      "                                                                                           post_expansion  \n",
      "0                                                                        sam at 3:24 LMAO run for ur life  \n",
      "1                                                 Corey Hostetler that's what the bull represents.....duh  \n",
      "2                                                                                      Lux you’re welcome  \n",
      "3                                                                            Stop killing inocent people!  \n",
      "4     The Syrian crisis is a horrible thing, but has anyone noticed the situation’s strange components...  \n",
      "...                                                                                                   ...  \n",
      "3127  @Scorp308 There are not really many good options in Syria right now, but doing nothing or suppor...  \n",
      "3128                    Assad has three children, so it's probably them who were downloading those songs.  \n",
      "3129  +ZenRules - you have made that mistake in Afghanistan and out came Bin Laden. Assad was responsi...  \n",
      "3130  John Oliver is acting like a court jester rather than a satirist by using clueless celebrities t...  \n",
      "3131                                                       Bashar Alassad is manipulating you every time.  \n",
      "\n",
      "[3132 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Expand the YT comments to include the thread context:\n",
    "chunked_result: typing.List[pd.DataFrame] = []\n",
    "GROUPER='videoTitle'\n",
    "#sort data by Time_comment\n",
    "YT_input_sort = YT_input.sort_values(by='parsed_datetime').reset_index(drop=False)\n",
    "groupeddata = YT_input_sort.groupby(GROUPER)\n",
    "for group, df in tqdm.tqdm(groupeddata):\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.loc[:, 'preceding_index'] = df.index.to_series().shift(1)\n",
    "    for index, row in df.iterrows():\n",
    "        if pd.isna(row['preceding_index']):\n",
    "            chunked_result.append(\n",
    "                pd.DataFrame(\n",
    "                    data=[[row['dataset_index'], row['commentText']]],\n",
    "                    columns=['index', 'post_expansion']\n",
    "                )\n",
    "            )\n",
    "        if pd.notna(row['preceding_index']):\n",
    "            #threadset = int(row['preceding_index'])\n",
    "            retry_count = 0\n",
    "            max_retries = 10\n",
    "           \n",
    "            while retry_count < max_retries:\n",
    "                try: \n",
    "                    response = requests.post(\n",
    "                            url=api_endpoint,\n",
    "                            headers=headers,\n",
    "                            json={\n",
    "                                'model': MODELgpt4o,\n",
    "                                'messages': [\n",
    "                                    {\n",
    "                                        \"role\": \"system\",\n",
    "                                        \"content\": SYSTEM_expansion\n",
    "                                    },\n",
    "                                    {\n",
    "                                        \"role\": \"user\",\n",
    "                                        \"content\": f'\"Thread\":\\n<{df[\"commentText\"][:index].to_list()}>, \"Target reply\":<<{df[\"commentText\"].iloc[index]}>>',\n",
    "                                    }\n",
    "                                ],\n",
    "                                'temperature': temperature_0,  \n",
    "                                'seed': SEED,\n",
    "                                \n",
    "                            }\n",
    "                        )  \n",
    "                    if response.status_code == 200:\n",
    "                        data_response = response.json()\n",
    "                        chunked_result.append(\n",
    "                        pd.DataFrame(\n",
    "                            data=[[row['dataset_index'], data_response[\"choices\"][0][\"message\"][\"content\"]]],                                \n",
    "                            columns=['index', 'post_expansion']\n",
    "                            )\n",
    "                        )\n",
    "                        break  # Exit the retry loop on success\n",
    "                    elif response.status_code == 429:\n",
    "                        retry_count += 1\n",
    "                        retry_after = response.headers.get(\"Retry-After\")\n",
    "                        error_message = response.json().get(\"error\", {}).get(\"message\", \"\")\n",
    "                        retry_after = 30  # Default to 30 seconds if not found\n",
    "\n",
    "                        # Extract retry time from the error message\n",
    "                        if \"Try again in\" in error_message:\n",
    "                            match = re.search(r\"Try again in (\\d+) second\", error_message)\n",
    "                            if match:\n",
    "                                try:\n",
    "                                    retry_after = int(match.group(1))\n",
    "                                except (IndexError, ValueError) as e:\n",
    "                                    print(f\"Rate limit exceeded. Error extracting retry time: {e}. Retrying in {retry_after} seconds.\")\n",
    "                                    pass\n",
    "                        elif \"Please retry after\" in error_message:\n",
    "                            match = re.search(r\"Please retry after (\\d+) second\", error_message)\n",
    "                            if match:\n",
    "                                try:\n",
    "                                    retry_after = int(match.group(1))\n",
    "                                except (IndexError, ValueError) as e:\n",
    "                                    print(f\"Rate limit exceeded. Error extracting retry time: {e}. Retrying in {retry_after} seconds.\")\n",
    "                                    pass\n",
    "                                \n",
    "                        else:\n",
    "                            retry_after = 30  # Default to 30 seconds if not found\n",
    "                            print(f\"Rate limit exceeded. Defaulting to retry in {retry_after} seconds.\")\n",
    "\n",
    "                        print(f\"Rate limit exceeded. Retrying in {retry_after} seconds: {response.json()}. Retry count = {retry_count}\") \n",
    "                        time.sleep(retry_after)\n",
    "\n",
    "                    #    print(f\"Rate limit exceeded. Retrying in {wait_time} seconds...\")\n",
    "                    #    print(response.text)\n",
    "                    #    time.sleep(wait_time)\n",
    "                    elif response.status_code == 500:\n",
    "                        retry_count += 1\n",
    "                        wait_time = 20\n",
    "                        print(f\"Failed to connect to API. Status code: {response.status_code}. Retrying in {wait_time} seconds...\")\n",
    "                        print(response.text)\n",
    "                        time.sleep(wait_time)\n",
    "                    else:\n",
    "                        print(f\"Failed to connect to API. Status code: {response.status_code}\")\n",
    "                        print(response.text)\n",
    "                        break\n",
    "                except requests.exceptions.RequestException as e:   \n",
    "                    print(f\"Failed to connect to API: {e}\")\n",
    "                    retry_count += 1\n",
    "                    wait_time = 60\n",
    "                    print(f\"Retrying in {wait_time} seconds...\")\n",
    "                    time.sleep(wait_time)                 \n",
    "\n",
    "expanded_YT_posts = pd.concat(chunked_result, ignore_index=True)\n",
    "print(expanded_YT_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_YT_posts = pd.concat(chunked_result, ignore_index=True)\n",
    "expanded_YT_posts.set_index(expanded_YT_posts['index'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>post_expansion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2936</th>\n",
       "      <td>2936</td>\n",
       "      <td>sam at 3:24 LMAO run for ur life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3573</th>\n",
       "      <td>3573</td>\n",
       "      <td>Corey Hostetler that's what the bull represents.....duh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2864</th>\n",
       "      <td>2864</td>\n",
       "      <td>Lux you’re welcome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098</th>\n",
       "      <td>3098</td>\n",
       "      <td>Stop killing inocent people!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3861</th>\n",
       "      <td>3861</td>\n",
       "      <td>The Syrian crisis is a horrible thing, but has anyone noticed the situation’s strange components...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3787</th>\n",
       "      <td>3787</td>\n",
       "      <td>@Scorp308 There are not really many good options in Syria right now, but doing nothing or suppor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>1746</td>\n",
       "      <td>Assad has three children, so it's probably them who were downloading those songs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>1552</td>\n",
       "      <td>+ZenRules - you have made that mistake in Afghanistan and out came Bin Laden. Assad was responsi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3035</th>\n",
       "      <td>3035</td>\n",
       "      <td>John Oliver is acting like a court jester rather than a satirist by using clueless celebrities t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362</th>\n",
       "      <td>2362</td>\n",
       "      <td>Bashar Alassad is manipulating you every time.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3132 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  \\\n",
       "index          \n",
       "2936    2936   \n",
       "3573    3573   \n",
       "2864    2864   \n",
       "3098    3098   \n",
       "3861    3861   \n",
       "...      ...   \n",
       "3787    3787   \n",
       "1746    1746   \n",
       "1552    1552   \n",
       "3035    3035   \n",
       "2362    2362   \n",
       "\n",
       "                                                                                            post_expansion  \n",
       "index                                                                                                       \n",
       "2936                                                                      sam at 3:24 LMAO run for ur life  \n",
       "3573                                               Corey Hostetler that's what the bull represents.....duh  \n",
       "2864                                                                                    Lux you’re welcome  \n",
       "3098                                                                          Stop killing inocent people!  \n",
       "3861   The Syrian crisis is a horrible thing, but has anyone noticed the situation’s strange components...  \n",
       "...                                                                                                    ...  \n",
       "3787   @Scorp308 There are not really many good options in Syria right now, but doing nothing or suppor...  \n",
       "1746                     Assad has three children, so it's probably them who were downloading those songs.  \n",
       "1552   +ZenRules - you have made that mistake in Afghanistan and out came Bin Laden. Assad was responsi...  \n",
       "3035   John Oliver is acting like a court jester rather than a satirist by using clueless celebrities t...  \n",
       "2362                                                        Bashar Alassad is manipulating you every time.  \n",
       "\n",
       "[3132 rows x 2 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new run 2: now without token output limitation:\n",
    "expanded_YT_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>post_expansion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2936</th>\n",
       "      <td>2936</td>\n",
       "      <td>sam at 3:24 LMAO run for ur life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3573</th>\n",
       "      <td>3573</td>\n",
       "      <td>Corey Hostetler that's what the bull represents.....duh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2864</th>\n",
       "      <td>2864</td>\n",
       "      <td>Lux you’re welcome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098</th>\n",
       "      <td>3098</td>\n",
       "      <td>Stop killing inocent people!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3861</th>\n",
       "      <td>3861</td>\n",
       "      <td>The Syrian crisis is a horrible thing, but has</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3787</th>\n",
       "      <td>3787</td>\n",
       "      <td>@Scorp308 There are not really many good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>1746</td>\n",
       "      <td>Assad has three children, so it's probably them</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>1552</td>\n",
       "      <td>+ZenRules - you have made that mistake in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3035</th>\n",
       "      <td>3035</td>\n",
       "      <td>John Oliver is acting like a court jester rather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362</th>\n",
       "      <td>2362</td>\n",
       "      <td>Bashar Alassad are fucking you in</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3132 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                           post_expansion\n",
       "index                                                                \n",
       "2936    2936                         sam at 3:24 LMAO run for ur life\n",
       "3573    3573  Corey Hostetler that's what the bull represents.....duh\n",
       "2864    2864                                       Lux you’re welcome\n",
       "3098    3098                             Stop killing inocent people!\n",
       "3861    3861           The Syrian crisis is a horrible thing, but has\n",
       "...      ...                                                      ...\n",
       "3787    3787                 @Scorp308 There are not really many good\n",
       "1746    1746          Assad has three children, so it's probably them\n",
       "1552    1552                +ZenRules - you have made that mistake in\n",
       "3035    3035         John Oliver is acting like a court jester rather\n",
       "2362    2362                        Bashar Alassad are fucking you in\n",
       "\n",
       "[3132 rows x 2 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new run, with better listing of preceding comments, i.e. not including the target comment:\n",
    "expanded_YT_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>post_expansion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2936</th>\n",
       "      <td>2936</td>\n",
       "      <td>sam at 3:24 LMAO run for ur life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3573</th>\n",
       "      <td>3573</td>\n",
       "      <td>Corey Hostetler that's what the bull represents.....duh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2864</th>\n",
       "      <td>2864</td>\n",
       "      <td>Lux you’re welcome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098</th>\n",
       "      <td>3098</td>\n",
       "      <td>Stop killing innocent people involved in the Syrian crisis!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3861</th>\n",
       "      <td>3861</td>\n",
       "      <td>The Syrian crisis is a horrible thing, but has</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3787</th>\n",
       "      <td>3787</td>\n",
       "      <td>@Scorp308, considering the current situation in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>1746</td>\n",
       "      <td>Assad has three children, so it's probably them</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1552</th>\n",
       "      <td>1552</td>\n",
       "      <td>+ZenRules - you have made that mistake in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3035</th>\n",
       "      <td>3035</td>\n",
       "      <td>John Oliver is being criticized as a mere entertainer rather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362</th>\n",
       "      <td>2362</td>\n",
       "      <td>Bashar Alassad are fucking you in</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3132 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index                                                post_expansion\n",
       "index                                                                     \n",
       "2936    2936                              sam at 3:24 LMAO run for ur life\n",
       "3573    3573       Corey Hostetler that's what the bull represents.....duh\n",
       "2864    2864                                            Lux you’re welcome\n",
       "3098    3098   Stop killing innocent people involved in the Syrian crisis!\n",
       "3861    3861                The Syrian crisis is a horrible thing, but has\n",
       "...      ...                                                           ...\n",
       "3787    3787               @Scorp308, considering the current situation in\n",
       "1746    1746               Assad has three children, so it's probably them\n",
       "1552    1552                     +ZenRules - you have made that mistake in\n",
       "3035    3035  John Oliver is being criticized as a mere entertainer rather\n",
       "2362    2362                             Bashar Alassad are fucking you in\n",
       "\n",
       "[3132 rows x 2 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_YT_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read legacy data:\n",
    "YT_claim_embeds_leg = pd.read_parquet(f'{CFG.report_dir}/pubsphere_YT_posts.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "YT_claim_embeds_leg.drop(columns=['post_expansion_gpt4o'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YT_input.merge(expanded_YT_posts, left_on='dataset_index', right_index=True, how='left').loc[:, ['dataset_index', 'commentText', 'post_expansion']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "YT_inputmerge = YT_input.merge(expanded_YT_posts, left_on='dataset_index', right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['StartDate', 'RecordedDate', 'IPAddress', 'Finished', 'Coder', 'ID',\n",
       "       'Mark_ID', 'Genre', 'topiccode', 'Platform',\n",
       "       ...\n",
       "       'most_similar_index_gpt4o', 'similarity_score_gpt4o',\n",
       "       'commentText_most_sim_gpt4o', 'claims_ext_gpt4o_token10', 'post_index',\n",
       "       'most_similar_ext_ID_gpt4o_token10',\n",
       "       'similarity_score_ext_gpt4o_token10',\n",
       "       'post_expenasion_most_sim_gpt4o_token10', 'dataset_index',\n",
       "       'post_expansion'],\n",
       "      dtype='object', length=123)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YT_claim_embeds_leg.merge(YT_inputmerge.loc[:, ['dataset_index', 'Mark_ID', 'post_expansion']], left_on='Mark_ID', right_on='Mark_ID', how='left').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YT_claim_embeds = YT_claim_embeds_leg.merge(YT_inputmerge.loc[:, ['dataset_index', 'Mark_ID', 'post_expansion']], left_on='Mark_ID', right_on='Mark_ID', how='left')\n",
    "#YT_claim_embeds.drop(columns=['post_expansion_gpt4o'], inplace=True)\n",
    "YT_claim_embeds.rename(columns={'post_expansion': 'post_expansion_gpt4o'}, inplace=True)\n",
    "YT_claim_embeds.loc[:, ['commentText', 'post_expansion_gpt4o']].tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YT_claim_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "YT_claim_embeds.rename(columns={'post_expansion_gpt4o_tokenlimit10': 'post_expansion_gpt4o_token10', 'most_similar_ext_ID_gpt4o':'most_similar_ext_ID_gpt4o_token10', 'similarity_score_ext_gpt4o':'similarity_score_ext_gpt4o_token10', 'post_expenasion_most_sim_gpt4o':'post_expenasion_most_sim_gpt4o_token10', 'claims_ext_gpt4o':'claims_ext_gpt4o_token10'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data:\n",
    "YT_claim_embeds.to_parquet(f'{CFG.report_dir}/pubsphere_YT_posts.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_claim_embeds.rename(columns={'post_expansion_gpt4o': 'post_expansion_gpt4o_token10', 'most_similar_ext_ID_gpt4o':'most_similar_ext_ID_gpt4o_token10', 'similarity_score_ext_gpt4o':'similarity_score_ext_gpt4o_token10', 'post_expenasion_most_sim_gpt4o':'post_expenasion_most_sim_gpt4o_token10'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_claim_embeds.rename(columns={'claims_ext_gpt4o':'claims_ext_gpt4o_token10'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_claim_embeds = dataset_claim_embeds.merge(YT_inputmerge.loc[:, ['dataset_index', 'Mark_ID', 'post_expansion']], left_on='Mark_ID', right_on='Mark_ID', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['StartDate', 'RecordedDate', 'IPAddress', 'Finished', 'Coder', 'ID',\n",
       "       'Mark_ID', 'Genre', 'topiccode', 'Platform',\n",
       "       ...\n",
       "       'either_political', 'post_ada_embedding', 'dataset_index_x',\n",
       "       'post_expansion_gpt4o_token10', 'most_similar_index_gpt4o',\n",
       "       'similarity_score_gpt4o', 'commentText_most_sim_gpt4o',\n",
       "       'claims_ext_gpt4o_token10', 'dataset_index_y', 'post_expansion'],\n",
       "      dtype='object', length=118)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_claim_embeds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_claim_embeds.drop(columns=['dataset_index_y'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_claim_embeds.drop(columns=['post_expansion_gpt4o'], inplace=True)\n",
    "dataset_claim_embeds.rename(columns={'post_expansion': 'post_expansion_gpt4o'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_claim_embeds = dataset_claim_embeds.join(expanded_YT_posts['post_expansion'], rsuffix='_gpt4o')\n",
    "dataset_claim_embeds.rename(columns={'post_expansion': 'post_expansion_gpt4o'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data:\n",
    "dataset_claim_embeds.to_parquet(f'{CFG.report_dir}/pubsphere.claim_embed.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "57it [00:58,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64it [01:03,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "121it [02:51,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 21 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 21 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "126it [03:14,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 5 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "182it [05:16,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 7 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "186it [05:25,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 5 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "243it [07:18,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 17 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 17 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "259it [07:50,  2.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "315it [09:54,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "317it [09:57,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "373it [11:40,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 22 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 22 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "403it [12:17,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 5 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "459it [14:18,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 9 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "466it [14:30,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "523it [16:32,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "524it [16:37,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 8 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "533it [16:52,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "589it [18:39,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 20 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 20 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "593it [19:01,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "650it [20:39,  2.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 27 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 27 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "651it [21:07,  8.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "708it [22:48,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 25 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 25 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "712it [23:16,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "768it [25:06,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 18 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 18 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "823it [26:17,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 8 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "826it [26:28,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "880it [28:23,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 11 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 11 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "893it [28:45,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "950it [30:28,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 22 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 22 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1041it [32:35,  2.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1043it [32:38,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1055it [32:54,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1111it [34:49,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 10 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1112it [35:00,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1168it [36:53,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 12 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 12 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1173it [37:11,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1226it [39:09,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 9 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1227it [39:19,  3.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1283it [41:06,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 20 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 20 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1286it [41:28,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1341it [43:30,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1342it [43:34,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 6 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1343it [43:42,  3.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1399it [45:36,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 12 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 12 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1423it [46:09,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1480it [47:56,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 18 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 18 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1553it [49:31,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1611it [50:39,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1620it [50:46,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1752it [54:23,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1759it [54:31,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1864it [57:27,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 12 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 12 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1868it [57:44,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1924it [59:46,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1930it [59:54,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 5 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1986it [1:01:54,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 10 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1993it [1:02:12,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2049it [1:04:03,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 15 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 15 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2054it [1:04:20,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2110it [1:06:08,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 20 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 20 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2166it [1:07:25,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2168it [1:07:36,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2223it [1:08:32,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2224it [1:08:37,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 5 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2225it [1:08:45,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2297it [1:11:16,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 9 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2307it [1:11:40,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2363it [1:13:50,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 6 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2374it [1:14:04,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 7 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2430it [1:15:58,  2.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 17 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 17 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2432it [1:16:16,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2488it [1:18:02,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 19 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 19 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2491it [1:18:23,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2548it [1:20:22,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 7 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2551it [1:20:31,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 13 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 13 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2558it [1:20:51,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 5 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2615it [1:22:40,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 20 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 20 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2644it [1:23:15,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2700it [1:24:59,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 22 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 22 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2703it [1:25:22,  4.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2759it [1:27:19,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 9 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2770it [1:27:40,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2826it [1:29:41,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 6 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2844it [1:30:03,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2900it [1:31:54,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 15 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 15 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2906it [1:32:14,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2962it [1:34:05,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 14 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 14 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3016it [1:35:04,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3073it [1:36:48,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 22 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 22 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3074it [1:37:10,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 5 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3129it [1:39:13,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 7 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3132it [1:39:26,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index  \\\n",
      "0      0   \n",
      "1      1   \n",
      "2      3   \n",
      "3      4   \n",
      "4      5   \n",
      "\n",
      "                                                                   claims  \n",
      "0                                                                      []  \n",
      "1                                            [\"Minerals have rights too\"]  \n",
      "2  [\"The death of free and civil dialogue has been effectively depicted\"]  \n",
      "3                                            [\"No-one else will hug him\"]  \n",
      "4                                                                      []  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#mine claims from the original posts as a benchmark\n",
    "\n",
    "chunked_result: typing.List[pd.DataFrame] = []\n",
    "for index, row in tqdm.tqdm(YT_claim_embeds.iterrows()):\n",
    "    retry_count = 0\n",
    "    max_retries = 10\n",
    "    \n",
    "    while retry_count < max_retries:\n",
    "        try: \n",
    "            response = requests.post(\n",
    "                    url=api_endpoint,\n",
    "                    headers=headers,\n",
    "                    json={\n",
    "                        'model': MODELgpt4o,\n",
    "                        'messages': [\n",
    "                            {\n",
    "                                \"role\": \"system\",\n",
    "                                \"content\": SYSTEM_claim                         \n",
    "                            },\n",
    "                            {\n",
    "                                \"role\": \"user\",\n",
    "                                \"content\": f'The following social media post is a reply to a news- or infotainment video. '\n",
    "                                         + f'Check whether your answer strictly adheres to the specified format. \\n\"Post\":\\n<{row[\"commentText\"]}>',\n",
    "                            }\n",
    "                        ],\n",
    "                        'temperature': temperature_0,  \n",
    "                        'seed': SEED\n",
    "                    }\n",
    "                )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                data_response = response.json()\n",
    "                chunked_result.append(\n",
    "                pd.DataFrame(\n",
    "                    data=[[row['dataset_index'], data_response[\"choices\"][0][\"message\"][\"content\"]]],                                \n",
    "                    columns=['index', 'claims']\n",
    "                    )\n",
    "                )\n",
    "                break  # Exit the retry loop on success  \n",
    "            elif response.status_code == 429:\n",
    "                retry_count += 1\n",
    "                retry_after = response.headers.get(\"Retry-After\")\n",
    "                error_message = response.json().get(\"error\", {}).get(\"message\", \"\")\n",
    "                retry_after = 30  # Default to 30 seconds if not found\n",
    "            \n",
    "                # Extract retry time from the error message\n",
    "                if \"Try again in\" in error_message:\n",
    "                    match = re.search(r\"Try again in (\\d+) second\", error_message)\n",
    "                    if match:\n",
    "                        try:\n",
    "                            retry_after = int(match.group(1))\n",
    "                        except (IndexError, ValueError) as e:\n",
    "                            print(f\"Rate limit exceeded. Error extracting retry time: {e}. Retrying in {retry_after} seconds.\")\n",
    "                            pass\n",
    "                elif \"Please retry after\" in error_message:\n",
    "                    match = re.search(r\"Please retry after (\\d+) second\", error_message)\n",
    "                    if match:\n",
    "                        try:\n",
    "                            retry_after = int(match.group(1))\n",
    "                        except (IndexError, ValueError) as e:\n",
    "                            print(f\"Rate limit exceeded. Error extracting retry time: {e}. Retrying in {retry_after} seconds.\")\n",
    "                            pass\n",
    "                \n",
    "\n",
    "                else:\n",
    "                    retry_after = 30  # Default to 30 seconds if not found\n",
    "                    print(f\"Rate limit exceeded. Defaulting to retry in {retry_after} seconds.\")\n",
    "                            \n",
    "        \n",
    "                print(f\"Rate limit exceeded. Retrying in {retry_after} seconds: {response.json()}. Retry count = {retry_count}\") \n",
    "                time.sleep(retry_after)\n",
    "                \n",
    "            #    print(f\"Rate limit exceeded. Retrying in {wait_time} seconds...\")\n",
    "            #    print(response.text)\n",
    "            #    time.sleep(wait_time)\n",
    "            elif response.status_code == 500:\n",
    "                retry_count += 1\n",
    "                wait_time = 20\n",
    "                print(f\"Failed to connect to API. Status code: {response.status_code}. Retrying in {wait_time} seconds...\")\n",
    "                print(response.text)\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                print(f\"Failed to connect to API. Status code: {response.status_code}\")\n",
    "                print(response.text)\n",
    "                break\n",
    "        except requests.exceptions.RequestException as e:   \n",
    "            print(f\"Failed to connect to API: {e}\")\n",
    "            retry_count += 1\n",
    "            wait_time = 60\n",
    "            print(f\"Retrying in {wait_time} seconds...\")\n",
    "            time.sleep(wait_time)   \n",
    "\n",
    "        if retry_count >= max_retries:\n",
    "            print(f\"Max retries reached for index {index}. Skipping to next item.\")\n",
    "            break  # Exit the loop if max retries are reached              \n",
    "\n",
    "YT_claims = pd.concat(chunked_result, ignore_index=True)\n",
    "print(YT_claims.head())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[   index claims\n",
       " 0      0     [],\n",
       "    index                        claims\n",
       " 0      1  [\"Minerals have rights too\"],\n",
       "    index  \\\n",
       " 0      3   \n",
       " \n",
       "                                                                    claims  \n",
       " 0  [\"The death of free and civil dialogue has been effectively depicted\"]  ,\n",
       "    index                        claims\n",
       " 0      4  [\"No-one else will hug him\"],\n",
       "    index claims\n",
       " 0      5     [],\n",
       "    index                                               claims\n",
       " 0      6  [\"Trump is a traitor\", \"Trump should be locked up\"],\n",
       "    index claims\n",
       " 0      7     [],\n",
       "    index  \\\n",
       " 0      8   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"America is a country of idiots run by the NRA\", \"America should get rid of the 2nd amendment\",...  ,\n",
       "    index                                            claims\n",
       " 0      9  [\"They weren't going to vote democratic anyway\"],\n",
       "    index                                         claims\n",
       " 0     10  [\"Ivanka does not have high moral standards\"],\n",
       "    index claims\n",
       " 0     11     [],\n",
       "    index claims\n",
       " 0     12     [],\n",
       "    index  \\\n",
       " 0     13   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Talking directly to Russia is necessary when discussing issues related to Russia\", \"Admitting ...  ,\n",
       "    index                          claims\n",
       " 0     14  [\"You will lose the midterms\"],\n",
       "    index claims\n",
       " 0     15     [],\n",
       "    index  \\\n",
       " 0     16   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"DJT is a Mary Sue character in his own mind\", \"DJT is a draft dodger who belittles real war he...  ,\n",
       "    index claims\n",
       " 0     17     [],\n",
       "    index  \\\n",
       " 0     18   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The President's weekend trips to his resort are costly\", \"The President's trips are opposed by...  ,\n",
       "    index  \\\n",
       " 0     19   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The young girl is misguided\", \"The girl's mom did nothing wrong\", \"The mom committed identity ...  ,\n",
       "    index  \\\n",
       " 0     20   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The doctor claims Trump is 6'3\\\" and 239 pounds\", \"The doctor is in charge of the VA\", \"The do...  ,\n",
       "    index              claims\n",
       " 0     21  [\"Mika is low IQ\"],\n",
       "    index  \\\n",
       " 0     22   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The POTUS lacks emotional intelligence\", \"The POTUS has no impulse control\", \"The POTUS may ha...  ,\n",
       "    index claims\n",
       " 0     23     [],\n",
       "    index  \\\n",
       " 0     24   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Republicans need to be forced to impeach the president\", \"A Democratic president would have fa...  ,\n",
       "    index                                             claims\n",
       " 0     25  [\"Trump belongs at the bottom of the trash heap\"],\n",
       "    index  \\\n",
       " 0     26   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Mueller has cast doubt on the accuracy of the Buzzfeed article\", \"The Trump team should avoid ...  ,\n",
       "    index  \\\n",
       " 0     27   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The spying program started in Bush era\", \"The spying program arguably contributes to national ...  ,\n",
       "    index claims\n",
       " 0     28     [],\n",
       "    index                                  claims\n",
       " 0     29  [\"Democrats will not take any action\"],\n",
       "    index                                                       claims\n",
       " 0     30  [\"He does not have the right to kidnap people's children.\"],\n",
       "    index claims\n",
       " 0     31     [],\n",
       "    index  \\\n",
       " 0     32   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"John is building a case to fire Kelly\", \"There is a Communist takeover of our government\", \"Mu...  ,\n",
       "    index claims\n",
       " 0     33     [],\n",
       "    index claims\n",
       " 0     34     [],\n",
       "    index claims\n",
       " 0     35     [],\n",
       "    index claims\n",
       " 0     36     [],\n",
       "    index claims\n",
       " 0     37     [],\n",
       "    index  \\\n",
       " 0     38   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"We are desperate for the next 4 years to pass quickly\", \"There is a concern that the country m...  ,\n",
       "    index                                                                claims\n",
       " 0     39  [\"Saying his films are propaganda because he was a soldier is dumb\"],\n",
       "    index  \\\n",
       " 0     40   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Trump is in the White House because Hillary Clinton was a terrible candidate\", \"People continu...  ,\n",
       "    index claims\n",
       " 0     41     [],\n",
       "    index  \\\n",
       " 0     42   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"She only gained critical thinking skills from Harvard\", \"She attended Harvard just to say she ...  ,\n",
       "    index claims\n",
       " 0     43     [],\n",
       "    index  \\\n",
       " 0     44   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The US government no longer punishes treason with death\", \"The US government punishes treason ...  ,\n",
       "    index                          claims\n",
       " 0     45  [\"The U.S is overly dramatic\"],\n",
       "    index claims\n",
       " 0     46     [],\n",
       "    index                                                         claims\n",
       " 0     47  [\"Sneezing, coughing, and vomiting are symptoms of the flu.\"],\n",
       "    index claims\n",
       " 0     48     [],\n",
       "    index claims\n",
       " 0     49     [],\n",
       "    index claims\n",
       " 0     50     [],\n",
       "    index claims\n",
       " 0     51     [],\n",
       "    index                                              claims\n",
       " 0     52  [\"The news about the monument collapsing is fake\"],\n",
       "    index                 claims\n",
       " 0     53  [\"She's a huge liar\"],\n",
       "    index claims\n",
       " 0     54     [],\n",
       "    index claims\n",
       " 0     55     [],\n",
       "    index  \\\n",
       " 0     56   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Trump doesn't pay his contractors\", \"Trump spent money paying off porn stars for work they did...  ,\n",
       "    index  \\\n",
       " 0     57   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"This dude is rich\", \"He could take the rest of his life off\", \"You should humble yourself when...  ,\n",
       "    index                                                                claims\n",
       " 0     58  [\"The interview is boring\", \"Bernie was replaced for the interview\"],\n",
       "    index claims\n",
       " 0     59     [],\n",
       "    index claims\n",
       " 0     60     [],\n",
       "    index  \\\n",
       " 0     61   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Hilary Clinton solicited money for the Clinton Foundation, not a campaign fundraising entity\",...  ,\n",
       "    index claims\n",
       " 0     62     [],\n",
       "    index claims\n",
       " 0     63     [],\n",
       "    index claims\n",
       " 0     64     [],\n",
       "    index  \\\n",
       " 0     65   \n",
       " \n",
       "                                                                   claims  \n",
       " 0  [\"Need more storytellers like her on late night\", \"Stephen loves it\"]  ,\n",
       "    index claims\n",
       " 0     66     [],\n",
       "    index  \\\n",
       " 0     67   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Despair is hubris because it assumes knowledge of the future\", \"Intelligence involves anticipa...  ,\n",
       "    index claims\n",
       " 0     68     [],\n",
       "    index                                               claims\n",
       " 0     69  [\"She kept innocent people locked up for her ego.\"],\n",
       "    index claims\n",
       " 0     70     [],\n",
       "    index claims\n",
       " 0     71     [],\n",
       "    index claims\n",
       " 0     72     [],\n",
       "    index                                             claims\n",
       " 0     73  [\"Citizens of the country flee and flood Europe\"],\n",
       "    index claims\n",
       " 0     74     [],\n",
       "    index claims\n",
       " 0     75     [],\n",
       "    index  \\\n",
       " 0     76   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Republicans lack understanding\", \"Republicans need to gain understanding before losing support...  ,\n",
       "    index                                            claims\n",
       " 0     77  [\"People are racist because they are terrified\"],\n",
       "    index claims\n",
       " 0     78     [],\n",
       "    index claims\n",
       " 0     79     [],\n",
       "    index claims\n",
       " 0     80     [],\n",
       "    index  \\\n",
       " 0     81   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"North Korea and Arabian Muslims want Trump to succeed\", \"North Korea and Arabian Muslims are p...  ,\n",
       "    index claims\n",
       " 0     82     [],\n",
       "    index claims\n",
       " 0     83     [],\n",
       "    index                            claims\n",
       " 0     84  [\"The comment was very hateful\"],\n",
       "    index claims\n",
       " 0     85     [],\n",
       "    index claims\n",
       " 0     86     [],\n",
       "    index  \\\n",
       " 0     87   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Buzzfeed is a news outlet\", \"Buzzfeed posts humorous content\", \"Buzzfeed is a mix of Vox and T...  ,\n",
       "    index claims\n",
       " 0     88     [],\n",
       "    index claims\n",
       " 0     89     [],\n",
       "    index                   claims\n",
       " 0     90  [\"Trudeau is a savage\"],\n",
       "    index  \\\n",
       " 0     91   \n",
       " \n",
       "                                                                    claims  \n",
       " 0  [\"Racists are easily offended by comments from people of other races\"]  ,\n",
       "    index claims\n",
       " 0     92     [],\n",
       "    index                                        claims\n",
       " 0     93  [\"She meant facts that support their claim\"],\n",
       "    index claims\n",
       " 0     94     [],\n",
       "    index claims\n",
       " 0     95     [],\n",
       "    index  \\\n",
       " 0     96   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The Dutch are top in intelligence and height standings\", \"Trump voters have a survival instinc...  ,\n",
       "    index claims\n",
       " 0     97     [],\n",
       "    index  \\\n",
       " 0     98   \n",
       " \n",
       "                                                                                        claims  \n",
       " 0  [\"The new show is purely sarcasm\", \"He is not being silenced because he has his own show\"]  ,\n",
       "    index  \\\n",
       " 0     99   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"It's unnecessary to tell her results to the world\", \"She and her mom are resting in peace toge...  ,\n",
       "    index claims\n",
       " 0    100     [],\n",
       "    index claims\n",
       " 0    101     [],\n",
       "    index claims\n",
       " 0    102     [],\n",
       "    index  \\\n",
       " 0    103   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"She looks older than her age\", \"Being too skinny makes her look older\", \"It's better to have a...  ,\n",
       "    index claims\n",
       " 0    104     [],\n",
       "    index  \\\n",
       " 0    105   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The media has been criticizing Russia non-stop for 400 days\", \"The criticism is driven by the ...  ,\n",
       "    index claims\n",
       " 0    106     [],\n",
       "    index  \\\n",
       " 0    107   \n",
       " \n",
       "                                                                   claims  \n",
       " 0  [\"Black Lives Matter is racist\", \"Black Lives Matter is never right\"]  ,\n",
       "    index claims\n",
       " 0    108     [],\n",
       "    index claims\n",
       " 0    109     [],\n",
       "    index claims\n",
       " 0    110     [],\n",
       "    index  \\\n",
       " 0    111   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Liberals will not succeed in 2020\", \"Liberal ideologies are anti-American and socialist\", \"Lib...  ,\n",
       "    index                            claims\n",
       " 0    112  [\"Mexico will pay for the wall\"],\n",
       "    index claims\n",
       " 0    113     [],\n",
       "    index  \\\n",
       " 0    114   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Feminazis should be shipped out of the country\", \"Everyone should be equal in pay if they can ...  ,\n",
       "    index claims\n",
       " 0    115     [],\n",
       "    index  \\\n",
       " 0    116   \n",
       " \n",
       "                                                                                     claims  \n",
       " 0  [\"There is no evidence of Russia collusion after 2 years and 40 million dollars spent\"]  ,\n",
       "    index  \\\n",
       " 0    117   \n",
       " \n",
       "                                                                               claims  \n",
       " 0  [\"He doesn't stand for the national anthem\", \"He should not get paid in the USA\"]  ,\n",
       "    index                                                   claims\n",
       " 0    118  [\"The woman is corrupt\", \"Veritas delivered the goods\"],\n",
       "    index                          claims\n",
       " 0    119  [\"Russell O'Neal is very old\"],\n",
       "    index claims\n",
       " 0    120     [],\n",
       "    index claims\n",
       " 0    121     [],\n",
       "    index claims\n",
       " 0    122     [],\n",
       "    index claims\n",
       " 0    123     [],\n",
       "    index claims\n",
       " 0    124     [],\n",
       "    index claims\n",
       " 0    125     [],\n",
       "    index                                                claims\n",
       " 0    126  [\"Trump has little command of the English language\"],\n",
       "    index  \\\n",
       " 0    127   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Harry didn't act foolishly in front of the media during his party days\", \"There is a time and ...  ,\n",
       "    index  \\\n",
       " 0    128   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Democrats are a waste of time\", \"Democrats are nasty because of Mr. Trump\", \"Mr. Trump will wi...  ,\n",
       "    index  \\\n",
       " 0    129   \n",
       " \n",
       "                                                                           claims  \n",
       " 0  [\"Democrats want Trump to end the shutdown\", \"Trump is the one holding back\"]  ,\n",
       "    index claims\n",
       " 0    130     [],\n",
       "    index claims\n",
       " 0    131     [],\n",
       "    index claims\n",
       " 0    132     [],\n",
       "    index claims\n",
       " 0    133     [],\n",
       "    index  \\\n",
       " 0    134   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Conditions in Central America are a consequence of Reagan and Kissinger's wars\", \"Iran-Contra ...  ,\n",
       "    index claims\n",
       " 0    135     [],\n",
       "    index claims\n",
       " 0    136     [],\n",
       "    index                  claims\n",
       " 0    137  [\"Barrack is crooked\"],\n",
       "    index                                           claims\n",
       " 0    138  [\"Hezbollah would not last a day without Iran\"],\n",
       "    index claims\n",
       " 0    139     [],\n",
       "    index claims\n",
       " 0    140     [],\n",
       "    index claims\n",
       " 0    141     [],\n",
       "    index claims\n",
       " 0    142     [],\n",
       "    index                                                    claims\n",
       " 0    143  [\"We need more senators from the south with his values\"],\n",
       "    index  \\\n",
       " 0    144   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"He knew the rules when he got in\", \"You can't change the rules if you don't like them\", \"Repub...  ,\n",
       "    index  \\\n",
       " 0    145   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The person is a gun zealot maniac\", \"The person makes no sense\", \"The person has no evidence t...  ,\n",
       "    index                                          claims\n",
       " 0    146  [\"Kaine is still very sore he and Hilda lost\"],\n",
       "    index claims\n",
       " 0    147     [],\n",
       "    index claims\n",
       " 0    148     [],\n",
       "    index                                                  claims\n",
       " 0    149  [\"They are setting Iran up for violation of the deal\"],\n",
       "    index  \\\n",
       " 0    150   \n",
       " \n",
       "                                                                     claims  \n",
       " 0  [\"Mueller and Rosenstein should be fired\", \"Donnie will get impeached\"]  ,\n",
       "    index  \\\n",
       " 0    151   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The people of the United States can impeach a sitting President through Congress\", \"A sitting ...  ,\n",
       "    index  \\\n",
       " 0    152   \n",
       " \n",
       "                                                                               claims  \n",
       " 0  [\"The person being referred to has not worked or provided a service for America\"]  ,\n",
       "    index claims\n",
       " 0    153     [],\n",
       "    index  \\\n",
       " 0    154   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Clinton Propaganda Machine spreads lies\", \"Clinton Propaganda Machine uses Goebbels methods\", ...  ,\n",
       "    index                     claims\n",
       " 0    155  [\"I am voting for Trump\"],\n",
       "    index  \\\n",
       " 0    156   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Name calling and belittling labels make you look small\", \"Extremists are doing harm to America...  ,\n",
       "    index                      claims\n",
       " 0    157  [\"CBS lies to the nation\"],\n",
       "    index claims\n",
       " 0    158     [],\n",
       "    index claims\n",
       " 0    159     [],\n",
       "    index claims\n",
       " 0    160     [],\n",
       "    index claims\n",
       " 0    161     [],\n",
       "    index  \\\n",
       " 0    162   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Trump was expected to be on good behavior for UN appearance\", \"The media is covering for Trump...  ,\n",
       "    index  \\\n",
       " 0    163   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Russia could only influence US elections by hacking voting machines\", \"It is outrageous to sug...  ,\n",
       "    index claims\n",
       " 0    164     [],\n",
       "    index claims\n",
       " 0    165     [],\n",
       "    index  \\\n",
       " 0    166   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Women are not as physically and mentally strong as men\", \"Women cannot fit the job as well as ...  ,\n",
       "    index                                 claims\n",
       " 0    167  [\"white people fall for dumb things\"],\n",
       "    index claims\n",
       " 0    168     [],\n",
       "    index  \\\n",
       " 0    169   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Obama provided amnesty to illegal immigrants\", \"ICE Director John Morton prohibited ICE office...  ,\n",
       "    index claims\n",
       " 0    170     [],\n",
       "    index claims\n",
       " 0    171     [],\n",
       "    index claims\n",
       " 0    172     [],\n",
       "    index                                             claims\n",
       " 0    173  [\"Carlos Santana has the best performances ever\"],\n",
       "    index claims\n",
       " 0    174     [],\n",
       "    index claims\n",
       " 0    175     [],\n",
       "    index  \\\n",
       " 0    176   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"There are health ramifications of getting shot in the face\", \"People might need to wear bullet...  ,\n",
       "    index claims\n",
       " 0    177     [],\n",
       "    index claims\n",
       " 0    178     [],\n",
       "    index claims\n",
       " 0    179     [],\n",
       "    index claims\n",
       " 0    180     [],\n",
       "    index  \\\n",
       " 0    181   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Trump is in charge\", \"The FBI are in tatters\", \"Trump should never have sacked Comey\", \"It's a...  ,\n",
       "    index claims\n",
       " 0    182     [],\n",
       "    index  \\\n",
       " 0    183   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The photography uses amazing tricks\", \"Some shots are mindblowing\", \"The music is overblown\", ...  ,\n",
       "    index  \\\n",
       " 0    184   \n",
       " \n",
       "                                                                                             claims  \n",
       " 0  [\"The second one was not as good as the first one\", \"The second one did not meet expectations\"]  ,\n",
       "    index claims\n",
       " 0    185     [],\n",
       "    index claims\n",
       " 0    186     [],\n",
       "    index claims\n",
       " 0    187     [],\n",
       "    index  \\\n",
       " 0    188   \n",
       " \n",
       "                                                                         claims  \n",
       " 0  [\"Men who kiss and tell will hurt you\", \"A jealous man is not trustworthy\"]  ,\n",
       "    index claims\n",
       " 0    189     [],\n",
       "    index  \\\n",
       " 0    190   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The show was amazing\", \"You won't regret seeing the show\", \"The sound clips of Reeve are enjoy...  ,\n",
       "    index  \\\n",
       " 0    191   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"You have started lying about your age\", \"A year ago you were 47\", \"Now you claim to be 41\", \"Y...  ,\n",
       "    index claims\n",
       " 0    192     [],\n",
       "    index claims\n",
       " 0    193     [],\n",
       "    index claims\n",
       " 0    194     [],\n",
       "    index claims\n",
       " 0    195     [],\n",
       "    index  \\\n",
       " 0    196   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The industry is worse\", \"Biodiversity is a fundamental pillar for all life on earth\", \"Cloned ...  ,\n",
       "    index claims\n",
       " 0    197     [],\n",
       "    index claims\n",
       " 0    198     [],\n",
       "    index claims\n",
       " 0    199     [],\n",
       "    index  \\\n",
       " 0    200   \n",
       " \n",
       "                                                                                   claims  \n",
       " 0  [\"We should stop competing with each other\", \"We should start completing each other\"]  ,\n",
       "    index claims\n",
       " 0    201     [],\n",
       "    index  \\\n",
       " 0    202   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Stress does horrible things to a body\", \"Every veteran that I know is on blood pressure pills\"...  ,\n",
       "    index  \\\n",
       " 0    203   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The board behind Samantha is blurred\", \"The shirt in Sam's hand has the 'UN' part covered by b...  ,\n",
       "    index claims\n",
       " 0    204     [],\n",
       "    index claims\n",
       " 0    205     [],\n",
       "    index  \\\n",
       " 0    206   \n",
       " \n",
       "                                                                             claims  \n",
       " 0  [\"The show would succeed if they didn't mock half their potential viewer-base\"]  ,\n",
       "    index claims\n",
       " 0    207     [],\n",
       "    index  \\\n",
       " 0    208   \n",
       " \n",
       "                                                                                           claims  \n",
       " 0  [\"Sam was unfair to Bernie during the election\", \"Bernie could have beaten the Orange Idiot\"]  ,\n",
       "    index  \\\n",
       " 0    209   \n",
       " \n",
       "                                                                        claims  \n",
       " 0  [\"I am turning off this show for good\", \"I am turning off the daily show\"]  ,\n",
       "    index claims\n",
       " 0    210     [],\n",
       "    index claims\n",
       " 0    211     [],\n",
       "    index claims\n",
       " 0    212     [],\n",
       "    index claims\n",
       " 0    213     [],\n",
       "    index  \\\n",
       " 0    214   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The person being discussed is considered more attractive\", \"The commenter questions if the opi...  ,\n",
       "    index                                   claims\n",
       " 0    215  [\"Women can't say no on a cruise ship\"],\n",
       "    index  \\\n",
       " 0    216   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"People should not be shocked that a Republican appointed a conservative justice\", \"People shou...  ,\n",
       "    index claims\n",
       " 0    217     [],\n",
       "    index  \\\n",
       " 0    218   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Many Trump supporters and conservatives don't see the difference\", \"It is frustrating to be ca...  ,\n",
       "    index                                       claims\n",
       " 0    219  [\"Tom Martell is a four-time draft dodger\"],\n",
       "    index claims\n",
       " 0    220     [],\n",
       "    index  \\\n",
       " 0    221   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"US politicians are blocking bills designed to protect children from child marriage\", \"Blocking...  ,\n",
       "    index claims\n",
       " 0    222     [],\n",
       "    index  \\\n",
       " 0    223   \n",
       " \n",
       "                                                                                   claims  \n",
       " 0  [\"The enablers of the 'useful idiot' need to be roasted\", \"Don-the-Con doesn't care\"]  ,\n",
       "    index claims\n",
       " 0    224     [],\n",
       "    index  \\\n",
       " 0    225   \n",
       " \n",
       "                                                                                  claims  \n",
       " 0  [\"The video did not try to appropriate a style\", \"The video made a good whole song\"]  ,\n",
       "    index  \\\n",
       " 0    226   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"They are only working for Trump as long as Trump works for their greedy, conscience-free donors\"]  ,\n",
       "    index claims\n",
       " 0    227     [],\n",
       "    index                                          claims\n",
       " 0    228  [\"Seth Myers is the true heir of Jon Stewart\"],\n",
       "    index claims\n",
       " 0    229     [],\n",
       "    index claims\n",
       " 0    230     [],\n",
       "    index                                                      claims\n",
       " 0    231  [\"Sam does not understand what Trump's movement is about\"],\n",
       "    index  \\\n",
       " 0    232   \n",
       " \n",
       "                                                                                      claims  \n",
       " 0  [\"Trump is an authoritarian\", \"Unity is a code word for doing everything Trump demands\"]  ,\n",
       "    index claims\n",
       " 0    233     [],\n",
       "    index claims\n",
       " 0    234     [],\n",
       "    index claims\n",
       " 0    235     [],\n",
       "    index claims\n",
       " 0    236     [],\n",
       "    index claims\n",
       " 0    237     [],\n",
       "    index claims\n",
       " 0    238     [],\n",
       "    index claims\n",
       " 0    239     [],\n",
       "    index claims\n",
       " 0    240     [],\n",
       "    index claims\n",
       " 0    241     [],\n",
       "    index claims\n",
       " 0    242     [],\n",
       "    index claims\n",
       " 0    243     [],\n",
       "    index claims\n",
       " 0    244     [],\n",
       "    index  \\\n",
       " 0    245   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Gerald Fraas misses the point of satire\", \"Gerald Fraas condescends by pasting a definition of...  ,\n",
       "    index claims\n",
       " 0    246     [],\n",
       "    index claims\n",
       " 0    247     [],\n",
       "    index claims\n",
       " 0    248     [],\n",
       "    index claims\n",
       " 0    249     [],\n",
       "    index claims\n",
       " 0    250     [],\n",
       "    index claims\n",
       " 0    251     [],\n",
       "    index claims\n",
       " 0    252     [],\n",
       "    index  \\\n",
       " 0    253   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"All lives matter\", \"BLM is its own thing\", \"Responding with all lives matter takes away from w...  ,\n",
       "    index claims\n",
       " 0    254     [],\n",
       "    index claims\n",
       " 0    255     [],\n",
       "    index claims\n",
       " 0    256     [],\n",
       "    index claims\n",
       " 0    257     [],\n",
       "    index                                 claims\n",
       " 0    258  [\"I would get HBO just for this guy\"],\n",
       "    index claims\n",
       " 0    259     [],\n",
       "    index  \\\n",
       " 0    260   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Humans do not cause climate change\", \"Humans can't fix anything related to climate change\", \"T...  ,\n",
       "    index                                                 claims\n",
       " 0    261  [\"Last Week Tonight criticizes many things HBO does\"],\n",
       "    index claims\n",
       " 0    262     [],\n",
       "    index                                        claims\n",
       " 0    263  [\"He was sending a message to his mistress\"],\n",
       "    index  \\\n",
       " 0    264   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Payments from Medicare are about half of what private insurance typically pays\", \"Hospitals an...  ,\n",
       "    index                                              claims\n",
       " 0    265  [\"Trump needs more criminals to fill his cabinet\"],\n",
       "    index claims\n",
       " 0    266     [],\n",
       "    index  \\\n",
       " 0    267   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Trump acts more like Hitler than any other president\", \"Trump sells hate and fear of scapegoat...  ,\n",
       "    index                 claims\n",
       " 0    268  [\"I'm voting Rosen.\"],\n",
       "    index  \\\n",
       " 0    269   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Matthews intentionally did not cover Bernie\", \"Matthews is a Clinton supporter\", \"Hillary may ...  ,\n",
       "    index  \\\n",
       " 0    270   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"If Hillary wins the nomination, Trump has a 9/10 or better chance of winning the general elect...  ,\n",
       "    index  \\\n",
       " 0    271   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Fox News runs stories without verification\", \"MSNBC informs viewers when a story is not indepe...  ,\n",
       "    index claims\n",
       " 0    272     [],\n",
       "    index claims\n",
       " 0    273     [],\n",
       "    index  \\\n",
       " 0    274   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The President is playing golf instead of being at the White House\", \"The President's absence f...  ,\n",
       "    index  \\\n",
       " 0    275   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"There was an actual study out of London aired on NPR in the late nineties\", \"The speaker would...  ,\n",
       "    index claims\n",
       " 0    276     [],\n",
       "    index claims\n",
       " 0    277     [],\n",
       "    index claims\n",
       " 0    278     [],\n",
       "    index  \\\n",
       " 0    279   \n",
       " \n",
       "                                                                                   claims  \n",
       " 0  [\"Only 19% of Americans voted for Trump\", \"More people voted for Hillary than Trump\"]  ,\n",
       "    index claims\n",
       " 0    280     [],\n",
       "    index claims\n",
       " 0    281     [],\n",
       "    index claims\n",
       " 0    282     [],\n",
       "    index  \\\n",
       " 0    283   \n",
       " \n",
       "                                                                           claims  \n",
       " 0  [\"She is a corrupted corporate Democrat\", \"MSNBC treats her with kid gloves\"]  ,\n",
       "    index claims\n",
       " 0    284     [],\n",
       "    index                                                      claims\n",
       " 0    285  [\"Conspirators could never have kept it secret this long\"],\n",
       "    index  \\\n",
       " 0    286   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"You will not get answers\", \"You will be distracted\", \"Americans are stupid, gullible and easil...  ,\n",
       "    index  \\\n",
       " 0    287   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"MSNBC is worried\", \"Omarosa is promoting herself\", \"True Americans can see through MSNBC's spin\"]  ,\n",
       "    index                claims\n",
       " 0    288  [\"Donny is crooked\"],\n",
       "    index claims\n",
       " 0    289     [],\n",
       "    index  \\\n",
       " 0    290   \n",
       " \n",
       "                                                                            claims  \n",
       " 0  [\"she might be a leaker\", \"if she spied for a deep state then that's treason\"]  ,\n",
       "    index claims\n",
       " 0    291     [],\n",
       "    index  \\\n",
       " 0    292   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Innocent people have protections in law\", \"Innocent people have protections regarding accusati...  ,\n",
       "    index  \\\n",
       " 0    293   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Trump committed a crime by pushing an altered map as real\", \"Trump should be fined and/or jail...  ,\n",
       "    index  \\\n",
       " 0    294   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Forbes estimate of Trump's worth is inaccurate\", \"Forbes was inaccurate about Wilbur Ross's we...  ,\n",
       "    index  \\\n",
       " 0    295   \n",
       " \n",
       "                                                                             claims  \n",
       " 0  [\"The Democrats lost again\", \"The speaker is thankful for the Democrats' loss\"]  ,\n",
       "    index                       claims\n",
       " 0    296  [\"There is no exoneration\"],\n",
       "    index claims\n",
       " 0    297     [],\n",
       "    index  \\\n",
       " 0    298   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Looking up and to the right means you're trying to remember something\", \"Looking up and to the...  ,\n",
       "    index  \\\n",
       " 0    299   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Trump is President because Americans were sick of government corruption\", \"Liberals are scared...  ,\n",
       "    index  \\\n",
       " 0    300   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"They should be outraged about abortion\", \"They should be outraged about federal funding of Pla...  ,\n",
       "    index  \\\n",
       " 0    301   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Russian trolls are involved\", \"The situation referred to as 'swampgate' is becoming more compl...  ,\n",
       "    index  \\\n",
       " 0    302   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Chris dominates the conversation\", \"Guests are not given a chance to speak\", \"Media should not...  ,\n",
       "    index claims\n",
       " 0    303     [],\n",
       "    index  \\\n",
       " 0    304   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"A female attorney questioning the all-male panel will not change the Republican narrative\", \"F...  ,\n",
       "    index  \\\n",
       " 0    305   \n",
       " \n",
       "                                                                                                claims  \n",
       " 0  [\"She has had 35 years to prepare\", \"He has had 35 minutes to prepare\", \"The situation is unfair\"]  ,\n",
       "    index claims\n",
       " 0    306     [],\n",
       "    index  \\\n",
       " 0    307   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Trump is going to make a deal with Putin\", \"Putin fixes the midterms for the republicans\", \"Tr...  ,\n",
       "    index                                        claims\n",
       " 0    308  [\"They own much of the Senate and Congress\"],\n",
       "    index  \\\n",
       " 0    309   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"They don't care about lies\", \"They don't care about sexual assault\", \"The only hope is that th...  ,\n",
       "    index  \\\n",
       " 0    310   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Republican governors in Massachusetts, New Hampshire, and Vermont are not extremely conservati...  ,\n",
       "    index claims\n",
       " 0    311     [],\n",
       "    index                                                claims\n",
       " 0    312  [\"It's just an attempt to stall the investigation.\"],\n",
       "    index                        claims\n",
       " 0    313  [\"The US executes traitors\"],\n",
       "    index  \\\n",
       " 0    314   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Uneducated people are the worst kind of fools\", \"The commenter believes the person they are re...  ,\n",
       "    index  \\\n",
       " 0    315   \n",
       " \n",
       "                                                                         claims  \n",
       " 0  [\"The president exposed fake news\", \"People who can't see this are stupid\"]  ,\n",
       "    index claims\n",
       " 0    316     [],\n",
       "    index claims\n",
       " 0    317     [],\n",
       "    index claims\n",
       " 0    318     [],\n",
       "    index  \\\n",
       " 0    319   \n",
       " \n",
       "                                                                   claims  \n",
       " 0  [\"Close to 100% of Trump supporters believe strongly in having guns\"]  ,\n",
       "    index                                                             claims\n",
       " 0    320  [\"Women running for President are a joke\", \"Women are not equal\"],\n",
       "    index claims\n",
       " 0    321     [],\n",
       "    index claims\n",
       " 0    322     [],\n",
       "    index  \\\n",
       " 0    323   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Taking away the ability for people to speak is not free speech and becomes censorship\", \"Burni...  ,\n",
       "    index claims\n",
       " 0    324     [],\n",
       "    index claims\n",
       " 0    325     [],\n",
       "    index claims\n",
       " 0    326     [],\n",
       "    index                                                                claims\n",
       " 0    327  [\"Bernie is the only candidate that represents dignity and honesty\"],\n",
       "    index claims\n",
       " 0    328     [],\n",
       "    index claims\n",
       " 0    329     [],\n",
       "    index claims\n",
       " 0    330     [],\n",
       "    index claims\n",
       " 0    331     [],\n",
       "    index claims\n",
       " 0    332     [],\n",
       "    index claims\n",
       " 0    333     [],\n",
       "    index claims\n",
       " 0    334     [],\n",
       "    index claims\n",
       " 0    335     [],\n",
       "    index  \\\n",
       " 0    336   \n",
       " \n",
       "                                                                         claims  \n",
       " 0  [\"He will never make it\", \"America is way too homophobic\", \"It is a shame\"]  ,\n",
       "    index  \\\n",
       " 0    337   \n",
       " \n",
       "                                                                              claims  \n",
       " 0  [\"The religious content is unconvincing\", \"The person is otherwise intelligent\"]  ,\n",
       "    index  \\\n",
       " 0    338   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Her left-wing populist rhetoric is extremely unpopular on a national level\", \"Special business...  ,\n",
       "    index  \\\n",
       " 0    339   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The speaker is soft balling for the establishment\", \"Her rhetoric about clean air energy sourc...  ,\n",
       "    index claims\n",
       " 0    340     [],\n",
       "    index claims\n",
       " 0    341     [],\n",
       "    index claims\n",
       " 0    342     [],\n",
       "    index claims\n",
       " 0    343     [],\n",
       "    index claims\n",
       " 0    344     [],\n",
       "    index  \\\n",
       " 0    345   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"They suggested it was a black man on day 2 of the investigation\", \"Her eyes got big and scared...  ,\n",
       "    index  \\\n",
       " 0    346   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Obama hasn't been in a workplace in the Midwest in a long time\", \"People are always trying to ...  ,\n",
       "    index  \\\n",
       " 0    347   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Dinosaurs, microscopic organisms, Neanderthals, and other prehistoric life are not mentioned i...  ,\n",
       "    index claims\n",
       " 0    348     [],\n",
       "    index claims\n",
       " 0    349     [],\n",
       "    index claims\n",
       " 0    350     [],\n",
       "    index  \\\n",
       " 0    351   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The US has invaded over 20 countries after WWII\", \"The US is in the midst of an ethnic and rel...  ,\n",
       "    index claims\n",
       " 0    352     [],\n",
       "    index claims\n",
       " 0    353     [],\n",
       "    index claims\n",
       " 0    354     [],\n",
       "    index claims\n",
       " 0    355     [],\n",
       "    index  \\\n",
       " 0    356   \n",
       " \n",
       "                                                                                               claims  \n",
       " 0  [\"Impeach Trump\", \"Bomb Russia\", \"Tax the Churches\", \"Separate Republicans From Their Swastikas\"]  ,\n",
       "    index claims\n",
       " 0    357     [],\n",
       "    index  \\\n",
       " 0    358   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"President Trump made 8,158 false or misleading claims in his first two years\", \"President Trum...  ,\n",
       "    index                                                       claims\n",
       " 0    359  [\"They changed their tag from news channel to comedy show\"],\n",
       "    index claims\n",
       " 0    360     [],\n",
       "    index  \\\n",
       " 0    361   \n",
       " \n",
       "                                                                                            claims  \n",
       " 0  [\"Someone is upset that they are trying to compete with Fox\", \"Fox still controls that niche\"]  ,\n",
       "    index claims\n",
       " 0    362     [],\n",
       "    index  \\\n",
       " 0    363   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Anderson Cooper is a positive representative of the world\", \"The commenter learned about Ander...  ,\n",
       "    index                                                       claims\n",
       " 0    364  [\"CNN accused an old woman of colluding with the Russians\"],\n",
       "    index claims\n",
       " 0    365     [],\n",
       "    index claims\n",
       " 0    366     [],\n",
       "    index  \\\n",
       " 0    367   \n",
       " \n",
       "                                                                        claims  \n",
       " 0  [\"Donald Trump and his remaining supporters are traitors to this country\"]  ,\n",
       "    index claims\n",
       " 0    368     [],\n",
       "    index  \\\n",
       " 0    369   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Hillary Clinton masterminded the uranium deal\", \"Hillary Clinton sold out the American people ...  ,\n",
       "    index  \\\n",
       " 0    370   \n",
       " \n",
       "                                                                                         claims  \n",
       " 0  [\"This is old footage from Hurricane Hugo\", \"The footage is meant to make Trump look weak\"]  ,\n",
       "    index claims\n",
       " 0    371     [],\n",
       "    index                                claims\n",
       " 0    372  [\"CNN's journalism is not relevant\"],\n",
       "    index  \\\n",
       " 0    373   \n",
       " \n",
       "                                                                                               claims  \n",
       " 0  [\"The response is ridiculous\", \"The only appropriate reason for the military and war is justice\"]  ,\n",
       "    index                                                    claims\n",
       " 0    374  [\"You never cared about Obama's presidential privilege\"],\n",
       "    index  \\\n",
       " 0    375   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The person on the Supreme Court is a drunken individual\", \"The person on the Supreme Court is ...  ,\n",
       "    index claims\n",
       " 0    376     [],\n",
       "    index  \\\n",
       " 0    377   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Cooper used to be considered cute\", \"Cooper's statements are now perceived as garbage\", \"It is...  ,\n",
       "    index claims\n",
       " 0    378     [],\n",
       "    index claims\n",
       " 0    379     [],\n",
       "    index claims\n",
       " 0    380     [],\n",
       "    index                                                           claims\n",
       " 0    381  [\"Trump lies frequently\", \"Trump should be punished for lying\"],\n",
       "    index  \\\n",
       " 0    382   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Trump is immature\", \"Trump cannot handle tough discussions\", \"Trump cannot handle complex situ...  ,\n",
       "    index                                      claims\n",
       " 0    383  [\"CNN is equivalent to Fox News in Korea\"],\n",
       "    index claims\n",
       " 0    384     [],\n",
       "    index claims\n",
       " 0    385     [],\n",
       "    index  \\\n",
       " 0    386   \n",
       " \n",
       "                                                                                     claims  \n",
       " 0  [\"John Podesta is a child rapist\", \"Bill Clinton is a rapist\", \"Weiner is a pedophile\"]  ,\n",
       "    index claims\n",
       " 0    387     [],\n",
       "    index                                         claims\n",
       " 0    388  [\"Trump is fixing America\", \"Obama is Satan\"],\n",
       "    index  \\\n",
       " 0    389   \n",
       " \n",
       "                                                                     claims  \n",
       " 0  [\"People repeatedly accuse videos of being fake news without evidence\"]  ,\n",
       "    index  \\\n",
       " 0    390   \n",
       " \n",
       "                                                                   claims  \n",
       " 0  [\"Gus Dupree is not taking a salary\", \"Gus Dupree is a humanitarian\"]  ,\n",
       "    index claims\n",
       " 0    391     [],\n",
       "    index  \\\n",
       " 0    392   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Truth, morality, and facts matter for the future of children\", \"Adults are allowing blaming, n...  ,\n",
       "    index claims\n",
       " 0    393     [],\n",
       "    index                            claims\n",
       " 0    394  [\"CNN is now officially a joke\"],\n",
       "    index claims\n",
       " 0    395     [],\n",
       "    index  \\\n",
       " 0    396   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Irish people were distinguished from whites based on ethnicity\", \"Many Irish referred to thems...  ,\n",
       "    index                              claims\n",
       " 0    397  [\"CNN has been lying for 3 years\"],\n",
       "    index claims\n",
       " 0    398     [],\n",
       "    index  \\\n",
       " 0    399   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"He is not man enough to serve\", \"He is not man enough to look at a reminder of what he isn't a...  ,\n",
       "    index claims\n",
       " 0    400     [],\n",
       "    index claims\n",
       " 0    401     [],\n",
       "    index claims\n",
       " 0    402     [],\n",
       "    index claims\n",
       " 0    403     [],\n",
       "    index  \\\n",
       " 0    404   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The world is in a bad state\", \"The comments on the video are disgraceful\", \"The story in the v...  ,\n",
       "    index                                   claims\n",
       " 0    405  [\"The military assets are being moved\"],\n",
       "    index  \\\n",
       " 0    406   \n",
       " \n",
       "                                                                                         claims  \n",
       " 0  [\"Bernie is the most consistent progressive\", \"Bernie is the most trustworthy progressive\"]  ,\n",
       "    index claims\n",
       " 0    407     [],\n",
       "    index claims\n",
       " 0    408     [],\n",
       "    index claims\n",
       " 0    409     [],\n",
       "    index  \\\n",
       " 0    410   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The drug war is causing an overtaking of South American countries\", \"Taxpayer dollars are bein...  ,\n",
       "    index  \\\n",
       " 0    411   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Oakland is the wild west\", \"I pay $750 for a bedroom in the ghetto\", \"I share the apartment wi...  ,\n",
       "    index  \\\n",
       " 0    412   \n",
       " \n",
       "                                                                          claims  \n",
       " 0  [\"Shoplifter kills grandma\", \"The headline is intended to increase ratings\"]  ,\n",
       "    index                                            claims\n",
       " 0    413  [\"The ladies were forced to sleep with someone\"],\n",
       "    index claims\n",
       " 0    414     [],\n",
       "    index  \\\n",
       " 0    415   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The inexperienced guy does not know what he is doing\", \"People of Venezuela are not morons for...  ,\n",
       "    index  \\\n",
       " 0    416   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"American people have a reputation for being workaholics\", \"People from third world countries c...  ,\n",
       "    index  \\\n",
       " 0    417   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"CBS promotes war for the military industrial complex\", \"There has been enough bloodshed\", \"Tro...  ,\n",
       "    index  \\\n",
       " 0    418   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The government is ineffective\", \"People should keep what they find\", \"People should arm themse...  ,\n",
       "    index                                                     claims\n",
       " 0    419  [\"This is the dumbest president ever\", \"God help us all\"],\n",
       "    index  \\\n",
       " 0    420   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Americans are under threat of tariffs from Trump\", \"Trillions of dollars are leaving the stock...  ,\n",
       "    index claims\n",
       " 0    421     [],\n",
       "    index  \\\n",
       " 0    422   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Gun enthusiasts contributed to taking away the right to life of 58 people\", \"The right to life...  ,\n",
       "    index  \\\n",
       " 0    423   \n",
       " \n",
       "                                                                                    claims  \n",
       " 0  [\"Zionists are trying to finish off the Palestinians\", \"Palestinians are poor people\"]  ,\n",
       "    index  \\\n",
       " 0    424   \n",
       " \n",
       "                                                                             claims  \n",
       " 0  [\"Epstein is leaving the country\", \"Bloomberg is personally escorting Epstein\"]  ,\n",
       "    index claims\n",
       " 0    425     [],\n",
       "    index claims\n",
       " 0    426     [],\n",
       "    index claims\n",
       " 0    427     [],\n",
       "    index  \\\n",
       " 0    428   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"No one cares about you trying to get a woman\", \"He saved 3 girls, you didn’t\", \"God can’t save...  ,\n",
       "    index  \\\n",
       " 0    429   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Innocent people should not settle rape accusations with money\", \"Settling rape accusations wit...  ,\n",
       "    index claims\n",
       " 0    430     [],\n",
       "    index claims\n",
       " 0    431     [],\n",
       "    index                  claims\n",
       " 0    432  [\"This guy is a hero\"],\n",
       "    index claims\n",
       " 0    433     [],\n",
       "    index claims\n",
       " 0    434     [],\n",
       "    index claims\n",
       " 0    435     [],\n",
       "    index                      claims\n",
       " 0    437  [\"A great man was killed\"],\n",
       "    index claims\n",
       " 0    438     [],\n",
       "    index claims\n",
       " 0    439     [],\n",
       "    index  \\\n",
       " 0    440   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Israel is bullying other countries in the region\", \"Israel has nuclear weapons\", \"No one can a...  ,\n",
       "    index claims\n",
       " 0    441     [],\n",
       "    index                         claims\n",
       " 0    442  [\"Marijuana is good for ADD\"],\n",
       "    index  \\\n",
       " 0    443   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Nomi is spying on you for the government\", \"Nomi listens and has a camera\", \"People are blinde...  ,\n",
       "    index  \\\n",
       " 0    444   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Paying extra for Priority Boarding usually results in a B or A boarding card\", \"Early ticket p...  ,\n",
       "    index  \\\n",
       " 0    445   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Shaqueem broke the record for the 40 yd dash for linebackers\", \"Their bond has made the whole ...  ,\n",
       "    index  \\\n",
       " 0    446   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"He visited for the first time in 2009\", \"He did not visit Senna's grave in 2007 despite being ...  ,\n",
       "    index  \\\n",
       " 0    447   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"California requires a 60-hour certified course and a test for licensing\", \"Conservatives claim...  ,\n",
       "    index  \\\n",
       " 0    448   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Elon Musk is on another level compared to others\", \"Elon Musk is innovating\", \"Elon Musk is cr...  ,\n",
       "    index                                                  claims\n",
       " 0    449  [\"The song Brainless doesn't need to rhyme perfectly\"],\n",
       "    index claims\n",
       " 0    450     [],\n",
       "    index claims\n",
       " 0    451     [],\n",
       "    index claims\n",
       " 0    452     [],\n",
       "    index  \\\n",
       " 0    453   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The Inverse Square Law does not apply to extended sources of radiation\", \"All Geiger counters ...  ,\n",
       "    index                                                      claims\n",
       " 0    454  [\"The government knows something that journalists do not\"],\n",
       "    index claims\n",
       " 0    455     [],\n",
       "    index  \\\n",
       " 0    456   \n",
       " \n",
       "                                                                        claims  \n",
       " 0  [\"The original 60 minutes episode is being sold on Amazon for $79.99 USD\"]  ,\n",
       "    index claims\n",
       " 0    457     [],\n",
       "    index  \\\n",
       " 0    458   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The ACA was modeled for people who didn't have access to health care\", \"Single Payer (Medicare...  ,\n",
       "    index claims\n",
       " 0    459     [],\n",
       "    index                      claims\n",
       " 0    460  [\"They did not bully him\"],\n",
       "    index claims\n",
       " 0    461     [],\n",
       "    index claims\n",
       " 0    462     [],\n",
       "    index                                                      claims\n",
       " 0    463  [\"Americans voted for Trump instead of another candidate\"],\n",
       "    index claims\n",
       " 0    464     [],\n",
       "    index                          claims\n",
       " 0    465  [\"The beek did not apologize\"],\n",
       "    index claims\n",
       " 0    466     [],\n",
       "    index claims\n",
       " 0    467     [],\n",
       "    index  \\\n",
       " 0    468   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Art mirrors life\", \"The American public is getting its mirror through its president\", \"The Ame...  ,\n",
       "    index                            claims\n",
       " 0    469  [\"Francesco won't last 4 years\"],\n",
       "    index claims\n",
       " 0    470     [],\n",
       "    index claims\n",
       " 0    471     [],\n",
       "    index claims\n",
       " 0    472     [],\n",
       "    index claims\n",
       " 0    473     [],\n",
       "    index  \\\n",
       " 0    474   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"A widening perspective and money will change your outlook\", \"Young people should realize the i...  ,\n",
       "    index  \\\n",
       " 0    475   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Racism, sexism, homophobia, and ignorance are not acceptable positions or arguments\", \"Ignoran...  ,\n",
       "    index  \\\n",
       " 0    476   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"There was one good joke in this\", \"It was a very good joke\", \"They ruined the joke by explaini...  ,\n",
       "    index claims\n",
       " 0    477     [],\n",
       "    index claims\n",
       " 0    478     [],\n",
       "    index  \\\n",
       " 0    479   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Seth Meyers looks like the hero's most awkward friend\", \"The commenter likes that Seth Meyers ...  ,\n",
       "    index                            claims\n",
       " 0    480  [\"He is not funny on this show\"],\n",
       "    index claims\n",
       " 0    481     [],\n",
       "    index  \\\n",
       " 0    482   \n",
       " \n",
       "                                                                                     claims  \n",
       " 0  [\"Trump said George Washington was stupid\", \"Trump should be exiled for his statement\"]  ,\n",
       "    index  \\\n",
       " 0    483   \n",
       " \n",
       "                                                                                     claims  \n",
       " 0  [\"Apple has had exploding batteries since 2009\", \"Samsung produces the iPhone battery\"]  ,\n",
       "    index claims\n",
       " 0    484     [],\n",
       "    index claims\n",
       " 0    485     [],\n",
       "    index                                                    claims\n",
       " 0    486  [\"The use of expensive truffle was a complete disaster\"],\n",
       "    index claims\n",
       " 0    487     [],\n",
       "    index                                                    claims\n",
       " 0    488  [\"Annie is pretty young\", \"We try not to sexualize her\"],\n",
       "    index                          claims\n",
       " 0    489  [\"The AFD is a fascist party\"],\n",
       "    index claims\n",
       " 0    490     [],\n",
       "    index  \\\n",
       " 0    491   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Seth is not at 400,000 subscribers\", \"Seth's subscriber count may increase if certain celebrit...  ,\n",
       "    index  \\\n",
       " 0    492   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The Secretary of Defense was honest about his intentions\", \"The Secretary of Defense wants to ...  ,\n",
       "    index  \\\n",
       " 0    493   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Trump thinks women are pay-to-play sperm receptacles\", \"Trump treats women as unreproachable, ...  ,\n",
       "    index claims\n",
       " 0    494     [],\n",
       "    index claims\n",
       " 0    495     [],\n",
       "    index  \\\n",
       " 0    496   \n",
       " \n",
       "                                                                                      claims  \n",
       " 0  [\"Lindsey Graham and Susan Collins acted like Republicans\", \"It's a new day in America\"]  ,\n",
       "    index claims\n",
       " 0    497     [],\n",
       "    index claims\n",
       " 0    498     [],\n",
       "    index claims\n",
       " 0    499     [],\n",
       "    index claims\n",
       " 0    500     [],\n",
       "    index claims\n",
       " 0    501     [],\n",
       "    index  \\\n",
       " 0    502   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Graham's opinion is correct\", \"If the vote fails, Kavanagh should be re-nominated\", \"The decis...  ,\n",
       "    index  \\\n",
       " 0    503   \n",
       " \n",
       "                                                                     claims  \n",
       " 0  [\"U.S. citizens have dreams\", \"President Trump is right on his remark\"]  ,\n",
       "    index  \\\n",
       " 0    504   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"No one decides on their sex\", \"People are born either the male or female sex\", \"Gender is a re...  ,\n",
       "    index  \\\n",
       " 0    505   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"An armed officer was present at the school during the shooting\", \"The presence of an armed off...  ,\n",
       "    index claims\n",
       " 0    506     [],\n",
       "    index  \\\n",
       " 0    507   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Trump should distance himself from Kushner\", \"Kushner might start revealing information\", \"Hil...  ,\n",
       "    index claims\n",
       " 0    508     [],\n",
       "    index claims\n",
       " 0    509     [],\n",
       "    index  \\\n",
       " 0    510   \n",
       " \n",
       "                                                                               claims  \n",
       " 0  [\"Trump is a traitor to his country\", \"He has committed treason against America\"]  ,\n",
       "    index claims\n",
       " 0    511     [],\n",
       "    index claims\n",
       " 0    512     [],\n",
       "    index claims\n",
       " 0    513     [],\n",
       "    index                                                     claims\n",
       " 0    514  [\"A bunch of other people voted no too, not just McCain\"],\n",
       "    index  \\\n",
       " 0    515   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Mueller is hired by the Clintons\", \"The Russian Probe never included the Clintons\", \"The Clint...  ,\n",
       "    index  \\\n",
       " 0    516   \n",
       " \n",
       "                                                                     claims  \n",
       " 0  [\"Jesus Christ returns\", \"Repent of sin and change your way of living\"]  ,\n",
       "    index  \\\n",
       " 0    517   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"They cannot be fired\", \"They can be transferred\", \"There's plenty for them to do in Adak Alaska\"]  ,\n",
       "    index claims\n",
       " 0    518     [],\n",
       "    index                       claims\n",
       " 0    519  [\"Pelosi has lost control\"],\n",
       "    index  \\\n",
       " 0    520   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The Democrats will give Trump 10% of what he wants\", \"Trump will cave and call it a win\", \"The...  ,\n",
       "    index                                                     claims\n",
       " 0    521  [\"Voting to not defend the nation is considered treason\"],\n",
       "    index claims\n",
       " 0    522     [],\n",
       "    index claims\n",
       " 0    523     [],\n",
       "    index  \\\n",
       " 0    524   \n",
       " \n",
       "                                                                                             claims  \n",
       " 0  [\"Liberal Hollywood is responsible for over 95% of America's pedophiles, rapists, and racists\"]  ,\n",
       "    index  \\\n",
       " 0    525   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"He lives in America\", \"He is an American national\", \"He has been an American national for a lo...  ,\n",
       "    index claims\n",
       " 0    526     [],\n",
       "    index                                                 claims\n",
       " 0    527  [\"Trump can use a certain pathway to build the wall\"],\n",
       "    index                                        claims\n",
       " 0    528  [\"Hannity should start doing movie reviews\"],\n",
       "    index claims\n",
       " 0    529     [],\n",
       "    index claims\n",
       " 0    530     [],\n",
       "    index  \\\n",
       " 0    531   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Youngsters are vulnerable to evil influences and actions, especially without decent parental g...  ,\n",
       "    index claims\n",
       " 0    532     [],\n",
       "    index claims\n",
       " 0    533     [],\n",
       "    index                               claims\n",
       " 0    534  [\"Trump-haters want to hate Trump\"],\n",
       "    index            claims\n",
       " 0    535  [\"Hillary lies\"],\n",
       "    index claims\n",
       " 0    536     [],\n",
       "    index claims\n",
       " 0    537     [],\n",
       "    index  \\\n",
       " 0    538   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Trump supporters became so racist\", \"Fox could no longer align themselves with Trump supporters\"]  ,\n",
       "    index claims\n",
       " 0    539     [],\n",
       "    index claims\n",
       " 0    540     [],\n",
       "    index claims\n",
       " 0    541     [],\n",
       "    index claims\n",
       " 0    542     [],\n",
       "    index  \\\n",
       " 0    543   \n",
       " \n",
       "                                                                       claims  \n",
       " 0  [\"The national disgrace was under Obama\", \"Trump will win again in 2020\"]  ,\n",
       "    index  \\\n",
       " 0    544   \n",
       " \n",
       "                                                                                            claims  \n",
       " 0  [\"Corrine Brown is a prime example\", \"Corrine Brown made many of her family and friends rich\"]  ,\n",
       "    index                                                    claims\n",
       " 0    545  [\"Hunter Biden is involved in the Ukraine oil business\"],\n",
       "    index claims\n",
       " 0    546     [],\n",
       "    index claims\n",
       " 0    547     [],\n",
       "    index                claims\n",
       " 0    548  [\"Trump is a loser\"],\n",
       "    index                                          claims\n",
       " 0    549  [\"President Trump is the fairest of them all\"],\n",
       "    index claims\n",
       " 0    550     [],\n",
       "    index claims\n",
       " 0    551     [],\n",
       "    index  \\\n",
       " 0    552   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"There are racists out there\", \"I don't believe he is racist\", \"The guy was mad\", \"Killing an i...  ,\n",
       "    index  \\\n",
       " 0    553   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"People died because they used an unsafe vehicle\", \"The people are to blame for using the unsaf...  ,\n",
       "    index claims\n",
       " 0    554     [],\n",
       "    index  \\\n",
       " 0    555   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The cops made an honest mistake\", \"The gun should not be out if the burglars are already gone\"...  ,\n",
       "    index claims\n",
       " 0    556     [],\n",
       "    index claims\n",
       " 0    557     [],\n",
       "    index claims\n",
       " 0    558     [],\n",
       "    index claims\n",
       " 0    559     [],\n",
       "    index                                                              claims\n",
       " 0    560  [\"It's a miracle she survived\", \"Puerto Rico is America's colony\"],\n",
       "    index                                                      claims\n",
       " 0    561  [\"Evil things could happen in the speaker's home country\"],\n",
       "    index  \\\n",
       " 0    562   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Living things on Earth have gone through evolution\", \"Living things on Earth are going through...  ,\n",
       "    index claims\n",
       " 0    563     [],\n",
       "    index claims\n",
       " 0    564     [],\n",
       "    index claims\n",
       " 0    565     [],\n",
       "    index claims\n",
       " 0    566     [],\n",
       "    index claims\n",
       " 0    567     [],\n",
       "    index  \\\n",
       " 0    568   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"A random act of kindness is a beautiful thing\", \"A kidney is a beautiful thing\", \"ABC posts so...  ,\n",
       "    index claims\n",
       " 0    569     [],\n",
       "    index  \\\n",
       " 0    570   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Gang stalking will destroy the country\", \"Gang stalking involves spying, stealing, and attempt...  ,\n",
       "    index                                                        claims\n",
       " 0    571  [\"We saved these companies\", \"We saved these people's jobs\"],\n",
       "    index claims\n",
       " 0    572     [],\n",
       "    index claims\n",
       " 0    573     [],\n",
       "    index  \\\n",
       " 0    574   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Whopper Jr costs $1.39\", \"Completing a 3-minute survey on the receipt provides a code for a fr...  ,\n",
       "    index  \\\n",
       " 0    575   \n",
       " \n",
       "                                                                      claims  \n",
       " 0  [\"The person who chose to shoot a gun over words is solely responsible\"]  ,\n",
       "    index  \\\n",
       " 0    576   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The left is hysterical\", \"Another conservative judge will be nominated when Ginsberg leaves\", ...  ,\n",
       "    index  \\\n",
       " 0    577   \n",
       " \n",
       "                                                                                       claims  \n",
       " 0  [\"Never travel without travel insurance\", \"You never know what might happen on vacation\"]  ,\n",
       "    index claims\n",
       " 0    578     [],\n",
       "    index claims\n",
       " 0    579     [],\n",
       "    index claims\n",
       " 0    580     [],\n",
       "    index claims\n",
       " 0    581     [],\n",
       "    index  \\\n",
       " 0    582   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The origins of the universe imply the existence of God\", \"The universe's matter and energy mus...  ,\n",
       "    index claims\n",
       " 0    583     [],\n",
       "    index claims\n",
       " 0    584     [],\n",
       "    index claims\n",
       " 0    585     [],\n",
       "    index claims\n",
       " 0    586     [],\n",
       "    index  \\\n",
       " 0    587   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The situation is inhumane\", \"Democrats promote an animalistic way of living\", \"The humane thin...  ,\n",
       "    index  \\\n",
       " 0    588   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The government won't give citizenship to illegal Hispanics who have applied\", \"Everything is a...  ,\n",
       "    index  \\\n",
       " 0    589   \n",
       " \n",
       "                                                                              claims  \n",
       " 0  [\"Protecting borders is important\", \"Enforcing long-standing laws is necessary\"]  ,\n",
       "    index claims\n",
       " 0    590     [],\n",
       "    index  \\\n",
       " 0    591   \n",
       " \n",
       "                                                                    claims  \n",
       " 0  [\"97% of the homeless in downtown LA are unemployable due to illness\"]  ,\n",
       "    index claims\n",
       " 0    592     [],\n",
       "    index claims\n",
       " 0    593     [],\n",
       "    index  \\\n",
       " 0    594   \n",
       " \n",
       "                                                                                      claims  \n",
       " 0  [\"Democrats' policies will make America like Mumbai\", \"Mumbai will become like America\"]  ,\n",
       "    index claims\n",
       " 0    595     [],\n",
       "    index claims\n",
       " 0    596     [],\n",
       "    index                         claims\n",
       " 0    597  [\"It is a political hit-job\"],\n",
       "    index                                  claims\n",
       " 0    598  [\"Absolute power corrupts absolutely\"],\n",
       "    index  \\\n",
       " 0    599   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The Trump/Fox News Machine is sounding more desperate\", \"Things are not looking good for Trump...  ,\n",
       "    index  \\\n",
       " 0    600   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Black people are constantly making racial remarks about white people\", \"It is acceptable to ma...  ,\n",
       "    index                     claims\n",
       " 0    601  [\"Trump should be fired\"],\n",
       "    index claims\n",
       " 0    602     [],\n",
       "    index claims\n",
       " 0    603     [],\n",
       "    index            claims\n",
       " 0    604  [\"Sales are up\"],\n",
       "    index                claims\n",
       " 0    605  [\"Zinke is corrupt\"],\n",
       "    index  \\\n",
       " 0    606   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"There are only two genders\", \"Sexual orientation should be kept private\", \"Sexual orientation ...  ,\n",
       "    index  \\\n",
       " 0    607   \n",
       " \n",
       "                                                                    claims  \n",
       " 0  [\"The museum is nice\", \"The museum is not nice when Hillary is there\"]  ,\n",
       "    index claims\n",
       " 0    608     [],\n",
       "    index claims\n",
       " 0    609     [],\n",
       "    index  \\\n",
       " 0    610   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Fox has been reporting more facts about this ongoing story than just about all of the networks...  ,\n",
       "    index                                    claims\n",
       " 0    611  [\"Fox News is not entirely trustworthy\"],\n",
       "    index  \\\n",
       " 0    612   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The rich and powerful's crimes are ignored\", \"The rich and powerful are above the law\", \"The r...  ,\n",
       "    index  \\\n",
       " 0    613   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"England has become like a Muslim country\", \"England is no longer a land of democracy and commo...  ,\n",
       "    index claims\n",
       " 0    614     [],\n",
       "    index claims\n",
       " 0    615     [],\n",
       "    index claims\n",
       " 0    616     [],\n",
       "    index  \\\n",
       " 0    617   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"People should read the terms and services\", \"If you don't like YouTube, find a new site\", \"Con...  ,\n",
       "    index claims\n",
       " 0    618     [],\n",
       "    index  \\\n",
       " 0    619   \n",
       " \n",
       "                                                                       claims  \n",
       " 0  [\"America will eat itself from inside out because of liberals/Democrats\"]  ,\n",
       "    index                                                  claims\n",
       " 0    620  [\"Wray said that the reports of resigning were false\"],\n",
       "    index  \\\n",
       " 0    621   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"North Korea is not honoring the agreement\", \"North Korea is still testing ballistic missiles\",...  ,\n",
       "    index                              claims\n",
       " 0    622  [\"Trump hasn't been found guilty\"],\n",
       "    index claims\n",
       " 0    623     [],\n",
       "    index claims\n",
       " 0    624     [],\n",
       "    index claims\n",
       " 0    625     [],\n",
       "    index claims\n",
       " 0    626     [],\n",
       "    index  \\\n",
       " 0    627   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Progressives are fakers following a false ideology\", \"Progressives are willing to give up thei...  ,\n",
       "    index                                       claims\n",
       " 0    628  [\"Dailystormer was the first to be banned\"],\n",
       "    index                       claims\n",
       " 0    629  [\"California is declining\"],\n",
       "    index claims\n",
       " 0    630     [],\n",
       "    index claims\n",
       " 0    631     [],\n",
       "    index                                             claims\n",
       " 0    632  [\"He should be forcibly removed from office now\"],\n",
       "    index  \\\n",
       " 0    633   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Nunes should be tried for treason\", \"The House investigation is a joke\", \"Faux News is a joke\"...  ,\n",
       "    index                                                         claims\n",
       " 0    634  [\"The intel on Saddam Hussein's WMD program was rock solid.\"],\n",
       "    index claims\n",
       " 0    635     [],\n",
       "    index  \\\n",
       " 0    636   \n",
       " \n",
       "                                                                                    claims  \n",
       " 0  [\"These people are engaging in seditious activities\", \"The situation is very serious\"]  ,\n",
       "    index  \\\n",
       " 0    637   \n",
       " \n",
       "                                                                                        claims  \n",
       " 0  [\"Republican politicians betray their own members\", \"Democrats protect their own members\"]  ,\n",
       "    index                                                 claims\n",
       " 0    638  [\"Democrats claim President Trump committed treason\"],\n",
       "    index  \\\n",
       " 0    639   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Tucker is hinting he is under investigation\", \"The investigation would be the completion of a ...  ,\n",
       "    index claims\n",
       " 0    640     [],\n",
       "    index claims\n",
       " 0    641     [],\n",
       "    index                       claims\n",
       " 0    642  [\"Libtards are communists\"],\n",
       "    index claims\n",
       " 0    643     [],\n",
       "    index  \\\n",
       " 0    644   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"America can only deal with leftists in one way\", \"Leftists are too violent to have dialogue wi...  ,\n",
       "    index claims\n",
       " 0    645     [],\n",
       "    index claims\n",
       " 0    646     [],\n",
       "    index claims\n",
       " 0    647     [],\n",
       "    index                               claims\n",
       " 0    648  [\"I think it's an important topic\"],\n",
       "    index claims\n",
       " 0    649     [],\n",
       "    index claims\n",
       " 0    650     [],\n",
       "    index  \\\n",
       " 0    651   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Governments disarming populations can lead to tyranny\", \"Leftist rhetoric only highlights crim...  ,\n",
       "    index                                claims\n",
       " 0    652  [\"Hasan can actually pull that off\"],\n",
       "    index claims\n",
       " 0    653     [],\n",
       "    index  \\\n",
       " 0    654   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The show is being promoted to get people to subscribe to Netflix\", \"HBO promotes The Tonight S...  ,\n",
       "    index  \\\n",
       " 0    655   \n",
       " \n",
       "                                                                                     claims  \n",
       " 0  [\"The episode is available on Netflix\", \"The episode is complete except for the intro\"]  ,\n",
       "    index  \\\n",
       " 0    656   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Politics and business are connected\", \"If I don't like your politics, you won't get my business\"]  ,\n",
       "    index claims\n",
       " 0    657     [],\n",
       "    index claims\n",
       " 0    658     [],\n",
       "    index claims\n",
       " 0    659     [],\n",
       "    index claims\n",
       " 0    660     [],\n",
       "    index claims\n",
       " 0    661     [],\n",
       "    index  \\\n",
       " 0    662   \n",
       " \n",
       "                                                                                   claims  \n",
       " 0  [\"No one can do anything even if we live with Imran Khan\", \"Our country is hopeless\"]  ,\n",
       "    index claims\n",
       " 0    663     [],\n",
       "    index                            claims\n",
       " 0    664  [\"His wife asked for a divorce\"],\n",
       "    index claims\n",
       " 0    665     [],\n",
       "    index claims\n",
       " 0    666     [],\n",
       "    index claims\n",
       " 0    667     [],\n",
       "    index claims\n",
       " 0    668     [],\n",
       "    index claims\n",
       " 0    669     [],\n",
       "    index claims\n",
       " 0    670     [],\n",
       "    index claims\n",
       " 0    671     [],\n",
       "    index claims\n",
       " 0    672     [],\n",
       "    index claims\n",
       " 0    673     [],\n",
       "    index claims\n",
       " 0    674     [],\n",
       "    index claims\n",
       " 0    675     [],\n",
       "    index claims\n",
       " 0    676     [],\n",
       "    index claims\n",
       " 0    677     [],\n",
       "    index claims\n",
       " 0    678     [],\n",
       "    index claims\n",
       " 0    679     [],\n",
       "    index claims\n",
       " 0    680     [],\n",
       "    index                                                claims\n",
       " 0   1406  [\"Only wimps, perverts, and lazy men vote Democrat\"],\n",
       "    index  \\\n",
       " 0   1407   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Melania's body language is stiff\", \"The commenter does not like Melania\", \"The commenter quest...  ,\n",
       "    index  \\\n",
       " 0   1408   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Resource hoarding needs to be contained\", \"Resources should be divided equally among all peopl...  ,\n",
       "    index claims\n",
       " 0   1409     [],\n",
       "    index claims\n",
       " 0   1410     [],\n",
       "    index  \\\n",
       " 0   1411   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"He is a corporate tool for the Democratic establishment\", \"People like him hinder real change\"...  ,\n",
       "    index                                  claims\n",
       " 0   1412  [\"Most of academia is leftist driven\"],\n",
       "    index  \\\n",
       " 0   1413   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The USA doesn't want Iran to have nuclear weapons\", \"Iran has never broken the nuclear agreeme...  ,\n",
       "    index                                        claims\n",
       " 0   1414  [\"Religion imposes abuse on women and gays\"],\n",
       "    index  \\\n",
       " 0   1415   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Bill is starting to act like an old person\", \"Bill is not funny anymore\", \"Bill is doing the s...  ,\n",
       "    index  \\\n",
       " 0   1416   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Tulsi is the only candidate willing to stand up for people worldwide\", \"Tulsi has a track reco...  ,\n",
       "    index  \\\n",
       " 0   1417   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The wall is a waste of money\", \"No one wants the wall\", \"More agents should be hired instead o...  ,\n",
       "    index  \\\n",
       " 0   1418   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"All Attorney Generals are appointed by a President\", \"John F. Kennedy appointed his own brothe...  ,\n",
       "    index claims\n",
       " 0   1419     [],\n",
       "    index claims\n",
       " 0   1420     [],\n",
       "    index claims\n",
       " 0   1421     [],\n",
       "    index  \\\n",
       " 0   1422   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The main player is left out of the discussion\", \"Bernie did not mention Israel\", \"Anderson did...  ,\n",
       "    index claims\n",
       " 0   1423     [],\n",
       "    index claims\n",
       " 0   1424     [],\n",
       "    index  \\\n",
       " 0   1425   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The West imposes the Saudis on South Asians\", \"The Saudis do not represent Islam\", \"The Saudis...  ,\n",
       "    index  \\\n",
       " 0   1426   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Representatives should impeach regardless of Senate response\", \"Americans should hold Senators...  ,\n",
       "    index claims\n",
       " 0   1427     [],\n",
       "    index claims\n",
       " 0   1428     [],\n",
       "    index claims\n",
       " 0   1429     [],\n",
       "    index claims\n",
       " 0   1430     [],\n",
       "    index  \\\n",
       " 0   1431   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Trump does not represent all Americans\", \"Trump represents only those who share his skin pigme...  ,\n",
       "    index                                    claims\n",
       " 0   1432  [\"Flint still doesn't have clean water\"],\n",
       "    index claims\n",
       " 0   1433     [],\n",
       "    index claims\n",
       " 0   1434     [],\n",
       "    index claims\n",
       " 0   1435     [],\n",
       "    index  \\\n",
       " 0   1436   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Trump had Epstein executed\", \"Epstein was about to expose his clientele\", \"Exposing Epstein's ...  ,\n",
       "    index  \\\n",
       " 0   1437   \n",
       " \n",
       "                                                                                 claims  \n",
       " 0  [\"The government rigged it\", \"He is in power because the government put him there\"]  ,\n",
       "    index  \\\n",
       " 0   1438   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Anderson is telling it as it is\", \"A Democrat asking Mueller questions is like fairy dust on a...  ,\n",
       "    index                                             claims\n",
       " 0   1439  [\"Rod Rosenstein recommended firing James Comey\"],\n",
       "    index claims\n",
       " 0   1440     [],\n",
       "    index                                                           claims\n",
       " 0   1441  [\"Without the NFL, NBA, and rap, the 'knee-lers' have nothing\"],\n",
       "    index claims\n",
       " 0   1442     [],\n",
       "    index  \\\n",
       " 0   1443   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Obama was afraid to offend terrorists\", \"Obama became the largest financial contributor to ter...  ,\n",
       "    index                              claims\n",
       " 0   1444  [\"He is only a coffee boy lawyer\"],\n",
       "    index  \\\n",
       " 0   1445   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The US is starting another mess in the Middle East\", \"The US is adding to refugee lists\", \"The...  ,\n",
       "    index  \\\n",
       " 0   1446   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Trump has done more in three months than Obama or Hillary would have done\", \"There will be a n...  ,\n",
       "    index  \\\n",
       " 0   1447   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The speaker would not have waited after the tankers were struck\", \"The speaker believes in imm...  ,\n",
       "    index  \\\n",
       " 0   1448   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The match should have been stopped due to an injury\", \"The situation is different from being h...  ,\n",
       "    index claims\n",
       " 0   1449     [],\n",
       "    index  \\\n",
       " 0   1450   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The radical left is trying to harm the country\", \"Moderate liberals are not part of the radica...  ,\n",
       "    index                                                   claims\n",
       " 0   1451  [\"Trump's departure will signify the end of something\"],\n",
       "    index  \\\n",
       " 0   1452   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The man is playing to Trump's base\", \"The man may get a position like chief of staff\", \"The ma...  ,\n",
       "    index  \\\n",
       " 0   1453   \n",
       " \n",
       "                                                                                claims  \n",
       " 0  [\"End AIPAC to drain the swamp\", \"Abolish the federal reserve to drain the swamp\"]  ,\n",
       "    index  \\\n",
       " 0   1454   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The president does not exhibit behaviors of a thoughtful gentleman or leader\", \"The president ...  ,\n",
       "    index claims\n",
       " 0   1455     [],\n",
       "    index claims\n",
       " 0   1456     [],\n",
       "    index claims\n",
       " 0   1457     [],\n",
       "    index claims\n",
       " 0   1458     [],\n",
       "    index  \\\n",
       " 0   1459   \n",
       " \n",
       "                                                                     claims  \n",
       " 0  [\"There are no cameras on the ships\", \"No one knows who really did it\"]  ,\n",
       "    index  \\\n",
       " 0   1460   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Democrats have picked up eight seats in statehouse elections this year\", \"Seven of those seats...  ,\n",
       "    index claims\n",
       " 0   1461     [],\n",
       "    index claims\n",
       " 0   1462     [],\n",
       "    index  \\\n",
       " 0   1463   \n",
       " \n",
       "                                                                                             claims  \n",
       " 0  [\"The GOP should have been providing oversight\", \"The GOP were too busy snapping at their CIC\"]  ,\n",
       "    index  \\\n",
       " 0   1464   \n",
       " \n",
       "                                                                     claims  \n",
       " 0  [\"Some people do not understand that we are a Constitutional Republic\"]  ,\n",
       "    index                                         claims\n",
       " 0   1465  [\"The only word Trump listens for is 'jobs'\"],\n",
       "    index claims\n",
       " 0   1466     [],\n",
       "    index claims\n",
       " 0   1467     [],\n",
       "    index                        claims\n",
       " 0   1468  [\"Collusion is not a crime\"],\n",
       "    index  \\\n",
       " 0   1469   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Islam is a disease that needs to be purged from Europe\", \"People of Europe should start gettin...  ,\n",
       "    index  \\\n",
       " 0   1470   \n",
       " \n",
       "                                                                                              claims  \n",
       " 0  [\"Prosecuting oneself is a misuse of power\", \"With power, one could have drugs, sex, and money\"]  ,\n",
       "    index claims\n",
       " 0   1471     [],\n",
       "    index                            claims\n",
       " 0   1472  [\"People should arm themselves\"],\n",
       "    index claims\n",
       " 0   1473     [],\n",
       "    index  \\\n",
       " 0   1474   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Europe is full of homophobic and misogynistic crimes\", \"The refugee influx is responsible for ...  ,\n",
       "    index claims\n",
       " 0   1475     [],\n",
       "    index  \\\n",
       " 0   1476   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"There are many different types of Shia with different ideologies and practices\", \"Not all Sunn...  ,\n",
       "    index  \\\n",
       " 0   1477   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"A lot of people are projecting her to be Secretary of Defense or Foreign Affairs\", \"She would ...  ,\n",
       "    index                                      claims\n",
       " 0   1478  [\"Gowdy is a criminal\", \"Gowdy is a liar\"],\n",
       "    index  \\\n",
       " 0   1479   \n",
       " \n",
       "                                                                                               claims  \n",
       " 0  [\"You lost 99% of your audience if they were Trump supporters as soon as you started doing math\"]  ,\n",
       "    index  \\\n",
       " 0   1480   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The Constitution of America is being forgotten\", \"There should be no more wars\", \"Trump is res...  ,\n",
       "    index claims\n",
       " 0   1481     [],\n",
       "    index  \\\n",
       " 0   1482   \n",
       " \n",
       "                                                                                       claims  \n",
       " 0  [\"The person referred to is a lying draft dodger\", \"The person referred to is a traitor\"]  ,\n",
       "    index claims\n",
       " 0   1483     [],\n",
       "    index  \\\n",
       " 0   1484   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Mueller will continue the investigation\", \"Trump is a career criminal and con-man\", \"Mueller b...  ,\n",
       "    index claims\n",
       " 0   1485     [],\n",
       "    index claims\n",
       " 0   1486     [],\n",
       "    index  \\\n",
       " 0   1487   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The GOP and his base are misinformed and ignorant\", \"The actions are intentional\", \"The action...  ,\n",
       "    index claims\n",
       " 0   1488     [],\n",
       "    index claims\n",
       " 0   1489     [],\n",
       "    index  \\\n",
       " 0   1490   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"John Dowd was the Trump lawyer assigned to work with Mueller\", \"Cummings is not credible\", \"If...  ,\n",
       "    index  \\\n",
       " 0   1491   \n",
       " \n",
       "                                                                        claims  \n",
       " 0  [\"the swamp is alive and well\", \"the swamp is full of fat barr creatures\"]  ,\n",
       "    index claims\n",
       " 0   1492     [],\n",
       "    index claims\n",
       " 0   1493     [],\n",
       "    index                          claims\n",
       " 0   1494  [\"The name has been overused\"],\n",
       "    index  \\\n",
       " 0   1495   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Liberals are brain dead\", \"Leftists don't know what to cheer for\", \"Comedy has been reduced to...  ,\n",
       "    index  \\\n",
       " 0   1496   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Narcissists project their own behavior onto others\", \"If a narcissist accuses their partner of...  ,\n",
       "    index  \\\n",
       " 0   1497   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"He is trying to incite us into a war\", \"He cannot leave things alone\", \"Everything this man to...  ,\n",
       "    index  \\\n",
       " 0   1498   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"They have been building something with 150 billion of laundered money\", \"The money was stolen ...  ,\n",
       "    index                                              claims\n",
       " 0   1499  [\"Muhammad's Islam is associated with being woke\"],\n",
       "    index claims\n",
       " 0   1500     [],\n",
       "    index claims\n",
       " 0   1501     [],\n",
       "    index claims\n",
       " 0   1502     [],\n",
       "    index  \\\n",
       " 0   1503   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Collusion did occur according to the report\", \"Mueller's report was not an exoneration\", \"The ...  ,\n",
       "    index  \\\n",
       " 0   1504   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Democrats are immature\", \"Democrats post vile rants on the President's Facebook page\", \"Democr...  ,\n",
       "    index claims\n",
       " 0   1505     [],\n",
       "    index claims\n",
       " 0   1506     [],\n",
       "    index claims\n",
       " 0   1507     [],\n",
       "    index  \\\n",
       " 0   1508   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Trump has the economy rolling\", \"We are not almost at war with China and Russia like we were w...  ,\n",
       "    index claims\n",
       " 0   1509     [],\n",
       "    index claims\n",
       " 0   1510     [],\n",
       "    index                                                              claims\n",
       " 0   1511  [\"CNN spreads fake news propaganda\", \"CNN has zombified citizens\"],\n",
       "    index  \\\n",
       " 0   1512   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Supporting federal or state funding of schools, homes, debt, and national healthcare is corrup...  ,\n",
       "    index                                                     claims\n",
       " 0   1513  [\"The US surrounded Russia after Reagan promised not to\"],\n",
       "    index claims\n",
       " 0   1514     [],\n",
       "    index claims\n",
       " 0   1515     [],\n",
       "    index  \\\n",
       " 0   1516   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"ABC usually shows political bias\", \"ABC might regain lost customers if they continue unbiased ...  ,\n",
       "    index  \\\n",
       " 0   1517   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Proof is needed before going to war\", \"Hannity is being hypocritical by doing what he criticiz...  ,\n",
       "    index claims\n",
       " 0   1518     [],\n",
       "    index claims\n",
       " 0   1519     [],\n",
       "    index                                                     claims\n",
       " 0   1520  [\"The audience laughter sounds 'canned' on this segment\"],\n",
       "    index claims\n",
       " 0   1521     [],\n",
       "    index  \\\n",
       " 0   1522   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Politicians start wars but do not fight them\", \"Politicians do not risk their own lives in war...  ,\n",
       "    index  \\\n",
       " 0   1523   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"People consider trivial factors when voting\", \"Republicans want to dumb down the nation\", \"Sim...  ,\n",
       "    index  \\\n",
       " 0   1524   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Cash on pallets is suspicious\", \"Only criminals send cash on pallets\", \"Money should be transf...  ,\n",
       "    index  \\\n",
       " 0   1525   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Their actions were meant to set up the president\", \"They knew Mr. President would react that w...  ,\n",
       "    index  \\\n",
       " 0   1526   \n",
       " \n",
       "                                                                                  claims  \n",
       " 0  [\"False investigations can cause devastation\", \"It is easy to say but hard to live\"]  ,\n",
       "    index  \\\n",
       " 0   1527   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"America started all the wars in the Middle East, Osama bin Laden was from Saudi Arabia which i...  ,\n",
       "    index  \\\n",
       " 0   1528   \n",
       " \n",
       "                                                                          claims  \n",
       " 0  [\"They might get nukes and you die\", \"They might try to get nukes but fail\"]  ,\n",
       "    index claims\n",
       " 0   1529     [],\n",
       "    index                                                     claims\n",
       " 0   1530  [\"No one gets kicked out for not paying two months rent\"],\n",
       "    index claims\n",
       " 0   1531     [],\n",
       "    index claims\n",
       " 0   1532     [],\n",
       "    index                                     claims\n",
       " 0   1533  [\"liberals are confused by common sense\"],\n",
       "    index  \\\n",
       " 0   1534   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Most Muslim countries are practicing democracy\", \"The US thinks democracy is a failed secular ...  ,\n",
       "    index claims\n",
       " 0   1535     [],\n",
       "    index  \\\n",
       " 0   1536   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Benny Walker is brainwashed by the people around him\", \"Benny Walker cannot respond well due t...  ,\n",
       "    index claims\n",
       " 0   1537     [],\n",
       "    index  \\\n",
       " 0   1538   \n",
       " \n",
       "                                                                    claims  \n",
       " 0  [\"The laughter in the video is fake\", \"The video contains propaganda\"]  ,\n",
       "    index  \\\n",
       " 0   1539   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Iran knows it has no win with America\", \"If America makes any move on Iran, Iran will respond\"...  ,\n",
       "    index claims\n",
       " 0   1540     [],\n",
       "    index claims\n",
       " 0   1541     [],\n",
       "    index  \\\n",
       " 0   1542   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Being involved in international affairs has kept us safe\", \"People without knowledge make unin...  ,\n",
       "    index  \\\n",
       " 0   1543   \n",
       " \n",
       "                                                                    claims  \n",
       " 0  [\"Religion and the belief in 'god' is what's wrong with this country\"]  ,\n",
       "    index  \\\n",
       " 0   1544   \n",
       " \n",
       "                                                                                       claims  \n",
       " 0  [\"Nothing has changed despite being there for some time\", \"Bring our men and women home\"]  ,\n",
       "    index  \\\n",
       " 0   1545   \n",
       " \n",
       "                                                                                         claims  \n",
       " 0  [\"We spend too much money\", \"The richest nation in the world shouldn't be falling to bits\"]  ,\n",
       "    index claims\n",
       " 0   1546     [],\n",
       "    index  \\\n",
       " 0   1547   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Obama knew about Iran's nuclear weapons program\", \"Obama acted like Iran wasn't developing nuc...  ,\n",
       "    index  \\\n",
       " 0   1548   \n",
       " \n",
       "                                                                                                claims  \n",
       " 0  [\"Colbert's 8 million dollar salary can change his priorities\", \"Colbert was funnier in the past\"]  ,\n",
       "    index  \\\n",
       " 0   1549   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Fear mongering and brain washing is horrific\", \"Canada is not perfect\", \"PM Trudeau is embraci...  ,\n",
       "    index claims\n",
       " 0   1550     [],\n",
       "    index                                                              claims\n",
       " 0   1551  [\"45ers can't spell\", \"45ers are illiterate like their president\"],\n",
       "    index  \\\n",
       " 0   1552   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The US made a mistake in Afghanistan leading to Bin Laden\", \"Assad was responsible for creatin...  ,\n",
       "    index claims\n",
       " 0   1553     [],\n",
       "    index  \\\n",
       " 0   1554   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Native Americans and Australians may want their land back\", \"White people could be kicked out ...  ,\n",
       "    index claims\n",
       " 0   1555     [],\n",
       "    index claims\n",
       " 0   1556     [],\n",
       "    index claims\n",
       " 0   1557     [],\n",
       "    index  \\\n",
       " 0   1558   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The condition is not a disorder but a symptom\", \"Tiny intercostal muscles and other muscle gro...  ,\n",
       "    index  \\\n",
       " 0   1559   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"They used Australian passports\", \"Australians were not happy about it\", \"Australians called in...  ,\n",
       "    index claims\n",
       " 0   1560     [],\n",
       "    index  \\\n",
       " 0   1561   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Steven Colbert is accused of distracting attention from Trump\", \"Steven Colbert is accused of ...  ,\n",
       "    index claims\n",
       " 0   1562     [],\n",
       "    index                                                              claims\n",
       " 0   1563  [\"They don't know what respect is\", \"They love being a showpiece\"],\n",
       "    index claims\n",
       " 0   1564     [],\n",
       "    index  \\\n",
       " 0   1565   \n",
       " \n",
       "                                                                                                claims  \n",
       " 0  [\"Obama was not pen pals with Kim Jong Un\", \"Kim Jong Un murders his people in public executions\"]  ,\n",
       "    index claims\n",
       " 0   1566     [],\n",
       "    index  \\\n",
       " 0   1567   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"He might be corrupt from envelope at funeral\", \"Ryan Pence letter before election about an art...  ,\n",
       "    index claims\n",
       " 0   1568     [],\n",
       "    index  \\\n",
       " 0   1569   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The twins are Hebrews\", \"The mother is Esau\", \"The mother is an Edomite\", \"The person should r...  ,\n",
       "    index  \\\n",
       " 0   1570   \n",
       " \n",
       "                                                                             claims  \n",
       " 0  [\"Trump makes arbitrary promises\", \"Trump does not follow through on promises\"]  ,\n",
       "    index claims\n",
       " 0   1571     [],\n",
       "    index                        claims\n",
       " 0   1572  [\"Mueller is an FBI Weasel\"],\n",
       "    index                                   claims\n",
       " 0   1573  [\"There were no deaths in the strikes\"],\n",
       "    index claims\n",
       " 0   1574     [],\n",
       "    index claims\n",
       " 0   1575     [],\n",
       "    index  \\\n",
       " 0   1576   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Hillary Clinton sold 20% of American uranium to a Russian company\", \"The sale was for $145 mil...  ,\n",
       "    index claims\n",
       " 0   1577     [],\n",
       "    index claims\n",
       " 0   1578     [],\n",
       "    index claims\n",
       " 0   1579     [],\n",
       "    index claims\n",
       " 0   1580     [],\n",
       "    index  \\\n",
       " 0   1581   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The link shared is unreliable\", \"The person in the link is unverified\", \"Walmart supports a mi...  ,\n",
       "    index claims\n",
       " 0   1582     [],\n",
       "    index claims\n",
       " 0   1583     [],\n",
       "    index claims\n",
       " 0   1584     [],\n",
       "    index claims\n",
       " 0   1585     [],\n",
       "    index                     claims\n",
       " 0   1586  [\"She would destroy him\"],\n",
       "    index  \\\n",
       " 0   1587   \n",
       " \n",
       "                                                                             claims  \n",
       " 0  [\"John Bolton will not learn any lesson unless Israel is attacked by Iranians\"]  ,\n",
       "    index  \\\n",
       " 0   1588   \n",
       " \n",
       "                                                                                        claims  \n",
       " 0  [\"People should not take nude photos if they don't want to worry about them being shared\"]  ,\n",
       "    index  \\\n",
       " 0   1589   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The Trump Administration placed sanctions on Russia\", \"The Trump Russia conspiracy is yet to b...  ,\n",
       "    index                      claims\n",
       " 0   1590  [\"He didn't cut spending\"],\n",
       "    index claims\n",
       " 0   1591     [],\n",
       "    index  \\\n",
       " 0   1592   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Syrian rebellion was not organized by the West or Saudi Arabia\", \"The rebellion happened due t...  ,\n",
       "    index claims\n",
       " 0   1593     [],\n",
       "    index                                                             claims\n",
       " 0   1594  [\"Doctors are not being held accountable for being drug pushers\"],\n",
       "    index  \\\n",
       " 0   1595   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"They are trying to bribe their way and take the black/brown vote for their party\", \"They cheer...  ,\n",
       "    index  \\\n",
       " 0   1596   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The investigation is a massive clown show\", \"No evidence of Trump campaign collusion with Russ...  ,\n",
       "    index claims\n",
       " 0   1597     [],\n",
       "    index claims\n",
       " 0   1598     [],\n",
       "    index  \\\n",
       " 0   1599   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"None of the people mentioned have been verified as Russian agents\", \"Manafort and Flynn are un...  ,\n",
       "    index  \\\n",
       " 0   1600   \n",
       " \n",
       "                                                                                  claims  \n",
       " 0  [\"Nobody makes fun of Asians\", \"People are just finding things to be victims about\"]  ,\n",
       "    index claims\n",
       " 0   1601     [],\n",
       "    index claims\n",
       " 0   1602     [],\n",
       "    index  \\\n",
       " 0   1603   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"People should form unions\", \"People should get involved in voting and run for office\", \"People...  ,\n",
       "    index  \\\n",
       " 0   1604   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Canada is a market-based economy\", \"People in Canada pay high taxes\", \"In Canada, people recei...  ,\n",
       "    index  \\\n",
       " 0   1605   \n",
       " \n",
       "                                                                       claims  \n",
       " 0  [\"You are not a cop hater\", \"You are a patriot\", \"You are a libertarian\"]  ,\n",
       "    index                              claims\n",
       " 0   1606  [\"Christians will not replace us\"],\n",
       "    index  \\\n",
       " 0   1607   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The money is going from the Russians to Trump's associates\", \"Russian oligarchs are transferri...  ,\n",
       "    index                                                      claims\n",
       " 0   1608  [\"this gun is scary looking\", \"this gun should be banned\"],\n",
       "    index                                      claims\n",
       " 0   1609  [\"He is the most unstable I've ever seen\"],\n",
       "    index                              claims\n",
       " 0   1610  [\"Intel officials helped Hillary\"],\n",
       "    index  \\\n",
       " 0   1611   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"WH briefings have been amusing since Psaki\", \"People at WH briefings avoid questions\", \"Kremli...  ,\n",
       "    index  \\\n",
       " 0   1612   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Tulsi is better informed on foreign policy than anyone on the debate stage\", \"Tulsi has a bett...  ,\n",
       "    index                       claims\n",
       " 0   1613  [\"CBS has a liberal slant\"],\n",
       "    index                                                         claims\n",
       " 0   1614  [\"Trump and his supporters are scared of Mueller testifying\"],\n",
       "    index  \\\n",
       " 0   1615   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"He has until this Friday to answer his subpoena\", \"He refused to produce his emails\", \"He is s...  ,\n",
       "    index claims\n",
       " 0   1616     [],\n",
       "    index claims\n",
       " 0   1617     [],\n",
       "    index claims\n",
       " 0   1618     [],\n",
       "    index claims\n",
       " 0   1619     [],\n",
       "    index claims\n",
       " 0   1620     [],\n",
       "    index claims\n",
       " 0   1621     [],\n",
       "    index claims\n",
       " 0   1622     [],\n",
       "    index  \\\n",
       " 0   1623   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Mueller should have released the investigation results by now\", \"The investigation has taken t...  ,\n",
       "    index claims\n",
       " 0   1624     [],\n",
       "    index  \\\n",
       " 0   1625   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Tourist attractions funded by taxpayer money should not discriminate against taxpayers\", \"A Gr...  ,\n",
       "    index claims\n",
       " 0   1626     [],\n",
       "    index                     claims\n",
       " 0   1627  [\"Trump lies frequently\"],\n",
       "    index                                      claims\n",
       " 0   1628  [\"That woman is an embarrassment to Cuba\"],\n",
       "    index  \\\n",
       " 0   1629   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Leftists get their facts and policies from unreliable sources\", \"CNN and Rachel Maddow are not...  ,\n",
       "    index claims\n",
       " 0   1630     [],\n",
       "    index  \\\n",
       " 0   1631   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Trump was named as a co-conspirator in a federal crime\", \"Trump ordered his lawyer Cohen not t...  ,\n",
       "    index claims\n",
       " 0   1632     [],\n",
       "    index claims\n",
       " 0   1633     [],\n",
       "    index  \\\n",
       " 0   1634   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"They are never going to leave this alone\", \"They are sure to find something that suits their a...  ,\n",
       "    index  \\\n",
       " 0   1635   \n",
       " \n",
       "                                                                                               claims  \n",
       " 0  [\"The stock market numbers are fake news\", \"People spend a fortune on fake food with fake money\"]  ,\n",
       "    index claims\n",
       " 0   1636     [],\n",
       "    index claims\n",
       " 0   1637     [],\n",
       "    index                                                   claims\n",
       " 0   1638  [\"Trump is a pathological liar\", \"Liberals are stupid\"],\n",
       "    index  \\\n",
       " 0   1639   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The Dossier has not been discredited\", \"Many items in the Dossier have been backed up by relea...  ,\n",
       "    index  \\\n",
       " 0   1640   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The American people are mostly fools\", \"The American people believe whatever the media tells t...  ,\n",
       "    index claims\n",
       " 0   1641     [],\n",
       "    index  \\\n",
       " 0   1642   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"MAGA supporters have low intelligence\", \"The commenter believes the person they are replying t...  ,\n",
       "    index claims\n",
       " 0   1643     [],\n",
       "    index                         claims\n",
       " 0   1644  [\"They are really after you\"],\n",
       "    index  \\\n",
       " 0   1645   \n",
       " \n",
       "                                                                              claims  \n",
       " 0  [\"Face the nation is an alt-right propaganda show\", \"Never watching ever again\"]  ,\n",
       "    index claims\n",
       " 0   1646     [],\n",
       "    index  \\\n",
       " 0   1647   \n",
       " \n",
       "                                                                            claims  \n",
       " 0  [\"There is no limit to how graphic TV can be when depicting Black suffering.\"]  ,\n",
       "    index  \\\n",
       " 0   1648   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Some people vote straight Republican while receiving food stamps\", \"Voting Republican is again...  ,\n",
       "    index claims\n",
       " 0   1649     [],\n",
       "    index claims\n",
       " 0   1650     [],\n",
       "    index claims\n",
       " 0   1651     [],\n",
       "    index  \\\n",
       " 0   1652   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The commenter struggled for 7 years with employment\", \"The commenter only worked 4-5 months ea...  ,\n",
       "    index claims\n",
       " 0   1653     [],\n",
       "    index claims\n",
       " 0   1654     [],\n",
       "    index claims\n",
       " 0   1655     [],\n",
       "    index  \\\n",
       " 0   1656   \n",
       " \n",
       "                                                                                              claims  \n",
       " 0  [\"Republican health care plan involves taxes\", \"Republicans pushed the plan through forcefully\"]  ,\n",
       "    index claims\n",
       " 0   1657     [],\n",
       "    index                              claims\n",
       " 0   1658  [\"It will never happen for Syria\"],\n",
       "    index                                    claims\n",
       " 0   1659  [\"Comey doesn't know how to do his job\"],\n",
       "    index                                                claims\n",
       " 0   1660  [\"Afghanistan is not safe until the US army leaves\"],\n",
       "    index claims\n",
       " 0   1661     [],\n",
       "    index  \\\n",
       " 0   1662   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Obama criticized Fox News\", \"Trump discredits anyone who disagrees with him\", \"Fox News is one...  ,\n",
       "    index  \\\n",
       " 0   1663   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The speaker is questioning the willingness to risk billions of dollars over Israel\", \"The spea...  ,\n",
       "    index                                                           claims\n",
       " 0   1664  [\"Sedition charges will put most of CCCPNN reporters in Gitmo\"],\n",
       "    index                         claims\n",
       " 0   1665  [\"Trump is outsourcing jobs\"],\n",
       "    index  \\\n",
       " 0   1666   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Iran is a regional power\", \"Iran virtually controls Iraq, Lebanon, and Syria\", \"Iran actively ...  ,\n",
       "    index  \\\n",
       " 0   1667   \n",
       " \n",
       "                                                                                             claims  \n",
       " 0  [\"People are deluded about Patrick Stewart being against Trump\", \"Jessie Waters is an asshole\"]  ,\n",
       "    index  \\\n",
       " 0   1668   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Sally Yates is attractive\", \"The speaker wants to bring down a person referred to as 'orange a...  ,\n",
       "    index claims\n",
       " 0   1669     [],\n",
       "    index claims\n",
       " 0   1670     [],\n",
       "    index claims\n",
       " 0   1671     [],\n",
       "    index  \\\n",
       " 0   1672   \n",
       " \n",
       "                                                                                   claims  \n",
       " 0  [\"White male privilege exists\", \"There is delusion and denial at 15:00 in the video\"]  ,\n",
       "    index claims\n",
       " 0   1673     [],\n",
       "    index claims\n",
       " 0   1674     [],\n",
       "    index claims\n",
       " 0   1675     [],\n",
       "    index  \\\n",
       " 0   1676   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"We are right supremacists\", \"We have the right to believe in our creator, country, countrymen,...  ,\n",
       "    index                                                 claims\n",
       " 0   1677  [\"He loves money\", \"He loves women\", \"He loves golf\"],\n",
       "    index  \\\n",
       " 0   1678   \n",
       " \n",
       "                                                                          claims  \n",
       " 0  [\"This issue takes more victims than a hurricane or other natural disaster\"]  ,\n",
       "    index  \\\n",
       " 0   1679   \n",
       " \n",
       "                                                                                               claims  \n",
       " 0  [\"White people set the bear up for destruction\", \"White people set everybody up for destruction\"]  ,\n",
       "    index claims\n",
       " 0   1680     [],\n",
       "    index                                           claims\n",
       " 0   1681  [\"Kevin J and Michelle stole it from some guy\"],\n",
       "    index claims\n",
       " 0   1682     [],\n",
       "    index  \\\n",
       " 0   1683   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"These guys tried to bribe women to make a charge against Mueller\", \"The women kept the emails\"...  ,\n",
       "    index  \\\n",
       " 0   1684   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Iran funds more terrorists than anyone else\", \"Leaving Iran alone will not fix the problem\", \"...  ,\n",
       "    index  \\\n",
       " 0   1685   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Anarchy would be a vast improvement over the current system\", \"Anarchy would not be a perfect ...  ,\n",
       "    index claims\n",
       " 0   1686     [],\n",
       "    index  \\\n",
       " 0   1687   \n",
       " \n",
       "                                                                                          claims  \n",
       " 0  [\"He should be evaluated for mental incompetence\", \"The doctor should not be chosen by him\"]  ,\n",
       "    index                                 claims\n",
       " 0   1688  [\"Trump exposed himself as an idiot\"],\n",
       "    index                                         claims\n",
       " 0   1689  [\"We should start boycotting their sponsors\"],\n",
       "    index claims\n",
       " 0   1690     [],\n",
       "    index  \\\n",
       " 0   1691   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"He tweeted about the NY attack 7 times that day\", \"He has tweeted several more times about the...  ,\n",
       "    index  \\\n",
       " 0   1692   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"America's government is failing\", \"America was destined to collapse\", \"Many people in America ...  ,\n",
       "    index  \\\n",
       " 0   1693   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Edward Gutierrez is a fake account\", \"Edward Gutierrez copies and pastes the same comment\", \"E...  ,\n",
       "    index                                                       claims\n",
       " 0   1694  [\"You are considered a traitor to your family and friends\"],\n",
       "    index claims\n",
       " 0   1695     [],\n",
       "    index  \\\n",
       " 0   1696   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Mueller's report will demonstrate no criminal activity\", \"The investigation was a colossal was...  ,\n",
       "    index claims\n",
       " 0   1697     [],\n",
       "    index  \\\n",
       " 0   1698   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Russia exposed things Hillary said and did\", \"Hillary could have lied her way into office\", \"T...  ,\n",
       "    index  \\\n",
       " 0   1699   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The United States is a parasite\", \"The United States is an extortionist\", \"The US currency is ...  ,\n",
       "    index                                                                claims\n",
       " 0   1700  [\"Hannity might end up in prison\", \"The news is propaganda garbage\"],\n",
       "    index                                            claims\n",
       " 0   1701  [\"The people chosen to run Israel are to blame\"],\n",
       "    index claims\n",
       " 0   1702     [],\n",
       "    index  \\\n",
       " 0   1703   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Trump has created an alternate reality\", \"Trump's supporters are sycophantic and ignorant\", \"T...  ,\n",
       "    index claims\n",
       " 0   1704     [],\n",
       "    index  \\\n",
       " 0   1705   \n",
       " \n",
       "                                                                       claims  \n",
       " 0  [\"They want to hide their criminal activity\", \"They are afraid of Trump\"]  ,\n",
       "    index  \\\n",
       " 0   1706   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Sam forgot to put ASMR in the title\", \"The video would have had 10 million views by now if ASM...  ,\n",
       "    index  \\\n",
       " 0   1707   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Trevor Noah has been appreciated for another year\", \"There is hope that 2018 will bring good n...  ,\n",
       "    index                                                    claims\n",
       " 0   1708  [\"Mueller's conclusions are factual\", \"She is an idiot\"],\n",
       "    index                                             claims\n",
       " 0   1709  [\"The Democrats have reached a new level of low\"],\n",
       "    index                                                  claims\n",
       " 0   1710  [\"I have the right to freedom of religion in America\"],\n",
       "    index  \\\n",
       " 0   1711   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"He backed down from attacking Iran because Putin told him to\", \"Putin sent the North Seas flot...  ,\n",
       "    index claims\n",
       " 0   1712     [],\n",
       "    index  \\\n",
       " 0   1713   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Comey helped Trump get elected with Hillary Clinton's email scandal\", \"Comey's firing and memo...  ,\n",
       "    index claims\n",
       " 0   1714     [],\n",
       "    index  \\\n",
       " 0   1715   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Being conservative is not a bad thing\", \"Most soldiers are conservative because they believe i...  ,\n",
       "    index  \\\n",
       " 0   1716   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The public is being hyped up to anticipate something\", \"There will be no escape from the situa...  ,\n",
       "    index claims\n",
       " 0   1717     [],\n",
       "    index  \\\n",
       " 0   1718   \n",
       " \n",
       "                                                                                  claims  \n",
       " 0  [\"The media is opinionated propaganda\", \"The media does not report fact-based news\"]  ,\n",
       "    index                                                             claims\n",
       " 0   1719  [\"The map of India is incorrect\", \"Travor should study properly\"],\n",
       "    index  \\\n",
       " 0   1720   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"The Kurds will return to the Syrian state after Assad is deposed and the Iranians leave\", \"The...  ,\n",
       "    index  \\\n",
       " 0   1721   \n",
       " \n",
       "                                                                                          claims  \n",
       " 0  [\"Trevino would drink the koolaid at Jonestown when the government had warned those people\"]  ,\n",
       "    index  \\\n",
       " 0   1722   \n",
       " \n",
       "                                                                           claims  \n",
       " 0  [\"Truckers were lied to\", \"Truckers were part of a majority who fell for it\"]  ,\n",
       "    index                             claims\n",
       " 0   1723  [\"Everything Trump touches dies\"],\n",
       "    index  \\\n",
       " 0   1724   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"Lindsey Graham is a rat\", \"Lindsey Graham will backstab the President\", \"Lindsey Graham is lik...  ,\n",
       "    index                                                      claims\n",
       " 0   1725  [\"Adam Schiff would be the president we wish we deserved\"],\n",
       "    index  \\\n",
       " 0   1726   \n",
       " \n",
       "                                                                                                 claims  \n",
       " 0  [\"He shouldn't have held that Hillary press conference\", \"He personally went after Trump to save...  ,\n",
       " ...]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index  \\\n",
      "0      0   \n",
      "1      1   \n",
      "2      3   \n",
      "3      4   \n",
      "4      5   \n",
      "\n",
      "                                                                   claims  \n",
      "0                                                                      []  \n",
      "1                                            [\"Minerals have rights too\"]  \n",
      "2  [\"The death of free and civil dialogue has been effectively depicted\"]  \n",
      "3                                            [\"No-one else will hug him\"]  \n",
      "4                                                                      []  \n"
     ]
    }
   ],
   "source": [
    "YT_claims = pd.concat(chunked_result, ignore_index=True)\n",
    "print(YT_claims.head())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "YT_claims.set_index(YT_claims['index'], inplace=True)\n",
    "YT_claim_embeds = YT_claim_embeds.join(YT_claims['claims'])\n",
    "YT_claim_embeds.rename(columns={'claims': 'claims_gpt4o'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data:\n",
    "YT_claim_embeds.to_parquet(f'{CFG.report_dir}/pubsphere_YT_posts.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data: \n",
    "YT_claim_embeds = pd.read_parquet(f'{CFG.report_dir}/pubsphere_YT_posts.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['StartDate', 'RecordedDate', 'IPAddress', 'Finished', 'Coder', 'ID',\n",
       "       'Mark_ID', 'Genre', 'topiccode', 'Platform',\n",
       "       ...\n",
       "       'political_post_gpt4o', 'political_post_gpt4o_dum', 'either_political',\n",
       "       'Time_comment_dt', 'post_ada_embedding', 'claims_gpt4o',\n",
       "       'post_expansion_gpt4o', 'most_similar_index_gpt4o',\n",
       "       'similarity_score_gpt4o', 'commentText_most_sim_gpt4o'],\n",
       "      dtype='object', length=116)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YT_claim_embeds.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56it [00:28,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 33 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 33 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80it [01:10,  3.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "137it [03:00,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 17 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 17 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "139it [03:18,  4.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "196it [04:52,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 31 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 31 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [05:25,  3.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "257it [06:56,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 35 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 35 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "313it [08:10,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 22 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 22 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "343it [08:48,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 8 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [10:24,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 36 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 36 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "404it [11:02,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "460it [12:51,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 16 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 16 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "461it [13:08,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 8 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "518it [15:06,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 15 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 15 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "529it [15:26,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "583it [17:00,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 34 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 34 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "640it [18:04,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 31 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 31 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "642it [18:36,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "699it [20:04,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 38 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 38 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "755it [21:09,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 34 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 34 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "776it [21:53,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "830it [23:27,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 31 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 31 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "851it [24:09,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "906it [25:51,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 24 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 24 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "924it [26:27,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "979it [28:02,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 32 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 32 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1035it [29:05,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 30 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 30 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1040it [29:38,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1096it [31:09,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 35 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 35 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1151it [32:13,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 31 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 31 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1156it [32:47,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1212it [34:18,  2.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 34 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 34 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1267it [35:25,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 27 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 27 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1316it [36:21,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1322it [36:29,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 24 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 24 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1324it [36:55,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1380it [38:29,  2.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 33 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 33 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1436it [39:34,  2.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 29 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 29 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1454it [40:17,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1511it [41:49,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 33 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 33 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1567it [42:53,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 30 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 30 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1572it [43:27,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1628it [45:02,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 32 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 32 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1683it [46:08,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 27 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 27 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1698it [46:46,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1753it [48:23,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 27 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 27 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1757it [48:52,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1812it [50:30,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 28 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 28 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1849it [51:16,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1905it [52:58,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 24 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 24 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1906it [53:22,  7.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1927it [53:40,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1983it [55:15,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 31 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 31 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1999it [55:54,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2055it [57:34,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 25 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 25 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2057it [58:01,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2113it [59:38,  2.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 31 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 31 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2131it [1:00:19,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2186it [1:01:52,  2.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 33 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 33 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2242it [1:02:53,  2.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 32 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 32 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2246it [1:03:26,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2302it [1:05:06,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 27 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 27 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2306it [1:05:35,  3.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2361it [1:07:12,  2.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 29 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 29 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2375it [1:07:49,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2431it [1:09:27,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 29 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 29 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2436it [1:09:59,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2492it [1:11:34,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 31 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 31 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2500it [1:12:08,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2556it [1:13:44,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 29 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 29 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2558it [1:14:14,  6.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2615it [1:15:47,  3.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 36 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 36 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2671it [1:16:53,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 31 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 31 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2718it [1:17:48,  2.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2774it [1:19:20,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 34 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 34 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2830it [1:20:32,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 23 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 23 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2835it [1:20:57,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2891it [1:22:33,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 31 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 31 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2896it [1:23:06,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2952it [1:24:43,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 30 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 30 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2954it [1:25:15,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3009it [1:26:56,  1.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 26 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 26 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3013it [1:27:25,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3070it [1:28:55,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 35 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 35 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3125it [1:30:02,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 29 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 29 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3132it [1:30:36,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index  \\\n",
      "0    119   \n",
      "1    282   \n",
      "2    769   \n",
      "3   1206   \n",
      "4   1214   \n",
      "\n",
      "                                                                   claims  \n",
      "0                                                                      []  \n",
      "1                                            [\"Minerals have rights too\"]  \n",
      "2  [\"The death of free and civil dialogue has been effectively depicted\"]  \n",
      "3                                            [\"No-one else will hug him\"]  \n",
      "4                                                                      []  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#mine claims from the expanded posts:\n",
    "\n",
    "chunked_result2: typing.List[pd.DataFrame] = []\n",
    "for index, row in tqdm.tqdm(YT_claim_embeds.iterrows()):\n",
    "    retry_count = 0\n",
    "    max_retries = 10\n",
    "    \n",
    "    while retry_count < max_retries:\n",
    "        try: \n",
    "            response = requests.post(\n",
    "                    url=api_endpoint,\n",
    "                    headers=headers,\n",
    "                    json={\n",
    "                        'model': MODELgpt4o,\n",
    "                        'messages': [\n",
    "                            {\n",
    "                                \"role\": \"system\",\n",
    "                                \"content\": SYSTEM_claim                         \n",
    "                            },\n",
    "                            {\n",
    "                                \"role\": \"user\",\n",
    "                                \"content\": f'The following social media post is a reply to a news- or infotainment video. '\n",
    "                                         + f'Check whether your answer strictly adheres to the specified format. \\n\"Post\":\\n<{row[\"post_expansion_gpt4o\"]}>',\n",
    "                            }\n",
    "                        ],\n",
    "                        'temperature': temperature_0,  \n",
    "                        'seed': SEED\n",
    "                    }\n",
    "                )\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                data_response = response.json()\n",
    "                chunked_result2.append(\n",
    "                pd.DataFrame(\n",
    "                    data=[[row['Mark_ID'], data_response[\"choices\"][0][\"message\"][\"content\"]]],                                \n",
    "                    columns=['index', 'claims']\n",
    "                    )\n",
    "                )\n",
    "                break  # Exit the retry loop on success  \n",
    "            elif response.status_code == 429:\n",
    "                retry_count += 1\n",
    "                retry_after = response.headers.get(\"Retry-After\")\n",
    "                error_message = response.json().get(\"error\", {}).get(\"message\", \"\")\n",
    "                retry_after = 30  # Default to 30 seconds if not found\n",
    "            \n",
    "                # Extract retry time from the error message\n",
    "                if \"Try again in\" in error_message:\n",
    "                    match = re.search(r\"Try again in (\\d+) second\", error_message)\n",
    "                    if match:\n",
    "                        try:\n",
    "                            retry_after = int(match.group(1))\n",
    "                        except (IndexError, ValueError) as e:\n",
    "                            print(f\"Rate limit exceeded. Error extracting retry time: {e}. Retrying in {retry_after} seconds.\")\n",
    "                            pass\n",
    "                elif \"Please retry after\" in error_message:\n",
    "                    match = re.search(r\"Please retry after (\\d+) second\", error_message)\n",
    "                    if match:\n",
    "                        try:\n",
    "                            retry_after = int(match.group(1))\n",
    "                        except (IndexError, ValueError) as e:\n",
    "                            print(f\"Rate limit exceeded. Error extracting retry time: {e}. Retrying in {retry_after} seconds.\")\n",
    "                            pass\n",
    "                \n",
    "\n",
    "                else:\n",
    "                    retry_after = 30  # Default to 30 seconds if not found\n",
    "                    print(f\"Rate limit exceeded. Defaulting to retry in {retry_after} seconds.\")\n",
    "                            \n",
    "        \n",
    "                print(f\"Rate limit exceeded. Retrying in {retry_after} seconds: {response.json()}. Retry count = {retry_count}\") \n",
    "                time.sleep(retry_after)\n",
    "                \n",
    "            #    print(f\"Rate limit exceeded. Retrying in {wait_time} seconds...\")\n",
    "            #    print(response.text)\n",
    "            #    time.sleep(wait_time)\n",
    "            elif response.status_code == 500:\n",
    "                retry_count += 1\n",
    "                wait_time = 20\n",
    "                print(f\"Failed to connect to API. Status code: {response.status_code}. Retrying in {wait_time} seconds...\")\n",
    "                print(response.text)\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                print(f\"Failed to connect to API. Status code: {response.status_code}\")\n",
    "                print(response.text)\n",
    "                break\n",
    "        except requests.exceptions.RequestException as e:   \n",
    "            print(f\"Failed to connect to API: {e}\")\n",
    "            retry_count += 1\n",
    "            wait_time = 60\n",
    "            print(f\"Retrying in {wait_time} seconds...\")\n",
    "            time.sleep(wait_time)   \n",
    "\n",
    "        if retry_count >= max_retries:\n",
    "            print(f\"Max retries reached for index {index}. Skipping to next item.\")\n",
    "            break  # Exit the loop if max retries are reached              \n",
    "\n",
    "YT_exp_claims = pd.concat(chunked_result2, ignore_index=True)\n",
    "print(YT_exp_claims.head())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>claims</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>282</td>\n",
       "      <td>[\"Minerals have rights too\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>769</td>\n",
       "      <td>[\"The death of free and civil dialogue has been effectively depicted\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1206</td>\n",
       "      <td>[\"No-one else will hug him\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1214</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3127</th>\n",
       "      <td>2002575</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3128</th>\n",
       "      <td>3000508</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3129</th>\n",
       "      <td>20000102</td>\n",
       "      <td>[\"They knew all about the cameras\", \"The bald guy probably has a head of hair\", \"The red haired ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3130</th>\n",
       "      <td>20000418</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>20001003</td>\n",
       "      <td>[\"The Syrian crisis is a horrible thing\", \"Al Assad is against Daesh and the rebels\", \"Putin is ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3132 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index  \\\n",
       "0          119   \n",
       "1          282   \n",
       "2          769   \n",
       "3         1206   \n",
       "4         1214   \n",
       "...        ...   \n",
       "3127   2002575   \n",
       "3128   3000508   \n",
       "3129  20000102   \n",
       "3130  20000418   \n",
       "3131  20001003   \n",
       "\n",
       "                                                                                                   claims  \n",
       "0                                                                                                      []  \n",
       "1                                                                            [\"Minerals have rights too\"]  \n",
       "2                                  [\"The death of free and civil dialogue has been effectively depicted\"]  \n",
       "3                                                                            [\"No-one else will hug him\"]  \n",
       "4                                                                                                      []  \n",
       "...                                                                                                   ...  \n",
       "3127                                                                                                   []  \n",
       "3128                                                                                                   []  \n",
       "3129  [\"They knew all about the cameras\", \"The bald guy probably has a head of hair\", \"The red haired ...  \n",
       "3130                                                                                                   []  \n",
       "3131  [\"The Syrian crisis is a horrible thing\", \"Al Assad is against Daesh and the rebels\", \"Putin is ...  \n",
       "\n",
       "[3132 rows x 2 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new run:\n",
    "YT_exp_claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>claims</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>119</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>282</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>769</td>\n",
       "      <td>[\"The death of free and civil dialogue has been effectively depicted\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>1206</td>\n",
       "      <td>[\"No-one else will hug him.\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>1214</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002575</th>\n",
       "      <td>2002575</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000508</th>\n",
       "      <td>3000508</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000102</th>\n",
       "      <td>20000102</td>\n",
       "      <td>[\"They knew all about the cameras\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20000418</th>\n",
       "      <td>20000418</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20001003</th>\n",
       "      <td>20001003</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3132 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             index  \\\n",
       "index                \n",
       "119            119   \n",
       "282            282   \n",
       "769            769   \n",
       "1206          1206   \n",
       "1214          1214   \n",
       "...            ...   \n",
       "2002575    2002575   \n",
       "3000508    3000508   \n",
       "20000102  20000102   \n",
       "20000418  20000418   \n",
       "20001003  20001003   \n",
       "\n",
       "                                                                          claims  \n",
       "index                                                                             \n",
       "119                                                                           []  \n",
       "282                                                                           []  \n",
       "769       [\"The death of free and civil dialogue has been effectively depicted\"]  \n",
       "1206                                               [\"No-one else will hug him.\"]  \n",
       "1214                                                                          []  \n",
       "...                                                                          ...  \n",
       "2002575                                                                       []  \n",
       "3000508                                                                       []  \n",
       "20000102                                     [\"They knew all about the cameras\"]  \n",
       "20000418                                                                      []  \n",
       "20001003                                                                      []  \n",
       "\n",
       "[3132 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YT_exp_claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "YT_exp_claims.set_index(YT_exp_claims['index'], inplace=True)\n",
    "YT_claim_embeds = YT_claim_embeds.join(YT_exp_claims['claims'], on='Mark_ID', rsuffix='_ext_gpt4o')\n",
    "YT_claim_embeds.rename(columns={'claims': 'claims_ext_gpt4o'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YT_claim_embeds.loc[:, ['commentText', 'post_expansion_gpt4o', 'claims_ext_gpt4o']].head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data:\n",
    "YT_claim_embeds.to_parquet(f'{CFG.report_dir}/pubsphere_YT_posts.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_claim_embeds.drop(columns=['claims_ext_gpt4o'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_claim_embeds = dataset_claim_embeds.merge(YT_claim_embeds.loc[:,['claims_ext_gpt4o', 'Mark_ID']], how='left', on='Mark_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data:\n",
    "dataset_claim_embeds.to_parquet(f'{CFG.report_dir}/pubsphere.claim_embed.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_new: str = \\\n",
    "    \"\"\"\n",
    "# Instruction\n",
    "\n",
    "Identify whether a social media posts adds new information (2), expands on information (1) or does not add new information (0) on the topic of a debate. New information is present (2) if the post introduces a new argument or perspective within the thread topic. \n",
    "A post expands on an existing argument or perspective (1) if it provides additional context or examples to an existing argument or perspective, or if it provides a sub-argument (parent-child relation). \n",
    "If the post does not relate to the thread topic or provides no new information, assign a value of 0. Follow these steps:\n",
    "\n",
    "\n",
    "Follow these steps:\n",
    "\n",
    "1. You will receive a target post in double chevrons <<...>> along with the thread topic in single chevrons <...>, and preceding posts enclosed in triple chevrons `<<<...>>>`.\n",
    "2. Verify if the target post is on the thread topic.\n",
    "3. Identify if new information is presented in the target post with respect to the preceding posts. \n",
    "4. If in doubt, assign a value of 0.\n",
    "\n",
    "Respond with only the predicted class (0 or 1 or 2) of the request. Do not include any additional text or explanations.\n",
    "Class:\n",
    "\t\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_claim_new: str = \\\n",
    "    \"\"\"\n",
    "# Instruction\n",
    "\n",
    "Identify whether a claim adds new information (2), expands on information (1) or does not add new information (0) with respect to preceding claims. New information is present (2) if the claim introduces a new argument or perspective. \n",
    "A claim expands on an existing argument or perspective (1) if it strongly related to it, or it provides additional context or examples to an argument or perspective in a preceding claim, or if it provides a sub-argument (parent-child relation). \n",
    "If the claim is very similar to a preceding claim or does not add any perspective or argument, assign a value of 0. Follow these steps:\n",
    "\n",
    "\n",
    "Follow these steps:\n",
    "\n",
    "1. You will receive a target claim in double chevrons <<...>> along with the preceding claims in single chevrons <...>.\n",
    "2. Identify if new information is presented in the target claim with respect to the preceding posts. \n",
    "4. If in doubt, assign a value of 0.\n",
    "\n",
    "Respond with only the predicted class (0 or 1 or 2) of the request. Do not include any additional text or explanations.\n",
    "Class:\n",
    "\t\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3132/3132 [14:26<00:00,  3.62it/s] \n"
     ]
    }
   ],
   "source": [
    "#get ADA embeddings for posts:\n",
    "YT_claim_embeds.loc[:, 'post_ada_embedding'] = YT_claim_embeds['commentText'].progress_apply(get_ada_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [0.0012491943780332804, -0.01312993373721838, 0.004941582679748535, -0.026987144723534584, -0.01...\n",
       "1       [-0.012995055876672268, -0.016615739092230797, 0.018477026373147964, -0.013490946963429451, -0.0...\n",
       "3       [-0.0008296146406792104, 0.0013742600567638874, 0.010784990154206753, -0.030297795310616493, -0....\n",
       "4       [-0.026431242004036903, -0.003406326286494732, 0.005844608414918184, -0.01946660876274109, -0.00...\n",
       "5       [-0.03259480744600296, 0.0038548349402844906, -0.006202991586178541, 0.008793946355581284, -0.03...\n",
       "                                                       ...                                                 \n",
       "3854    [-0.0018265506951138377, -0.02517927996814251, -0.0021120987366884947, -0.015046310611069202, -0...\n",
       "3855    [-0.005544822663068771, -0.017791016027331352, -0.00620570732280612, -0.019258178770542145, -0.0...\n",
       "3859    [0.002804453717544675, -0.009028810076415539, 0.024697821587324142, -0.02455144375562668, 0.0020...\n",
       "3860    [-0.024419017136096954, -0.027028879150748253, -0.00868877675384283, -0.011925265192985535, 0.00...\n",
       "3861    [-0.006858734413981438, 0.017054861411452293, -0.015412443317472935, -0.022704776376485825, -0.0...\n",
       "Name: post_ada_embedding, Length: 3132, dtype: object"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YT_claim_embeds.loc[:, 'post_ada_embedding']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data:\n",
    "YT_claim_embeds.to_parquet(f'{CFG.report_dir}/pubsphere_YT_posts.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_claim_embeds = dataset_claim_embeds.join(YT_claim_embeds['post_ada_embedding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 730/730 [03:20<00:00,  3.64it/s]\n"
     ]
    }
   ],
   "source": [
    "#get ada embeddings for post with missing ada embedding values:\n",
    "missing_indices = dataset_claim_embeds['post_ada_embedding'].isna()\n",
    "dataset_claim_embeds.loc[missing_indices, 'post_ada_embedding'] = dataset_claim_embeds.loc[missing_indices, 'commentText'].progress_apply(get_ada_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartDate</th>\n",
       "      <th>RecordedDate</th>\n",
       "      <th>IPAddress</th>\n",
       "      <th>Finished</th>\n",
       "      <th>Coder</th>\n",
       "      <th>ID</th>\n",
       "      <th>Mark_ID</th>\n",
       "      <th>Genre</th>\n",
       "      <th>topiccode</th>\n",
       "      <th>Platform</th>\n",
       "      <th>...</th>\n",
       "      <th>cosine_similarity_post_claim_MXBAI</th>\n",
       "      <th>cosine_low_high_MXBAI</th>\n",
       "      <th>tfidf_embed_post_svd</th>\n",
       "      <th>Llama31_political_post_8b</th>\n",
       "      <th>Llama31_political_fill_8b</th>\n",
       "      <th>Llama31_political_fill_8b_score</th>\n",
       "      <th>political_post_gpt4o</th>\n",
       "      <th>political_post_gpt4o_dum</th>\n",
       "      <th>either_political</th>\n",
       "      <th>post_ada_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/30/2021 13:03:17</td>\n",
       "      <td>5/30/2021 13:04:17</td>\n",
       "      <td>62.194.51.29</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgyPHwv8G0cDE6-wEgl4AaABAg.8_0ZjJKSJty8_0kXGkAd2U</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960095</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>non-political</td>\n",
       "      <td>non-political</td>\n",
       "      <td>0</td>\n",
       "      <td>non-political</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0012491943780332804, -0.01312993373721838, 0.004941582679748535, -0.026987144723534584, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/11/2021 10:34:05</td>\n",
       "      <td>10/11/2021 10:36:46</td>\n",
       "      <td>213.127.109.191</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Ugx2WXq9UdV8mPPjejJ4AaABAg.8yHCKV0Boe58yYRxEQEF45</td>\n",
       "      <td>282</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957984</td>\n",
       "      <td>0.991973</td>\n",
       "      <td>[0.9999999959466253]</td>\n",
       "      <td>political</td>\n",
       "      <td>political</td>\n",
       "      <td>1</td>\n",
       "      <td>non-political</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.012995055876672268, -0.016615739092230797, 0.018477026373147964, -0.013490946963429451, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9/9/2021 18:49:48</td>\n",
       "      <td>9/9/2021 18:51:32</td>\n",
       "      <td>213.127.110.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1110578710648890000</td>\n",
       "      <td>372</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.967763</td>\n",
       "      <td>0.996136</td>\n",
       "      <td>[1.0000000354648362]</td>\n",
       "      <td>political</td>\n",
       "      <td>political</td>\n",
       "      <td>1</td>\n",
       "      <td>political</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.0028026909567415714, 0.007603764999657869, 0.022936813533306122, -0.055016644299030304, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6/6/2021 16:12:46</td>\n",
       "      <td>6/6/2021 16:16:16</td>\n",
       "      <td>213.127.76.145</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgwUPFScjJ0MCeaP2F54AaABAg.8lvp3fc9Euf8lvvgsUgEgV</td>\n",
       "      <td>769</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.952258</td>\n",
       "      <td>0.992674</td>\n",
       "      <td>[0.9999999904984119]</td>\n",
       "      <td>political</td>\n",
       "      <td>political</td>\n",
       "      <td>1</td>\n",
       "      <td>non-political</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.0008296146406792104, 0.0013742600567638874, 0.010784990154206753, -0.030297795310616493, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6/13/2021 13:25:49</td>\n",
       "      <td>6/13/2021 13:27:28</td>\n",
       "      <td>213.127.82.232</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgwWKCWtSJdFvjGHvTp4AaABAg.8kUC5dGrQ2H8kUDRihE2f3</td>\n",
       "      <td>1206</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977981</td>\n",
       "      <td>0.992789</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>non-political</td>\n",
       "      <td>non-political</td>\n",
       "      <td>0</td>\n",
       "      <td>non-political</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.026431242004036903, -0.003406326286494732, 0.005844608414918184, -0.01946660876274109, -0.00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             StartDate         RecordedDate        IPAddress  Finished  Coder  \\\n",
       "0   5/30/2021 13:03:17   5/30/2021 13:04:17     62.194.51.29         1      6   \n",
       "1  10/11/2021 10:34:05  10/11/2021 10:36:46  213.127.109.191         1      6   \n",
       "2    9/9/2021 18:49:48    9/9/2021 18:51:32    213.127.110.0         1      6   \n",
       "3    6/6/2021 16:12:46    6/6/2021 16:16:16   213.127.76.145         1      6   \n",
       "4   6/13/2021 13:25:49   6/13/2021 13:27:28   213.127.82.232         1      6   \n",
       "\n",
       "                                                  ID  Mark_ID  Genre  \\\n",
       "0  UgyPHwv8G0cDE6-wEgl4AaABAg.8_0ZjJKSJty8_0kXGkAd2U      119      0   \n",
       "1  Ugx2WXq9UdV8mPPjejJ4AaABAg.8yHCKV0Boe58yYRxEQEF45      282      1   \n",
       "2                                1110578710648890000      372      2   \n",
       "3  UgwUPFScjJ0MCeaP2F54AaABAg.8lvp3fc9Euf8lvvgsUgEgV      769      0   \n",
       "4  UgwWKCWtSJdFvjGHvTp4AaABAg.8kUC5dGrQ2H8kUDRihE2f3     1206      0   \n",
       "\n",
       "   topiccode  Platform  ...  cosine_similarity_post_claim_MXBAI  \\\n",
       "0          0         1  ...                            0.960095   \n",
       "1          2         1  ...                            0.957984   \n",
       "2          4         2  ...                            0.967763   \n",
       "3          0         1  ...                            0.952258   \n",
       "4          0         1  ...                            0.977981   \n",
       "\n",
       "  cosine_low_high_MXBAI  tfidf_embed_post_svd  Llama31_political_post_8b  \\\n",
       "0              1.000000                 [1.0]              non-political   \n",
       "1              0.991973  [0.9999999959466253]                  political   \n",
       "2              0.996136  [1.0000000354648362]                  political   \n",
       "3              0.992674  [0.9999999904984119]                  political   \n",
       "4              0.992789                 [1.0]              non-political   \n",
       "\n",
       "   Llama31_political_fill_8b  Llama31_political_fill_8b_score  \\\n",
       "0              non-political                                0   \n",
       "1                  political                                1   \n",
       "2                  political                                1   \n",
       "3                  political                                1   \n",
       "4              non-political                                0   \n",
       "\n",
       "   political_post_gpt4o  political_post_gpt4o_dum  either_political  \\\n",
       "0         non-political                         0                 0   \n",
       "1         non-political                         0                 1   \n",
       "2             political                         1                 1   \n",
       "3         non-political                         0                 1   \n",
       "4         non-political                         0                 0   \n",
       "\n",
       "                                                                                    post_ada_embedding  \n",
       "0  [0.0012491943780332804, -0.01312993373721838, 0.004941582679748535, -0.026987144723534584, -0.01...  \n",
       "1  [-0.012995055876672268, -0.016615739092230797, 0.018477026373147964, -0.013490946963429451, -0.0...  \n",
       "2  [-0.0028026909567415714, 0.007603764999657869, 0.022936813533306122, -0.055016644299030304, -0.0...  \n",
       "3  [-0.0008296146406792104, 0.0013742600567638874, 0.010784990154206753, -0.030297795310616493, -0....  \n",
       "4  [-0.026431242004036903, -0.003406326286494732, 0.005844608414918184, -0.01946660876274109, -0.00...  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_claim_embeds.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data:\n",
    "dataset_claim_embeds.to_parquet(f'{CFG.report_dir}/pubsphere.claim_embed.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get embeddings for the claims:\n",
    "#first load the claims:\n",
    "YT_claim_embeds = pd.read_parquet(f'{CFG.report_dir}/pubsphere_YT_posts.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartDate</th>\n",
       "      <th>RecordedDate</th>\n",
       "      <th>IPAddress</th>\n",
       "      <th>Finished</th>\n",
       "      <th>Coder</th>\n",
       "      <th>ID</th>\n",
       "      <th>Mark_ID</th>\n",
       "      <th>Genre</th>\n",
       "      <th>topiccode</th>\n",
       "      <th>Platform</th>\n",
       "      <th>...</th>\n",
       "      <th>tfidf_embed_post_svd</th>\n",
       "      <th>Llama31_political_post_8b</th>\n",
       "      <th>Llama31_political_fill_8b</th>\n",
       "      <th>Llama31_political_fill_8b_score</th>\n",
       "      <th>political_post_gpt4o</th>\n",
       "      <th>political_post_gpt4o_dum</th>\n",
       "      <th>either_political</th>\n",
       "      <th>Time_comment_dt</th>\n",
       "      <th>post_expansion_gpt4o</th>\n",
       "      <th>post_ada_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/30/2021 13:03:17</td>\n",
       "      <td>5/30/2021 13:04:17</td>\n",
       "      <td>62.194.51.29</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgyPHwv8G0cDE6-wEgl4AaABAg.8_0ZjJKSJty8_0kXGkAd2U</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>non-political</td>\n",
       "      <td>non-political</td>\n",
       "      <td>0</td>\n",
       "      <td>non-political</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-11-16 09:14:09+00:00</td>\n",
       "      <td>Is 1:37 the new 60 minutes</td>\n",
       "      <td>[0.0012491943780332804, -0.01312993373721838, 0.004941582679748535, -0.026987144723534584, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/11/2021 10:34:05</td>\n",
       "      <td>10/11/2021 10:36:46</td>\n",
       "      <td>213.127.109.191</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Ugx2WXq9UdV8mPPjejJ4AaABAg.8yHCKV0Boe58yYRxEQEF45</td>\n",
       "      <td>282</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9999999959466253]</td>\n",
       "      <td>political</td>\n",
       "      <td>political</td>\n",
       "      <td>1</td>\n",
       "      <td>non-political</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-08-12 20:22:06+00:00</td>\n",
       "      <td>the only solution for it...... hire a rapist..... just kidding</td>\n",
       "      <td>[-0.012995055876672268, -0.016615739092230797, 0.018477026373147964, -0.013490946963429451, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6/6/2021 16:12:46</td>\n",
       "      <td>6/6/2021 16:16:16</td>\n",
       "      <td>213.127.76.145</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgwUPFScjJ0MCeaP2F54AaABAg.8lvp3fc9Euf8lvvgsUgEgV</td>\n",
       "      <td>769</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[0.9999999904984119]</td>\n",
       "      <td>political</td>\n",
       "      <td>political</td>\n",
       "      <td>1</td>\n",
       "      <td>non-political</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-10-03 05:44:24+00:00</td>\n",
       "      <td>@TheJohny815   true. dinosaurs microscopic organisms, neanderthals and other pre-historic humans...</td>\n",
       "      <td>[-0.0008296146406792104, 0.0013742600567638874, 0.010784990154206753, -0.030297795310616493, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6/13/2021 13:25:49</td>\n",
       "      <td>6/13/2021 13:27:28</td>\n",
       "      <td>213.127.82.232</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgwWKCWtSJdFvjGHvTp4AaABAg.8kUC5dGrQ2H8kUDRihE2f3</td>\n",
       "      <td>1206</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.0]</td>\n",
       "      <td>non-political</td>\n",
       "      <td>non-political</td>\n",
       "      <td>0</td>\n",
       "      <td>non-political</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-08-28 05:38:51+00:00</td>\n",
       "      <td>No, the industry is worse! If you to took a biologylesson you would learn that the biodiversity ...</td>\n",
       "      <td>[-0.026431242004036903, -0.003406326286494732, 0.005844608414918184, -0.01946660876274109, -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11/30/2021 17:24:18</td>\n",
       "      <td>11/30/2021 17:27:16</td>\n",
       "      <td>213.127.109.191</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Ugw2eTvkZLfH9MDVg1R4AaABAg</td>\n",
       "      <td>1214</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[1.000000006283446]</td>\n",
       "      <td>political</td>\n",
       "      <td>political</td>\n",
       "      <td>1</td>\n",
       "      <td>political</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-08-20 00:31:48+00:00</td>\n",
       "      <td>go mitt Romney 2012</td>\n",
       "      <td>[-0.03259480744600296, 0.0038548349402844906, -0.006202991586178541, 0.008793946355581284, -0.03...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             StartDate         RecordedDate        IPAddress  Finished  Coder  \\\n",
       "0   5/30/2021 13:03:17   5/30/2021 13:04:17     62.194.51.29         1      6   \n",
       "1  10/11/2021 10:34:05  10/11/2021 10:36:46  213.127.109.191         1      6   \n",
       "3    6/6/2021 16:12:46    6/6/2021 16:16:16   213.127.76.145         1      6   \n",
       "4   6/13/2021 13:25:49   6/13/2021 13:27:28   213.127.82.232         1      6   \n",
       "5  11/30/2021 17:24:18  11/30/2021 17:27:16  213.127.109.191         1      6   \n",
       "\n",
       "                                                  ID  Mark_ID  Genre  \\\n",
       "0  UgyPHwv8G0cDE6-wEgl4AaABAg.8_0ZjJKSJty8_0kXGkAd2U      119      0   \n",
       "1  Ugx2WXq9UdV8mPPjejJ4AaABAg.8yHCKV0Boe58yYRxEQEF45      282      1   \n",
       "3  UgwUPFScjJ0MCeaP2F54AaABAg.8lvp3fc9Euf8lvvgsUgEgV      769      0   \n",
       "4  UgwWKCWtSJdFvjGHvTp4AaABAg.8kUC5dGrQ2H8kUDRihE2f3     1206      0   \n",
       "5                         Ugw2eTvkZLfH9MDVg1R4AaABAg     1214      1   \n",
       "\n",
       "   topiccode  Platform  ...  tfidf_embed_post_svd Llama31_political_post_8b  \\\n",
       "0          0         1  ...                 [1.0]             non-political   \n",
       "1          2         1  ...  [0.9999999959466253]                 political   \n",
       "3          0         1  ...  [0.9999999904984119]                 political   \n",
       "4          0         1  ...                 [1.0]             non-political   \n",
       "5          2         1  ...   [1.000000006283446]                 political   \n",
       "\n",
       "   Llama31_political_fill_8b  Llama31_political_fill_8b_score  \\\n",
       "0              non-political                                0   \n",
       "1                  political                                1   \n",
       "3                  political                                1   \n",
       "4              non-political                                0   \n",
       "5                  political                                1   \n",
       "\n",
       "   political_post_gpt4o  political_post_gpt4o_dum  either_political  \\\n",
       "0         non-political                         0                 0   \n",
       "1         non-political                         0                 1   \n",
       "3         non-political                         0                 1   \n",
       "4         non-political                         0                 0   \n",
       "5             political                         1                 1   \n",
       "\n",
       "            Time_comment_dt  \\\n",
       "0 2017-11-16 09:14:09+00:00   \n",
       "1 2019-08-12 20:22:06+00:00   \n",
       "3 2018-10-03 05:44:24+00:00   \n",
       "4 2018-08-28 05:38:51+00:00   \n",
       "5 2019-08-20 00:31:48+00:00   \n",
       "\n",
       "                                                                                  post_expansion_gpt4o  \\\n",
       "0                                                                          Is 1:37 the new 60 minutes    \n",
       "1                                       the only solution for it...... hire a rapist..... just kidding   \n",
       "3  @TheJohny815   true. dinosaurs microscopic organisms, neanderthals and other pre-historic humans...   \n",
       "4  No, the industry is worse! If you to took a biologylesson you would learn that the biodiversity ...   \n",
       "5                                                                                  go mitt Romney 2012   \n",
       "\n",
       "                                                                                    post_ada_embedding  \n",
       "0  [0.0012491943780332804, -0.01312993373721838, 0.004941582679748535, -0.026987144723534584, -0.01...  \n",
       "1  [-0.012995055876672268, -0.016615739092230797, 0.018477026373147964, -0.013490946963429451, -0.0...  \n",
       "3  [-0.0008296146406792104, 0.0013742600567638874, 0.010784990154206753, -0.030297795310616493, -0....  \n",
       "4  [-0.026431242004036903, -0.003406326286494732, 0.005844608414918184, -0.01946660876274109, -0.00...  \n",
       "5  [-0.03259480744600296, 0.0038548349402844906, -0.006202991586178541, 0.008793946355581284, -0.03...  \n",
       "\n",
       "[5 rows x 112 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YT_claim_embeds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartDate</th>\n",
       "      <th>RecordedDate</th>\n",
       "      <th>IPAddress</th>\n",
       "      <th>Finished</th>\n",
       "      <th>Coder</th>\n",
       "      <th>ID</th>\n",
       "      <th>Mark_ID</th>\n",
       "      <th>Genre</th>\n",
       "      <th>topiccode</th>\n",
       "      <th>Platform</th>\n",
       "      <th>...</th>\n",
       "      <th>likeCount_video</th>\n",
       "      <th>date_difference</th>\n",
       "      <th>commentCount_video</th>\n",
       "      <th>replyCount_comment</th>\n",
       "      <th>topic</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>HATELIST_FOCUSED_DUMMY</th>\n",
       "      <th>Time_comment_year</th>\n",
       "      <th>Time_video_year</th>\n",
       "      <th>dataset_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/30/2021 13:03:17</td>\n",
       "      <td>5/30/2021 13:04:17</td>\n",
       "      <td>62.194.51.29</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgyPHwv8G0cDE6-wEgl4AaABAg.8_0ZjJKSJty8_0kXGkAd2U</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/11/2021 10:34:05</td>\n",
       "      <td>10/11/2021 10:36:46</td>\n",
       "      <td>213.127.109.191</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Ugx2WXq9UdV8mPPjejJ4AaABAg.8yHCKV0Boe58yYRxEQEF45</td>\n",
       "      <td>282</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3817.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>1748.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>economy</td>\n",
       "      <td>3630000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6/6/2021 16:12:46</td>\n",
       "      <td>6/6/2021 16:16:16</td>\n",
       "      <td>213.127.76.145</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgwUPFScjJ0MCeaP2F54AaABAg.8lvp3fc9Euf8lvvgsUgEgV</td>\n",
       "      <td>769</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6/13/2021 13:25:49</td>\n",
       "      <td>6/13/2021 13:27:28</td>\n",
       "      <td>213.127.82.232</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgwWKCWtSJdFvjGHvTp4AaABAg.8kUC5dGrQ2H8kUDRihE2f3</td>\n",
       "      <td>1206</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11/30/2021 17:24:18</td>\n",
       "      <td>11/30/2021 17:27:16</td>\n",
       "      <td>213.127.109.191</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Ugw2eTvkZLfH9MDVg1R4AaABAg</td>\n",
       "      <td>1214</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>9472.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>2912.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>economy</td>\n",
       "      <td>3630000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3854</th>\n",
       "      <td>12/31/2021 15:07:40</td>\n",
       "      <td>12/31/2021 15:08:38</td>\n",
       "      <td>193.154.174.158</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgwiL6YZam5Xg4FWUHh4AaABAg</td>\n",
       "      <td>2002575</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>776.0</td>\n",
       "      <td>2574.0</td>\n",
       "      <td>1004.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>east</td>\n",
       "      <td>105000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>3854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3855</th>\n",
       "      <td>10/19/2021 22:23:07</td>\n",
       "      <td>10/19/2021 22:24:30</td>\n",
       "      <td>213.127.109.191</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgxGubygP72yCR0-la14AaABAg</td>\n",
       "      <td>3000508</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>12475.0</td>\n",
       "      <td>3803.0</td>\n",
       "      <td>4785.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>east</td>\n",
       "      <td>6740000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>3855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3859</th>\n",
       "      <td>10/6/2021 16:08:39</td>\n",
       "      <td>10/6/2021 16:10:42</td>\n",
       "      <td>213.127.113.113</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UghFY3QJ6nmT_ngCoAEC.7-H0Z7--wxd8goqpaPs-bl</td>\n",
       "      <td>20000102</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>12475.0</td>\n",
       "      <td>3803.0</td>\n",
       "      <td>4785.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>east</td>\n",
       "      <td>6740000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>3859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3860</th>\n",
       "      <td>10/15/2021 18:30:04</td>\n",
       "      <td>10/15/2021 18:35:40</td>\n",
       "      <td>213.127.109.191</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgyWabsmmnq3zam4DgZ4AaABAg</td>\n",
       "      <td>20000418</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>31761.0</td>\n",
       "      <td>1531.0</td>\n",
       "      <td>2206.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>east</td>\n",
       "      <td>6800000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>3860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3861</th>\n",
       "      <td>11/19/2021 17:49:17</td>\n",
       "      <td>11/19/2021 17:51:04</td>\n",
       "      <td>213.127.109.191</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgwPOHIDyICm10k0Mvx4AaABAg</td>\n",
       "      <td>20001003</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5740.0</td>\n",
       "      <td>2276.0</td>\n",
       "      <td>2887.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>east</td>\n",
       "      <td>549000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>3861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3132 rows × 80 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                StartDate         RecordedDate        IPAddress  Finished  \\\n",
       "0      5/30/2021 13:03:17   5/30/2021 13:04:17     62.194.51.29         1   \n",
       "1     10/11/2021 10:34:05  10/11/2021 10:36:46  213.127.109.191         1   \n",
       "3       6/6/2021 16:12:46    6/6/2021 16:16:16   213.127.76.145         1   \n",
       "4      6/13/2021 13:25:49   6/13/2021 13:27:28   213.127.82.232         1   \n",
       "5     11/30/2021 17:24:18  11/30/2021 17:27:16  213.127.109.191         1   \n",
       "...                   ...                  ...              ...       ...   \n",
       "3854  12/31/2021 15:07:40  12/31/2021 15:08:38  193.154.174.158         1   \n",
       "3855  10/19/2021 22:23:07  10/19/2021 22:24:30  213.127.109.191         1   \n",
       "3859   10/6/2021 16:08:39   10/6/2021 16:10:42  213.127.113.113         1   \n",
       "3860  10/15/2021 18:30:04  10/15/2021 18:35:40  213.127.109.191         1   \n",
       "3861  11/19/2021 17:49:17  11/19/2021 17:51:04  213.127.109.191         1   \n",
       "\n",
       "      Coder                                                 ID   Mark_ID  \\\n",
       "0         6  UgyPHwv8G0cDE6-wEgl4AaABAg.8_0ZjJKSJty8_0kXGkAd2U       119   \n",
       "1         6  Ugx2WXq9UdV8mPPjejJ4AaABAg.8yHCKV0Boe58yYRxEQEF45       282   \n",
       "3         6  UgwUPFScjJ0MCeaP2F54AaABAg.8lvp3fc9Euf8lvvgsUgEgV       769   \n",
       "4         6  UgwWKCWtSJdFvjGHvTp4AaABAg.8kUC5dGrQ2H8kUDRihE2f3      1206   \n",
       "5         6                         Ugw2eTvkZLfH9MDVg1R4AaABAg      1214   \n",
       "...     ...                                                ...       ...   \n",
       "3854      6                         UgwiL6YZam5Xg4FWUHh4AaABAg   2002575   \n",
       "3855      6                         UgxGubygP72yCR0-la14AaABAg   3000508   \n",
       "3859      6        UghFY3QJ6nmT_ngCoAEC.7-H0Z7--wxd8goqpaPs-bl  20000102   \n",
       "3860      6                         UgyWabsmmnq3zam4DgZ4AaABAg  20000418   \n",
       "3861      6                         UgwPOHIDyICm10k0Mvx4AaABAg  20001003   \n",
       "\n",
       "      Genre  topiccode  Platform  ...  likeCount_video date_difference  \\\n",
       "0         0          0         1  ...              NaN             NaN   \n",
       "1         1          2         1  ...           3817.0           743.0   \n",
       "3         0          0         1  ...              NaN             NaN   \n",
       "4         0          0         1  ...              NaN             NaN   \n",
       "5         1          2         1  ...           9472.0           743.0   \n",
       "...     ...        ...       ...  ...              ...             ...   \n",
       "3854      0          3         1  ...            776.0          2574.0   \n",
       "3855      0          3         1  ...          12475.0          3803.0   \n",
       "3859      0          3         1  ...          12475.0          3803.0   \n",
       "3860      2          3         1  ...          31761.0          1531.0   \n",
       "3861      0          3         1  ...           5740.0          2276.0   \n",
       "\n",
       "      commentCount_video  replyCount_comment    topic  subscribers  \\\n",
       "0                    NaN                 NaN      NaN          NaN   \n",
       "1                 1748.0                 NaN  economy    3630000.0   \n",
       "3                    NaN                 NaN      NaN          NaN   \n",
       "4                    NaN                 NaN      NaN          NaN   \n",
       "5                 2912.0                 0.0  economy    3630000.0   \n",
       "...                  ...                 ...      ...          ...   \n",
       "3854              1004.0                 0.0     east     105000.0   \n",
       "3855              4785.0                 0.0     east    6740000.0   \n",
       "3859              4785.0                 NaN     east    6740000.0   \n",
       "3860              2206.0                 0.0     east    6800000.0   \n",
       "3861              2887.0                 1.0     east     549000.0   \n",
       "\n",
       "      HATELIST_FOCUSED_DUMMY  Time_comment_year  Time_video_year dataset_index  \n",
       "0                          0               2017           2017.0             0  \n",
       "1                          0               2019           2019.0             1  \n",
       "3                          0               2018           2018.0             3  \n",
       "4                          0               2018           2018.0             4  \n",
       "5                          1               2019           2018.0             5  \n",
       "...                      ...                ...              ...           ...  \n",
       "3854                       0               2019           2019.0          3854  \n",
       "3855                       0               2019           2010.0          3855  \n",
       "3859                       0               2018           2010.0          3859  \n",
       "3860                       0               2018           2015.0          3860  \n",
       "3861                       0               2018           2018.0          3861  \n",
       "\n",
       "[3132 rows x 80 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YT_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = YT_input.sort_values(by='parsed_datetime', ascending=True).reset_index(drop=False).iloc[:50]\n",
    "test['preceding_index'] = test.index.to_series().shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 490.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "\"Target comment\":<<If your criteria begins and ends with \"hot\".>>, index:1, preceding index:0, \"preceding comments\":\n",
      "<[{\"dataset_index\":331,\"commentText\":\"She looks like a pron star I don't \\u00c2\\u00a0but to me she has like a porn star vibe about her like she's someone you'll see on bang bus.\"}]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for group, df in tqdm.tqdm(test[11:13].groupby(GROUPER)):\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.loc[:, 'preceding_index'] = df.index.to_series().shift(1)\n",
    "    for index, row in df.iterrows():\n",
    "        if pd.notna(row['preceding_index']):\n",
    "            threadset = int(row['preceding_index'])\n",
    "            print(threadset)\n",
    "            preceding_comments = df.loc[:, ['dataset_index', 'commentText']].iloc[:index]\n",
    "            print(f'\"Target comment\":<<{row[\"commentText\"]}>>, index:{index}, preceding index:{threadset}, \"preceding comments\":\\n<{preceding_comments.to_json(orient=\"records\")}>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 154.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df:\n",
      "   dataset_index  \\\n",
      "0            331   \n",
      "1            330   \n",
      "\n",
      "                                                                                           commentText  \\\n",
      "0  She looks like a pron star I don't Â but to me she has like a porn star vibe about her like she'...   \n",
      "1                                                         If your criteria begins and ends with \"hot\".   \n",
      "\n",
      "   preceding_index  \\\n",
      "0              NaN   \n",
      "1              0.0   \n",
      "\n",
      "                                                          videoTitle  \\\n",
      "0  Real Time with Bill Maher: Haters Gonna Hate with S.E. Cupp (HBO)   \n",
      "1  Real Time with Bill Maher: Haters Gonna Hate with S.E. Cupp (HBO)   \n",
      "\n",
      "            parsed_datetime  \n",
      "0 2014-02-14 23:33:54+00:00  \n",
      "1 2014-02-15 03:22:49+00:00  \n",
      "preceding comment:She looks like a pron star I don't Â but to me she has like a porn star vibe about her like she's someone you'll see on bang bus.\n",
      "preceding df:\n",
      "Empty DataFrame\n",
      "Columns: [dataset_index, commentText, preceding_index, videoTitle, parsed_datetime]\n",
      "Index: []\n",
      "\"Target comment\":<<If your criteria begins and ends with \"hot\".>>, index:1, dataset_index:330 preceding index:0.0, \"preceding comments\":\n",
      "<[{\"dataset_index\":331,\"commentText\":\"She looks like a pron star I don't \\u00c2\\u00a0but to me she has like a porn star vibe about her like she's someone you'll see on bang bus.\"}]>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#get post simscore per thread:\n",
    "chunked_result: typing.List[pd.DataFrame] = []\n",
    "GROUPER='videoTitle'\n",
    "#sort data by Time_comment\n",
    "YT_input_sort = YT_input.sort_values(by='parsed_datetime', ascending=True).reset_index(drop=False)\n",
    "groupeddata = YT_input_sort[11:13].groupby(GROUPER)\n",
    "#groupeddata = dataset_claim_embeds.commentText[1:10].groupby(GROUPER)\n",
    "for group, df in tqdm.tqdm(groupeddata):\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.loc[:, 'preceding_index'] = df.index.to_series().shift(1)\n",
    "    print('df:')\n",
    "    print(df.loc[:,['dataset_index', 'commentText', 'preceding_index','videoTitle', 'parsed_datetime']])\n",
    "    for index, row in df.iterrows():\n",
    "        if pd.notna(row['preceding_index']):\n",
    "            threadset = int(row['preceding_index'])\n",
    "            print(\"preceding comment:\" + df.commentText[threadset])\n",
    "            print('preceding df:')\n",
    "            print(df.loc[:,['dataset_index', 'commentText', 'preceding_index','videoTitle', 'parsed_datetime']].iloc[:int(row['preceding_index'])])\n",
    "            print(f'\"Target comment\":<<{row[\"commentText\"]}>>, index:{index}, dataset_index:{row['dataset_index']} preceding index:{row['preceding_index']}, \"preceding comments\":\\n<{df.loc[:,['dataset_index', 'commentText']][:index].to_json(orient='records')}>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:04<00:00,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                             similariy\n",
      "0  [\\n    {\\n        \"most_similar_comment_index\": \"1\",\\n        \"similarity_score\": \"1\"\\n    }\\n]\\...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#get simscore for posts using Llama3.1:8b:\n",
    "\n",
    "chunked_result: typing.List[pd.DataFrame] = []\n",
    "GROUPER='videoTitle'\n",
    "#sort data by Time_comment\n",
    "YT_input_sort = YT_input.sort_values(by='parsed_datetime', ascending=True).reset_index(drop=False)\n",
    "groupeddata = YT_input_sort[10:13].groupby(GROUPER)\n",
    "for group, df in tqdm.tqdm(groupeddata):\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.loc[:, 'preceding_index'] = df.index.to_series().shift(1)\n",
    "    for index, row in df.iterrows():\n",
    "        if pd.notna(row['preceding_index']):\n",
    "            threadset = int(row['preceding_index'])\n",
    "            try: \n",
    "                chunked_result.append(pd.DataFrame(\n",
    "                    data=[[requests.post(\n",
    "                                'https://inf.cl.uni-trier.de/',\n",
    "                                json={\n",
    "                                    'model': MODELsmall,\n",
    "                                    'system': SYSTEM_post_simscore,\n",
    "                                    'prompt': f'\"Target comment\":<<{row[\"commentText\"]}>>, \"preceding comments\":\\n<{df.loc[:,['dataset_index', 'commentText']][:index].to_json(orient='records')}>',\n",
    "                                    'options': options_zero\n",
    "                                    }).json()['response']]],\n",
    "                    columns=['similariy']\n",
    "                ))\n",
    "                \n",
    "            except json.JSONDecodeError:\n",
    "                print(\"invalid json response, skipping to next batch\")\n",
    "\n",
    "similarity = pd.concat(chunked_result, ignore_index=True)\n",
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\n    {\\n        \"most_similar_comment_index\": \"1\",\\n        \"similarity_score\": \"1\"\\n    }\\n]\\nThe target comment and the preceding comment are identical, so I\\'ve assigned a similarity score of 10.'"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity['similariy'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1137 [00:19<1:28:45,  4.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 25 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 25 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/1137 [02:31<3:35:39, 11.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 30 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 30 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 33/1137 [03:30<55:51,  3.04s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 29 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 29 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 48/1137 [04:49<1:36:41,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 17 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 17 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 62/1137 [06:39<32:09,  1.80s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 32 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 32 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 6 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 78/1137 [09:15<1:15:29,  4.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 12 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 12 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 91/1137 [09:41<42:26,  2.43s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 5 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 129/1137 [11:58<36:22,  2.17s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 5 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 158/1137 [12:34<17:00,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 20 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 20 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 20 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 182/1137 [14:48<49:05,  3.08s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 5 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 191/1137 [16:27<1:18:09,  4.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 24 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 24 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 225/1137 [18:50<25:15,  1.66s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 24 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 24 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 261/1137 [19:53<23:13,  1.59s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 21 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 21 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 301/1137 [21:59<30:13,  2.17s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 24 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 24 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 319/1137 [23:04<37:33,  2.76s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 17 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 17 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 320/1137 [23:25<1:23:13,  6.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 334/1137 [25:19<49:06,  3.67s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 11 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 11 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 4 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 350/1137 [27:08<48:03,  3.66s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 31 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 31 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 351/1137 [27:40<1:53:12,  8.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 366/1137 [29:25<1:21:43,  6.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 19 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 19 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 400/1137 [31:32<27:54,  2.27s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 19 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 19 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 428/1137 [32:15<09:46,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 469/1137 [34:20<14:42,  1.32s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 5 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 481/1137 [35:57<59:17,  5.42s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 18 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 18 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 483/1137 [36:37<1:29:32,  8.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 509/1137 [38:56<40:10,  3.84s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 515/1137 [39:11<30:36,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 543/1137 [40:54<11:50,  1.20s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 24 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 24 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 578/1137 [42:10<17:14,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 8 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 586/1137 [43:43<58:26,  6.36s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 26 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 26 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 601/1137 [45:20<44:46,  5.01s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 9 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 621/1137 [47:06<20:04,  2.33s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 17 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 17 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 649/1137 [49:58<07:42,  1.06it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 8 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 657/1137 [50:23<17:14,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 684/1137 [52:07<12:43,  1.69s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 24 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 24 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 722/1137 [54:25<07:03,  1.02s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 20 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 20 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 745/1137 [55:24<16:02,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 14 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 14 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 4 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 753/1137 [57:17<45:12,  7.06s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON: Expecting ',' delimiter: line 5 column 2 (char 76)\n",
      "{'id': 'chatcmpl-AkE7IU0zKjsZvE3WsSvAQoYgLrIdM', 'choices': [{'finish_reason': 'stop', 'index': 0, 'message': {'content': '[\\n    {\\n        \"most_similar_comment_index\": 0,\\n    \"similarity_score\": 5\\n}', 'role': 'assistant', 'tool_calls': None, 'function_call': None}}], 'created': 1735580716, 'model': 'gpt-4o-2024-08-06', 'object': 'chat.completion', 'system_fingerprint': 'fp_4e924a4b48', 'usage': {'prompt_tokens': 366, 'completion_tokens': 24, 'total_tokens': 390, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'service_tier': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 759/1137 [57:47<39:45,  6.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 7 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 761/1137 [57:59<38:56,  6.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 5 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 770/1137 [58:19<18:19,  3.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 810/1137 [1:00:23<08:43,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 14 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 14 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 818/1137 [1:00:47<12:12,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 822/1137 [1:02:32<1:03:46, 12.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 26 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 26 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 837/1137 [1:03:23<12:52,  2.57s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 860/1137 [1:04:59<12:10,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 26 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 26 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 880/1137 [1:07:11<12:55,  3.02s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 29 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 29 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 904/1137 [1:08:54<11:13,  2.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 906/1137 [1:08:59<10:42,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 17 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 17 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 13 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 928/1137 [1:10:53<09:11,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 24 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 24 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 5 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 943/1137 [1:12:54<12:30,  3.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 21 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 21 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 968/1137 [1:14:30<07:26,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 5 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 971/1137 [1:14:52<12:18,  4.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 987/1137 [1:16:40<06:06,  2.44s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 26 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 26 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 1006/1137 [1:17:52<09:09,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 15 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 15 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 1008/1137 [1:18:08<11:31,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 1018/1137 [1:19:58<13:05,  6.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 7 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1047/1137 [1:22:04<01:18,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 15 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 15 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 1068/1137 [1:24:16<02:19,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 18 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 18 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 1092/1137 [1:25:21<01:06,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 12 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 12 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 1121/1137 [1:27:18<00:31,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 22 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 22 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1132/1137 [1:29:07<00:23,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 18 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 18 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1137/1137 [1:29:51<00:00,  4.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   post_index most_similar_post_index similarity_score\n",
      "0        3098                    2864                1\n",
      "1        3861                    3098                2\n",
      "2        2334                    3098                5\n",
      "3        1841                    3861                5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#get simscore for posts using GPT4o:\n",
    "\n",
    "chunked_result: typing.List[pd.DataFrame] = []\n",
    "GROUPER='videoTitle'\n",
    "#sort data by Time_comment\n",
    "YT_input_sort = YT_input.sort_values(by='parsed_datetime', ascending=True).reset_index(drop=False)\n",
    "groupeddata = YT_input_sort.groupby(GROUPER)\n",
    "for group, df in tqdm.tqdm(groupeddata):\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.loc[:, 'preceding_index'] = df.index.to_series().shift(1)\n",
    "    for index, row in df.iterrows():\n",
    "        if pd.notna(row['preceding_index']):\n",
    "            retry_count = 0\n",
    "            max_retries = 10\n",
    "    \n",
    "            while retry_count < max_retries:\n",
    "                try:  \n",
    "                    response = requests.post(\n",
    "                            url=api_endpoint,\n",
    "                            headers=headers,\n",
    "                            json={\n",
    "                                'model': MODELgpt4o,\n",
    "                                'messages': [\n",
    "                                    {\n",
    "                                        \"role\": \"system\",\n",
    "                                        \"content\": SYSTEM_post_simscore                        \n",
    "                                    },\n",
    "                                    {\n",
    "                                        \"role\": \"user\",\n",
    "                                        \"content\": f'\"Target comment\":<<{row[\"commentText\"]}>>, \"preceding comments\":\\n<{df.loc[:,['dataset_index', 'commentText']][:index].to_json(orient='records')}>'\n",
    "                                    \n",
    "                                    }\n",
    "                                ],\n",
    "                                'temperature': temperature_0,  \n",
    "                                'seed': SEED\n",
    "                            }\n",
    "                        )\n",
    "                    \n",
    "                    if response.status_code == 200:\n",
    "                        data_response = response.json()\n",
    "                        # Check if 'response' key exists in the JSON response\n",
    "                        if 'choices' in data_response:\n",
    "                            content = data_response[\"choices\"][0][\"message\"][\"content\"]\n",
    "                            # Remove code block markers if present\n",
    "                            content = re.sub(r'```json|```', '', content).strip()\n",
    "                            try:\n",
    "                                content = json.loads(content)   \n",
    "                                # Check if content_json is a list or a dictionary\n",
    "                                if isinstance(content, dict):\n",
    "                                    chunked_result.append({\n",
    "                                        \"post_index\": row['dataset_index'],\n",
    "                                        \"most_similar_post_index\": content.get('most_similar_comment_index', ''),\n",
    "                                        'similarity_score': content.get('similarity_score', '')  \n",
    "                                    })\n",
    "                                elif isinstance(content, list):\n",
    "                                    for item in content:\n",
    "                                        chunked_result.append({\n",
    "                                            \"post_index\": row['dataset_index'],\n",
    "                                            \"most_similar_post_index\": item.get('most_similar_comment_index', ''),\n",
    "                                            'similarity_score': item.get('similarity_score', '')  \n",
    "                                        })\n",
    "                                else:\n",
    "                                    print(f\"Unexpected content type: {type(content)}\")\n",
    "\n",
    "                            except json.JSONDecodeError as e:\n",
    "                                print(f\"Error decoding JSON: {e}\")\n",
    "                                print(data_response)\n",
    "                        else:\n",
    "                            print(f\"No 'choices' key in response or 'choices' is empty: {content}\")                        \n",
    "                        break  # Exit the retry loop on success  \n",
    "                    elif response.status_code == 429:\n",
    "                        retry_count += 1\n",
    "                        retry_after = response.headers.get(\"Retry-After\")\n",
    "                        error_message = response.json().get(\"error\", {}).get(\"message\", \"\")\n",
    "                        retry_after = 30  # Default to 30 seconds if not found\n",
    "                    \n",
    "                        # Extract retry time from the error message\n",
    "                        if \"Try again in\" in error_message:\n",
    "                            match = re.search(r\"Try again in (\\d+) second\", error_message)\n",
    "                            if match:\n",
    "                                try:\n",
    "                                    retry_after = int(match.group(1))\n",
    "                                except (IndexError, ValueError) as e:\n",
    "                                    print(f\"Rate limit exceeded. Error extracting retry time: {e}. Retrying in {retry_after} seconds.\")\n",
    "                                    pass\n",
    "                        elif \"Please retry after\" in error_message:\n",
    "                            match = re.search(r\"Please retry after (\\d+) second\", error_message)\n",
    "                            if match:\n",
    "                                try:\n",
    "                                    retry_after = int(match.group(1))\n",
    "                                except (IndexError, ValueError) as e:\n",
    "                                    print(f\"Rate limit exceeded. Error extracting retry time: {e}. Retrying in {retry_after} seconds.\")\n",
    "                                    pass\n",
    "                                \n",
    "                                \n",
    "                        else:\n",
    "                            retry_after = 30  # Default to 30 seconds if not found\n",
    "                            print(f\"Rate limit exceeded. Defaulting to retry in {retry_after} seconds.\")\n",
    "                                    \n",
    "                \n",
    "                        print(f\"Rate limit exceeded. Retrying in {retry_after} seconds: {response.json()}. Retry count = {retry_count}\") \n",
    "                        time.sleep(retry_after)\n",
    "                        \n",
    "                    #    print(f\"Rate limit exceeded. Retrying in {wait_time} seconds...\")\n",
    "                    #    print(response.text)\n",
    "                    #    time.sleep(wait_time)\n",
    "                    elif response.status_code == 500:\n",
    "                        retry_count += 1\n",
    "                        wait_time = 20\n",
    "                        print(f\"Failed to connect to API. Status code: {response.status_code}. Retrying in {wait_time} seconds...\")\n",
    "                        print(response.text)\n",
    "                        time.sleep(wait_time)\n",
    "                    else:\n",
    "                        print(f\"Failed to connect to API. Status code: {response.status_code}\")\n",
    "                        print(response.text)\n",
    "                        break\n",
    "                except requests.exceptions.RequestException as e:   \n",
    "                    print(f\"Failed to connect to API: {e}\")\n",
    "                    retry_count += 1\n",
    "                    wait_time = 60\n",
    "                    print(f\"Retrying in {wait_time} seconds...\")\n",
    "                    time.sleep(wait_time)   \n",
    "        \n",
    "                if retry_count >= max_retries:\n",
    "                    print(f\"Max retries reached for index {index}. Skipping to next item.\")\n",
    "                    break  # Exit the loop if max retries are reached              \n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "similarity = pd.DataFrame(chunked_result)\n",
    "\n",
    "# Display the DataFrame to verify the changes\n",
    "print(similarity.head(4))\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   post_index most_similar_post_index similarity_score\n",
      "0        3098                    2864                1\n",
      "1        3861                    3098                2\n",
      "2        2334                    3098                5\n",
      "3        1841                    3861                5\n"
     ]
    }
   ],
   "source": [
    "similarity = pd.DataFrame(chunked_result)\n",
    "\n",
    "# Display the DataFrame to verify the changes\n",
    "print(similarity.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add target comment and most similar comment to similarity:\n",
    "similarity.set_index(similarity['post_index'], inplace=True)\n",
    "similarity = similarity.join(YT_input_sort.set_index('dataset_index')['commentText'], rsuffix='_target')\n",
    "similarity.loc[:, 'most_similar_post_index'] = similarity.loc[:, 'most_similar_post_index'].astype(int)\n",
    "similarity = similarity.merge(YT_input_sort.loc[:, ['dataset_index', 'commentText']], left_on = 'most_similar_post_index', right_on = 'dataset_index' , suffixes=('', '_source'))\n",
    "similarity.drop(columns=['dataset_index'], inplace=True)\n",
    "similarity.rename(columns={'most_similar_post_index': 'most_similar_index_gpt4o', 'similarity_score': 'similarity_score_gpt4o', 'commentText_source':'commentText_most_sim_gpt4o' }, inplace=True)\n",
    "YT_claim_embeds = YT_claim_embeds.join(similarity.loc[:, ['most_similar_index_gpt4o', 'similarity_score_gpt4o', 'commentText_most_sim_gpt4o']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data:\n",
    "YT_claim_embeds.to_parquet(f'{CFG.report_dir}/pubsphere_YT_posts.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_claim_embeds = dataset_claim_embeds.join(similarity.loc[:, ['most_similar_index_gpt4o', 'similarity_score_gpt4o', 'commentText_most_sim_gpt4o']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_claim_embeds.loc[:, ['commentText', 'videoTitle','most_similar_index_gpt4o', 'similarity_score_gpt4o', 'commentText_most_sim_gpt4o']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data:\n",
    "dataset_claim_embeds.to_parquet(f'{CFG.report_dir}/pubsphere.claim_embed.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1137 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1137 [00:17<1:16:56,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 37 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 37 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/1137 [01:09<1:52:49,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/1137 [02:26<4:05:34, 13.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 40 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 42/1137 [03:41<37:00,  2.03s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 40 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 48/1137 [04:36<1:29:15,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 38 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 38 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 68/1137 [07:01<43:00,  2.41s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 27 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 27 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 91/1137 [08:54<29:35,  1.70s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 39 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 39 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 129/1137 [11:04<20:30,  1.22s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 41 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 41 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 165/1137 [13:17<10:55,  1.48it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 33 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 33 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 173/1137 [13:57<39:14,  2.44s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 184/1137 [15:22<1:04:22,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 38 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 38 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 192/1137 [16:20<1:19:43,  5.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 225/1137 [17:47<13:44,  1.11it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 37 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 37 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 261/1137 [20:04<29:02,  1.99s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 25 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 25 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 278/1137 [20:36<18:53,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 310/1137 [22:11<20:09,  1.46s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 32 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 32 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 312/1137 [22:48<1:37:15,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 326/1137 [24:16<36:51,  2.73s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 33 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 33 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 328/1137 [24:56<1:59:42,  8.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 347/1137 [26:28<29:33,  2.24s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 37 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 37 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 365/1137 [27:31<14:11,  1.10s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 32 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 32 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 366/1137 [28:19<2:02:05,  9.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 400/1137 [29:46<17:09,  1.40s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 40 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 437/1137 [30:51<11:17,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 36 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 36 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 480/1137 [31:49<04:39,  2.35it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 35 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 35 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 485/1137 [33:56<1:19:18,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 36 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 36 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 509/1137 [34:57<15:47,  1.51s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 36 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 36 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 533/1137 [37:07<23:40,  2.35s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 38 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 38 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 575/1137 [38:09<07:28,  1.25it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 38 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 38 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 586/1137 [39:06<27:24,  2.98s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 34 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 34 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 599/1137 [41:15<36:32,  4.08s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 35 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 35 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 617/1137 [42:12<08:33,  1.01it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 625/1137 [43:44<44:53,  5.26s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 36 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 36 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 631/1137 [44:23<45:10,  5.36s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 657/1137 [45:58<06:33,  1.22it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 33 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 33 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 664/1137 [46:40<28:48,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 684/1137 [48:04<23:10,  3.07s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 36 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 36 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 700/1137 [49:01<12:53,  1.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 730/1137 [49:15<03:15,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 32 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 32 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 740/1137 [49:55<12:36,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 755/1137 [51:27<15:40,  2.46s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 41 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 41 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 770/1137 [52:32<12:11,  1.99s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 36 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 36 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 806/1137 [54:38<03:51,  1.43it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 40 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 818/1137 [55:28<11:04,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 38 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 38 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 821/1137 [56:22<39:01,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 854/1137 [57:49<02:54,  1.62it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 36 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 36 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 864/1137 [1:00:08<23:45,  5.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 33 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 33 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 866/1137 [1:00:43<43:51,  9.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 898/1137 [1:02:14<04:14,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 34 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 34 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████▏ | 924/1137 [1:04:27<05:58,  1.68s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 34 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 34 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 934/1137 [1:05:21<10:21,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 949/1137 [1:06:50<08:08,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 36 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 36 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 959/1137 [1:07:39<07:24,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 976/1137 [1:09:06<04:39,  1.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 38 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 38 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 998/1137 [1:10:10<02:18,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 37 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 37 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 1003/1137 [1:10:49<08:31,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 1013/1137 [1:12:16<08:21,  4.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 40 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 40 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 1020/1137 [1:13:12<10:50,  5.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 39 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 39 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1050/1137 [1:14:19<01:41,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 32 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 32 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 1052/1137 [1:14:59<08:16,  5.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 1070/1137 [1:16:21<01:33,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 38 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 38 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1107/1137 [1:17:27<00:14,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 37 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 37 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 1121/1137 [1:18:23<00:34,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 34 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 34 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1137/1137 [1:20:30<00:00,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   post_index most_similar_post_index similarity_score\n",
      "0     2001794                 2001557                1\n",
      "1    20001003                 2001794                2\n",
      "2     2001015                20001003                7\n",
      "3     2000505                20001003                6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#get simscore for post EXPANSION using GPT4o:\n",
    "\n",
    "chunked_result: typing.List[pd.DataFrame] = []\n",
    "GROUPER='videoTitle'\n",
    "#sort data by Time_comment\n",
    "YT_claim_embeds_sort = YT_claim_embeds.sort_values(by='Time_comment_dt', ascending=True).reset_index(drop=False)\n",
    "groupeddata = YT_claim_embeds_sort.groupby(GROUPER)\n",
    "for group, df in tqdm.tqdm(groupeddata):\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.loc[:, 'preceding_index'] = df.index.to_series().shift(1)\n",
    "    for index, row in df.iterrows():\n",
    "        if pd.notna(row['preceding_index']):\n",
    "            retry_count = 0\n",
    "            max_retries = 10\n",
    "    \n",
    "            while retry_count < max_retries:\n",
    "                try:  \n",
    "                    response = requests.post(\n",
    "                            url=api_endpoint,\n",
    "                            headers=headers,\n",
    "                            json={\n",
    "                                'model': MODELgpt4o,\n",
    "                                'messages': [\n",
    "                                    {\n",
    "                                        \"role\": \"system\",\n",
    "                                        \"content\": SYSTEM_post_simscore                        \n",
    "                                    },\n",
    "                                    {\n",
    "                                        \"role\": \"user\",\n",
    "                                        \"content\": f'\"Target comment\":<<{row[\"post_expansion_gpt4o\"]}>>, \"preceding comments\":\\n<{df.loc[:,['Mark_ID', 'post_expansion_gpt4o']][:index].to_json(orient='records')}>'\n",
    "                                    \n",
    "                                    }\n",
    "                                ],\n",
    "                                'temperature': temperature_0,  \n",
    "                                'seed': SEED\n",
    "                            }\n",
    "                        )\n",
    "                    \n",
    "                    if response.status_code == 200:\n",
    "                        data_response = response.json()\n",
    "                        # Check if 'response' key exists in the JSON response\n",
    "                        if 'choices' in data_response:\n",
    "                            content = data_response[\"choices\"][0][\"message\"][\"content\"]\n",
    "                            # Remove code block markers if present\n",
    "                            content = re.sub(r'```json|```', '', content).strip()\n",
    "                            try:\n",
    "                                content = json.loads(content)   \n",
    "                                # Check if content_json is a list or a dictionary\n",
    "                                if isinstance(content, dict):\n",
    "                                    chunked_result.append({\n",
    "                                        \"post_index\": row['Mark_ID'],\n",
    "                                        \"most_similar_post_index\": content.get('most_similar_comment_index', ''),\n",
    "                                        'similarity_score': content.get('similarity_score', '')  \n",
    "                                    })\n",
    "                                elif isinstance(content, list):\n",
    "                                    for item in content:\n",
    "                                        chunked_result.append({\n",
    "                                            \"post_index\": row['Mark_ID'],\n",
    "                                            \"most_similar_post_index\": item.get('most_similar_comment_index', ''),\n",
    "                                            'similarity_score': item.get('similarity_score', '')  \n",
    "                                        })\n",
    "                                else:\n",
    "                                    print(f\"Unexpected content type: {type(content)}\")\n",
    "\n",
    "                            except json.JSONDecodeError as e:\n",
    "                                print(f\"Error decoding JSON: {e}\")\n",
    "                                print(data_response)\n",
    "                        else:\n",
    "                            print(f\"No 'choices' key in response or 'choices' is empty: {content}\")                        \n",
    "                        break  # Exit the retry loop on success  \n",
    "                    elif response.status_code == 429:\n",
    "                        retry_count += 1\n",
    "                        retry_after = response.headers.get(\"Retry-After\")\n",
    "                        error_message = response.json().get(\"error\", {}).get(\"message\", \"\")\n",
    "                        retry_after = 30  # Default to 30 seconds if not found\n",
    "                    \n",
    "                        # Extract retry time from the error message\n",
    "                        if \"Try again in\" in error_message:\n",
    "                            match = re.search(r\"Try again in (\\d+) second\", error_message)\n",
    "                            if match:\n",
    "                                try:\n",
    "                                    retry_after = int(match.group(1))\n",
    "                                except (IndexError, ValueError) as e:\n",
    "                                    print(f\"Rate limit exceeded. Error extracting retry time: {e}. Retrying in {retry_after} seconds.\")\n",
    "                                    pass\n",
    "                        elif \"Please retry after\" in error_message:\n",
    "                            match = re.search(r\"Please retry after (\\d+) second\", error_message)\n",
    "                            if match:\n",
    "                                try:\n",
    "                                    retry_after = int(match.group(1))\n",
    "                                except (IndexError, ValueError) as e:\n",
    "                                    print(f\"Rate limit exceeded. Error extracting retry time: {e}. Retrying in {retry_after} seconds.\")\n",
    "                                    pass\n",
    "                                \n",
    "                                \n",
    "                        else:\n",
    "                            retry_after = 30  # Default to 30 seconds if not found\n",
    "                            print(f\"Rate limit exceeded. Defaulting to retry in {retry_after} seconds.\")\n",
    "                                    \n",
    "                \n",
    "                        print(f\"Rate limit exceeded. Retrying in {retry_after} seconds: {response.json()}. Retry count = {retry_count}\") \n",
    "                        time.sleep(retry_after)\n",
    "                        \n",
    "                    #    print(f\"Rate limit exceeded. Retrying in {wait_time} seconds...\")\n",
    "                    #    print(response.text)\n",
    "                    #    time.sleep(wait_time)\n",
    "                    elif response.status_code == 500:\n",
    "                        retry_count += 1\n",
    "                        wait_time = 20\n",
    "                        print(f\"Failed to connect to API. Status code: {response.status_code}. Retrying in {wait_time} seconds...\")\n",
    "                        print(response.text)\n",
    "                        time.sleep(wait_time)\n",
    "                    else:\n",
    "                        print(f\"Failed to connect to API. Status code: {response.status_code}\")\n",
    "                        print(response.text)\n",
    "                        break\n",
    "                except requests.exceptions.RequestException as e:   \n",
    "                    print(f\"Failed to connect to API: {e}\")\n",
    "                    retry_count += 1\n",
    "                    wait_time = 60\n",
    "                    print(f\"Retrying in {wait_time} seconds...\")\n",
    "                    time.sleep(wait_time)   \n",
    "        \n",
    "                if retry_count >= max_retries:\n",
    "                    print(f\"Max retries reached for index {index}. Skipping to next item.\")\n",
    "                    break  # Exit the loop if max retries are reached              \n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "similarity_ext = pd.DataFrame(chunked_result)\n",
    "\n",
    "# Display the DataFrame to verify the changes\n",
    "print(similarity_ext.head(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_ext.set_index(similarity_ext['post_index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_ext.join(YT_claim_embeds_sort.set_index('Mark_ID')['post_expansion_gpt4o'], rsuffix='_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_ext = similarity_ext.join(YT_claim_embeds_sort.set_index('Mark_ID')['post_expansion_gpt4o'], rsuffix='_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_int(value):\n",
    "    if isinstance(value, list):\n",
    "        return np.nan\n",
    "    try:\n",
    "        return int(value)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "similarity_ext['most_similar_post_index'].apply(convert_to_int).isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apparently there were some lists in the most_similar_post_index column, which need to be converted to NaNs\n",
    "similarity_ext.loc[:, 'most_similar_post_index_int'] = similarity_ext['most_similar_post_index'].apply(convert_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_index</th>\n",
       "      <th>most_similar_post_index</th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>post_expansion_gpt4o</th>\n",
       "      <th>most_similar_post_index_int</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>post_index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001038</th>\n",
       "      <td>2001038</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000066</th>\n",
       "      <td>2000066</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001530</th>\n",
       "      <td>2001530</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            post_index most_similar_post_index similarity_score  \\\n",
       "post_index                                                        \n",
       "2001038        2001038                      []               []   \n",
       "2000066        2000066                      []               []   \n",
       "2001530        2001530                      []               []   \n",
       "\n",
       "           post_expansion_gpt4o  most_similar_post_index_int  \n",
       "post_index                                                    \n",
       "2001038                      []                          NaN  \n",
       "2000066                      []                          NaN  \n",
       "2001530                      []                          NaN  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_ext.loc[similarity_ext['most_similar_post_index_int'].isna(), :] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apparently these lists are empty lists, which can be converted to NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_ext.join(YT_claim_embeds_sort.set_index('Mark_ID')['commentText'], rsuffix='_target').merge(YT_claim_embeds_sort.loc[:, ['Mark_ID', 'post_expansion_gpt4o']], left_on = 'most_similar_post_index_int', right_on = 'Mark_ID' , suffixes=('', '_source'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_ext.merge(YT_claim_embeds_sort.loc[:, ['Mark_ID', 'post_expansion_gpt4o']], left_on = 'most_similar_post_index_int', right_on = 'Mark_ID' , suffixes=('', '_source'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_ext = similarity_ext.merge(YT_claim_embeds_sort.loc[:, ['Mark_ID', 'post_expansion_gpt4o']], left_on = 'most_similar_post_index_int', right_on = 'Mark_ID' , suffixes=('', '_source'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_ext.drop(columns=['Mark_ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_ext.rename(columns={'most_similar_post_index_int': 'most_similar_ext_ID_gpt4o', 'similarity_score': 'similarity_score_ext_gpt4o', 'post_expansion_gpt4o_source':'post_expenasion_most_sim_gpt4o' }, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_index</th>\n",
       "      <th>most_similar_ext_ID_gpt4o</th>\n",
       "      <th>similarity_score_ext_gpt4o</th>\n",
       "      <th>post_expenasion_most_sim_gpt4o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [post_index, most_similar_ext_ID_gpt4o, similarity_score_ext_gpt4o, post_expenasion_most_sim_gpt4o]\n",
       "Index: []"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_ext.loc[similarity_ext.post_index == 119, ['post_index', 'most_similar_ext_ID_gpt4o', 'similarity_score_ext_gpt4o', 'post_expenasion_most_sim_gpt4o']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_index</th>\n",
       "      <th>most_similar_post_index</th>\n",
       "      <th>similarity_score_ext_gpt4o</th>\n",
       "      <th>post_expansion_gpt4o</th>\n",
       "      <th>most_similar_ext_ID_gpt4o</th>\n",
       "      <th>post_expenasion_most_sim_gpt4o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001794</td>\n",
       "      <td>2001557</td>\n",
       "      <td>1</td>\n",
       "      <td>Stop killing inocent people!</td>\n",
       "      <td>2001557.0</td>\n",
       "      <td>Lux you’re welcome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001003</td>\n",
       "      <td>2001794</td>\n",
       "      <td>2</td>\n",
       "      <td>The Syrian crisis is a horrible thing, but has anyone noticed the situation’s strange components...</td>\n",
       "      <td>2001794.0</td>\n",
       "      <td>Stop killing inocent people!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2001015</td>\n",
       "      <td>20001003</td>\n",
       "      <td>7</td>\n",
       "      <td>But the environment and everything that humans are doing, like the conflicts in Syria and the in...</td>\n",
       "      <td>20001003.0</td>\n",
       "      <td>The Syrian crisis is a horrible thing, but has anyone noticed the situation’s strange components...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000505</td>\n",
       "      <td>20001003</td>\n",
       "      <td>6</td>\n",
       "      <td>1. Why is the rest of the world praising the US? Why is the rest of the world (Britain and Franc...</td>\n",
       "      <td>20001003.0</td>\n",
       "      <td>The Syrian crisis is a horrible thing, but has anyone noticed the situation’s strange components...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001417</td>\n",
       "      <td>20001003</td>\n",
       "      <td>5</td>\n",
       "      <td>It would have cost less to just fly a B-52 over the targets and carpet bomb the living daylights...</td>\n",
       "      <td>20001003.0</td>\n",
       "      <td>The Syrian crisis is a horrible thing, but has anyone noticed the situation’s strange components...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_index most_similar_post_index similarity_score_ext_gpt4o  \\\n",
       "0     2001794                 2001557                          1   \n",
       "1    20001003                 2001794                          2   \n",
       "2     2001015                20001003                          7   \n",
       "3     2000505                20001003                          6   \n",
       "4     2001417                20001003                          5   \n",
       "\n",
       "                                                                                  post_expansion_gpt4o  \\\n",
       "0                                                                         Stop killing inocent people!   \n",
       "1  The Syrian crisis is a horrible thing, but has anyone noticed the situation’s strange components...   \n",
       "2  But the environment and everything that humans are doing, like the conflicts in Syria and the in...   \n",
       "3  1. Why is the rest of the world praising the US? Why is the rest of the world (Britain and Franc...   \n",
       "4  It would have cost less to just fly a B-52 over the targets and carpet bomb the living daylights...   \n",
       "\n",
       "   most_similar_ext_ID_gpt4o  \\\n",
       "0                  2001557.0   \n",
       "1                  2001794.0   \n",
       "2                 20001003.0   \n",
       "3                 20001003.0   \n",
       "4                 20001003.0   \n",
       "\n",
       "                                                                        post_expenasion_most_sim_gpt4o  \n",
       "0                                                                                   Lux you’re welcome  \n",
       "1                                                                         Stop killing inocent people!  \n",
       "2  The Syrian crisis is a horrible thing, but has anyone noticed the situation’s strange components...  \n",
       "3  The Syrian crisis is a horrible thing, but has anyone noticed the situation’s strange components...  \n",
       "4  The Syrian crisis is a horrible thing, but has anyone noticed the situation’s strange components...  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_ext.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "YT_claim_embeds = YT_claim_embeds.merge(similarity_ext.loc[:, ['post_index', 'most_similar_ext_ID_gpt4o', 'similarity_score_ext_gpt4o', 'post_expenasion_most_sim_gpt4o']], how='left', left_on='Mark_ID', right_on='post_index', suffixes=('', '_ext_gpt4o'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YT_claim_embeds.loc[:, ['Mark_ID', 'commentText', 'post_expansion_gpt4o', 'most_similar_ext_ID_gpt4o', 'similarity_score_ext_gpt4o', 'post_expenasion_most_sim_gpt4o']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YT_claim_embeds.loc[:, ['commentText', 'post_expansion_gpt4o']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data:\n",
    "YT_claim_embeds.to_parquet(f'{CFG.report_dir}/pubsphere_YT_posts.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_claim_embeds = dataset_claim_embeds.merge(YT_claim_embeds.loc[:, ['Mark_ID', 'most_similar_ext_ID_gpt4o', 'similarity_score_ext_gpt4o', 'post_expenasion_most_sim_gpt4o']], how='left', left_on='Mark_ID', right_on='Mark_ID', suffixes=('', '_ext_gpt4o'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data:\n",
    "dataset_claim_embeds.to_parquet(f'{CFG.report_dir}/pubsphere.claim_embed.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data:\n",
    "YT_claim_embeds = pd.read_parquet(f'{CFG.report_dir}/pubsphere_YT_posts.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                           []\n",
       "1                                                 [\"Minerals have rights too\"]\n",
       "2       [\"The death of free and civil dialogue has been effectively depicted\"]\n",
       "3                                                 [\"No-one else will hug him\"]\n",
       "4                                                                           []\n",
       "                                         ...                                  \n",
       "3131                           \"Putin is aligned with al Assad to combat Daesh\n",
       "3131                                             \"The U.S. is against al Assad\n",
       "3131                                \"Russia and the U.S. are both against ISIS\n",
       "3131                             \"Russia is aligned with the Syrian government\n",
       "3131      \"The U.S. is against the Syrian government for attacking civilians\"]\n",
       "Name: claims_gpt4o, Length: 6211, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YT_claim_embeds['claims_gpt4o'].str.split('\",').explode()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a expanded dataset of claims along with Mark_IDs and videoTitles:\n",
    "YT_claim_embeds['claims_split'] = YT_claim_embeds['claims_gpt4o'].str.split('\",')\n",
    "YT_claim_embeds_explode = YT_claim_embeds.explode('claims_split')\n",
    "YT_claim_embeds_explode = YT_claim_embeds_explode.reset_index(drop=True)\n",
    "YT_claim_embeds_explode['claims_split'] = YT_claim_embeds_explode['claims_split'].str.replace('\"', '').str.replace('[', '').str.replace(']', '').str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YT_claim_embeds_explode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YT_claim_embeds_explode.sort_values(by='Time_comment_dt', ascending=True).reset_index(drop=False).head().loc[:, ['Mark_ID', 'videoTitle', 'claims_split', 'Time_comment_dt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "YT_claim_embeds_explode.loc[:, \"explode_index\"] = YT_claim_embeds_explode.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/1137 [00:25<2:42:23,  8.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 32 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 32 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 10/1137 [01:14<1:33:14,  4.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 10 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 13/1137 [03:28<6:47:13, 21.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 17 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 17 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/1137 [04:46<10:41:26, 34.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 15/1137 [06:34<16:15:40, 52.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 28 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 28 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 20/1137 [07:05<6:27:55, 20.84s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 36/1137 [08:37<1:35:55,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 18 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 18 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 43/1137 [10:52<2:35:08,  8.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 25 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 25 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 48/1137 [12:50<4:45:44, 15.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 27 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 27 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 21 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 21 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 6 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 63/1137 [16:19<1:07:42,  3.78s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 17 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 17 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 68/1137 [18:31<4:44:48, 15.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 21 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 21 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 4 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 78/1137 [19:30<1:47:58,  6.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 93/1137 [21:00<55:02,  3.16s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 16 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 16 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 115/1137 [23:13<27:09,  1.59s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 14 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 14 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 132/1137 [25:14<1:02:36,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 32 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 32 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 144/1137 [26:32<1:01:34,  3.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 20 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 20 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 154/1137 [27:12<27:19,  1.67s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 161/1137 [28:58<2:13:15,  8.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 17 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 17 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 4 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 172/1137 [30:59<1:50:41,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 19 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 19 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 176/1137 [31:49<2:30:18,  9.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 6 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 185/1137 [33:44<2:18:12,  8.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 15 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 15 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 4 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 191/1137 [35:54<2:40:40, 10.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 11 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 11 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 194/1137 [37:56<5:51:22, 22.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 31 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 31 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 209/1137 [40:13<1:06:50,  4.32s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 12 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 12 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 218/1137 [40:45<35:55,  2.35s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 221/1137 [41:57<2:15:33,  8.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 25 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 25 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 229/1137 [44:32<3:02:03, 12.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 10 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 230/1137 [44:57<3:38:03, 14.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 245/1137 [46:38<44:49,  3.02s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 23 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 23 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 248/1137 [47:06<1:16:19,  5.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 260/1137 [48:41<56:49,  3.89s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 13 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 13 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 278/1137 [50:56<22:51,  1.60s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 23 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 23 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 297/1137 [53:04<34:50,  2.49s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 18 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 18 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 303/1137 [55:36<2:50:54, 12.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 7 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 308/1137 [55:54<1:06:32,  4.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 313/1137 [57:40<2:20:52, 10.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 15 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 15 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 7 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 319/1137 [59:51<2:55:35, 12.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 25 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 25 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 327/1137 [1:01:55<1:31:52,  6.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 21 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 21 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 328/1137 [1:03:50<7:45:33, 34.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 14 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 14 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 342/1137 [1:06:13<1:42:42,  7.75s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 27 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 27 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 347/1137 [1:07:19<2:28:08, 11.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 22 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 22 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 351/1137 [1:08:25<2:34:06, 11.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 16 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 16 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 354/1137 [1:08:46<2:02:22,  9.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 365/1137 [1:10:40<57:24,  4.46s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 10 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n",
      "Rate limit exceeded. Retrying in 32 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 32 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 4 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 369/1137 [1:13:38<4:13:02, 19.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 17 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 17 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 371/1137 [1:14:02<3:35:40, 16.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 6 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 387/1137 [1:14:22<34:42,  2.78s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 7 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 396/1137 [1:15:37<1:04:46,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 23 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 23 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 414/1137 [1:18:23<40:52,  3.39s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 22 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 22 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 415/1137 [1:18:50<1:50:06,  9.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 425/1137 [1:20:30<1:17:00,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 26 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 26 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▊      | 439/1137 [1:22:36<52:28,  4.51s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 21 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 21 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 441/1137 [1:23:07<1:35:39,  8.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 451/1137 [1:24:52<1:13:05,  6.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 23 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 23 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 454/1137 [1:25:18<1:21:09,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 480/1137 [1:26:52<17:43,  1.62s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 12 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 12 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 482/1137 [1:28:38<3:00:14, 16.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 32 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 32 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 485/1137 [1:31:15<5:06:57, 28.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 25 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 25 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 499/1137 [1:32:19<52:22,  4.93s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 21 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 21 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 506/1137 [1:34:19<1:26:02,  8.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 25 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 25 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 517/1137 [1:35:16<44:46,  4.33s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 530/1137 [1:37:06<28:49,  2.85s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 13 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 13 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 548/1137 [1:38:58<18:51,  1.92s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 30 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 30 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 551/1137 [1:39:52<1:17:13,  7.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON: Invalid control character at: line 3 column 38 (char 45)\n",
      "{'id': 'chatcmpl-AlJeFMqq1h5y7yPU4ejnydjdZLmMp', 'choices': [{'finish_reason': 'stop', 'index': 0, 'message': {'content': '[\\n    {\\n        \"most_similar_claim_index = 0\\n        similarity_score = 1\\n    elif target_claim == \"<<The sky is blue.>>\":\\n        most_similar_claim_index = 1\\n        similarity_score = 10\\n    elif target_claim == \"<<The sky is blue.>>\":\\n        most_similar_claim_index = 2\\n        similarity_score = 10\\n    elif target_claim == \"<<The sky is blue.>>\":\\n        most_similar_claim_index = 3\\n        similarity_score = 10\\n    elif target_claim == \"<<The sky is blue.>>\":\\n        most_similar_claim_index = 4\\n        similarity_score = 0; i < 10; i++) {\\n    if (i < 5) {\\n        console.log(\"The number is less than 5\");\\n    } else {\\n        console.log(\"The number is 5 or greater\");\\n    }\\n}\\'\\'\\'\\n\\n# Define the preceding claims\\npreceding_claims = [\\n    {\"claim_index\": 1, \"claim\": \"The code is a loop that iterates 10 times.\"},\\n    {\"claim_index\": 2, \"claim\": \"The code checks if the number is less than 5.\"},\\n    {\"claim_index\": 3, \"claim\": \"The code, and the `similarity_score` is 5, indicating that the claims share context or topic, but otherwise present different information.', 'role': 'assistant', 'tool_calls': None, 'function_call': None}}], 'created': 1735840307, 'model': 'gpt-4o-2024-08-06', 'object': 'chat.completion', 'system_fingerprint': 'fp_4e924a4b48', 'usage': {'prompt_tokens': 363, 'completion_tokens': 293, 'total_tokens': 656, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'service_tier': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 566/1137 [1:40:23<16:59,  1.78s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 10 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 569/1137 [1:42:15<2:46:46, 17.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 20 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 20 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 583/1137 [1:43:33<46:36,  5.05s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 9 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 586/1137 [1:45:09<2:20:38, 15.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 30 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 30 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 594/1137 [1:47:29<1:59:16, 13.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 28 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 28 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 595/1137 [1:48:07<2:34:33, 17.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 601/1137 [1:49:46<1:51:11, 12.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 16 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 16 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▎    | 609/1137 [1:51:57<1:08:46,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 18 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 18 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 617/1137 [1:52:44<34:27,  3.98s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 621/1137 [1:54:05<1:43:27, 12.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 24 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 24 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 622/1137 [1:56:21<5:19:36, 37.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 31 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 31 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 633/1137 [1:57:49<53:19,  6.35s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 15 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 15 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 651/1137 [2:00:05<25:40,  3.17s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 7 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 662/1137 [2:02:00<33:36,  4.24s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 13 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 13 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 668/1137 [2:04:04<1:31:51, 11.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 28 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 28 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 684/1137 [2:06:07<40:53,  5.42s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 10 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 694/1137 [2:08:18<37:13,  5.04s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 20 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 20 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 698/1137 [2:09:03<1:01:06,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 712/1137 [2:09:46<11:43,  1.65s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 718/1137 [2:09:51<08:25,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 732/1137 [2:11:51<18:41,  2.77s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 7 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 740/1137 [2:12:17<21:22,  3.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 11 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 11 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 11 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 745/1137 [2:14:23<1:28:50, 13.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 10 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 4 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 746/1137 [2:16:18<3:19:57, 30.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 24 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 24 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 757/1137 [2:17:37<1:09:56, 11.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 16 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 16 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 758/1137 [2:17:58<1:26:50, 13.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 763/1137 [2:19:46<1:30:11, 14.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 27 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 27 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 766/1137 [2:20:53<1:57:35, 19.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 767/1137 [2:21:15<2:00:52, 19.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 5 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 770/1137 [2:22:34<2:12:55, 21.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 29 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 29 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 780/1137 [2:25:15<47:54,  8.05s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 24 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 24 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 800/1137 [2:26:22<28:46,  5.12s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 14 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 14 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 806/1137 [2:26:57<27:33,  5.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 812/1137 [2:27:25<23:13,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 10 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 818/1137 [2:29:13<58:08, 10.94s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 21 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 21 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 822/1137 [2:31:29<1:43:23, 19.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 34 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 34 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 23 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 23 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 855/1137 [2:34:50<06:07,  1.30s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 21 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 21 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 860/1137 [2:36:59<57:48, 12.52s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 8 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 6 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 863/1137 [2:39:09<1:48:00, 23.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 37 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 37 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 879/1137 [2:40:23<13:30,  3.14s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 25 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 25 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 885/1137 [2:42:25<41:03,  9.77s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 30 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 30 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 894/1137 [2:43:32<26:11,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 26 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 26 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 898/1137 [2:44:10<32:59,  8.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 903/1137 [2:45:50<47:58, 12.30s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 30 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 30 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 917/1137 [2:48:06<22:01,  6.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 25 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 25 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 931/1137 [2:49:01<08:02,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 13 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 13 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 936/1137 [2:51:16<34:59, 10.44s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 23 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 23 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 946/1137 [2:53:28<16:25,  5.16s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 14 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 14 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 949/1137 [2:55:18<53:23, 17.04s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 14 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 14 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 952/1137 [2:56:20<55:29, 18.00s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 7 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 962/1137 [2:57:58<26:10,  8.97s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 30 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 30 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 966/1137 [2:58:49<24:56,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 971/1137 [3:00:31<31:42, 11.46s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 27 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 27 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 980/1137 [3:02:55<18:26,  7.05s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 16 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 16 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 982/1137 [3:03:14<19:11,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 995/1137 [3:05:15<07:26,  3.14s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 18 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 18 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 1003/1137 [3:07:04<09:07,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 28 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 28 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▊ | 1009/1137 [3:09:27<27:54, 13.08s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 24 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 24 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 1013/1137 [3:10:19<20:33,  9.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 1020/1137 [3:12:04<19:49, 10.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 30 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 30 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 1034/1137 [3:14:23<05:39,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 12 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 12 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 5 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1047/1137 [3:16:23<05:29,  3.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 34 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 34 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1051/1137 [3:17:36<14:38, 10.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 24 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 24 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 5 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 1061/1137 [3:19:51<06:58,  5.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 8 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 6 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 1067/1137 [3:22:02<12:38, 10.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 30 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 30 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 1068/1137 [3:22:33<19:35, 17.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 1079/1137 [3:24:17<04:36,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 26 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 26 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 1081/1137 [3:24:48<07:01,  7.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 1089/1137 [3:26:33<04:29,  5.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 22 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 22 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 1093/1137 [3:27:01<03:55,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1106/1137 [3:28:53<01:54,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 10 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 1107/1137 [3:29:07<02:44,  5.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 1118/1137 [3:30:44<01:40,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 15 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 15 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 1121/1137 [3:32:57<04:28, 16.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 19 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 19 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 6 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1135/1137 [3:35:07<00:05,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 27 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 27 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 28 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 28 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1137/1137 [3:37:55<00:00, 11.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   post_index most_similar_claim_index similarity_score\n",
      "0     2001794                  2001557                1\n",
      "1    20001003                  2001794                5\n",
      "2    20001003                        3                5\n",
      "3    20001003                 20001003                7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "###############################\n",
    "#DO NO REUSE THIS CELL, IT MISSES A GOOD claim_split-level identifier and needs to be updated in line with the simscore annotation for expanded claims as described below\n",
    "###############################\n",
    "\n",
    "#get similarity scores for claims using GPT4o:\n",
    "#get simscore for posts using GPT4o:\n",
    "\n",
    "chunked_result: typing.List[pd.DataFrame] = []\n",
    "GROUPER='videoTitle'\n",
    "#sort data by Time_comment\n",
    "YT_input_sort = YT_claim_embeds_explode.sort_values(by='Time_comment_dt', ascending=True).reset_index(drop=False)\n",
    "groupeddata = YT_input_sort.groupby(GROUPER)\n",
    "for group, df in tqdm.tqdm(groupeddata):\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.loc[:, 'preceding_index'] = df.index.to_series().shift(1)\n",
    "    for index, row in df.iterrows():\n",
    "        if pd.notna(row['preceding_index']):\n",
    "            retry_count = 0\n",
    "            max_retries = 10\n",
    "    \n",
    "            while retry_count < max_retries:\n",
    "                try:  \n",
    "                    response = requests.post(\n",
    "                            url=api_endpoint,\n",
    "                            headers=headers,\n",
    "                            json={\n",
    "                                'model': MODELgpt4o,\n",
    "                                'messages': [\n",
    "                                    {\n",
    "                                        \"role\": \"system\",\n",
    "                                        \"content\": SYSTEM_claim_simscore                        \n",
    "                                    },\n",
    "                                    {\n",
    "                                        \"role\": \"user\",\n",
    "                                        \"content\": f'\"Target claim\":<<{row[\"claims_split\"]}>>, \"preceding claims\":\\n<{df.loc[:,['Mark_ID', 'claims_split']][:index].to_json(orient='records')}>'\n",
    "                                    \n",
    "                                    }\n",
    "                                ],\n",
    "                                'temperature': temperature_0,  \n",
    "                                'seed': SEED\n",
    "                            }\n",
    "                        )\n",
    "                    \n",
    "                    if response.status_code == 200:\n",
    "                        data_response = response.json()\n",
    "                        # Check if 'response' key exists in the JSON response\n",
    "                        if 'choices' in data_response:\n",
    "                            content = data_response[\"choices\"][0][\"message\"][\"content\"]\n",
    "                            # Remove code block markers if present\n",
    "                            content = re.sub(r'```json|```', '', content).strip()\n",
    "                            try:\n",
    "                                content = json.loads(content)   \n",
    "                                # Check if content_json is a list or a dictionary\n",
    "                                if isinstance(content, dict):\n",
    "                                    chunked_result.append({\n",
    "                                        \"post_index\": row['Mark_ID'],\n",
    "                                        \"most_similar_claim_index\": content.get('most_similar_claim_index', ''),\n",
    "                                        'similarity_score': content.get('similarity_score', '')  \n",
    "                                    })\n",
    "                                elif isinstance(content, list):\n",
    "                                    for item in content:\n",
    "                                        chunked_result.append({\n",
    "                                            \"post_index\": row['Mark_ID'],\n",
    "                                            \"most_similar_claim_index\": item.get('most_similar_claim_index', ''),\n",
    "                                            'similarity_score': item.get('similarity_score', '')  \n",
    "                                        })\n",
    "                                else:\n",
    "                                    print(f\"Unexpected content type: {type(content)}\")\n",
    "\n",
    "                            except json.JSONDecodeError as e:\n",
    "                                print(f\"Error decoding JSON: {e}\")\n",
    "                                print(data_response)\n",
    "                        else:\n",
    "                            print(f\"No 'choices' key in response or 'choices' is empty: {content}\")                        \n",
    "                        break  # Exit the retry loop on success  \n",
    "                    elif response.status_code == 429:\n",
    "                        retry_count += 1\n",
    "                        retry_after = response.headers.get(\"Retry-After\")\n",
    "                        error_message = response.json().get(\"error\", {}).get(\"message\", \"\")\n",
    "                        retry_after = 30  # Default to 30 seconds if not found\n",
    "                    \n",
    "                        # Extract retry time from the error message\n",
    "                        if \"Try again in\" in error_message:\n",
    "                            match = re.search(r\"Try again in (\\d+) second\", error_message)\n",
    "                            if match:\n",
    "                                try:\n",
    "                                    retry_after = int(match.group(1))\n",
    "                                except (IndexError, ValueError) as e:\n",
    "                                    print(f\"Rate limit exceeded. Error extracting retry time: {e}. Retrying in {retry_after} seconds.\")\n",
    "                                    pass\n",
    "                        elif \"Please retry after\" in error_message:\n",
    "                            match = re.search(r\"Please retry after (\\d+) second\", error_message)\n",
    "                            if match:\n",
    "                                try:\n",
    "                                    retry_after = int(match.group(1))\n",
    "                                except (IndexError, ValueError) as e:\n",
    "                                    print(f\"Rate limit exceeded. Error extracting retry time: {e}. Retrying in {retry_after} seconds.\")\n",
    "                                    pass\n",
    "                                \n",
    "                                \n",
    "                        else:\n",
    "                            retry_after = 30  # Default to 30 seconds if not found\n",
    "                            print(f\"Rate limit exceeded. Defaulting to retry in {retry_after} seconds.\")\n",
    "                                    \n",
    "                \n",
    "                        print(f\"Rate limit exceeded. Retrying in {retry_after} seconds: {response.json()}. Retry count = {retry_count}\") \n",
    "                        time.sleep(retry_after)\n",
    "                        \n",
    "                    #    print(f\"Rate limit exceeded. Retrying in {wait_time} seconds...\")\n",
    "                    #    print(response.text)\n",
    "                    #    time.sleep(wait_time)\n",
    "                    elif response.status_code == 500:\n",
    "                        retry_count += 1\n",
    "                        wait_time = 20\n",
    "                        print(f\"Failed to connect to API. Status code: {response.status_code}. Retrying in {wait_time} seconds...\")\n",
    "                        print(response.text)\n",
    "                        time.sleep(wait_time)\n",
    "                    else:\n",
    "                        print(f\"Failed to connect to API. Status code: {response.status_code}\")\n",
    "                        print(response.text)\n",
    "                        break\n",
    "                except requests.exceptions.RequestException as e:   \n",
    "                    print(f\"Failed to connect to API: {e}\")\n",
    "                    retry_count += 1\n",
    "                    wait_time = 60\n",
    "                    print(f\"Retrying in {wait_time} seconds...\")\n",
    "                    time.sleep(wait_time)   \n",
    "        \n",
    "                if retry_count >= max_retries:\n",
    "                    print(f\"Max retries reached for index {index}. Skipping to next item.\")\n",
    "                    break  # Exit the loop if max retries are reached              \n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "similarity_claim = pd.DataFrame(chunked_result)\n",
    "\n",
    "# Display the DataFrame to verify the changes\n",
    "print(similarity_claim.head(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_claim = pd.DataFrame(chunked_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_index</th>\n",
       "      <th>most_similar_claim_index</th>\n",
       "      <th>similarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001794</td>\n",
       "      <td>2001557</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001003</td>\n",
       "      <td>2001794</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001003</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001003</td>\n",
       "      <td>20001003</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20001003</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4847</th>\n",
       "      <td>2001730</td>\n",
       "      <td>2001590</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4848</th>\n",
       "      <td>2001730</td>\n",
       "      <td>2001590</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4849</th>\n",
       "      <td>2001730</td>\n",
       "      <td>2002436</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4850</th>\n",
       "      <td>2001730</td>\n",
       "      <td>2002436</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4851</th>\n",
       "      <td>2001046</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4852 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      post_index most_similar_claim_index similarity_score\n",
       "0        2001794                  2001557                1\n",
       "1       20001003                  2001794                5\n",
       "2       20001003                        3                5\n",
       "3       20001003                 20001003                7\n",
       "4       20001003                        3                5\n",
       "...          ...                      ...              ...\n",
       "4847     2001730                  2001590                6\n",
       "4848     2001730                  2001590                5\n",
       "4849     2001730                  2002436                7\n",
       "4850     2001730                  2002436                6\n",
       "4851     2001046                       []               []\n",
       "\n",
       "[4852 rows x 3 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "most_similar_claim_index\n",
       "[]         542\n",
       "1          392\n",
       "0          374\n",
       "3          210\n",
       "2          187\n",
       "          ... \n",
       "48539        1\n",
       "2001747      1\n",
       "125915       1\n",
       "125904       1\n",
       "2002196      1\n",
       "Name: count, Length: 1445, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_claim.most_similar_claim_index.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "post_index\n",
       "2000933    14\n",
       "2000939    14\n",
       "2002432    14\n",
       "2001304    12\n",
       "2001040    12\n",
       "           ..\n",
       "2001577     1\n",
       "2001806     1\n",
       "2001150     1\n",
       "2002043     1\n",
       "2001820     1\n",
       "Name: count, Length: 2206, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_claim.post_index.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1137/1137 [00:00<00:00, 2168.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      post_index   Mark_ID  explode_ID  \\\n",
      "0              1   2001794        4724   \n",
      "1              2  20001003        6204   \n",
      "2              3  20001003        6205   \n",
      "3              4  20001003        6206   \n",
      "4              5  20001003        6207   \n",
      "...          ...       ...         ...   \n",
      "5069          44   2001730        4572   \n",
      "5070          45   2001730        4576   \n",
      "5071          46   2001730        4574   \n",
      "5072          47   2001730        4573   \n",
      "5073          48   2001046        3129   \n",
      "\n",
      "                                         claims_split  \\\n",
      "0                        Stop killing innocent people   \n",
      "1               The Syrian crisis is a horrible thing   \n",
      "2            Al Assad is against Daesh and the rebels   \n",
      "3      Putin is aligned with al Assad to combat Daesh   \n",
      "4                        The U.S. is against al Assad   \n",
      "...                                               ...   \n",
      "5069      Celebrities are used to brainwash Americans   \n",
      "5070                                Liberals are scum   \n",
      "5071  American taxpayer money funds Al Qaeda and ISIS   \n",
      "5072                Assad is portrayed as the bad guy   \n",
      "5073                                                    \n",
      "\n",
      "               Time_comment_dt  \n",
      "0    2018-04-15 01:47:04+00:00  \n",
      "1    2018-04-15 01:48:53+00:00  \n",
      "2    2018-04-15 01:48:53+00:00  \n",
      "3    2018-04-15 01:48:53+00:00  \n",
      "4    2018-04-15 01:48:53+00:00  \n",
      "...                        ...  \n",
      "5069 2018-04-17 11:33:09+00:00  \n",
      "5070 2018-04-17 11:33:09+00:00  \n",
      "5071 2018-04-17 11:33:09+00:00  \n",
      "5072 2018-04-17 11:33:09+00:00  \n",
      "5073 2018-12-20 21:12:47+00:00  \n",
      "\n",
      "[5074 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#produce dataframe for context:\n",
    "chunked_result_df: typing.List[pd.DataFrame] = []\n",
    "GROUPER='videoTitle'\n",
    "YT_input_sort = YT_claim_embeds_explode.sort_values(by='Time_comment_dt', ascending=True).reset_index(drop=False)\n",
    "groupeddata = YT_input_sort.groupby(GROUPER)\n",
    "for group, df in tqdm.tqdm(groupeddata):\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.loc[:, 'preceding_index'] = df.index.to_series().shift(1)\n",
    "    for index, row in df.iterrows():\n",
    "        if pd.notna(row['preceding_index']):\n",
    "            chunked_result_df.append({\"post_index\": index, \"Mark_ID\": row['Mark_ID'], 'explode_ID': row['explode_index'], 'claims_split': row['claims_split'], 'Time_comment_dt': row['Time_comment_dt']})\n",
    "\n",
    "frame = pd.DataFrame(chunked_result_df)\n",
    "print(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values in similarity_claim.post_index not in frame.post_index:\n",
      "Empty DataFrame\n",
      "Columns: [post_index, most_similar_claim_index, similarity_score, index]\n",
      "Index: []\n",
      "\n",
      "Values in frame.post_index not in similarity_claim.post_index:\n",
      "      post_index  Mark_ID  explode_ID claims_split           Time_comment_dt  \\\n",
      "14            15  2000953        2936              2018-04-15 02:32:43+00:00   \n",
      "45            13   200225        1127              2018-08-21 13:50:07+00:00   \n",
      "58             4  2001021        3081              2019-05-08 12:20:10+00:00   \n",
      "84            30  2001332        3750              2019-05-15 10:57:37+00:00   \n",
      "116           15  2001391        3872              2019-06-22 15:30:37+00:00   \n",
      "...          ...      ...         ...          ...                       ...   \n",
      "4957           7  2001744        4610              2019-01-19 16:05:47+00:00   \n",
      "4979           8  2001379        3847              2019-06-17 16:26:14+00:00   \n",
      "4984          13  2001531        4167              2019-06-19 14:43:19+00:00   \n",
      "5021           5  2001809        4743              2018-04-14 13:40:34+00:00   \n",
      "5047          22  2002456        5971              2014-12-25 12:40:03+00:00   \n",
      "\n",
      "      index  \n",
      "14       14  \n",
      "45       45  \n",
      "58       58  \n",
      "84       84  \n",
      "116     116  \n",
      "...     ...  \n",
      "4957   4957  \n",
      "4979   4979  \n",
      "4984   4984  \n",
      "5021   5021  \n",
      "5047   5047  \n",
      "\n",
      "[205 rows x 6 columns]\n",
      "\n",
      "Common values in both post_index columns:\n",
      "      post_index most_similar_claim_index similarity_score  index\n",
      "0        2001794                  2001557                1      0\n",
      "1       20001003                  2001794                5      1\n",
      "2       20001003                        3                5      2\n",
      "3       20001003                 20001003                7      3\n",
      "4       20001003                        3                5      4\n",
      "...          ...                      ...              ...    ...\n",
      "4847     2001730                  2001590                6   4847\n",
      "4848     2001730                  2001590                5   4848\n",
      "4849     2001730                  2002436                7   4849\n",
      "4850     2001730                  2002436                6   4850\n",
      "4851     2001046                       []               []   4851\n",
      "\n",
      "[4852 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "not_in_frame = similarity_claim[~similarity_claim['post_index'].isin(frame['Mark_ID'])]\n",
    "print(\"Values in similarity_claim.post_index not in frame.post_index:\")\n",
    "print(not_in_frame)\n",
    "\n",
    "# Identify values in frame.post_index that are not in similarity_claim.post_index\n",
    "not_in_similarity_claim = frame[~frame['Mark_ID'].isin(similarity_claim['post_index'])]\n",
    "print(\"\\nValues in frame.post_index not in similarity_claim.post_index:\")\n",
    "print(not_in_similarity_claim)\n",
    "\n",
    "# Find common values in both post_index columns\n",
    "common_values = similarity_claim[similarity_claim['post_index'].isin(frame['Mark_ID'])]\n",
    "print(\"\\nCommon values in both post_index columns:\")\n",
    "print(common_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#common values appears to show the link with the output results:\n",
    "common_values = common_values.join(frame['explode_ID'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_index</th>\n",
       "      <th>most_similar_claim_index</th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>index</th>\n",
       "      <th>explode_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001794</td>\n",
       "      <td>2001557</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001003</td>\n",
       "      <td>2001794</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001003</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001003</td>\n",
       "      <td>20001003</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20001003</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4847</th>\n",
       "      <td>2001730</td>\n",
       "      <td>2001590</td>\n",
       "      <td>6</td>\n",
       "      <td>4847</td>\n",
       "      <td>4612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4848</th>\n",
       "      <td>2001730</td>\n",
       "      <td>2001590</td>\n",
       "      <td>5</td>\n",
       "      <td>4848</td>\n",
       "      <td>4614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4849</th>\n",
       "      <td>2001730</td>\n",
       "      <td>2002436</td>\n",
       "      <td>7</td>\n",
       "      <td>4849</td>\n",
       "      <td>4613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4850</th>\n",
       "      <td>2001730</td>\n",
       "      <td>2002436</td>\n",
       "      <td>6</td>\n",
       "      <td>4850</td>\n",
       "      <td>1205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4851</th>\n",
       "      <td>2001046</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>4851</td>\n",
       "      <td>4692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4852 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      post_index most_similar_claim_index similarity_score  index  explode_ID\n",
       "0        2001794                  2001557                1      0        4724\n",
       "1       20001003                  2001794                5      1        6204\n",
       "2       20001003                        3                5      2        6205\n",
       "3       20001003                 20001003                7      3        6206\n",
       "4       20001003                        3                5      4        6207\n",
       "...          ...                      ...              ...    ...         ...\n",
       "4847     2001730                  2001590                6   4847        4612\n",
       "4848     2001730                  2001590                5   4848        4614\n",
       "4849     2001730                  2002436                7   4849        4613\n",
       "4850     2001730                  2002436                6   4850        1205\n",
       "4851     2001046                       []               []   4851        4692\n",
       "\n",
       "[4852 rows x 5 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#similarity_claim = similarity_claim.join(YT_input_sort.set_index('dataset_index')['commentText'], rsuffix='_target')\n",
    "common_values = common_values.merge(YT_input_sort.loc[:, ['commentText','claims_split', 'explode_index']], left_on='explode_ID', right_on='explode_index', suffixes=('', '_target'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_int(value):\n",
    "    if isinstance(value, list):\n",
    "        return np.nan\n",
    "    try:\n",
    "        return int(value)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "common_values.loc[:, 'most_similar_claim_index_int'] = common_values.loc[:, 'most_similar_claim_index'].apply(convert_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_index</th>\n",
       "      <th>most_similar_claim_index</th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>index</th>\n",
       "      <th>explode_ID</th>\n",
       "      <th>commentText</th>\n",
       "      <th>claims_split</th>\n",
       "      <th>explode_index</th>\n",
       "      <th>most_similar_claim_index_int</th>\n",
       "      <th>Mark_ID</th>\n",
       "      <th>commentText_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2001794</td>\n",
       "      <td>2001557</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4724</td>\n",
       "      <td>Stop killing inocent people!</td>\n",
       "      <td>Stop killing innocent people</td>\n",
       "      <td>4724</td>\n",
       "      <td>2001557.0</td>\n",
       "      <td>2001557.0</td>\n",
       "      <td>Lux you’re welcome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20001003</td>\n",
       "      <td>2001794</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6204</td>\n",
       "      <td>The Syrian crisis is a horrible thing, but has anyone noticed the situation’s strange components...</td>\n",
       "      <td>The Syrian crisis is a horrible thing</td>\n",
       "      <td>6204</td>\n",
       "      <td>2001794.0</td>\n",
       "      <td>2001794.0</td>\n",
       "      <td>Stop killing inocent people!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20001003</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>6205</td>\n",
       "      <td>The Syrian crisis is a horrible thing, but has anyone noticed the situation’s strange components...</td>\n",
       "      <td>Al Assad is against Daesh and the rebels</td>\n",
       "      <td>6205</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20001003</td>\n",
       "      <td>20001003</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>6206</td>\n",
       "      <td>The Syrian crisis is a horrible thing, but has anyone noticed the situation’s strange components...</td>\n",
       "      <td>Putin is aligned with al Assad to combat Daesh</td>\n",
       "      <td>6206</td>\n",
       "      <td>20001003.0</td>\n",
       "      <td>20001003.0</td>\n",
       "      <td>The Syrian crisis is a horrible thing, but has anyone noticed the situation’s strange components...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20001003</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6207</td>\n",
       "      <td>The Syrian crisis is a horrible thing, but has anyone noticed the situation’s strange components...</td>\n",
       "      <td>The U.S. is against al Assad</td>\n",
       "      <td>6207</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4847</th>\n",
       "      <td>2001730</td>\n",
       "      <td>2001590</td>\n",
       "      <td>6</td>\n",
       "      <td>4847</td>\n",
       "      <td>4612</td>\n",
       "      <td>Will Roberts you will see what a clown you are. Your comments are useless garbage. None of us kn...</td>\n",
       "      <td>None of us know what any of these agencies have</td>\n",
       "      <td>4612</td>\n",
       "      <td>2001590.0</td>\n",
       "      <td>2001590.0</td>\n",
       "      <td>Again, I reiterate, it is the Taliban's fault. The war could have been avoided if they took him ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4848</th>\n",
       "      <td>2001730</td>\n",
       "      <td>2001590</td>\n",
       "      <td>5</td>\n",
       "      <td>4848</td>\n",
       "      <td>4614</td>\n",
       "      <td>Will Roberts you will see what a clown you are. Your comments are useless garbage. None of us kn...</td>\n",
       "      <td>It is laughable to think Trump is innocent of all</td>\n",
       "      <td>4614</td>\n",
       "      <td>2001590.0</td>\n",
       "      <td>2001590.0</td>\n",
       "      <td>Again, I reiterate, it is the Taliban's fault. The war could have been avoided if they took him ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4849</th>\n",
       "      <td>2001730</td>\n",
       "      <td>2002436</td>\n",
       "      <td>7</td>\n",
       "      <td>4849</td>\n",
       "      <td>4613</td>\n",
       "      <td>Will Roberts you will see what a clown you are. Your comments are useless garbage. None of us kn...</td>\n",
       "      <td>Many people around Trump are crooked</td>\n",
       "      <td>4613</td>\n",
       "      <td>2002436.0</td>\n",
       "      <td>2002436.0</td>\n",
       "      <td>Well I apologize for not practicing the best grammar online, especially since my it's not even t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4850</th>\n",
       "      <td>2001730</td>\n",
       "      <td>2002436</td>\n",
       "      <td>6</td>\n",
       "      <td>4850</td>\n",
       "      <td>1205</td>\n",
       "      <td>He is only a coffee boy lawyer.</td>\n",
       "      <td>He is only a coffee boy lawyer</td>\n",
       "      <td>1205</td>\n",
       "      <td>2002436.0</td>\n",
       "      <td>2002436.0</td>\n",
       "      <td>Well I apologize for not practicing the best grammar online, especially since my it's not even t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4851</th>\n",
       "      <td>2001046</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>4851</td>\n",
       "      <td>4692</td>\n",
       "      <td>Broad charges that experts don't fully understand  ?\\nSounds about right , fits right in with th...</td>\n",
       "      <td>The left makes false accusations against Trump</td>\n",
       "      <td>4692</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4852 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      post_index most_similar_claim_index similarity_score  index  explode_ID  \\\n",
       "0        2001794                  2001557                1      0        4724   \n",
       "1       20001003                  2001794                5      1        6204   \n",
       "2       20001003                        3                5      2        6205   \n",
       "3       20001003                 20001003                7      3        6206   \n",
       "4       20001003                        3                5      4        6207   \n",
       "...          ...                      ...              ...    ...         ...   \n",
       "4847     2001730                  2001590                6   4847        4612   \n",
       "4848     2001730                  2001590                5   4848        4614   \n",
       "4849     2001730                  2002436                7   4849        4613   \n",
       "4850     2001730                  2002436                6   4850        1205   \n",
       "4851     2001046                       []               []   4851        4692   \n",
       "\n",
       "                                                                                              commentText  \\\n",
       "0                                                                            Stop killing inocent people!   \n",
       "1     The Syrian crisis is a horrible thing, but has anyone noticed the situation’s strange components...   \n",
       "2     The Syrian crisis is a horrible thing, but has anyone noticed the situation’s strange components...   \n",
       "3     The Syrian crisis is a horrible thing, but has anyone noticed the situation’s strange components...   \n",
       "4     The Syrian crisis is a horrible thing, but has anyone noticed the situation’s strange components...   \n",
       "...                                                                                                   ...   \n",
       "4847  Will Roberts you will see what a clown you are. Your comments are useless garbage. None of us kn...   \n",
       "4848  Will Roberts you will see what a clown you are. Your comments are useless garbage. None of us kn...   \n",
       "4849  Will Roberts you will see what a clown you are. Your comments are useless garbage. None of us kn...   \n",
       "4850                                                                      He is only a coffee boy lawyer.   \n",
       "4851  Broad charges that experts don't fully understand  ?\\nSounds about right , fits right in with th...   \n",
       "\n",
       "                                           claims_split  explode_index  \\\n",
       "0                          Stop killing innocent people           4724   \n",
       "1                 The Syrian crisis is a horrible thing           6204   \n",
       "2              Al Assad is against Daesh and the rebels           6205   \n",
       "3        Putin is aligned with al Assad to combat Daesh           6206   \n",
       "4                          The U.S. is against al Assad           6207   \n",
       "...                                                 ...            ...   \n",
       "4847    None of us know what any of these agencies have           4612   \n",
       "4848  It is laughable to think Trump is innocent of all           4614   \n",
       "4849               Many people around Trump are crooked           4613   \n",
       "4850                     He is only a coffee boy lawyer           1205   \n",
       "4851     The left makes false accusations against Trump           4692   \n",
       "\n",
       "      most_similar_claim_index_int     Mark_ID  \\\n",
       "0                        2001557.0   2001557.0   \n",
       "1                        2001794.0   2001794.0   \n",
       "2                              3.0         NaN   \n",
       "3                       20001003.0  20001003.0   \n",
       "4                              3.0         NaN   \n",
       "...                            ...         ...   \n",
       "4847                     2001590.0   2001590.0   \n",
       "4848                     2001590.0   2001590.0   \n",
       "4849                     2002436.0   2002436.0   \n",
       "4850                     2002436.0   2002436.0   \n",
       "4851                           NaN         NaN   \n",
       "\n",
       "                                                                                       commentText_source  \n",
       "0                                                                                      Lux you’re welcome  \n",
       "1                                                                            Stop killing inocent people!  \n",
       "2                                                                                                     NaN  \n",
       "3     The Syrian crisis is a horrible thing, but has anyone noticed the situation’s strange components...  \n",
       "4                                                                                                     NaN  \n",
       "...                                                                                                   ...  \n",
       "4847  Again, I reiterate, it is the Taliban's fault. The war could have been avoided if they took him ...  \n",
       "4848  Again, I reiterate, it is the Taliban's fault. The war could have been avoided if they took him ...  \n",
       "4849  Well I apologize for not practicing the best grammar online, especially since my it's not even t...  \n",
       "4850  Well I apologize for not practicing the best grammar online, especially since my it's not even t...  \n",
       "4851                                                                                                  NaN  \n",
       "\n",
       "[4852 rows x 11 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_values.merge(YT_claim_embeds.loc[:, ['Mark_ID', 'commentText']], left_on = 'most_similar_claim_index_int', right_on = 'Mark_ID' , suffixes=('', '_source'), how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_values = common_values.merge(YT_claim_embeds.loc[:, ['Mark_ID', 'commentText']], left_on = 'most_similar_claim_index_int', right_on = 'Mark_ID' , suffixes=('', '_source'), how='left')\n",
    "common_values.drop(columns=['Mark_ID'], inplace=True)\n",
    "common_values.rename(columns={'most_similar_claim_index': 'most_similar_claim_index_gpt4o', 'most_similar_claim_index_int': 'most_similar_claim_index_int_gpt4o', 'similarity_score': 'similarity_score_claim_gpt4o', 'commentText':'commentText_most_sim_claim_gpt4o' }, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "YT_claim_embeds_explode = YT_claim_embeds_explode.merge(common_values.loc[:, ['most_similar_claim_index_int_gpt4o', 'similarity_score_claim_gpt4o', 'commentText_most_sim_claim_gpt4o', 'explode_ID']], left_on = 'explode_index', right_on = 'explode_ID' , suffixes=('', '_source'), how='left')\n",
    "YT_claim_embeds_explode.drop(columns=['explode_ID'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YT_claim_embeds_explode['similarity_score_claim_gpt4o'] = YT_claim_embeds_explode['similarity_score_claim_gpt4o'].apply(convert_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data:\n",
    "YT_claim_embeds_explode.to_parquet(f'{CFG.report_dir}/pubsphere_YT_post_claim_explode.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data:\n",
    "YT_claim_embeds_explode = pd.read_parquet(f'{CFG.report_dir}/pubsphere_YT_post_claim_explode.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YT_claim_embeds_explode.loc[:, ['Mark_ID', 'videoTitle', 'claims_split', 'Time_comment_dt', 'most_similar_claim_index_int_gpt4o', 'similarity_score_claim_gpt4o', 'commentText_most_sim_claim_gpt4o']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "videoTitle\n",
       "John Berman: Is it even news when the President lies?                                                  50\n",
       "Rep. Adam Schiff: Authoritarianism vs. Democracy  | Real Time with Bill Maher (HBO)                    50\n",
       "iTunes, Assad, and Right Said Fred: Last Week Tonight with John Oliver (HBO)                           49\n",
       "'Hannity' panel on the important questions Mueller needs to answer                                     46\n",
       "Trump talks race, football, foreign policy and more ahead of the Super Bowl                            46\n",
       "                                                                                                       ..\n",
       "2020 Democrats Divided Over Impeachment After Mueller Report | NBC Nightly News                         1\n",
       "Senator Lindsey Graham: Why He's Opposed to the Iran Nuclear Deal - Late Night with Seth Meyers         1\n",
       "Matthews: How Does Pres. Donald Trump Justify Putting More Troops In Harm's Way? | Hardball | MSNBC     1\n",
       "ISIS-destroyed monuments reconstructed                                                                  1\n",
       "Stephen Colbert's Thanksgiving Turkey Tips (Part 1)                                                     1\n",
       "Name: count, Length: 1137, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YT_claim_embeds_explode.videoTitle.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Fmr. Prosecutor On Donald Trump Mocking Kavanaugh Accuser: 'Who Are We?' | The 11th Hour | MSNBC\",\n",
       " 'Nicolle Wallace: John McCain In Death Was Able To Shame Donald Trump In Life | The 11th Hour | MSNBC']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YT_claim_embeds_explode['videoTitle'].iloc[2:4].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartDate</th>\n",
       "      <th>RecordedDate</th>\n",
       "      <th>IPAddress</th>\n",
       "      <th>Finished</th>\n",
       "      <th>Coder</th>\n",
       "      <th>ID</th>\n",
       "      <th>Mark_ID</th>\n",
       "      <th>Genre</th>\n",
       "      <th>topiccode</th>\n",
       "      <th>Platform</th>\n",
       "      <th>...</th>\n",
       "      <th>claims_ext_gpt4o</th>\n",
       "      <th>post_index_ext_gpt4o</th>\n",
       "      <th>most_similar_ext_ID_gpt4o</th>\n",
       "      <th>similarity_score_ext_gpt4o</th>\n",
       "      <th>post_expenasion_most_sim_gpt4o</th>\n",
       "      <th>claims_split</th>\n",
       "      <th>explode_index</th>\n",
       "      <th>most_similar_claim_index_int_gpt4o</th>\n",
       "      <th>similarity_score_claim_gpt4o</th>\n",
       "      <th>commentText_most_sim_claim_gpt4o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6/13/2021 13:25:49</td>\n",
       "      <td>6/13/2021 13:27:28</td>\n",
       "      <td>213.127.82.232</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgwWKCWtSJdFvjGHvTp4AaABAg.8kUC5dGrQ2H8kUDRihE2f3</td>\n",
       "      <td>1206</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[\"No-one else will hug him\"]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>No-one else will hug him</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            StartDate        RecordedDate       IPAddress  Finished  Coder  \\\n",
       "3  6/13/2021 13:25:49  6/13/2021 13:27:28  213.127.82.232         1      6   \n",
       "\n",
       "                                                  ID  Mark_ID  Genre  \\\n",
       "3  UgwWKCWtSJdFvjGHvTp4AaABAg.8kUC5dGrQ2H8kUDRihE2f3     1206      0   \n",
       "\n",
       "   topiccode  Platform  ...              claims_ext_gpt4o  \\\n",
       "3          0         1  ...  [\"No-one else will hug him\"]   \n",
       "\n",
       "  post_index_ext_gpt4o  most_similar_ext_ID_gpt4o  similarity_score_ext_gpt4o  \\\n",
       "3                  NaN                        NaN                        None   \n",
       "\n",
       "   post_expenasion_most_sim_gpt4o              claims_split  explode_index  \\\n",
       "3                            None  No-one else will hug him              3   \n",
       "\n",
       "   most_similar_claim_index_int_gpt4o  similarity_score_claim_gpt4o  \\\n",
       "3                                 NaN                           NaN   \n",
       "\n",
       "  commentText_most_sim_claim_gpt4o  \n",
       "3                             None  \n",
       "\n",
       "[1 rows x 133 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YT_claim_embeds_explode.loc[YT_claim_embeds_explode['videoTitle'] == 'Nicolle Wallace: John McCain In Death Was Able To Shame Donald Trump In Life | The 11th Hour | MSNBC',:]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the missing values in the similarity scores appear to be due to single comment videos, which do not have any preceding comments to compare with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data:\n",
    "YT_claim_embeds = pd.read_parquet(f'{CFG.report_dir}/pubsphere_YT_posts.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['StartDate',\n",
       " 'RecordedDate',\n",
       " 'IPAddress',\n",
       " 'Finished',\n",
       " 'Coder',\n",
       " 'ID',\n",
       " 'Mark_ID',\n",
       " 'Genre',\n",
       " 'topiccode',\n",
       " 'Platform',\n",
       " 'Anonymity',\n",
       " 'Anonymity_9_TEXT',\n",
       " 'codable',\n",
       " 'Interaction',\n",
       " 'Acknowledgement',\n",
       " 'TopicRelevance',\n",
       " 'Reasoning',\n",
       " 'BackgroundInfo',\n",
       " 'ExternalEvidence',\n",
       " 'ExternalEvidence_1_TEXT',\n",
       " 'Opinion',\n",
       " 'disagreement',\n",
       " 'Ideologicaldirection',\n",
       " 'Name_calling',\n",
       " 'Vulgarity',\n",
       " 'Attack_reputation',\n",
       " 'Question_Intelligenc',\n",
       " 'All_caps_function',\n",
       " 'Sarcasm_to_criticize',\n",
       " 'Individual_right',\n",
       " 'discrimination',\n",
       " 'Invoke_violence',\n",
       " 'Tone',\n",
       " 'INTERACTIVITY_DUMMY',\n",
       " 'RATIONALITY_DUMMY',\n",
       " 'HAS_OPINION_DUMMY',\n",
       " 'LIBERAL_NEUTRAL_CONSERVATIVE',\n",
       " 'LIBERAL_DUMMY',\n",
       " 'CONSERVATIVE_DUMMY',\n",
       " 'NAMECALLING_DUMMY',\n",
       " 'VULGAR_DUMMY',\n",
       " 'NAMECALLING_VULGAR_DUMMY',\n",
       " 'INCIVILITY_ORDINAL',\n",
       " 'INCIVILITY_DUMMY',\n",
       " 'INTOLERANCE_DUMMY',\n",
       " 'filter_$',\n",
       " 'IMPOLITENESS_DUMMY',\n",
       " 'commentText',\n",
       " 'showName',\n",
       " 'genre',\n",
       " 'Time_comment',\n",
       " 'likeCount_comment',\n",
       " 'entities',\n",
       " 'place',\n",
       " 'retweet_count',\n",
       " 'platform',\n",
       " 'retweeted',\n",
       " 'language',\n",
       " 'source',\n",
       " 'in_reply_to_status_id_str',\n",
       " 'in_reply_to_user_id_str',\n",
       " 'in_reply_to_screen_name',\n",
       " 'is_quote_status',\n",
       " 'videoTitle',\n",
       " 'description',\n",
       " 'Time_video',\n",
       " 'channelTitle',\n",
       " 'channelId',\n",
       " 'viewCount',\n",
       " 'dislikeCount_video',\n",
       " 'likeCount_video',\n",
       " 'date_difference',\n",
       " 'commentCount_video',\n",
       " 'replyCount_comment',\n",
       " 'topic',\n",
       " 'subscribers',\n",
       " 'HATELIST_FOCUSED_DUMMY',\n",
       " 'Time_comment_year',\n",
       " 'Time_video_year',\n",
       " 'interactivity_acknowledgement',\n",
       " 'political_ideology',\n",
       " 'rationality_external_evidence',\n",
       " 'rationality_topic_relevance',\n",
       " 'political_negativity',\n",
       " 'rationality_background_info',\n",
       " 'rationality_reasoning',\n",
       " 'sentiment',\n",
       " 'offensive',\n",
       " 'topics',\n",
       " 'emotions',\n",
       " 'irony',\n",
       " 'hate',\n",
       " 'topiccodeSTR',\n",
       " 'claim_run1',\n",
       " 'claim_optdef',\n",
       " 'claim_optdef_embed_MXBAI',\n",
       " 'claim_optlow',\n",
       " 'claim_optlow_MXBAI',\n",
       " 'tfidf_embed_post',\n",
       " 'embed_MXBAI_post',\n",
       " 'cosine_similarity_post_claim_MXBAI',\n",
       " 'cosine_low_high_MXBAI',\n",
       " 'tfidf_embed_post_svd',\n",
       " 'Llama31_political_post_8b',\n",
       " 'Llama31_political_fill_8b',\n",
       " 'Llama31_political_fill_8b_score',\n",
       " 'political_post_gpt4o',\n",
       " 'political_post_gpt4o_dum',\n",
       " 'either_political',\n",
       " 'Time_comment_dt',\n",
       " 'post_ada_embedding',\n",
       " 'claims_gpt4o',\n",
       " 'post_expansion_gpt4o_token10',\n",
       " 'most_similar_index_gpt4o',\n",
       " 'similarity_score_gpt4o',\n",
       " 'commentText_most_sim_gpt4o',\n",
       " 'claims_ext_gpt4o_token10',\n",
       " 'post_index',\n",
       " 'most_similar_ext_ID_gpt4o_token10',\n",
       " 'similarity_score_ext_gpt4o_token10',\n",
       " 'post_expenasion_most_sim_gpt4o_token10',\n",
       " 'dataset_index',\n",
       " 'post_expansion_gpt4o',\n",
       " 'claims_ext_gpt4o',\n",
       " 'post_index_ext_gpt4o',\n",
       " 'most_similar_ext_ID_gpt4o',\n",
       " 'similarity_score_ext_gpt4o',\n",
       " 'post_expenasion_most_sim_gpt4o']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YT_claim_embeds.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add ascending group index per comment:\n",
    "YT_claim_embeds_sort = YT_claim_embeds.sort_values(by='Time_comment_dt', ascending=True).reset_index(drop=True)\n",
    "YT_claim_embeds_sort['ascending_comment_index'] = YT_claim_embeds_sort.groupby('videoTitle').cumcount()\n",
    "YT_claim_embeds_sort['preceding_comment_index'] = YT_claim_embeds_sort.groupby('videoTitle')['ascending_comment_index'].shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "videoTitle                                                                    Time_comment_dt            ascending_comment_index  preceding_comment_index\n",
       "\"Haley: Airstrikes \"\"crippled\"\" Syria’s chemical weapons program  \"           2018-04-15 01:47:04+00:00  1                        0.0                        1\n",
       "                                                                              2018-04-15 01:48:53+00:00  2                        1.0                        1\n",
       "                                                                              2018-04-15 01:52:34+00:00  3                        2.0                        1\n",
       "                                                                              2018-04-15 02:07:45+00:00  4                        3.0                        1\n",
       "                                                                              2018-04-15 02:28:07+00:00  5                        4.0                        1\n",
       "                                                                                                                                                            ..\n",
       "iTunes, Assad, and Right Said Fred: Last Week Tonight with John Oliver (HBO)  2015-04-11 06:48:27+00:00  12                       11.0                       1\n",
       "                                                                              2016-09-21 19:47:02+00:00  13                       12.0                       1\n",
       "                                                                              2017-01-10 13:45:18+00:00  14                       13.0                       1\n",
       "                                                                              2018-04-17 11:33:09+00:00  15                       14.0                       1\n",
       "                                                                              2018-12-20 21:12:47+00:00  16                       15.0                       1\n",
       "Name: count, Length: 1995, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YT_claim_embeds_sort.sort_values(by='Time_comment_dt', ascending=True).loc[:, ['videoTitle', 'Time_comment_dt', 'ascending_comment_index', 'preceding_comment_index']].groupby('videoTitle').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "YT_claim_embeds = YT_claim_embeds.merge(YT_claim_embeds_sort.loc[:, ['Mark_ID', 'ascending_comment_index', 'preceding_comment_index']], on='Mark_ID', suffixes=('', '_sort'), how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get simscore for expanded claims using GPT4o:\n",
    "#first explode the expanded claims:\n",
    "#create a expanded dataset of claims along with Mark_IDs and videoTitles:\n",
    "\n",
    "YT_claim_embeds['claims_exp_split'] = YT_claim_embeds['claims_ext_gpt4o'].str.split('\",')\n",
    "YT_claim_embeds_exp_explode = YT_claim_embeds.explode('claims_exp_split')\n",
    "YT_claim_embeds_exp_explode = YT_claim_embeds_exp_explode.reset_index(drop=True)\n",
    "YT_claim_embeds_exp_explode['claims_exp_split'] = YT_claim_embeds_exp_explode['claims_exp_split'].str.replace('\"', '').str.replace('[', '').str.replace(']', '').str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartDate</th>\n",
       "      <th>RecordedDate</th>\n",
       "      <th>IPAddress</th>\n",
       "      <th>Finished</th>\n",
       "      <th>Coder</th>\n",
       "      <th>ID</th>\n",
       "      <th>Mark_ID</th>\n",
       "      <th>Genre</th>\n",
       "      <th>topiccode</th>\n",
       "      <th>Platform</th>\n",
       "      <th>...</th>\n",
       "      <th>most_similar_ext_ID_gpt4o</th>\n",
       "      <th>similarity_score_ext_gpt4o</th>\n",
       "      <th>post_expenasion_most_sim_gpt4o</th>\n",
       "      <th>claims_exp_split</th>\n",
       "      <th>ascending_comment_index_sort</th>\n",
       "      <th>preceding_comment_index_sort</th>\n",
       "      <th>ascending_comment_index</th>\n",
       "      <th>preceding_comment_index</th>\n",
       "      <th>exp_explode_index</th>\n",
       "      <th>claim_per_video_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/30/2021 13:03:17</td>\n",
       "      <td>5/30/2021 13:04:17</td>\n",
       "      <td>62.194.51.29</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgyPHwv8G0cDE6-wEgl4AaABAg.8_0ZjJKSJty8_0kXGkAd2U</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "      <td>641</td>\n",
       "      <td>640.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/11/2021 10:34:05</td>\n",
       "      <td>10/11/2021 10:36:46</td>\n",
       "      <td>213.127.109.191</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Ugx2WXq9UdV8mPPjejJ4AaABAg.8yHCKV0Boe58yYRxEQEF45</td>\n",
       "      <td>282</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2000336.0</td>\n",
       "      <td>3</td>\n",
       "      <td>@Zquadfather you sound like an Antifa punk!!!</td>\n",
       "      <td>Minerals have rights too</td>\n",
       "      <td>2927</td>\n",
       "      <td>2926.0</td>\n",
       "      <td>19</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6/6/2021 16:12:46</td>\n",
       "      <td>6/6/2021 16:16:16</td>\n",
       "      <td>213.127.76.145</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgwUPFScjJ0MCeaP2F54AaABAg.8lvp3fc9Euf8lvvgsUgEgV</td>\n",
       "      <td>769</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>The death of free and civil dialogue has been effectively depicted</td>\n",
       "      <td>1453</td>\n",
       "      <td>1452.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6/13/2021 13:25:49</td>\n",
       "      <td>6/13/2021 13:27:28</td>\n",
       "      <td>213.127.82.232</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgwWKCWtSJdFvjGHvTp4AaABAg.8kUC5dGrQ2H8kUDRihE2f3</td>\n",
       "      <td>1206</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>No-one else will hug him</td>\n",
       "      <td>1378</td>\n",
       "      <td>1377.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11/30/2021 17:24:18</td>\n",
       "      <td>11/30/2021 17:27:16</td>\n",
       "      <td>213.127.109.191</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Ugw2eTvkZLfH9MDVg1R4AaABAg</td>\n",
       "      <td>1214</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2000601.0</td>\n",
       "      <td>1</td>\n",
       "      <td>I RESPECTFULLY want an UPDATE ON THE DRAIN THE SWAMP PROMISE. You Tube killed my “Q” subscriptio...</td>\n",
       "      <td></td>\n",
       "      <td>2966</td>\n",
       "      <td>2965.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6293</th>\n",
       "      <td>11/19/2021 17:49:17</td>\n",
       "      <td>11/19/2021 17:51:04</td>\n",
       "      <td>213.127.109.191</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgwPOHIDyICm10k0Mvx4AaABAg</td>\n",
       "      <td>20001003</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2001794.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Stop killing inocent people!</td>\n",
       "      <td>Putin is aligned with al Assad to combat Daesh</td>\n",
       "      <td>926</td>\n",
       "      <td>925.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6293</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6294</th>\n",
       "      <td>11/19/2021 17:49:17</td>\n",
       "      <td>11/19/2021 17:51:04</td>\n",
       "      <td>213.127.109.191</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgwPOHIDyICm10k0Mvx4AaABAg</td>\n",
       "      <td>20001003</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2001794.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Stop killing inocent people!</td>\n",
       "      <td>The U.S. is against al Assad</td>\n",
       "      <td>926</td>\n",
       "      <td>925.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6294</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6295</th>\n",
       "      <td>11/19/2021 17:49:17</td>\n",
       "      <td>11/19/2021 17:51:04</td>\n",
       "      <td>213.127.109.191</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgwPOHIDyICm10k0Mvx4AaABAg</td>\n",
       "      <td>20001003</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2001794.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Stop killing inocent people!</td>\n",
       "      <td>Russia and the U.S. are both against ISIS</td>\n",
       "      <td>926</td>\n",
       "      <td>925.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6295</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6296</th>\n",
       "      <td>11/19/2021 17:49:17</td>\n",
       "      <td>11/19/2021 17:51:04</td>\n",
       "      <td>213.127.109.191</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgwPOHIDyICm10k0Mvx4AaABAg</td>\n",
       "      <td>20001003</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2001794.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Stop killing inocent people!</td>\n",
       "      <td>Russia is aligned with the Syrian government</td>\n",
       "      <td>926</td>\n",
       "      <td>925.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6296</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6297</th>\n",
       "      <td>11/19/2021 17:49:17</td>\n",
       "      <td>11/19/2021 17:51:04</td>\n",
       "      <td>213.127.109.191</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgwPOHIDyICm10k0Mvx4AaABAg</td>\n",
       "      <td>20001003</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2001794.0</td>\n",
       "      <td>2</td>\n",
       "      <td>Stop killing inocent people!</td>\n",
       "      <td>The U.S. is against the Syrian government for attacking civilians</td>\n",
       "      <td>926</td>\n",
       "      <td>925.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6297</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6298 rows × 135 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                StartDate         RecordedDate        IPAddress  Finished  \\\n",
       "0      5/30/2021 13:03:17   5/30/2021 13:04:17     62.194.51.29         1   \n",
       "1     10/11/2021 10:34:05  10/11/2021 10:36:46  213.127.109.191         1   \n",
       "2       6/6/2021 16:12:46    6/6/2021 16:16:16   213.127.76.145         1   \n",
       "3      6/13/2021 13:25:49   6/13/2021 13:27:28   213.127.82.232         1   \n",
       "4     11/30/2021 17:24:18  11/30/2021 17:27:16  213.127.109.191         1   \n",
       "...                   ...                  ...              ...       ...   \n",
       "6293  11/19/2021 17:49:17  11/19/2021 17:51:04  213.127.109.191         1   \n",
       "6294  11/19/2021 17:49:17  11/19/2021 17:51:04  213.127.109.191         1   \n",
       "6295  11/19/2021 17:49:17  11/19/2021 17:51:04  213.127.109.191         1   \n",
       "6296  11/19/2021 17:49:17  11/19/2021 17:51:04  213.127.109.191         1   \n",
       "6297  11/19/2021 17:49:17  11/19/2021 17:51:04  213.127.109.191         1   \n",
       "\n",
       "      Coder                                                 ID   Mark_ID  \\\n",
       "0         6  UgyPHwv8G0cDE6-wEgl4AaABAg.8_0ZjJKSJty8_0kXGkAd2U       119   \n",
       "1         6  Ugx2WXq9UdV8mPPjejJ4AaABAg.8yHCKV0Boe58yYRxEQEF45       282   \n",
       "2         6  UgwUPFScjJ0MCeaP2F54AaABAg.8lvp3fc9Euf8lvvgsUgEgV       769   \n",
       "3         6  UgwWKCWtSJdFvjGHvTp4AaABAg.8kUC5dGrQ2H8kUDRihE2f3      1206   \n",
       "4         6                         Ugw2eTvkZLfH9MDVg1R4AaABAg      1214   \n",
       "...     ...                                                ...       ...   \n",
       "6293      6                         UgwPOHIDyICm10k0Mvx4AaABAg  20001003   \n",
       "6294      6                         UgwPOHIDyICm10k0Mvx4AaABAg  20001003   \n",
       "6295      6                         UgwPOHIDyICm10k0Mvx4AaABAg  20001003   \n",
       "6296      6                         UgwPOHIDyICm10k0Mvx4AaABAg  20001003   \n",
       "6297      6                         UgwPOHIDyICm10k0Mvx4AaABAg  20001003   \n",
       "\n",
       "      Genre  topiccode  Platform  ...  most_similar_ext_ID_gpt4o  \\\n",
       "0         0          0         1  ...                        NaN   \n",
       "1         1          2         1  ...                  2000336.0   \n",
       "2         0          0         1  ...                        NaN   \n",
       "3         0          0         1  ...                        NaN   \n",
       "4         1          2         1  ...                  2000601.0   \n",
       "...     ...        ...       ...  ...                        ...   \n",
       "6293      0          3         1  ...                  2001794.0   \n",
       "6294      0          3         1  ...                  2001794.0   \n",
       "6295      0          3         1  ...                  2001794.0   \n",
       "6296      0          3         1  ...                  2001794.0   \n",
       "6297      0          3         1  ...                  2001794.0   \n",
       "\n",
       "     similarity_score_ext_gpt4o  \\\n",
       "0                          None   \n",
       "1                             3   \n",
       "2                          None   \n",
       "3                          None   \n",
       "4                             1   \n",
       "...                         ...   \n",
       "6293                          2   \n",
       "6294                          2   \n",
       "6295                          2   \n",
       "6296                          2   \n",
       "6297                          2   \n",
       "\n",
       "                                                                           post_expenasion_most_sim_gpt4o  \\\n",
       "0                                                                                                    None   \n",
       "1                                                           @Zquadfather you sound like an Antifa punk!!!   \n",
       "2                                                                                                    None   \n",
       "3                                                                                                    None   \n",
       "4     I RESPECTFULLY want an UPDATE ON THE DRAIN THE SWAMP PROMISE. You Tube killed my “Q” subscriptio...   \n",
       "...                                                                                                   ...   \n",
       "6293                                                                         Stop killing inocent people!   \n",
       "6294                                                                         Stop killing inocent people!   \n",
       "6295                                                                         Stop killing inocent people!   \n",
       "6296                                                                         Stop killing inocent people!   \n",
       "6297                                                                         Stop killing inocent people!   \n",
       "\n",
       "                                                        claims_exp_split  \\\n",
       "0                                                                          \n",
       "1                                               Minerals have rights too   \n",
       "2     The death of free and civil dialogue has been effectively depicted   \n",
       "3                                               No-one else will hug him   \n",
       "4                                                                          \n",
       "...                                                                  ...   \n",
       "6293                      Putin is aligned with al Assad to combat Daesh   \n",
       "6294                                        The U.S. is against al Assad   \n",
       "6295                           Russia and the U.S. are both against ISIS   \n",
       "6296                        Russia is aligned with the Syrian government   \n",
       "6297   The U.S. is against the Syrian government for attacking civilians   \n",
       "\n",
       "      ascending_comment_index_sort  preceding_comment_index_sort  \\\n",
       "0                              641                         640.0   \n",
       "1                             2927                        2926.0   \n",
       "2                             1453                        1452.0   \n",
       "3                             1378                        1377.0   \n",
       "4                             2966                        2965.0   \n",
       "...                            ...                           ...   \n",
       "6293                           926                         925.0   \n",
       "6294                           926                         925.0   \n",
       "6295                           926                         925.0   \n",
       "6296                           926                         925.0   \n",
       "6297                           926                         925.0   \n",
       "\n",
       "      ascending_comment_index  preceding_comment_index  exp_explode_index  \\\n",
       "0                           0                      NaN                  0   \n",
       "1                          19                     18.0                  1   \n",
       "2                           0                      NaN                  2   \n",
       "3                           0                      NaN                  3   \n",
       "4                           1                      0.0                  4   \n",
       "...                       ...                      ...                ...   \n",
       "6293                        2                      1.0               6293   \n",
       "6294                        2                      1.0               6294   \n",
       "6295                        2                      1.0               6295   \n",
       "6296                        2                      1.0               6296   \n",
       "6297                        2                      1.0               6297   \n",
       "\n",
       "     claim_per_video_index  \n",
       "0                        0  \n",
       "1                        0  \n",
       "2                        0  \n",
       "3                        1  \n",
       "4                        2  \n",
       "...                    ...  \n",
       "6293                    27  \n",
       "6294                    28  \n",
       "6295                     0  \n",
       "6296                     2  \n",
       "6297                     3  \n",
       "\n",
       "[6298 rows x 135 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YT_claim_embeds_exp_explode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add an exp_explode_index column:\n",
    "YT_claim_embeds_exp_explode.loc[:, \"exp_explode_index\"] = YT_claim_embeds_exp_explode.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "YT_claim_embeds_exp_explode.loc[:, 'claim_per_video_index'] = YT_claim_embeds_exp_explode.sort_values(by='Time_comment_dt', ascending=True).reset_index(drop=False).groupby('videoTitle').cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StartDate                       1291\n",
       "RecordedDate                    1291\n",
       "IPAddress                       1291\n",
       "Finished                        1291\n",
       "Coder                           1291\n",
       "                                ... \n",
       "preceding_comment_index_sort    1290\n",
       "ascending_comment_index         1291\n",
       "preceding_comment_index          742\n",
       "exp_explode_index               1291\n",
       "claim_per_video_index           1291\n",
       "Length: 135, dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YT_claim_embeds_exp_explode.loc[YT_claim_embeds_exp_explode.claims_exp_split=='',:].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 386.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframe:\n",
      "Empty DataFrame\n",
      "Columns: [exp_explode_index, claims_exp_split, ascending_comment_index]\n",
      "Index: []\n",
      "dataframe:\n",
      "Empty DataFrame\n",
      "Columns: [exp_explode_index, claims_exp_split, ascending_comment_index]\n",
      "Index: []\n",
      "dataframe:\n",
      "Empty DataFrame\n",
      "Columns: [exp_explode_index, claims_exp_split, ascending_comment_index]\n",
      "Index: []\n",
      "dataframe:\n",
      "   exp_explode_index                          claims_exp_split  \\\n",
      "0               3013  Using a broad brush can cost credibility   \n",
      "\n",
      "   ascending_comment_index  \n",
      "0                        0  \n",
      "loop index:\n",
      "0\n",
      "dataframe:\n",
      "   exp_explode_index  \\\n",
      "0               2612   \n",
      "4               6171   \n",
      "5               6172   \n",
      "\n",
      "                                              claims_exp_split  \\\n",
      "0                 Over 9 million Syrians have fled the country   \n",
      "4  The guitar player is not actually playing in the background   \n",
      "5                              Only bass is heard in the track   \n",
      "\n",
      "   ascending_comment_index  \n",
      "0                        0  \n",
      "4                        4  \n",
      "5                        4  \n",
      "loop index:\n",
      "0\n",
      "loop index:\n",
      "4\n",
      "\"Target claim\":<<The guitar player is not actually playing in the background>>, \"preceding claims\":\n",
      "<[{\"exp_explode_index\":2612,\"claims_exp_split\":\"Over 9 million Syrians have fled the country\"}]>\n",
      "6171\n",
      "3.0\n",
      "   exp_explode_index  \\\n",
      "0               2612   \n",
      "4               6171   \n",
      "5               6172   \n",
      "\n",
      "                                              claims_exp_split  \n",
      "0                 Over 9 million Syrians have fled the country  \n",
      "4  The guitar player is not actually playing in the background  \n",
      "5                              Only bass is heard in the track  \n",
      "loop index:\n",
      "5\n",
      "\"Target claim\":<<Only bass is heard in the track>>, \"preceding claims\":\n",
      "<[{\"exp_explode_index\":2612,\"claims_exp_split\":\"Over 9 million Syrians have fled the country\"}]>\n",
      "6172\n",
      "3.0\n",
      "   exp_explode_index  \\\n",
      "0               2612   \n",
      "4               6171   \n",
      "5               6172   \n",
      "\n",
      "                                              claims_exp_split  \n",
      "0                 Over 9 million Syrians have fled the country  \n",
      "4  The guitar player is not actually playing in the background  \n",
      "5                              Only bass is heard in the track  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "chunked_result: typing.List[pd.DataFrame] = []\n",
    "GROUPER='videoTitle'\n",
    "#sort data by Time_comment\n",
    "YT_input_sort = YT_claim_embeds_exp_explode.sort_values(by=['Time_comment_dt','ascending_comment_index'], ascending=True).reset_index(drop=False)[50:60]\n",
    "groupeddata = YT_input_sort.groupby(GROUPER)\n",
    "\n",
    "for group, df in tqdm.tqdm(groupeddata):\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df = df.loc[df.claims_exp_split != '',:]\n",
    "    df.sort_values(by=['Time_comment_dt','ascending_comment_index'], ascending=True).reset_index(drop=False)\n",
    "    print('dataframe:')\n",
    "    print(df.loc[:,['exp_explode_index', 'claims_exp_split', 'ascending_comment_index']])\n",
    "    for index, row in df.iterrows():\n",
    "        print('loop index:')\n",
    "        print(index)\n",
    "        if pd.notna(row['preceding_comment_index']):\n",
    "            if row['claims_exp_split'] != '':\n",
    "                print(f'\"Target claim\":<<{row[\"claims_exp_split\"]}>>, \"preceding claims\":\\n<{df.loc[df.ascending_comment_index != row['ascending_comment_index'], ['exp_explode_index', 'claims_exp_split']].iloc[:index].to_json(orient='records')}>')\n",
    "                print(row['exp_explode_index'])\n",
    "                print(row['preceding_comment_index'])\n",
    "                print(df.loc[:,['exp_explode_index', 'claims_exp_split']].iloc[:int(row['preceding_comment_index'])])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1137 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 4/1137 [01:43<7:30:23, 23.85s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 23 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 23 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 12/1137 [03:48<5:26:14, 17.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 21 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 21 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/1137 [06:13<9:11:36, 29.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 19 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 19 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 33/1137 [08:30<2:04:43,  6.78s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 26 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 26 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 47/1137 [11:02<1:51:56,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 16 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 16 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 48/1137 [11:36<3:11:31, 10.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 55/1137 [13:29<2:17:04,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 30 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 30 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 68/1137 [15:36<2:37:50,  8.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 31 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 31 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 111/1137 [18:11<28:52,  1.69s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 14 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 14 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 133/1137 [19:14<33:14,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 11 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 11 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 138/1137 [19:28<36:56,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 158/1137 [21:21<44:50,  2.75s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 18 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 18 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 166/1137 [22:09<1:04:15,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 179/1137 [23:46<1:25:28,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 25 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 25 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 190/1137 [26:15<1:58:26,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 9 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 4 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 194/1137 [28:08<3:40:25, 14.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 27 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 27 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 4 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 220/1137 [30:14<31:14,  2.04s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 18 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 18 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 232/1137 [32:41<1:38:43,  6.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 17 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 17 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 249/1137 [33:30<37:27,  2.53s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 267/1137 [35:26<53:50,  3.71s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 18 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 18 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 7 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 297/1137 [37:14<30:50,  2.20s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 26 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 26 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 312/1137 [39:45<53:00,  3.86s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 25 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 25 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 320/1137 [42:09<2:40:03, 11.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 10 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 326/1137 [42:38<1:25:29,  6.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 328/1137 [44:01<4:10:14, 18.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 23 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 23 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 334/1137 [45:09<2:27:57, 11.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 343/1137 [46:39<2:04:37,  9.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 30 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 30 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 351/1137 [49:06<2:47:01, 12.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 14 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 14 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 362/1137 [50:59<1:38:35,  7.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 13 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 13 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 11 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 11 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 11 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 366/1137 [53:07<4:02:39, 18.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 32 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 32 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 384/1137 [54:23<1:07:32,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 14 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 14 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 400/1137 [56:25<1:23:32,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 33 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 33 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 424/1137 [57:29<22:08,  1.86s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 22 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 22 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 428/1137 [58:04<43:47,  3.71s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 442/1137 [59:45<49:34,  4.28s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 22 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 22 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 443/1137 [1:00:25<2:08:55, 11.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 481/1137 [1:01:48<20:21,  1.86s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 34 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 34 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 483/1137 [1:03:02<1:23:13,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 22 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 22 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 499/1137 [1:05:21<1:00:40,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 13 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 13 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 509/1137 [1:06:32<50:22,  4.81s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 12 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 12 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 515/1137 [1:06:56<42:25,  4.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 550/1137 [1:09:00<18:40,  1.91s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 10 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 10 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 559/1137 [1:09:17<15:07,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 574/1137 [1:11:01<33:33,  3.58s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 22 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 22 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 578/1137 [1:11:30<38:26,  4.13s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 586/1137 [1:13:19<1:38:54, 10.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 12 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 12 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 594/1137 [1:15:15<1:33:48, 10.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 26 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 26 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 601/1137 [1:16:09<1:08:48,  7.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 24 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 24 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 602/1137 [1:16:54<2:13:26, 14.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 621/1137 [1:18:52<49:27,  5.75s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 6 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n",
      "Rate limit exceeded. Retrying in 29 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 29 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 623/1137 [1:22:48<4:44:37, 33.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 24 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 24 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 624/1137 [1:23:22<4:46:16, 33.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 655/1137 [1:25:06<10:19,  1.29s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 20 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 20 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 657/1137 [1:25:30<28:41,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 664/1137 [1:27:02<1:02:44,  7.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 23 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 23 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 684/1137 [1:29:04<35:52,  4.75s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 22 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 22 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 697/1137 [1:30:34<30:43,  4.19s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 7 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 698/1137 [1:30:47<39:04,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 9 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 731/1137 [1:32:48<11:44,  1.74s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 13 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 13 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 739/1137 [1:33:11<15:00,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 740/1137 [1:34:19<58:48,  8.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 33 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 33 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 741/1137 [1:35:32<1:51:54, 16.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 20 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 20 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 7 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 750/1137 [1:37:57<1:36:54, 15.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 28 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 28 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 756/1137 [1:38:51<1:19:04, 12.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 20 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 20 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 766/1137 [1:41:24<1:12:06, 11.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 18 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 18 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 6 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 770/1137 [1:43:12<1:31:39, 14.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 27 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 27 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 793/1137 [1:45:41<22:44,  3.97s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 31 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 31 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 810/1137 [1:47:01<22:11,  4.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 7 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 818/1137 [1:47:56<34:22,  6.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 821/1137 [1:49:37<1:20:22, 15.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 30 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 30 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 822/1137 [1:50:15<1:42:12, 19.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 32 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 32 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 857/1137 [1:51:54<10:34,  2.27s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 22 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 22 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 858/1137 [1:52:19<20:07,  4.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 860/1137 [1:53:27<46:38, 10.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 29 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 29 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 878/1137 [1:55:22<16:24,  3.80s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 879/1137 [1:55:26<17:00,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 9 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 881/1137 [1:57:09<1:13:14, 17.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 33 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 33 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 891/1137 [1:57:48<29:52,  7.29s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 898/1137 [1:59:29<34:35,  8.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 15 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 15 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 899/1137 [2:01:34<1:28:23, 22.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 31 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 31 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 928/1137 [2:03:54<15:00,  4.31s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 22 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 22 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 934/1137 [2:06:06<38:50, 11.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 20 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 20 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 943/1137 [2:06:59<21:58,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 18 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 18 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 6 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 949/1137 [2:09:00<43:30, 13.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 18 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 18 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 8 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 964/1137 [2:11:23<16:12,  5.62s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 29 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 29 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 972/1137 [2:12:35<18:34,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 18 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 18 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 973/1137 [2:12:54<27:38, 10.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 979/1137 [2:14:12<24:41,  9.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 19 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 19 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 988/1137 [2:15:16<14:28,  5.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 8 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 998/1137 [2:16:48<18:09,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 29 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 29 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 1010/1137 [2:19:24<22:10, 10.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 18 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 18 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 1012/1137 [2:19:48<22:36, 10.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 1026/1137 [2:21:39<08:57,  4.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 21 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 21 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1043/1137 [2:23:38<06:17,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 28 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 28 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1050/1137 [2:25:38<14:19,  9.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 22 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 22 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 1051/1137 [2:26:18<20:41, 14.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 1062/1137 [2:28:15<10:28,  8.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 11 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 11 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 11 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 1070/1137 [2:30:19<09:57,  8.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 19 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 19 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 1081/1137 [2:32:22<07:46,  8.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 6 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 6 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 1094/1137 [2:34:35<04:13,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 19 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 19 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 1096/1137 [2:35:08<05:50,  8.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 1 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 1117/1137 [2:36:36<01:06,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 24 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 24 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 1119/1137 [2:37:15<01:51,  6.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 3 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 1121/1137 [2:38:41<03:32, 13.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 14 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 14 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 2 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 1130/1137 [2:40:50<01:07,  9.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 29 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 29 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 4 seconds: {'error': {'message': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None', 'type': None, 'param': None, 'code': '429'}}. Retry count = 1\n",
      "Rate limit exceeded. Retrying in 60 seconds: {'error': {'message': \"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\", 'type': 'None', 'param': 'None', 'code': '429'}}. Retry count = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1137/1137 [2:42:58<00:00,  8.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   claim_exp_index  claim_per_video_index most_similar_claim_index  \\\n",
      "0             4782                      3                     6291   \n",
      "1             6291                     25                     4782   \n",
      "2             6292                     26                     3082   \n",
      "3             6293                     27                     3082   \n",
      "\n",
      "  similarity_score  \n",
      "0                5  \n",
      "1                5  \n",
      "2                5  \n",
      "3                5  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#get similarity scores for claims using GPT4o:\n",
    "#adjusted request to compare claims only with preceding claims in previous comments, so not preceding claims within the same comment:\n",
    "#get simscore for posts using GPT4o:\n",
    "\n",
    "chunked_result: typing.List[pd.DataFrame] = []\n",
    "GROUPER='videoTitle'\n",
    "#sort data by Time_comment\n",
    "YT_input_sort = YT_claim_embeds_exp_explode.sort_values(by=['Time_comment_dt','ascending_comment_index'], ascending=True).reset_index(drop=False)\n",
    "groupeddata = YT_input_sort.groupby(GROUPER)\n",
    "\n",
    "for group, df in tqdm.tqdm(groupeddata):\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df = df.loc[df.claims_exp_split != '',:]\n",
    "    df.sort_values(by=['Time_comment_dt','ascending_comment_index'], ascending=True).reset_index(drop=False)\n",
    "    for index, row in df.iterrows():\n",
    "        if pd.notna(row['preceding_comment_index']):\n",
    "            if row['claims_exp_split'] != '':\n",
    "                retry_count = 0\n",
    "                max_retries = 10\n",
    "\n",
    "                while retry_count < max_retries:\n",
    "                    try:  \n",
    "                        response = requests.post(\n",
    "                                url=api_endpoint,\n",
    "                                headers=headers,\n",
    "                                json={\n",
    "                                    'model': MODELgpt4o,\n",
    "                                    'messages': [\n",
    "                                        {\n",
    "                                            \"role\": \"system\",\n",
    "                                            \"content\": SYSTEM_claim_simscore                        \n",
    "                                        },\n",
    "                                        {\n",
    "                                            \"role\": \"user\",\n",
    "                                            \"content\": f'\"Target claim\":<<{row[\"claims_exp_split\"]}>>, \"preceding claims\":\\n<{df.loc[df.ascending_comment_index != row['ascending_comment_index'], ['exp_explode_index', 'claims_exp_split']].iloc[:index].to_json(orient='records')}>'\n",
    "                                        }\n",
    "                                    ],\n",
    "                                    'temperature': temperature_0,  \n",
    "                                    'seed': SEED\n",
    "                                }\n",
    "                            )\n",
    "\n",
    "                        if response.status_code == 200:\n",
    "                            data_response = response.json()\n",
    "                            # Check if 'response' key exists in the JSON response\n",
    "                            if 'choices' in data_response:\n",
    "                                content = data_response[\"choices\"][0][\"message\"][\"content\"]\n",
    "                                # Remove code block markers if present\n",
    "                                content = re.sub(r'```json|```', '', content).strip()\n",
    "                                try:\n",
    "                                    content = json.loads(content)   \n",
    "                                    # Check if content_json is a list or a dictionary\n",
    "                                    if isinstance(content, dict):\n",
    "                                        chunked_result.append({\n",
    "                                            \"claim_exp_index\": row['exp_explode_index'],\n",
    "                                            'claim_per_video_index': row['claim_per_video_index'],\n",
    "                                            \"most_similar_claim_index\": content.get('most_similar_claim_index', ''),\n",
    "                                            'similarity_score': content.get('similarity_score', '')  \n",
    "                                        })\n",
    "                                    elif isinstance(content, list):\n",
    "                                        for item in content:\n",
    "                                            chunked_result.append({\n",
    "                                            \"claim_exp_index\": row['exp_explode_index'],\n",
    "                                            'claim_per_video_index': row['claim_per_video_index'],\n",
    "                                            \"most_similar_claim_index\": item.get('most_similar_claim_index', ''),\n",
    "                                            'similarity_score': item.get('similarity_score', '') \n",
    "                                            })\n",
    "                                    else:\n",
    "                                        print(f\"Unexpected content type: {type(content)}\")\n",
    "\n",
    "                                except json.JSONDecodeError as e:\n",
    "                                    print(f\"Error decoding JSON: {e}\")\n",
    "                                    print(data_response)\n",
    "                            else:\n",
    "                                print(f\"No 'choices' key in response or 'choices' is empty: {content}\")                        \n",
    "                            break  # Exit the retry loop on success  \n",
    "                        elif response.status_code == 429:\n",
    "                            retry_count += 1\n",
    "                            retry_after = response.headers.get(\"Retry-After\")\n",
    "                            error_message = response.json().get(\"error\", {}).get(\"message\", \"\")\n",
    "                            retry_after = 30  # Default to 30 seconds if not found\n",
    "\n",
    "                            # Extract retry time from the error message\n",
    "                            if \"Try again in\" in error_message:\n",
    "                                match = re.search(r\"Try again in (\\d+) second\", error_message)\n",
    "                                if match:\n",
    "                                    try:\n",
    "                                        retry_after = int(match.group(1))\n",
    "                                    except (IndexError, ValueError) as e:\n",
    "                                        print(f\"Rate limit exceeded. Error extracting retry time: {e}. Retrying in {retry_after} seconds.\")\n",
    "                                        pass\n",
    "                            elif \"Please retry after\" in error_message:\n",
    "                                match = re.search(r\"Please retry after (\\d+) second\", error_message)\n",
    "                                if match:\n",
    "                                    try:\n",
    "                                        retry_after = int(match.group(1))\n",
    "                                    except (IndexError, ValueError) as e:\n",
    "                                        print(f\"Rate limit exceeded. Error extracting retry time: {e}. Retrying in {retry_after} seconds.\")\n",
    "                                        pass\n",
    "                                    \n",
    "                                    \n",
    "                            else:\n",
    "                                retry_after = 30  # Default to 30 seconds if not found\n",
    "                                print(f\"Rate limit exceeded. Defaulting to retry in {retry_after} seconds.\")\n",
    "\n",
    "\n",
    "                            print(f\"Rate limit exceeded. Retrying in {retry_after} seconds: {response.json()}. Retry count = {retry_count}\") \n",
    "                            time.sleep(retry_after)\n",
    "\n",
    "                        #    print(f\"Rate limit exceeded. Retrying in {wait_time} seconds...\")\n",
    "                        #    print(response.text)\n",
    "                        #    time.sleep(wait_time)\n",
    "                        elif response.status_code == 500:\n",
    "                            retry_count += 1\n",
    "                            wait_time = 20\n",
    "                            print(f\"Failed to connect to API. Status code: {response.status_code}. Retrying in {wait_time} seconds...\")\n",
    "                            print(response.text)\n",
    "                            time.sleep(wait_time)\n",
    "                        else:\n",
    "                            print(f\"Failed to connect to API. Status code: {response.status_code}\")\n",
    "                            print(response.text)\n",
    "                            break\n",
    "                    except requests.exceptions.RequestException as e:   \n",
    "                        print(f\"Failed to connect to API: {e}\")\n",
    "                        retry_count += 1\n",
    "                        wait_time = 60\n",
    "                        print(f\"Retrying in {wait_time} seconds...\")\n",
    "                        time.sleep(wait_time)   \n",
    "\n",
    "                    if retry_count >= max_retries:\n",
    "                        print(f\"Max retries reached for index {index}. Skipping to next item.\")\n",
    "                        break  # Exit the loop if max retries are reached              \n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "similarity_claim_exp = pd.DataFrame(chunked_result)\n",
    "\n",
    "# Display the DataFrame to verify the changes\n",
    "print(similarity_claim_exp.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['StartDate',\n",
       " 'RecordedDate',\n",
       " 'IPAddress',\n",
       " 'Finished',\n",
       " 'Coder',\n",
       " 'ID',\n",
       " 'Mark_ID',\n",
       " 'Genre',\n",
       " 'topiccode',\n",
       " 'Platform',\n",
       " 'Anonymity',\n",
       " 'Anonymity_9_TEXT',\n",
       " 'codable',\n",
       " 'Interaction',\n",
       " 'Acknowledgement',\n",
       " 'TopicRelevance',\n",
       " 'Reasoning',\n",
       " 'BackgroundInfo',\n",
       " 'ExternalEvidence',\n",
       " 'ExternalEvidence_1_TEXT',\n",
       " 'Opinion',\n",
       " 'disagreement',\n",
       " 'Ideologicaldirection',\n",
       " 'Name_calling',\n",
       " 'Vulgarity',\n",
       " 'Attack_reputation',\n",
       " 'Question_Intelligenc',\n",
       " 'All_caps_function',\n",
       " 'Sarcasm_to_criticize',\n",
       " 'Individual_right',\n",
       " 'discrimination',\n",
       " 'Invoke_violence',\n",
       " 'Tone',\n",
       " 'INTERACTIVITY_DUMMY',\n",
       " 'RATIONALITY_DUMMY',\n",
       " 'HAS_OPINION_DUMMY',\n",
       " 'LIBERAL_NEUTRAL_CONSERVATIVE',\n",
       " 'LIBERAL_DUMMY',\n",
       " 'CONSERVATIVE_DUMMY',\n",
       " 'NAMECALLING_DUMMY',\n",
       " 'VULGAR_DUMMY',\n",
       " 'NAMECALLING_VULGAR_DUMMY',\n",
       " 'INCIVILITY_ORDINAL',\n",
       " 'INCIVILITY_DUMMY',\n",
       " 'INTOLERANCE_DUMMY',\n",
       " 'filter_$',\n",
       " 'IMPOLITENESS_DUMMY',\n",
       " 'commentText',\n",
       " 'showName',\n",
       " 'genre',\n",
       " 'Time_comment',\n",
       " 'likeCount_comment',\n",
       " 'entities',\n",
       " 'place',\n",
       " 'retweet_count',\n",
       " 'platform',\n",
       " 'retweeted',\n",
       " 'language',\n",
       " 'source',\n",
       " 'in_reply_to_status_id_str',\n",
       " 'in_reply_to_user_id_str',\n",
       " 'in_reply_to_screen_name',\n",
       " 'is_quote_status',\n",
       " 'videoTitle',\n",
       " 'description',\n",
       " 'Time_video',\n",
       " 'channelTitle',\n",
       " 'channelId',\n",
       " 'viewCount',\n",
       " 'dislikeCount_video',\n",
       " 'likeCount_video',\n",
       " 'date_difference',\n",
       " 'commentCount_video',\n",
       " 'replyCount_comment',\n",
       " 'topic',\n",
       " 'subscribers',\n",
       " 'HATELIST_FOCUSED_DUMMY',\n",
       " 'Time_comment_year',\n",
       " 'Time_video_year',\n",
       " 'interactivity_acknowledgement',\n",
       " 'political_ideology',\n",
       " 'rationality_external_evidence',\n",
       " 'rationality_topic_relevance',\n",
       " 'political_negativity',\n",
       " 'rationality_background_info',\n",
       " 'rationality_reasoning',\n",
       " 'sentiment',\n",
       " 'offensive',\n",
       " 'topics',\n",
       " 'emotions',\n",
       " 'irony',\n",
       " 'hate',\n",
       " 'topiccodeSTR',\n",
       " 'claim_run1',\n",
       " 'claim_optdef',\n",
       " 'claim_optdef_embed_MXBAI',\n",
       " 'claim_optlow',\n",
       " 'claim_optlow_MXBAI',\n",
       " 'tfidf_embed_post',\n",
       " 'embed_MXBAI_post',\n",
       " 'cosine_similarity_post_claim_MXBAI',\n",
       " 'cosine_low_high_MXBAI',\n",
       " 'tfidf_embed_post_svd',\n",
       " 'Llama31_political_post_8b',\n",
       " 'Llama31_political_fill_8b',\n",
       " 'Llama31_political_fill_8b_score',\n",
       " 'political_post_gpt4o',\n",
       " 'political_post_gpt4o_dum',\n",
       " 'either_political',\n",
       " 'Time_comment_dt',\n",
       " 'post_ada_embedding',\n",
       " 'claims_gpt4o',\n",
       " 'post_expansion_gpt4o_token10',\n",
       " 'most_similar_index_gpt4o',\n",
       " 'similarity_score_gpt4o',\n",
       " 'commentText_most_sim_gpt4o',\n",
       " 'claims_ext_gpt4o_token10',\n",
       " 'post_index',\n",
       " 'most_similar_ext_ID_gpt4o_token10',\n",
       " 'similarity_score_ext_gpt4o_token10',\n",
       " 'post_expenasion_most_sim_gpt4o_token10',\n",
       " 'dataset_index',\n",
       " 'post_expansion_gpt4o',\n",
       " 'claims_ext_gpt4o',\n",
       " 'post_index_ext_gpt4o',\n",
       " 'most_similar_ext_ID_gpt4o',\n",
       " 'similarity_score_ext_gpt4o',\n",
       " 'post_expenasion_most_sim_gpt4o',\n",
       " 'claims_exp_split',\n",
       " 'ascending_comment_index_sort',\n",
       " 'preceding_comment_index_sort',\n",
       " 'ascending_comment_index',\n",
       " 'preceding_comment_index',\n",
       " 'exp_explode_index',\n",
       " 'claim_per_video_index']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YT_claim_embeds_exp_explode.columns.to_list()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim_exp_index</th>\n",
       "      <th>claim_per_video_index</th>\n",
       "      <th>most_similar_claim_index</th>\n",
       "      <th>similarity_score</th>\n",
       "      <th>Mark_ID</th>\n",
       "      <th>claims_ext_gpt4o</th>\n",
       "      <th>claims_exp_split</th>\n",
       "      <th>ascending_comment_index</th>\n",
       "      <th>preceding_comment_index</th>\n",
       "      <th>claim_per_video_index_source</th>\n",
       "      <th>Time_comment_dt</th>\n",
       "      <th>exp_explode_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4782</td>\n",
       "      <td>3</td>\n",
       "      <td>6291</td>\n",
       "      <td>5</td>\n",
       "      <td>2001794</td>\n",
       "      <td>[\"Stop killing innocent people\"]</td>\n",
       "      <td>Stop killing innocent people</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-04-15 01:47:04+00:00</td>\n",
       "      <td>4782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6291</td>\n",
       "      <td>25</td>\n",
       "      <td>4782</td>\n",
       "      <td>5</td>\n",
       "      <td>20001003</td>\n",
       "      <td>[\"The Syrian crisis is a horrible thing\", \"Al Assad is against Daesh and the rebels\", \"Putin is ...</td>\n",
       "      <td>The Syrian crisis is a horrible thing</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25</td>\n",
       "      <td>2018-04-15 01:48:53+00:00</td>\n",
       "      <td>6291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6292</td>\n",
       "      <td>26</td>\n",
       "      <td>3082</td>\n",
       "      <td>5</td>\n",
       "      <td>20001003</td>\n",
       "      <td>[\"The Syrian crisis is a horrible thing\", \"Al Assad is against Daesh and the rebels\", \"Putin is ...</td>\n",
       "      <td>Al Assad is against Daesh and the rebels</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26</td>\n",
       "      <td>2018-04-15 01:48:53+00:00</td>\n",
       "      <td>6292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6293</td>\n",
       "      <td>27</td>\n",
       "      <td>3082</td>\n",
       "      <td>5</td>\n",
       "      <td>20001003</td>\n",
       "      <td>[\"The Syrian crisis is a horrible thing\", \"Al Assad is against Daesh and the rebels\", \"Putin is ...</td>\n",
       "      <td>Putin is aligned with al Assad to combat Daesh</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27</td>\n",
       "      <td>2018-04-15 01:48:53+00:00</td>\n",
       "      <td>6293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6294</td>\n",
       "      <td>28</td>\n",
       "      <td>3082</td>\n",
       "      <td>5</td>\n",
       "      <td>20001003</td>\n",
       "      <td>[\"The Syrian crisis is a horrible thing\", \"Al Assad is against Daesh and the rebels\", \"Putin is ...</td>\n",
       "      <td>The U.S. is against al Assad</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28</td>\n",
       "      <td>2018-04-15 01:48:53+00:00</td>\n",
       "      <td>6294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3326</th>\n",
       "      <td>4630</td>\n",
       "      <td>0</td>\n",
       "      <td>2223</td>\n",
       "      <td>6</td>\n",
       "      <td>2001730</td>\n",
       "      <td>[\"John Oliver is using celebrities to mislead Americans about Assad\", \"American taxpayer money i...</td>\n",
       "      <td>John Oliver is using celebrities to mislead Americans about Assad</td>\n",
       "      <td>15</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-17 11:33:09+00:00</td>\n",
       "      <td>4630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3327</th>\n",
       "      <td>4631</td>\n",
       "      <td>1</td>\n",
       "      <td>6012</td>\n",
       "      <td>7</td>\n",
       "      <td>2001730</td>\n",
       "      <td>[\"John Oliver is using celebrities to mislead Americans about Assad\", \"American taxpayer money i...</td>\n",
       "      <td>American taxpayer money is funding Al Qaeda and ISIS</td>\n",
       "      <td>15</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-04-17 11:33:09+00:00</td>\n",
       "      <td>4631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3328</th>\n",
       "      <td>4632</td>\n",
       "      <td>0</td>\n",
       "      <td>4352</td>\n",
       "      <td>5</td>\n",
       "      <td>2001730</td>\n",
       "      <td>[\"John Oliver is using celebrities to mislead Americans about Assad\", \"American taxpayer money i...</td>\n",
       "      <td>Obama is responsible for drone strikes killing innocents</td>\n",
       "      <td>15</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-17 11:33:09+00:00</td>\n",
       "      <td>4632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3329</th>\n",
       "      <td>4633</td>\n",
       "      <td>0</td>\n",
       "      <td>6012</td>\n",
       "      <td>5</td>\n",
       "      <td>2001730</td>\n",
       "      <td>[\"John Oliver is using celebrities to mislead Americans about Assad\", \"American taxpayer money i...</td>\n",
       "      <td>Liberals are responsible for supporting harmful actions</td>\n",
       "      <td>15</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-17 11:33:09+00:00</td>\n",
       "      <td>4633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3330</th>\n",
       "      <td>3154</td>\n",
       "      <td>8</td>\n",
       "      <td>6018</td>\n",
       "      <td>6</td>\n",
       "      <td>2001046</td>\n",
       "      <td>[\"Bashar Alassad is manipulating you every time\"]</td>\n",
       "      <td>Bashar Alassad is manipulating you every time</td>\n",
       "      <td>16</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2018-12-20 21:12:47+00:00</td>\n",
       "      <td>3154</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3331 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      claim_exp_index  claim_per_video_index most_similar_claim_index  \\\n",
       "0                4782                      3                     6291   \n",
       "1                6291                     25                     4782   \n",
       "2                6292                     26                     3082   \n",
       "3                6293                     27                     3082   \n",
       "4                6294                     28                     3082   \n",
       "...               ...                    ...                      ...   \n",
       "3326             4630                      0                     2223   \n",
       "3327             4631                      1                     6012   \n",
       "3328             4632                      0                     4352   \n",
       "3329             4633                      0                     6012   \n",
       "3330             3154                      8                     6018   \n",
       "\n",
       "     similarity_score   Mark_ID  \\\n",
       "0                   5   2001794   \n",
       "1                   5  20001003   \n",
       "2                   5  20001003   \n",
       "3                   5  20001003   \n",
       "4                   5  20001003   \n",
       "...               ...       ...   \n",
       "3326                6   2001730   \n",
       "3327                7   2001730   \n",
       "3328                5   2001730   \n",
       "3329                5   2001730   \n",
       "3330                6   2001046   \n",
       "\n",
       "                                                                                         claims_ext_gpt4o  \\\n",
       "0                                                                        [\"Stop killing innocent people\"]   \n",
       "1     [\"The Syrian crisis is a horrible thing\", \"Al Assad is against Daesh and the rebels\", \"Putin is ...   \n",
       "2     [\"The Syrian crisis is a horrible thing\", \"Al Assad is against Daesh and the rebels\", \"Putin is ...   \n",
       "3     [\"The Syrian crisis is a horrible thing\", \"Al Assad is against Daesh and the rebels\", \"Putin is ...   \n",
       "4     [\"The Syrian crisis is a horrible thing\", \"Al Assad is against Daesh and the rebels\", \"Putin is ...   \n",
       "...                                                                                                   ...   \n",
       "3326  [\"John Oliver is using celebrities to mislead Americans about Assad\", \"American taxpayer money i...   \n",
       "3327  [\"John Oliver is using celebrities to mislead Americans about Assad\", \"American taxpayer money i...   \n",
       "3328  [\"John Oliver is using celebrities to mislead Americans about Assad\", \"American taxpayer money i...   \n",
       "3329  [\"John Oliver is using celebrities to mislead Americans about Assad\", \"American taxpayer money i...   \n",
       "3330                                                    [\"Bashar Alassad is manipulating you every time\"]   \n",
       "\n",
       "                                                       claims_exp_split  \\\n",
       "0                                          Stop killing innocent people   \n",
       "1                                 The Syrian crisis is a horrible thing   \n",
       "2                              Al Assad is against Daesh and the rebels   \n",
       "3                        Putin is aligned with al Assad to combat Daesh   \n",
       "4                                          The U.S. is against al Assad   \n",
       "...                                                                 ...   \n",
       "3326  John Oliver is using celebrities to mislead Americans about Assad   \n",
       "3327               American taxpayer money is funding Al Qaeda and ISIS   \n",
       "3328           Obama is responsible for drone strikes killing innocents   \n",
       "3329            Liberals are responsible for supporting harmful actions   \n",
       "3330                      Bashar Alassad is manipulating you every time   \n",
       "\n",
       "      ascending_comment_index  preceding_comment_index  \\\n",
       "0                           1                      0.0   \n",
       "1                           2                      1.0   \n",
       "2                           2                      1.0   \n",
       "3                           2                      1.0   \n",
       "4                           2                      1.0   \n",
       "...                       ...                      ...   \n",
       "3326                       15                     14.0   \n",
       "3327                       15                     14.0   \n",
       "3328                       15                     14.0   \n",
       "3329                       15                     14.0   \n",
       "3330                       16                     15.0   \n",
       "\n",
       "      claim_per_video_index_source           Time_comment_dt  \\\n",
       "0                                3 2018-04-15 01:47:04+00:00   \n",
       "1                               25 2018-04-15 01:48:53+00:00   \n",
       "2                               26 2018-04-15 01:48:53+00:00   \n",
       "3                               27 2018-04-15 01:48:53+00:00   \n",
       "4                               28 2018-04-15 01:48:53+00:00   \n",
       "...                            ...                       ...   \n",
       "3326                             0 2018-04-17 11:33:09+00:00   \n",
       "3327                             1 2018-04-17 11:33:09+00:00   \n",
       "3328                             0 2018-04-17 11:33:09+00:00   \n",
       "3329                             0 2018-04-17 11:33:09+00:00   \n",
       "3330                             8 2018-12-20 21:12:47+00:00   \n",
       "\n",
       "      exp_explode_index  \n",
       "0                  4782  \n",
       "1                  6291  \n",
       "2                  6292  \n",
       "3                  6293  \n",
       "4                  6294  \n",
       "...                 ...  \n",
       "3326               4630  \n",
       "3327               4631  \n",
       "3328               4632  \n",
       "3329               4633  \n",
       "3330               3154  \n",
       "\n",
       "[3331 rows x 12 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_claim_exp.merge(YT_claim_embeds_exp_explode.loc[:, ['Mark_ID', 'claims_ext_gpt4o', 'claims_exp_split', 'ascending_comment_index', 'preceding_comment_index', 'claim_per_video_index', 'Time_comment_dt', 'exp_explode_index']], left_on='claim_exp_index', right_on='exp_explode_index', suffixes=('', '_source'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "YT_claim_embeds_exp_explode_join = YT_claim_embeds_exp_explode.merge(similarity_claim_exp.loc[:, ['claim_exp_index', 'most_similar_claim_index', 'similarity_score']], left_on='exp_explode_index', right_on='claim_exp_index', suffixes=('', '_exp_gpt4o'), how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['StartDate',\n",
       " 'RecordedDate',\n",
       " 'IPAddress',\n",
       " 'Finished',\n",
       " 'Coder',\n",
       " 'ID',\n",
       " 'Mark_ID',\n",
       " 'Genre',\n",
       " 'topiccode',\n",
       " 'Platform',\n",
       " 'Anonymity',\n",
       " 'Anonymity_9_TEXT',\n",
       " 'codable',\n",
       " 'Interaction',\n",
       " 'Acknowledgement',\n",
       " 'TopicRelevance',\n",
       " 'Reasoning',\n",
       " 'BackgroundInfo',\n",
       " 'ExternalEvidence',\n",
       " 'ExternalEvidence_1_TEXT',\n",
       " 'Opinion',\n",
       " 'disagreement',\n",
       " 'Ideologicaldirection',\n",
       " 'Name_calling',\n",
       " 'Vulgarity',\n",
       " 'Attack_reputation',\n",
       " 'Question_Intelligenc',\n",
       " 'All_caps_function',\n",
       " 'Sarcasm_to_criticize',\n",
       " 'Individual_right',\n",
       " 'discrimination',\n",
       " 'Invoke_violence',\n",
       " 'Tone',\n",
       " 'INTERACTIVITY_DUMMY',\n",
       " 'RATIONALITY_DUMMY',\n",
       " 'HAS_OPINION_DUMMY',\n",
       " 'LIBERAL_NEUTRAL_CONSERVATIVE',\n",
       " 'LIBERAL_DUMMY',\n",
       " 'CONSERVATIVE_DUMMY',\n",
       " 'NAMECALLING_DUMMY',\n",
       " 'VULGAR_DUMMY',\n",
       " 'NAMECALLING_VULGAR_DUMMY',\n",
       " 'INCIVILITY_ORDINAL',\n",
       " 'INCIVILITY_DUMMY',\n",
       " 'INTOLERANCE_DUMMY',\n",
       " 'filter_$',\n",
       " 'IMPOLITENESS_DUMMY',\n",
       " 'commentText',\n",
       " 'showName',\n",
       " 'genre',\n",
       " 'Time_comment',\n",
       " 'likeCount_comment',\n",
       " 'entities',\n",
       " 'place',\n",
       " 'retweet_count',\n",
       " 'platform',\n",
       " 'retweeted',\n",
       " 'language',\n",
       " 'source',\n",
       " 'in_reply_to_status_id_str',\n",
       " 'in_reply_to_user_id_str',\n",
       " 'in_reply_to_screen_name',\n",
       " 'is_quote_status',\n",
       " 'videoTitle',\n",
       " 'description',\n",
       " 'Time_video',\n",
       " 'channelTitle',\n",
       " 'channelId',\n",
       " 'viewCount',\n",
       " 'dislikeCount_video',\n",
       " 'likeCount_video',\n",
       " 'date_difference',\n",
       " 'commentCount_video',\n",
       " 'replyCount_comment',\n",
       " 'topic',\n",
       " 'subscribers',\n",
       " 'HATELIST_FOCUSED_DUMMY',\n",
       " 'Time_comment_year',\n",
       " 'Time_video_year',\n",
       " 'interactivity_acknowledgement',\n",
       " 'political_ideology',\n",
       " 'rationality_external_evidence',\n",
       " 'rationality_topic_relevance',\n",
       " 'political_negativity',\n",
       " 'rationality_background_info',\n",
       " 'rationality_reasoning',\n",
       " 'sentiment',\n",
       " 'offensive',\n",
       " 'topics',\n",
       " 'emotions',\n",
       " 'irony',\n",
       " 'hate',\n",
       " 'topiccodeSTR',\n",
       " 'claim_run1',\n",
       " 'claim_optdef',\n",
       " 'claim_optdef_embed_MXBAI',\n",
       " 'claim_optlow',\n",
       " 'claim_optlow_MXBAI',\n",
       " 'tfidf_embed_post',\n",
       " 'embed_MXBAI_post',\n",
       " 'cosine_similarity_post_claim_MXBAI',\n",
       " 'cosine_low_high_MXBAI',\n",
       " 'tfidf_embed_post_svd',\n",
       " 'Llama31_political_post_8b',\n",
       " 'Llama31_political_fill_8b',\n",
       " 'Llama31_political_fill_8b_score',\n",
       " 'political_post_gpt4o',\n",
       " 'political_post_gpt4o_dum',\n",
       " 'either_political',\n",
       " 'Time_comment_dt',\n",
       " 'post_ada_embedding',\n",
       " 'claims_gpt4o',\n",
       " 'post_expansion_gpt4o_token10',\n",
       " 'most_similar_index_gpt4o',\n",
       " 'similarity_score_gpt4o',\n",
       " 'commentText_most_sim_gpt4o',\n",
       " 'claims_ext_gpt4o_token10',\n",
       " 'post_index',\n",
       " 'most_similar_ext_ID_gpt4o_token10',\n",
       " 'similarity_score_ext_gpt4o_token10',\n",
       " 'post_expenasion_most_sim_gpt4o_token10',\n",
       " 'dataset_index',\n",
       " 'post_expansion_gpt4o',\n",
       " 'claims_ext_gpt4o',\n",
       " 'post_index_ext_gpt4o',\n",
       " 'most_similar_ext_ID_gpt4o',\n",
       " 'similarity_score_ext_gpt4o',\n",
       " 'post_expenasion_most_sim_gpt4o',\n",
       " 'claims_exp_split',\n",
       " 'ascending_comment_index_sort',\n",
       " 'preceding_comment_index_sort',\n",
       " 'ascending_comment_index',\n",
       " 'preceding_comment_index',\n",
       " 'exp_explode_index',\n",
       " 'claim_per_video_index',\n",
       " 'claim_exp_index',\n",
       " 'most_similar_claim_index',\n",
       " 'similarity_score']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YT_claim_embeds_exp_explode_join.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "YT_claim_embeds_exp_explode_join.rename(columns={'most_similar_claim_index': 'most_similar_claim_index_exp_gpt4o', 'similarity_score': 'similarity_score_claim_exp_gpt4o'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "most_similar_claim_index_exp_gpt4o    object\n",
       "exp_explode_index                      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YT_claim_embeds_exp_explode_join.loc[:, ['most_similar_claim_index_exp_gpt4o', 'exp_explode_index']].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_int(value):\n",
    "    if isinstance(value, list):\n",
    "        return np.nan\n",
    "    try:\n",
    "        return int(value)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "YT_claim_embeds_exp_explode_join.loc[: , 'most_similar_claim_index_exp_gpt4o_int'] = YT_claim_embeds_exp_explode_join['most_similar_claim_index_exp_gpt4o'].apply(convert_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "YT_claim_embeds_exp_explode_join = YT_claim_embeds_exp_explode_join.merge(YT_claim_embeds_exp_explode.loc[:, ['claims_exp_split', 'exp_explode_index']], left_on='most_similar_claim_index_exp_gpt4o_int', right_on='exp_explode_index', suffixes=('', '_most_similar'), how='left')\n",
    "YT_claim_embeds_exp_explode_join.drop(columns=['exp_explode_index_most_similar'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YT_claim_embeds_exp_explode_join.drop(columns=['most_similar_claim_index_exp_gpt4o'], inplace=True)\n",
    "YT_claim_embeds_exp_explode_join.loc[:, 'similarity_score_claim_exp_gpt4o'] = YT_claim_embeds_exp_explode_join['similarity_score_claim_exp_gpt4o'].apply(convert_to_int)\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data:\n",
    "YT_claim_embeds_exp_explode_join.to_parquet(f'{CFG.report_dir}/pubsphere_YT_post_claim_exp_explode.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load exploded claims data:\n",
    "YT_claim_embeds_exp_explode = pd.read_parquet(f'{CFG.report_dir}/pubsphere_YT_post_claim_exp_explode.parquet')\n",
    "YT_claim_embeds_explode = pd.read_parquet(f'{CFG.report_dir}/pubsphere_YT_post_claim_explode.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load packages and obtain the ADA embedding for expanded posts and original and expanded claims:\n",
    "from tqdm import tqdm          #run these lines to run the ADA progress bar\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['StartDate',\n",
       " 'RecordedDate',\n",
       " 'IPAddress',\n",
       " 'Finished',\n",
       " 'Coder',\n",
       " 'ID',\n",
       " 'Mark_ID',\n",
       " 'Genre',\n",
       " 'topiccode',\n",
       " 'Platform',\n",
       " 'Anonymity',\n",
       " 'Anonymity_9_TEXT',\n",
       " 'codable',\n",
       " 'Interaction',\n",
       " 'Acknowledgement',\n",
       " 'TopicRelevance',\n",
       " 'Reasoning',\n",
       " 'BackgroundInfo',\n",
       " 'ExternalEvidence',\n",
       " 'ExternalEvidence_1_TEXT',\n",
       " 'Opinion',\n",
       " 'disagreement',\n",
       " 'Ideologicaldirection',\n",
       " 'Name_calling',\n",
       " 'Vulgarity',\n",
       " 'Attack_reputation',\n",
       " 'Question_Intelligenc',\n",
       " 'All_caps_function',\n",
       " 'Sarcasm_to_criticize',\n",
       " 'Individual_right',\n",
       " 'discrimination',\n",
       " 'Invoke_violence',\n",
       " 'Tone',\n",
       " 'INTERACTIVITY_DUMMY',\n",
       " 'RATIONALITY_DUMMY',\n",
       " 'HAS_OPINION_DUMMY',\n",
       " 'LIBERAL_NEUTRAL_CONSERVATIVE',\n",
       " 'LIBERAL_DUMMY',\n",
       " 'CONSERVATIVE_DUMMY',\n",
       " 'NAMECALLING_DUMMY',\n",
       " 'VULGAR_DUMMY',\n",
       " 'NAMECALLING_VULGAR_DUMMY',\n",
       " 'INCIVILITY_ORDINAL',\n",
       " 'INCIVILITY_DUMMY',\n",
       " 'INTOLERANCE_DUMMY',\n",
       " 'filter_$',\n",
       " 'IMPOLITENESS_DUMMY',\n",
       " 'commentText',\n",
       " 'showName',\n",
       " 'genre',\n",
       " 'Time_comment',\n",
       " 'likeCount_comment',\n",
       " 'entities',\n",
       " 'place',\n",
       " 'retweet_count',\n",
       " 'platform',\n",
       " 'retweeted',\n",
       " 'language',\n",
       " 'source',\n",
       " 'in_reply_to_status_id_str',\n",
       " 'in_reply_to_user_id_str',\n",
       " 'in_reply_to_screen_name',\n",
       " 'is_quote_status',\n",
       " 'videoTitle',\n",
       " 'description',\n",
       " 'Time_video',\n",
       " 'channelTitle',\n",
       " 'channelId',\n",
       " 'viewCount',\n",
       " 'dislikeCount_video',\n",
       " 'likeCount_video',\n",
       " 'date_difference',\n",
       " 'commentCount_video',\n",
       " 'replyCount_comment',\n",
       " 'topic',\n",
       " 'subscribers',\n",
       " 'HATELIST_FOCUSED_DUMMY',\n",
       " 'Time_comment_year',\n",
       " 'Time_video_year',\n",
       " 'interactivity_acknowledgement',\n",
       " 'political_ideology',\n",
       " 'rationality_external_evidence',\n",
       " 'rationality_topic_relevance',\n",
       " 'political_negativity',\n",
       " 'rationality_background_info',\n",
       " 'rationality_reasoning',\n",
       " 'sentiment',\n",
       " 'offensive',\n",
       " 'topics',\n",
       " 'emotions',\n",
       " 'irony',\n",
       " 'hate',\n",
       " 'topiccodeSTR',\n",
       " 'claim_run1',\n",
       " 'claim_optdef',\n",
       " 'claim_optdef_embed_MXBAI',\n",
       " 'claim_optlow',\n",
       " 'claim_optlow_MXBAI',\n",
       " 'tfidf_embed_post',\n",
       " 'embed_MXBAI_post',\n",
       " 'cosine_similarity_post_claim_MXBAI',\n",
       " 'cosine_low_high_MXBAI',\n",
       " 'tfidf_embed_post_svd',\n",
       " 'Llama31_political_post_8b',\n",
       " 'Llama31_political_fill_8b',\n",
       " 'Llama31_political_fill_8b_score',\n",
       " 'political_post_gpt4o',\n",
       " 'political_post_gpt4o_dum',\n",
       " 'either_political',\n",
       " 'post_ada_embedding',\n",
       " 'dataset_index_x',\n",
       " 'post_expansion_gpt4o_token10',\n",
       " 'most_similar_index_gpt4o',\n",
       " 'similarity_score_gpt4o',\n",
       " 'commentText_most_sim_gpt4o',\n",
       " 'claims_ext_gpt4o_token10',\n",
       " 'post_expansion_gpt4o',\n",
       " 'claims_ext_gpt4o',\n",
       " 'most_similar_ext_ID_gpt4o',\n",
       " 'similarity_score_ext_gpt4o',\n",
       " 'post_expenasion_most_sim_gpt4o']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_claim_embeds.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Platform\n",
       "1    3119\n",
       "2       0\n",
       "Name: post_expansion_gpt4o, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_claim_embeds.groupby('Platform')['post_expansion_gpt4o'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                       sad\n",
       "1       That's a vicious insult!!! What did a box of rocks ever do to you that you would slander it like...\n",
       "3       Goya Solidar.  So there are a few of us left.  Try reading the comments on both Fox News and The...\n",
       "4                                                                   hello hello \\nNo-one else will hug him.\n",
       "5       Please spare us you BS, Pocahantas! You will never be president of ths great country, daughter o...\n",
       "                                                       ...                                                 \n",
       "3854                                                                             Hints from evil to evil...\n",
       "3855    If you were going to hire more than one person for this, then you should've hired the akatsuki c...\n",
       "3859    Nah, they knew all about the cameras.  I'm guessing they look nothing like the people think.  Th...\n",
       "3860    Alexander Hamilton. Troops are waiting in the fields for you. If you join us right now together ...\n",
       "3861    The Syrian crisis is a horrible thing, but has anyone noticed the situation’s strange components...\n",
       "Name: post_expansion_gpt4o, Length: 3132, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_claim_embeds.loc[~dataset_claim_embeds['post_expansion_gpt4o'].isna(), 'post_expansion_gpt4o']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3132/3132 [13:39<00:00,  3.82it/s] \n"
     ]
    }
   ],
   "source": [
    "dataset_claim_embeds.loc[:, 'post_exp_gpt4o_ada_embedding'] = dataset_claim_embeds.loc[~dataset_claim_embeds['post_expansion_gpt4o'].isna(), 'post_expansion_gpt4o'].progress_apply(get_ada_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_expansion_gpt4o</th>\n",
       "      <th>post_exp_gpt4o_ada_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sad</td>\n",
       "      <td>[0.0012491943780332804, -0.01312993373721838, 0.004941582679748535, -0.026987144723534584, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>That's a vicious insult!!! What did a box of rocks ever do to you that you would slander it like...</td>\n",
       "      <td>[-0.012995055876672268, -0.016615739092230797, 0.018477026373147964, -0.013490946963429451, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Goya Solidar.  So there are a few of us left.  Try reading the comments on both Fox News and The...</td>\n",
       "      <td>[-0.0008296146406792104, 0.0013742600567638874, 0.010784990154206753, -0.030297795310616493, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hello hello \\nNo-one else will hug him.</td>\n",
       "      <td>[-0.026431242004036903, -0.003406326286494732, 0.005844608414918184, -0.01946660876274109, -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3857</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3858</th>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3859</th>\n",
       "      <td>Nah, they knew all about the cameras.  I'm guessing they look nothing like the people think.  Th...</td>\n",
       "      <td>[0.002804453717544675, -0.009028810076415539, 0.024697821587324142, -0.02455144375562668, 0.0020...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3860</th>\n",
       "      <td>Alexander Hamilton. Troops are waiting in the fields for you. If you join us right now together ...</td>\n",
       "      <td>[-0.027749337255954742, -0.024834491312503815, -0.00856317114084959, -0.01075902208685875, 0.006...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3861</th>\n",
       "      <td>The Syrian crisis is a horrible thing, but has anyone noticed the situation’s strange components...</td>\n",
       "      <td>[-0.006858734413981438, 0.017054861411452293, -0.015412443317472935, -0.022704776376485825, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3862 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                     post_expansion_gpt4o  \\\n",
       "0                                                                                                     sad   \n",
       "1     That's a vicious insult!!! What did a box of rocks ever do to you that you would slander it like...   \n",
       "2                                                                                                    None   \n",
       "3     Goya Solidar.  So there are a few of us left.  Try reading the comments on both Fox News and The...   \n",
       "4                                                                 hello hello \\nNo-one else will hug him.   \n",
       "...                                                                                                   ...   \n",
       "3857                                                                                                 None   \n",
       "3858                                                                                                 None   \n",
       "3859  Nah, they knew all about the cameras.  I'm guessing they look nothing like the people think.  Th...   \n",
       "3860  Alexander Hamilton. Troops are waiting in the fields for you. If you join us right now together ...   \n",
       "3861  The Syrian crisis is a horrible thing, but has anyone noticed the situation’s strange components...   \n",
       "\n",
       "                                                                             post_exp_gpt4o_ada_embedding  \n",
       "0     [0.0012491943780332804, -0.01312993373721838, 0.004941582679748535, -0.026987144723534584, -0.01...  \n",
       "1     [-0.012995055876672268, -0.016615739092230797, 0.018477026373147964, -0.013490946963429451, -0.0...  \n",
       "2                                                                                                     NaN  \n",
       "3     [-0.0008296146406792104, 0.0013742600567638874, 0.010784990154206753, -0.030297795310616493, -0....  \n",
       "4     [-0.026431242004036903, -0.003406326286494732, 0.005844608414918184, -0.01946660876274109, -0.00...  \n",
       "...                                                                                                   ...  \n",
       "3857                                                                                                  NaN  \n",
       "3858                                                                                                  NaN  \n",
       "3859  [0.002804453717544675, -0.009028810076415539, 0.024697821587324142, -0.02455144375562668, 0.0020...  \n",
       "3860  [-0.027749337255954742, -0.024834491312503815, -0.00856317114084959, -0.01075902208685875, 0.006...  \n",
       "3861  [-0.006858734413981438, 0.017054861411452293, -0.015412443317472935, -0.022704776376485825, -0.0...  \n",
       "\n",
       "[3862 rows x 2 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check whether the embedding is correctly joined to the dataset, since it is only run on a subset...:\n",
    "dataset_claim_embeds.loc[:, ['post_expansion_gpt4o', 'post_exp_gpt4o_ada_embedding']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#appears correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6298 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6298/6298 [28:57<00:00,  3.63it/s]  \n"
     ]
    }
   ],
   "source": [
    "YT_claim_embeds_exp_explode.loc[:, 'claim_exp_ada_embedding'] = YT_claim_embeds_exp_explode[\"claims_exp_split\"].progress_apply(get_ada_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YT_claim_embeds_exp_explode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: we could test whether most similar claim is also the closest claim with respect to the ada embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6211/6211 [28:33<00:00,  3.62it/s]  \n"
     ]
    }
   ],
   "source": [
    "#get ADA embeddings for posts:\n",
    "YT_claim_embeds_explode.loc[:, 'claim_ada_embedding'] = YT_claim_embeds_explode['claims_split'].progress_apply(get_ada_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data:\n",
    "YT_claim_embeds_explode.to_parquet(f'{CFG.report_dir}/pubsphere_YT_post_claim_explode.parquet')\n",
    "YT_claim_embeds_exp_explode.to_parquet(f'{CFG.report_dir}/pubsphere_YT_post_claim_exp_explode.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select all YT threads with 2+ comments, to ensure the possibility of a discussion and proper time labelling (-> YT) of comments to determine chronological order of comments:\n",
    "YTdebatethreads = dataset_claim_embeds[dataset_claim_embeds['videoTitle'].isin(dataset_claim_embeds['videoTitle'].value_counts()[dataset_claim_embeds['videoTitle'].value_counts() >= 2].index)]\n",
    "YTdebatethreads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data:\n",
    "YTdebatethreads.to_parquet(f'{CFG.report_dir}/pubsphere_YT_debate_threads.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "videoTitle\n",
       "'Hannity' panel on the important questions Mueller needs to answer                                23\n",
       "Anderson Cooper lays out questions surrounding Mueller report                                     23\n",
       "Sanders: Bolton is a guy who likes war                                                            22\n",
       "Hannity: Trump puts Iran on notice after drone shot down                                          20\n",
       "\"Haley: Airstrikes \"\"crippled\"\" Syria’s chemical weapons program  \"                               20\n",
       "                                                                                                  ..\n",
       "Andrew Yang Shares His Big Idea For Universal Basic Income | NBC Nightly News                      2\n",
       "President Trump Signs Executive Order To Review National Monuments, Protected Lands | NBC News     2\n",
       "Accidental Icon: 64 Year-Old Fordham Professor Becomes A Fashion Star | NBC Nightly News           2\n",
       "Watch Live: Trump Delivers Remarks After El Paso And Dayton Weekend Shootings | NBC News           2\n",
       "Mueller Passes the Impeachment Buck to Congress | The Daily Show                                   2\n",
       "Name: count, Length: 466, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YTdebatethreads.videoTitle.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(5.281115879828326)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YTdebatethreads.videoTitle.value_counts().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the 466 videos contain on average 5.3 comments, with a minimum of 2 and a maximum of 23 comments\n",
    "#they comprise 466 / 1137 = 41.0% of the videos, and 2461 / 3132 = 78.6% of the YT comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Platform\n",
       "1    1137\n",
       "2       0\n",
       "Name: videoTitle, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_claim_embeds.groupby(['Platform'])['videoTitle'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['StartDate',\n",
       " 'RecordedDate',\n",
       " 'IPAddress',\n",
       " 'Finished',\n",
       " 'Coder',\n",
       " 'ID',\n",
       " 'Mark_ID',\n",
       " 'Genre',\n",
       " 'topiccode',\n",
       " 'Platform',\n",
       " 'Anonymity',\n",
       " 'Anonymity_9_TEXT',\n",
       " 'codable',\n",
       " 'Interaction',\n",
       " 'Acknowledgement',\n",
       " 'TopicRelevance',\n",
       " 'Reasoning',\n",
       " 'BackgroundInfo',\n",
       " 'ExternalEvidence',\n",
       " 'ExternalEvidence_1_TEXT',\n",
       " 'Opinion',\n",
       " 'disagreement',\n",
       " 'Ideologicaldirection',\n",
       " 'Name_calling',\n",
       " 'Vulgarity',\n",
       " 'Attack_reputation',\n",
       " 'Question_Intelligenc',\n",
       " 'All_caps_function',\n",
       " 'Sarcasm_to_criticize',\n",
       " 'Individual_right',\n",
       " 'discrimination',\n",
       " 'Invoke_violence',\n",
       " 'Tone',\n",
       " 'INTERACTIVITY_DUMMY',\n",
       " 'RATIONALITY_DUMMY',\n",
       " 'HAS_OPINION_DUMMY',\n",
       " 'LIBERAL_NEUTRAL_CONSERVATIVE',\n",
       " 'LIBERAL_DUMMY',\n",
       " 'CONSERVATIVE_DUMMY',\n",
       " 'NAMECALLING_DUMMY',\n",
       " 'VULGAR_DUMMY',\n",
       " 'NAMECALLING_VULGAR_DUMMY',\n",
       " 'INCIVILITY_ORDINAL',\n",
       " 'INCIVILITY_DUMMY',\n",
       " 'INTOLERANCE_DUMMY',\n",
       " 'filter_$',\n",
       " 'IMPOLITENESS_DUMMY',\n",
       " 'commentText',\n",
       " 'showName',\n",
       " 'genre',\n",
       " 'Time_comment',\n",
       " 'likeCount_comment',\n",
       " 'entities',\n",
       " 'place',\n",
       " 'retweet_count',\n",
       " 'platform',\n",
       " 'retweeted',\n",
       " 'language',\n",
       " 'source',\n",
       " 'in_reply_to_status_id_str',\n",
       " 'in_reply_to_user_id_str',\n",
       " 'in_reply_to_screen_name',\n",
       " 'is_quote_status',\n",
       " 'videoTitle',\n",
       " 'description',\n",
       " 'Time_video',\n",
       " 'channelTitle',\n",
       " 'channelId',\n",
       " 'viewCount',\n",
       " 'dislikeCount_video',\n",
       " 'likeCount_video',\n",
       " 'date_difference',\n",
       " 'commentCount_video',\n",
       " 'replyCount_comment',\n",
       " 'topic',\n",
       " 'subscribers',\n",
       " 'HATELIST_FOCUSED_DUMMY',\n",
       " 'Time_comment_year',\n",
       " 'Time_video_year',\n",
       " 'interactivity_acknowledgement',\n",
       " 'political_ideology',\n",
       " 'rationality_external_evidence',\n",
       " 'rationality_topic_relevance',\n",
       " 'political_negativity',\n",
       " 'rationality_background_info',\n",
       " 'rationality_reasoning',\n",
       " 'sentiment',\n",
       " 'offensive',\n",
       " 'topics',\n",
       " 'emotions',\n",
       " 'irony',\n",
       " 'hate',\n",
       " 'topiccodeSTR',\n",
       " 'claim_run1',\n",
       " 'claim_optdef',\n",
       " 'claim_optdef_embed_MXBAI',\n",
       " 'claim_optlow',\n",
       " 'claim_optlow_MXBAI',\n",
       " 'tfidf_embed_post',\n",
       " 'embed_MXBAI_post',\n",
       " 'cosine_similarity_post_claim_MXBAI',\n",
       " 'cosine_low_high_MXBAI',\n",
       " 'tfidf_embed_post_svd',\n",
       " 'Llama31_political_post_8b',\n",
       " 'Llama31_political_fill_8b',\n",
       " 'Llama31_political_fill_8b_score',\n",
       " 'political_post_gpt4o',\n",
       " 'political_post_gpt4o_dum',\n",
       " 'either_political',\n",
       " 'post_ada_embedding',\n",
       " 'dataset_index_x',\n",
       " 'post_expansion_gpt4o_token10',\n",
       " 'most_similar_index_gpt4o',\n",
       " 'similarity_score_gpt4o',\n",
       " 'commentText_most_sim_gpt4o',\n",
       " 'claims_ext_gpt4o_token10',\n",
       " 'post_expansion_gpt4o',\n",
       " 'claims_ext_gpt4o',\n",
       " 'most_similar_ext_ID_gpt4o',\n",
       " 'similarity_score_ext_gpt4o',\n",
       " 'post_expenasion_most_sim_gpt4o']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YTdebatethreads.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmdiv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
