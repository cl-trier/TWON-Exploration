{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/sstolwijk/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/sstolwijk/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "/home/sstolwijk/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import typing\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import config\n",
    "import src\n",
    "import requests\n",
    "import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "import logging\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = config.Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartDate</th>\n",
       "      <th>RecordedDate</th>\n",
       "      <th>IPAddress</th>\n",
       "      <th>Finished</th>\n",
       "      <th>Coder</th>\n",
       "      <th>ID</th>\n",
       "      <th>Mark_ID</th>\n",
       "      <th>Genre</th>\n",
       "      <th>topiccode</th>\n",
       "      <th>Platform</th>\n",
       "      <th>...</th>\n",
       "      <th>date_difference</th>\n",
       "      <th>commentCount_video</th>\n",
       "      <th>replyCount_comment</th>\n",
       "      <th>topic</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>HATELIST_FOCUSED_DUMMY</th>\n",
       "      <th>Time_comment_year</th>\n",
       "      <th>Time_video_year</th>\n",
       "      <th>tfidf_embedding</th>\n",
       "      <th>embed_MXP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/30/2021 13:03:17</td>\n",
       "      <td>5/30/2021 13:04:17</td>\n",
       "      <td>62.194.51.29</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgyPHwv8G0cDE6-wEgl4AaABAg.8_0ZjJKSJty8_0kXGkAd2U</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.40566757321357727, -0.032418690621852875, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/11/2021 10:34:05</td>\n",
       "      <td>10/11/2021 10:36:46</td>\n",
       "      <td>213.127.109.191</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Ugx2WXq9UdV8mPPjejJ4AaABAg.8yHCKV0Boe58yYRxEQEF45</td>\n",
       "      <td>282</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>743.0</td>\n",
       "      <td>1748.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>economy</td>\n",
       "      <td>3630000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.49942252039909363, -0.22240903973579407, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9/9/2021 18:49:48</td>\n",
       "      <td>9/9/2021 18:51:32</td>\n",
       "      <td>213.127.110.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1110578710648890000</td>\n",
       "      <td>372</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.6132397651672363, -0.3024018704891205, -0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6/6/2021 16:12:46</td>\n",
       "      <td>6/6/2021 16:16:16</td>\n",
       "      <td>213.127.76.145</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgwUPFScjJ0MCeaP2F54AaABAg.8lvp3fc9Euf8lvvgsUgEgV</td>\n",
       "      <td>769</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.27884048223495483, -0.3008716404438019, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6/13/2021 13:25:49</td>\n",
       "      <td>6/13/2021 13:27:28</td>\n",
       "      <td>213.127.82.232</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgwWKCWtSJdFvjGHvTp4AaABAg.8kUC5dGrQ2H8kUDRihE2f3</td>\n",
       "      <td>1206</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.5210463404655457, 0.03200243413448334, -0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3857</th>\n",
       "      <td>8/19/2021 14:50:13</td>\n",
       "      <td>8/19/2021 14:54:28</td>\n",
       "      <td>62.194.51.29</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1152219467579100000</td>\n",
       "      <td>10000695</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.5265525579452515, -0.1172720193862915, -0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3858</th>\n",
       "      <td>8/19/2021 15:10:27</td>\n",
       "      <td>8/19/2021 15:12:21</td>\n",
       "      <td>62.194.51.29</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1085362296472430000</td>\n",
       "      <td>10007008</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.5607972741127014, -0.20688456296920776, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3859</th>\n",
       "      <td>10/6/2021 16:08:39</td>\n",
       "      <td>10/6/2021 16:10:42</td>\n",
       "      <td>213.127.113.113</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UghFY3QJ6nmT_ngCoAEC.7-H0Z7--wxd8goqpaPs-bl</td>\n",
       "      <td>20000102</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3803.0</td>\n",
       "      <td>4785.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>east</td>\n",
       "      <td>6740000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.7534456253051758, -0.44059860706329346, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3860</th>\n",
       "      <td>10/15/2021 18:30:04</td>\n",
       "      <td>10/15/2021 18:35:40</td>\n",
       "      <td>213.127.109.191</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgyWabsmmnq3zam4DgZ4AaABAg</td>\n",
       "      <td>20000418</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1531.0</td>\n",
       "      <td>2206.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>east</td>\n",
       "      <td>6800000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.6457327604293823, -0.21125030517578125, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3861</th>\n",
       "      <td>11/19/2021 17:49:17</td>\n",
       "      <td>11/19/2021 17:51:04</td>\n",
       "      <td>213.127.109.191</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgwPOHIDyICm10k0Mvx4AaABAg</td>\n",
       "      <td>20001003</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2276.0</td>\n",
       "      <td>2887.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>east</td>\n",
       "      <td>549000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.14273801445960999, -0.12535151839256287, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3862 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                StartDate         RecordedDate        IPAddress  Finished  \\\n",
       "0      5/30/2021 13:03:17   5/30/2021 13:04:17     62.194.51.29         1   \n",
       "1     10/11/2021 10:34:05  10/11/2021 10:36:46  213.127.109.191         1   \n",
       "2       9/9/2021 18:49:48    9/9/2021 18:51:32    213.127.110.0         1   \n",
       "3       6/6/2021 16:12:46    6/6/2021 16:16:16   213.127.76.145         1   \n",
       "4      6/13/2021 13:25:49   6/13/2021 13:27:28   213.127.82.232         1   \n",
       "...                   ...                  ...              ...       ...   \n",
       "3857   8/19/2021 14:50:13   8/19/2021 14:54:28     62.194.51.29         1   \n",
       "3858   8/19/2021 15:10:27   8/19/2021 15:12:21     62.194.51.29         1   \n",
       "3859   10/6/2021 16:08:39   10/6/2021 16:10:42  213.127.113.113         1   \n",
       "3860  10/15/2021 18:30:04  10/15/2021 18:35:40  213.127.109.191         1   \n",
       "3861  11/19/2021 17:49:17  11/19/2021 17:51:04  213.127.109.191         1   \n",
       "\n",
       "      Coder                                                 ID   Mark_ID  \\\n",
       "0         6  UgyPHwv8G0cDE6-wEgl4AaABAg.8_0ZjJKSJty8_0kXGkAd2U       119   \n",
       "1         6  Ugx2WXq9UdV8mPPjejJ4AaABAg.8yHCKV0Boe58yYRxEQEF45       282   \n",
       "2         6                                1110578710648890000       372   \n",
       "3         6  UgwUPFScjJ0MCeaP2F54AaABAg.8lvp3fc9Euf8lvvgsUgEgV       769   \n",
       "4         6  UgwWKCWtSJdFvjGHvTp4AaABAg.8kUC5dGrQ2H8kUDRihE2f3      1206   \n",
       "...     ...                                                ...       ...   \n",
       "3857      6                                1152219467579100000  10000695   \n",
       "3858      6                                1085362296472430000  10007008   \n",
       "3859      6        UghFY3QJ6nmT_ngCoAEC.7-H0Z7--wxd8goqpaPs-bl  20000102   \n",
       "3860      6                         UgyWabsmmnq3zam4DgZ4AaABAg  20000418   \n",
       "3861      6                         UgwPOHIDyICm10k0Mvx4AaABAg  20001003   \n",
       "\n",
       "      Genre  topiccode  Platform  ...  date_difference commentCount_video  \\\n",
       "0         0          0         1  ...              NaN                NaN   \n",
       "1         1          2         1  ...            743.0             1748.0   \n",
       "2         2          4         2  ...              NaN                NaN   \n",
       "3         0          0         1  ...              NaN                NaN   \n",
       "4         0          0         1  ...              NaN                NaN   \n",
       "...     ...        ...       ...  ...              ...                ...   \n",
       "3857      0          4         2  ...              NaN                NaN   \n",
       "3858      1          4         2  ...              NaN                NaN   \n",
       "3859      0          3         1  ...           3803.0             4785.0   \n",
       "3860      2          3         1  ...           1531.0             2206.0   \n",
       "3861      0          3         1  ...           2276.0             2887.0   \n",
       "\n",
       "      replyCount_comment    topic  subscribers  HATELIST_FOCUSED_DUMMY  \\\n",
       "0                    NaN     None          NaN                       0   \n",
       "1                    NaN  economy    3630000.0                       0   \n",
       "2                    NaN     None          NaN                       0   \n",
       "3                    NaN     None          NaN                       0   \n",
       "4                    NaN     None          NaN                       0   \n",
       "...                  ...      ...          ...                     ...   \n",
       "3857                 NaN     None          NaN                       0   \n",
       "3858                 NaN     None          NaN                       0   \n",
       "3859                 NaN     east    6740000.0                       0   \n",
       "3860                 0.0     east    6800000.0                       0   \n",
       "3861                 1.0     east     549000.0                       0   \n",
       "\n",
       "      Time_comment_year  Time_video_year  \\\n",
       "0                  2017           2017.0   \n",
       "1                  2019           2019.0   \n",
       "2                  2019              NaN   \n",
       "3                  2018           2018.0   \n",
       "4                  2018           2018.0   \n",
       "...                 ...              ...   \n",
       "3857               2019              NaN   \n",
       "3858               2019              NaN   \n",
       "3859               2018           2010.0   \n",
       "3860               2018           2015.0   \n",
       "3861               2018           2018.0   \n",
       "\n",
       "                                        tfidf_embedding  \\\n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "...                                                 ...   \n",
       "3857  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3858  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3859  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3860  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3861  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                              embed_MXP  \n",
       "0     [0.40566757321357727, -0.032418690621852875, -...  \n",
       "1     [0.49942252039909363, -0.22240903973579407, -0...  \n",
       "2     [0.6132397651672363, -0.3024018704891205, -0.6...  \n",
       "3     [0.27884048223495483, -0.3008716404438019, -0....  \n",
       "4     [0.5210463404655457, 0.03200243413448334, -0.3...  \n",
       "...                                                 ...  \n",
       "3857  [0.5265525579452515, -0.1172720193862915, -0.5...  \n",
       "3858  [0.5607972741127014, -0.20688456296920776, -0....  \n",
       "3859  [0.7534456253051758, -0.44059860706329346, -0....  \n",
       "3860  [0.6457327604293823, -0.21125030517578125, -0....  \n",
       "3861  [0.14273801445960999, -0.12535151839256287, -0...  \n",
       "\n",
       "[3862 rows x 81 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset: pd.DataFrame = pd.read_parquet(f'{CFG.report_dir}/pubsphere.MXPembeds.parquet')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first just try pre-processing and a simple tf-ivf:\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(texts):\n",
    "    x_train = []\n",
    "    for sent in tqdm.tqdm(texts):\n",
    "        sent = re.sub(r'@[^ ]+', '', sent)  #remove all usernames\n",
    "        sent = re.sub(r'https?://[^ ]+', '', sent) #remove all hyperlinks\n",
    "        sent = re.sub(r'#', '', sent) #remove all hashtags\n",
    "        sent = re.sub(r'([A-Za-z])\\1{2,}', r'\\1', sent) #normalize language use by replacing duplicate letters by single letters\n",
    "        sent = re.sub(\"[^a-zA-Z ]\", \"\", sent) #remove all non-words\n",
    "        sent = sent.lower().split()\n",
    "        sent = [lemmatizer.lemmatize(word) for word in sent if word not in set(stop_words)]\n",
    "        sent = ' '.join(sent)\n",
    "        x_train.append(sent)\n",
    "    return x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3862/3862 [00:03<00:00, 1196.74it/s]\n"
     ]
    }
   ],
   "source": [
    "X = preprocess(dataset[\"commentText\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=5000, analyzer='word', ngram_range=(1,2), stop_words='english')\n",
    "X_tfidf = tfidf.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['tfidf_embedding'] = [torch.tensor(X_tfidf[i], dtype=torch.float32).flatten().tolist() for i in range(X_tfidf.shape[0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "1       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "2       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "3       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "4       [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "                              ...                        \n",
       "3857    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "3858    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "3859    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "3860    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "3861    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...\n",
       "Name: tfidf_embedding, Length: 3862, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['tfidf_embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 1.        , 0.        , ..., 0.01644865, 0.10141343,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 1.        , ..., 0.08009685, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.01644865, 0.08009685, ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.10141343, 0.        , ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarities = cosine_similarity(X_tfidf)\n",
    "cosine_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_documents = len(cosine_similarities)\n",
    "\n",
    "# Initialize a list to store the most similar document pairs\n",
    "top_similar_pairs = []\n",
    "\n",
    "# Iterate through all document pairs\n",
    "for i in range(num_documents):\n",
    "    for j in range(i + 1, num_documents):\n",
    "        similarity = cosine_similarities[i][j]\n",
    "        \n",
    "        # Check if the similarity is NaN or zero\n",
    "        if not np.isnan(similarity) and similarity >= 1:\n",
    "            pair = (i, j)\n",
    "            top_similar_pairs.append((similarity, pair))\n",
    "            \n",
    "# Sort the list based on similarity in descending order\n",
    "top_similar_pairs.sort(key=lambda x: x[0], reverse=True)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_similar_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = [pair for value, pair in top_similar_pairs if value >= 1]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for first, second in result:\n",
    "    print(dataset[\"commentText\"][[first, second]])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hell yeah fam\n",
      "hell yeah\n",
      "vote trump\n",
      "vote trump\n",
      "mika low iq\n",
      "still low iq\n",
      "good grief\n",
      "opinionlol good grief\n",
      "persinger apple orange\n",
      "apple orange\n"
     ]
    }
   ],
   "source": [
    "print(X[246])\n",
    "print(X[1179])\n",
    "print(X[139])\n",
    "print(X[1990])\n",
    "print(X[21])\n",
    "print(X[1856])\n",
    "print(X[722])\n",
    "print(X[739])\n",
    "print(X[362])\n",
    "print(X[736])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [33:13<33:13, 1993.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:1:1.387083901878089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [41:02<00:00, 1231.49s/it]\u001b[A\n",
      " 50%|█████     | 1/2 [41:02<41:02, 2462.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:2:1.378470503605204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 2/2 [01:49<00:00, 54.77s/it]\u001b[A\n",
      "100%|██████████| 2/2 [42:52<00:00, 1286.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2:2:1.3663818729263082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "grouped_data = dataset.groupby(\"Platform\")\n",
    "dist = torch.nn.PairwiseDistance()\n",
    "resultsplatform: typing.Dict[typing.Tuple[str, str], float] = {}\n",
    "for model_1, c_1 in tqdm.tqdm(grouped_data['tfidf_embedding'], total=grouped_data.ngroups):\n",
    "    for model_2, c_2 in tqdm.tqdm(grouped_data['tfidf_embedding'], total=grouped_data.ngroups):\n",
    "\n",
    "        if (\n",
    "            (model_1, model_2) in resultsplatform.keys() or \n",
    "            (model_2, model_1) in resultsplatform.keys()\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        res = sum([\n",
    "            sum(dist(\n",
    "                torch.tensor(np.array(v_1)), \n",
    "                torch.tensor(np.array(c_2.tolist()))\n",
    "                )) / len(c_2)\n",
    "            for v_1 in c_1\n",
    "        ]) / len(c_1)\n",
    "\n",
    "        resultsplatform[(model_1, model_2)] = res\n",
    "\n",
    "        print(f'{model_1}:{model_2}:{res.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [01:36<06:27, 96.83s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:0:1.3645636310364535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 2/5 [03:31<05:22, 107.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:1:1.3801746759070188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 3/5 [05:23<03:39, 109.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:2:1.380216263104322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 4/5 [07:18<01:51, 111.56s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:3:1.3804281275286232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [09:00<00:00, 108.03s/it]\u001b[A\n",
      " 20%|██        | 1/5 [09:00<36:00, 540.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:4:1.3676527696495127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 40%|████      | 2/5 [02:19<03:29, 69.82s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:1:1.3905186068014541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 3/5 [04:35<03:14, 97.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:2:1.393283526407842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 4/5 [06:55<01:53, 113.36s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:3:1.3934971878373408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [09:00<00:00, 108.08s/it]\u001b[A\n",
      " 40%|████      | 2/5 [18:00<27:00, 540.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:4:1.3813658740220598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 60%|██████    | 3/5 [02:11<01:27, 43.74s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2:2:1.3912835814306548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 4/5 [04:26<01:13, 73.25s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2:3:1.393445432925349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [06:26<00:00, 77.28s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [24:26<15:40, 470.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2:4:1.3813345574310756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 80%|████████  | 4/5 [02:18<00:34, 34.73s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3:3:1.390982498968042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [04:23<00:00, 52.63s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [28:50<06:28, 388.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3:4:1.381690663108306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 5/5 [01:49<00:00, 21.85s/it]\u001b[A\n",
      "100%|██████████| 5/5 [30:39<00:00, 367.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4:4:1.3663818729263082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "grouped_data = dataset.groupby(\"topiccode\")\n",
    "dist = torch.nn.PairwiseDistance()\n",
    "resultstopic: typing.Dict[typing.Tuple[str, str], float] = {}\n",
    "for model_1, c_1 in tqdm.tqdm(grouped_data['tfidf_embedding'], total=grouped_data.ngroups):\n",
    "    for model_2, c_2 in tqdm.tqdm(grouped_data['tfidf_embedding'], total=grouped_data.ngroups):\n",
    "\n",
    "        if (\n",
    "            (model_1, model_2) in resultstopic.keys() or \n",
    "            (model_2, model_1) in resultstopic.keys()\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        res = sum([\n",
    "            sum(dist(\n",
    "                torch.tensor(np.array(v_1)), \n",
    "                torch.tensor(np.array(c_2.tolist()))\n",
    "                )) / len(c_2)\n",
    "            for v_1 in c_1\n",
    "        ]) / len(c_1)\n",
    "\n",
    "        resultstopic[(model_1, model_2)] = res\n",
    "\n",
    "        print(f'{model_1}:{model_2}:{res.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [04:55<09:51, 295.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:0:1.3860901042757274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 2/3 [10:25<05:15, 315.85s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:1:1.387775928468115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [15:47<00:00, 315.91s/it]\u001b[A\n",
      " 33%|███▎      | 1/3 [15:47<31:35, 947.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:2:1.3822033473785345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [06:09<03:04, 184.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:1:1.3867993339415101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [12:10<00:00, 243.59s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [27:58<13:40, 820.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:2:1.3827519017279932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3/3 [05:53<00:00, 117.84s/it]\u001b[A\n",
      "100%|██████████| 3/3 [33:52<00:00, 677.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2:2:1.3755636580085255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "grouped_data = dataset.groupby(\"Genre\")\n",
    "dist = torch.nn.PairwiseDistance()\n",
    "resultsgenre: typing.Dict[typing.Tuple[str, str], float] = {}\n",
    "for model_1, c_1 in tqdm.tqdm(grouped_data['tfidf_embedding'], total=grouped_data.ngroups):\n",
    "    for model_2, c_2 in tqdm.tqdm(grouped_data['tfidf_embedding'], total=grouped_data.ngroups):\n",
    "\n",
    "        if (\n",
    "            (model_1, model_2) in resultsgenre.keys() or \n",
    "            (model_2, model_1) in resultsgenre.keys()\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        res = sum([\n",
    "            sum(dist(\n",
    "                torch.tensor(np.array(v_1)), \n",
    "                torch.tensor(np.array(c_2.tolist()))\n",
    "                )) / len(c_2)\n",
    "            for v_1 in c_1\n",
    "        ]) / len(c_1)\n",
    "\n",
    "        resultsgenre[(model_1, model_2)] = res\n",
    "\n",
    "        print(f'{model_1}:{model_2}:{res.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_MXBAI: typing.Dict[str, np.ndarray] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['StartDate', 'RecordedDate', 'IPAddress', 'Finished', 'Coder', 'ID',\n",
       "       'Mark_ID', 'Genre', 'topiccode', 'Platform', 'Anonymity',\n",
       "       'Anonymity_9_TEXT', 'codable', 'Interaction', 'Acknowledgement',\n",
       "       'TopicRelevance', 'Reasoning', 'BackgroundInfo', 'ExternalEvidence',\n",
       "       'ExternalEvidence_1_TEXT', 'Opinion', 'disagreement',\n",
       "       'Ideologicaldirection', 'Name_calling', 'Vulgarity',\n",
       "       'Attack_reputation', 'Question_Intelligenc', 'All_caps_function',\n",
       "       'Sarcasm_to_criticize', 'Individual_right', 'discrimination',\n",
       "       'Invoke_violence', 'Tone', 'INTERACTIVITY_DUMMY', 'RATIONALITY_DUMMY',\n",
       "       'HAS_OPINION_DUMMY', 'LIBERAL_NEUTRAL_CONSERVATIVE', 'LIBERAL_DUMMY',\n",
       "       'CONSERVATIVE_DUMMY', 'NAMECALLING_DUMMY', 'VULGAR_DUMMY',\n",
       "       'NAMECALLING_VULGAR_DUMMY', 'INCIVILITY_ORDINAL', 'INCIVILITY_DUMMY',\n",
       "       'INTOLERANCE_DUMMY', 'filter_$', 'IMPOLITENESS_DUMMY', 'commentText',\n",
       "       'showName', 'genre', 'Time_comment', 'likeCount_comment', 'entities',\n",
       "       'place', 'retweet_count', 'platform', 'retweeted', 'language', 'source',\n",
       "       'in_reply_to_status_id_str', 'in_reply_to_user_id_str',\n",
       "       'in_reply_to_screen_name', 'is_quote_status', 'videoTitle',\n",
       "       'description', 'Time_video', 'channelTitle', 'channelId', 'viewCount',\n",
       "       'dislikeCount_video', 'likeCount_video', 'date_difference',\n",
       "       'commentCount_video', 'replyCount_comment', 'topic', 'subscribers',\n",
       "       'HATELIST_FOCUSED_DUMMY', 'Time_comment_year', 'Time_video_year',\n",
       "       'tfidf_embedding'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 2162/3862 [1:17:57<1:01:17,  2.16s/it]\n"
     ]
    }
   ],
   "source": [
    "context = 'social media replies to a news- or infotainment-post'\n",
    "for index, row in tqdm.tqdm(dataset[\"commentText\"].items(), total=len(dataset)):\n",
    "    try: \n",
    "        embed = np.array(requests.post(\n",
    "            'https://inf.cl.uni-trier.de/embed/',\n",
    "            json={'prompt': 'You help me get embeddings for a sentence. I provide you with a context and a sentence and you reply only with that exact sentence. Context = ' + context + '; Sentence: ' + row}\n",
    "            ).json()[\"response\"])\n",
    "    except Exception as _e:\n",
    "        logging.warning(_e)\n",
    "        embed = None\n",
    "    \n",
    "    embed_MXBAI[index] = embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.40566757 -0.03241869 -0.53458202 ...  0.15711065 -0.08119941\n",
      " -0.00576604]\n",
      "[ 0.27884048 -0.30087164 -0.48076391 ...  0.24177188 -0.36920482\n",
      "  0.2004005 ]\n",
      "[ 0.52104634  0.03200243 -0.37679625 ...  0.07765494 -0.12583201\n",
      "  0.07684822]\n",
      "[ 0.41127884 -0.00681883 -0.75118834 ... -0.06884278  0.1962322\n",
      "  0.15082534]\n"
     ]
    }
   ],
   "source": [
    "print(embed_MXBAI[0])\n",
    "print(embed_MXBAI[3])\n",
    "print(embed_MXBAI[4])\n",
    "print(embed_MXBAI[1800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartDate</th>\n",
       "      <th>RecordedDate</th>\n",
       "      <th>IPAddress</th>\n",
       "      <th>Finished</th>\n",
       "      <th>Coder</th>\n",
       "      <th>ID</th>\n",
       "      <th>Mark_ID</th>\n",
       "      <th>Genre</th>\n",
       "      <th>topiccode</th>\n",
       "      <th>Platform</th>\n",
       "      <th>...</th>\n",
       "      <th>date_difference</th>\n",
       "      <th>commentCount_video</th>\n",
       "      <th>replyCount_comment</th>\n",
       "      <th>topic</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>HATELIST_FOCUSED_DUMMY</th>\n",
       "      <th>Time_comment_year</th>\n",
       "      <th>Time_video_year</th>\n",
       "      <th>tfidf_embedding</th>\n",
       "      <th>embed_MXP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/30/2021 13:03:17</td>\n",
       "      <td>5/30/2021 13:04:17</td>\n",
       "      <td>62.194.51.29</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgyPHwv8G0cDE6-wEgl4AaABAg.8_0ZjJKSJty8_0kXGkAd2U</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.40566757321357727, -0.032418690621852875, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/11/2021 10:34:05</td>\n",
       "      <td>10/11/2021 10:36:46</td>\n",
       "      <td>213.127.109.191</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Ugx2WXq9UdV8mPPjejJ4AaABAg.8yHCKV0Boe58yYRxEQEF45</td>\n",
       "      <td>282</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>743.0</td>\n",
       "      <td>1748.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>economy</td>\n",
       "      <td>3630000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.49942252039909363, -0.22240903973579407, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9/9/2021 18:49:48</td>\n",
       "      <td>9/9/2021 18:51:32</td>\n",
       "      <td>213.127.110.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1110578710648890000</td>\n",
       "      <td>372</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.6132397651672363, -0.3024018704891205, -0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6/6/2021 16:12:46</td>\n",
       "      <td>6/6/2021 16:16:16</td>\n",
       "      <td>213.127.76.145</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgwUPFScjJ0MCeaP2F54AaABAg.8lvp3fc9Euf8lvvgsUgEgV</td>\n",
       "      <td>769</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.27884048223495483, -0.3008716404438019, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6/13/2021 13:25:49</td>\n",
       "      <td>6/13/2021 13:27:28</td>\n",
       "      <td>213.127.82.232</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgwWKCWtSJdFvjGHvTp4AaABAg.8kUC5dGrQ2H8kUDRihE2f3</td>\n",
       "      <td>1206</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>[0.5210463404655457, 0.03200243413448334, -0.3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             StartDate         RecordedDate        IPAddress  Finished  Coder  \\\n",
       "0   5/30/2021 13:03:17   5/30/2021 13:04:17     62.194.51.29         1      6   \n",
       "1  10/11/2021 10:34:05  10/11/2021 10:36:46  213.127.109.191         1      6   \n",
       "2    9/9/2021 18:49:48    9/9/2021 18:51:32    213.127.110.0         1      6   \n",
       "3    6/6/2021 16:12:46    6/6/2021 16:16:16   213.127.76.145         1      6   \n",
       "4   6/13/2021 13:25:49   6/13/2021 13:27:28   213.127.82.232         1      6   \n",
       "\n",
       "                                                  ID  Mark_ID  Genre  \\\n",
       "0  UgyPHwv8G0cDE6-wEgl4AaABAg.8_0ZjJKSJty8_0kXGkAd2U      119      0   \n",
       "1  Ugx2WXq9UdV8mPPjejJ4AaABAg.8yHCKV0Boe58yYRxEQEF45      282      1   \n",
       "2                                1110578710648890000      372      2   \n",
       "3  UgwUPFScjJ0MCeaP2F54AaABAg.8lvp3fc9Euf8lvvgsUgEgV      769      0   \n",
       "4  UgwWKCWtSJdFvjGHvTp4AaABAg.8kUC5dGrQ2H8kUDRihE2f3     1206      0   \n",
       "\n",
       "   topiccode  Platform  ...  date_difference commentCount_video  \\\n",
       "0          0         1  ...              NaN                NaN   \n",
       "1          2         1  ...            743.0             1748.0   \n",
       "2          4         2  ...              NaN                NaN   \n",
       "3          0         1  ...              NaN                NaN   \n",
       "4          0         1  ...              NaN                NaN   \n",
       "\n",
       "   replyCount_comment    topic  subscribers  HATELIST_FOCUSED_DUMMY  \\\n",
       "0                 NaN      NaN          NaN                       0   \n",
       "1                 NaN  economy    3630000.0                       0   \n",
       "2                 NaN      NaN          NaN                       0   \n",
       "3                 NaN      NaN          NaN                       0   \n",
       "4                 NaN      NaN          NaN                       0   \n",
       "\n",
       "   Time_comment_year  Time_video_year  \\\n",
       "0               2017           2017.0   \n",
       "1               2019           2019.0   \n",
       "2               2019              NaN   \n",
       "3               2018           2018.0   \n",
       "4               2018           2018.0   \n",
       "\n",
       "                                     tfidf_embedding  \\\n",
       "0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n",
       "\n",
       "                                           embed_MXP  \n",
       "0  [0.40566757321357727, -0.032418690621852875, -...  \n",
       "1  [0.49942252039909363, -0.22240903973579407, -0...  \n",
       "2  [0.6132397651672363, -0.3024018704891205, -0.6...  \n",
       "3  [0.27884048223495483, -0.3008716404438019, -0....  \n",
       "4  [0.5210463404655457, 0.03200243413448334, -0.3...  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_w_embeds = dataset.join(pd.Series(embed_MXBAI, name=\"embed_MXBAI\"))\n",
    "dataset_w_embeds.to_parquet(f'{CFG.report_dir}/pubsphere.MXBAIembeds.parquet')\n",
    "dataset_w_embeds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      " 50%|█████     | 1/2 [01:15<01:15, 75.71s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:1:8.274992962778118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 2/2 [01:30<00:00, 45.18s/it]\u001b[A\n",
      " 50%|█████     | 1/2 [01:30<01:30, 90.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:2:7.51343754601772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 2/2 [00:03<00:00,  1.72s/it]\u001b[A\n",
      "100%|██████████| 2/2 [01:33<00:00, 46.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2:2:6.060459538546106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "grouped_data = dataset.groupby(\"Platform\")\n",
    "dist = torch.nn.PairwiseDistance()\n",
    "resultsplatform: typing.Dict[typing.Tuple[str, str], float] = {}\n",
    "for model_1, c_1 in tqdm.tqdm(grouped_data['embed_MXBAI'], total=grouped_data.ngroups):\n",
    "    for model_2, c_2 in tqdm.tqdm(grouped_data['embed_MXBAI'], total=grouped_data.ngroups):\n",
    "\n",
    "        if (\n",
    "            (model_1, model_2) in resultsplatform.keys() or \n",
    "            (model_2, model_1) in resultsplatform.keys()\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        res = sum([\n",
    "            sum(dist(\n",
    "                torch.tensor(np.array(v_1)), \n",
    "                torch.tensor(np.array(c_2.tolist()))\n",
    "                )) / len(c_2)\n",
    "            for v_1 in c_1\n",
    "        ]) / len(c_1)\n",
    "\n",
    "        resultsplatform[(model_1, model_2)] = res\n",
    "\n",
    "        print(f'{model_1}:{model_2}:{res.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 20%|██        | 1/5 [00:02<00:11,  2.75s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between topiccode 0:0:7.761249318601641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 2/5 [00:06<00:09,  3.26s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between topiccode 0:1:8.075305272859095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 3/5 [00:09<00:06,  3.43s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between topiccode 0:2:8.07396665341206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 4/5 [00:13<00:03,  3.49s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between topiccode 0:3:8.237471193061861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:16<00:00,  3.33s/it]\u001b[A\n",
      " 20%|██        | 1/5 [00:16<01:06, 16.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between topiccode 0:4:7.179062944907428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 40%|████      | 2/5 [00:04<00:06,  2.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between topiccode 1:1:8.163760056540308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 3/5 [00:08<00:06,  3.17s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between topiccode 1:2:8.329572974140778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 4/5 [00:13<00:03,  3.83s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between topiccode 1:3:8.455668083965353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:17<00:00,  3.50s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:34<00:51, 17.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between topiccode 1:4:7.544355677259935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 60%|██████    | 3/5 [00:04<00:02,  1.40s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between topiccode 2:2:8.325426316232779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 4/5 [00:08<00:02,  2.32s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between topiccode 2:3:8.492055501452159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:12<00:00,  2.43s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [00:46<00:29, 14.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between topiccode 2:4:7.542171685709668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      " 80%|████████  | 4/5 [00:04<00:01,  1.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between topiccode 3:3:8.510271797717213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 5/5 [00:08<00:00,  1.63s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [00:54<00:12, 12.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between topiccode 3:4:7.7297440062986515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 5/5 [00:03<00:00,  1.55it/s]\u001b[A\n",
      "100%|██████████| 5/5 [00:57<00:00, 11.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between topiccode 4:4:6.060459538546106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:09<00:18,  9.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between Genre 0:0:7.992943483095683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 2/3 [00:19<00:09,  9.96s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between Genre 0:1:7.909363681834278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [00:30<00:00, 10.10s/it]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:30<01:00, 30.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between Genre 0:2:8.051982137707387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:11<00:05,  5.88s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between Genre 1:1:7.763014220220769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 3/3 [00:23<00:00,  7.68s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:53<00:26, 26.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between Genre 1:2:7.975648076236652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 3/3 [00:11<00:00,  3.68s/it]\u001b[A\n",
      "100%|██████████| 3/3 [01:04<00:00, 21.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between Genre 2:2:8.054402602772836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for group in [\"topiccode\", \"Genre\"]:\n",
    "    grouped_data = dataset.groupby(group)\n",
    "    dist = torch.nn.PairwiseDistance()\n",
    "    resultsplatform: typing.Dict[typing.Tuple[str, str], float] = {}\n",
    "    for model_1, c_1 in tqdm.tqdm(grouped_data['embed_MXBAI'], total=grouped_data.ngroups):\n",
    "        for model_2, c_2 in tqdm.tqdm(grouped_data['embed_MXBAI'], total=grouped_data.ngroups):\n",
    "    \n",
    "            if (\n",
    "                (model_1, model_2) in resultsplatform.keys() or \n",
    "                (model_2, model_1) in resultsplatform.keys()\n",
    "            ):\n",
    "                continue\n",
    "    \n",
    "            res = sum([\n",
    "                sum(dist(\n",
    "                    torch.tensor(np.array(v_1)), \n",
    "                    torch.tensor(np.array(c_2.tolist()))\n",
    "                    )) / len(c_2)\n",
    "                for v_1 in c_1\n",
    "            ]) / len(c_1)\n",
    "    \n",
    "            resultsplatform[(model_1, model_2)] = res\n",
    "    \n",
    "            print(f'Distance between {group} {model_1}:{model_2}:{res.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create BERT-base embeddings for each word:\n",
    "\n",
    "model_name = \"google-bert/bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Twhin-BERT-base embeddings for each word:\n",
    "model_name = \"Twitter/twhin-bert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate DiffCSE embeddings:\n",
    "model_name = \"voidism/diffcse-roberta-base-sts\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for encoding sentence embeddings based on the DiffCSE approach which is based on (and refers to) SimCSE/evaluation.py \n",
    "def encode_sentence(sentence):\n",
    "    input_ids = tokenizer.encode(sentence, add_special_tokens=True, truncation=True, max_length=512, padding='max_length')\n",
    "    input_ids_tensor = torch.tensor(input_ids).unsqueeze(0)  # Add batch dimension\n",
    "    attention_mask = torch.ones_like(input_ids_tensor)  # Creating attention mask \n",
    "    with torch.no_grad():\n",
    "            outputs = model(input_ids_tensor, output_hidden_states=True, return_dict=True, attention_mask=attention_mask)\n",
    "            sentence_embedding = outputs.last_hidden_state[:, 0].cpu()\n",
    "            return sentence_embedding.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for DiffCSE: Create embeddings for each argument and store them in a new column\n",
    "dataset.loc[:, 'DiffCSE_embedding'] = dataset[\"commentText\"].apply(encode_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmdiv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
