{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.10/site-packages/threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecomposition\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PCA\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_objs\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgo\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "import typing\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import config\n",
    "\n",
    "import logging\n",
    "import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = config.Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"I'm going to the bank.\", \"I'm going to the bank.\", \"I'm going to the bank.\", \"I need to visit the bank today.\", \"I'm heading to the bank to withdraw some cash.\", \"The bank is where I'm off to.\", \"I have an appointment at the bank.\", \"Let's spend the day by the river bank.\", \"The river bank is a peaceful place to relax.\", \"I enjoy walking along the river bank.\", \"We can have a picnic by the river bank.\",\n",
    "\"She has a cool job.\", \"She has a cool job.\", \"She has a cool job.\", \"Her job is really interesting and fun.\", \"She works in a creative field and loves it.\", \"That job of hers is so unique.\", \"She's lucky to have such a cool profession.\", \"Her workplace is always chilly.\", \"She works in a refrigerated environment.\", \"The temperature in her office is freezing.\", \"She needs to bundle up for her job.\",\n",
    "\"You need to check the trunk.\", \"You need to check the trunk.\", \"You need to check the trunk.\", \"Don't forget to look in the trunk of the car.\", \"There might be something important in the trunk.\", \"Make sure to verify the contents of the trunk.\", \"The trunk needs to be inspected for any damage.\", \"Take a look at the tree trunk for any damage.\", \"The trunk of the old tree might have some interesting carvings.\", \"Check if the tree trunk needs to be treated for pests.\", \"See if there are any unique patterns or textures on the tree trunk.\",\n",
    "\"I saw her duck.\", \"I saw her duck.\", \"I saw her duck.\", \"Her duck was waddling in the park.\", \"The duck she owns is so cute.\", \"I spotted her duck by the pond.\", \"Her duck was quacking loudly.\", \"She ducked to avoid the flying object.\", \"Her quick ducking saved her from the falling branch.\", \"I noticed her sudden ducking movement.\", \"She ducked and dodged the incoming ball.\",\n",
    "\"She has a great figure.\", \"She has a great figure.\", \"She has a great figure.\", \"Her body shape is very flattering.\", \"She carries herself with grace and confidence.\", \"Her figure is well-proportioned and attractive.\", \"She knows how to dress to highlight her figure.\", \"The numerical figure she presented was impressive.\", \"Her calculations yielded a significant figure.\", \"The data supports a substantial figure.\", \"The figure she quoted was accurate and reliable.\"]\n",
    "\n",
    "context = [\"bank\", \"bank-money\", \"bank-river\", \"bank-money\", \"bank-money\", \"bank-money\", \"bank-money\", \"bank-river\", \"bank-river\", \"bank-river\", \"bank-river\", \"cool\", \"cool-nice\", \"cool-cold\", \"cool-nice\", \"cool-nice\", \"cool-nice\", \"cool-nice\", \"cool-cold\", \"cool-cold\", \"cool-cold\", \"cool-cold\", \"trunk\", \"trunk-car\", \"trunk-tree\", \"trunk-car\", \"trunk-car\", \"trunk-car\", \"trunk-car\", \"trunk-tree\", \"trunk-tree\", \"trunk-tree\", \"trunk-tree\", \n",
    "           \"duck\", \"duck-animal\", \"duck-down\", \"duck-animal\", \"duck-animal\", \"duck-animal\", \"duck-animal\", \"duck-down\", \"duck-down\", \"duck-down\", \"duck-down\", \"figure\", \"figure-body\", \"figure-number\", \"figure-body\", \"figure-body\", \"figure-body\", \"figure-body\", \"figure-number\", \"figure-number\", \"figure-number\", \"figure-number\"]\n",
    "\n",
    "set = [\"bank-base\", \"bank-base-money\", \"bank-base-river\", \"bank-money\", \"bank-money\", \"bank-money\", \"bank-money\", \"bank-river\", \"bank-river\", \"bank-river\", \"bank-river\", \"cool-base\", \"cool-base-nice\", \"cool-base-cold\", \"cool-nice\", \"cool-nice\", \"cool-nice\", \"cool-nice\", \"cool-cold\", \"cool-cold\", \"cool-cold\", \"cool-cold\", \"trunk-base\", \"trunk-base-car\", \"trunk-base-tree\", \"trunk-car\", \"trunk-car\", \"trunk-car\", \"trunk-car\", \"trunk-tree\", \"trunk-tree\", \"trunk-tree\", \"trunk-tree\", \n",
    "           \"duck-base\", \"duck-base-animal\", \"duck-base-down\", \"duck-animal\", \"duck-animal\", \"duck-animal\", \"duck-animal\", \"duck-down\", \"duck-down\", \"duck-down\", \"duck-down\", \"figure-base\", \"figure-base-body\", \"figure-base-number\", \"figure-body\", \"figure-body\", \"figure-body\", \"figure-body\", \"figure-number\", \"figure-number\", \"figure-number\", \"figure-number\"]\n",
    "\n",
    "dataset = pd.DataFrame({'Sentence': sentences, 'Context': context, 'Set': set})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Context</th>\n",
       "      <th>Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm going to the bank.</td>\n",
       "      <td>bank</td>\n",
       "      <td>bank-base</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm going to the bank.</td>\n",
       "      <td>bank-money</td>\n",
       "      <td>bank-base-money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm going to the bank.</td>\n",
       "      <td>bank-river</td>\n",
       "      <td>bank-base-river</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I need to visit the bank today.</td>\n",
       "      <td>bank-money</td>\n",
       "      <td>bank-money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm heading to the bank to withdraw some cash.</td>\n",
       "      <td>bank-money</td>\n",
       "      <td>bank-money</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Sentence     Context              Set\n",
       "0                          I'm going to the bank.        bank        bank-base\n",
       "1                          I'm going to the bank.  bank-money  bank-base-money\n",
       "2                          I'm going to the bank.  bank-river  bank-base-river\n",
       "3                 I need to visit the bank today.  bank-money       bank-money\n",
       "4  I'm heading to the bank to withdraw some cash.  bank-money       bank-money"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['political_ideology', 'embedding_semantic_rich', 'political_negativity', 'embedding_base', 'argument'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL: str = \"llama3:70b-instruct-q6_K\" # \"mixtral:8x7b-instruct-v0.1-q6_K\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = [\n",
    "    {\"name\": \"embed_base\", \"template\": 'You help me get embeddings for a sentence. I provide you a with a context and a sentence and you reply only with that exact sentence. Context = '},\n",
    "    {\"name\": \"embed_rich\", \"template\": 'You help me get embeddings for a sentence that will help me to determine semantic sentence similarity. I provide you a sentence and you reply only with that exact sentence. Context = '},\n",
    "]\n",
    "\n",
    "template_dict = pd.DataFrame(templates).to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_base: typing.Dict[str, np.ndarray] = {}\n",
    "embed_rich: typing.Dict[str, np.ndarray] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:15<00:00,  3.58it/s]\n",
      "100%|██████████| 55/55 [00:13<00:00,  4.18it/s]\n"
     ]
    }
   ],
   "source": [
    "for item in template_dict:\n",
    "    name = item['name']\n",
    "    template = item['template']\n",
    "    for index, row in tqdm.tqdm(dataset.iterrows(), total=len(dataset)):\n",
    "        context = row[\"Context\"]\n",
    "        sentence = row[\"Sentence\"]\n",
    "        try: \n",
    "            embed = np.array(requests.post(\n",
    "                'https://inf.cl.uni-trier.de/embed/',\n",
    "                json={'model': MODEL, 'prompt': template + context + '; Sentence: ' + sentence}\n",
    "                ).json()[\"response\"])\n",
    "        except Exception as _e:\n",
    "            logging.warning(_e)\n",
    "            embed = None\n",
    "        \n",
    "        if name=='embed_base':\n",
    "            embed_base[index] = embed\n",
    "        if name=='embed_rich':\n",
    "            embed_rich[index] = embed\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Context</th>\n",
       "      <th>Set</th>\n",
       "      <th>embed_base</th>\n",
       "      <th>embed_rich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I'm going to the bank.</td>\n",
       "      <td>bank</td>\n",
       "      <td>bank-base</td>\n",
       "      <td>[0.2825756371021271, -0.7305834889411926, -0.6...</td>\n",
       "      <td>[0.40476152300834656, -0.40213334560394287, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm going to the bank.</td>\n",
       "      <td>bank-money</td>\n",
       "      <td>bank-base-money</td>\n",
       "      <td>[0.4423738121986389, -0.6933848857879639, -0.6...</td>\n",
       "      <td>[0.4015294909477234, -0.24794012308120728, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm going to the bank.</td>\n",
       "      <td>bank-river</td>\n",
       "      <td>bank-base-river</td>\n",
       "      <td>[0.31343695521354675, -0.6396633982658386, -0....</td>\n",
       "      <td>[0.3487618863582611, -0.11420242488384247, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I need to visit the bank today.</td>\n",
       "      <td>bank-money</td>\n",
       "      <td>bank-money</td>\n",
       "      <td>[0.4185699224472046, -0.8129321336746216, -0.7...</td>\n",
       "      <td>[0.3717159330844879, -0.28542259335517883, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm heading to the bank to withdraw some cash.</td>\n",
       "      <td>bank-money</td>\n",
       "      <td>bank-money</td>\n",
       "      <td>[0.35524073243141174, -0.5443449020385742, -0....</td>\n",
       "      <td>[0.322308748960495, -0.14055457711219788, -0.3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Sentence     Context  \\\n",
       "0                          I'm going to the bank.        bank   \n",
       "1                          I'm going to the bank.  bank-money   \n",
       "2                          I'm going to the bank.  bank-river   \n",
       "3                 I need to visit the bank today.  bank-money   \n",
       "4  I'm heading to the bank to withdraw some cash.  bank-money   \n",
       "\n",
       "               Set                                         embed_base  \\\n",
       "0        bank-base  [0.2825756371021271, -0.7305834889411926, -0.6...   \n",
       "1  bank-base-money  [0.4423738121986389, -0.6933848857879639, -0.6...   \n",
       "2  bank-base-river  [0.31343695521354675, -0.6396633982658386, -0....   \n",
       "3       bank-money  [0.4185699224472046, -0.8129321336746216, -0.7...   \n",
       "4       bank-money  [0.35524073243141174, -0.5443449020385742, -0....   \n",
       "\n",
       "                                          embed_rich  \n",
       "0  [0.40476152300834656, -0.40213334560394287, -0...  \n",
       "1  [0.4015294909477234, -0.24794012308120728, -0....  \n",
       "2  [0.3487618863582611, -0.11420242488384247, -0....  \n",
       "3  [0.3717159330844879, -0.28542259335517883, -0....  \n",
       "4  [0.322308748960495, -0.14055457711219788, -0.3...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_w_embeds = dataset.join(pd.Series(embed_base, name=\"embed_base\")).join(pd.Series(embed_rich, name=\"embed_rich\"))\n",
    "#dataset_w_embeds.to_parquet(f'{CFG.report_dir}/dataset.embeds.parquet')\n",
    "dataset_w_embeds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add visualisation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing effect of prompt (base versus rich) and context (base versus context) for distance base-river: base-prompt results\n",
    "results: typing.Dict[typing.Tuple[str, str], float] = {}\n",
    "groups = {\n",
    "    \"prombase-senbase\": dataset_w_embeds[dataset_w_embeds[\"Set\"] == \"bank-base\"][\"embed_base\"],\n",
    "    \"prombase-senriver\": dataset_w_embeds[dataset_w_embeds[\"Set\"] == \"bank-river\"][\"embed_base\"],\n",
    "    \"prombase-senbase-river\": dataset_w_embeds[dataset_w_embeds[\"Set\"] == \"bank-base-river\"][\"embed_base\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing effect of prompt (base versus rich) and context (base versus context) for distance base-river: rich-prompt results\n",
    "groups = {\n",
    "    \"promrich-senbase\": dataset_w_embeds[dataset_w_embeds[\"Set\"] == \"bank-base\"][\"embed_rich\"],\n",
    "    \"promrich-senriver\": dataset_w_embeds[dataset_w_embeds[\"Set\"] == \"bank-river\"][\"embed_rich\"],\n",
    "    \"promrich-senbase-river\": dataset_w_embeds[dataset_w_embeds[\"Set\"] == \"bank-base-river\"][\"embed_rich\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "promrich-senbase:promrich-senbase:3.1999999999999965e-05\n",
      "promrich-senbase:promrich-senriver:4.316801094975404\n",
      "promrich-senbase:promrich-senbase-river:3.6447948132129264\n",
      "promrich-senriver:promrich-senriver:1.6584892020724247\n",
      "promrich-senriver:promrich-senbase-river:2.08751125735614\n",
      "promrich-senbase-river:promrich-senbase-river:3.1999999999999965e-05\n"
     ]
    }
   ],
   "source": [
    "dist = torch.nn.PairwiseDistance()\n",
    "\n",
    "for label_1, c_1 in groups.items():\n",
    "    for label_2, c_2 in groups.items():\n",
    "\n",
    "        if (\n",
    "            (label_1, label_2) in results.keys() or \n",
    "            (label_2, label_1) in results.keys()\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        res = sum([\n",
    "            sum(dist(\n",
    "                torch.tensor(np.array(v_1)), \n",
    "                torch.tensor(np.array(c_2.tolist()))\n",
    "                )) / len(c_2)\n",
    "            for v_1 in c_1\n",
    "        ]) / len(c_1)\n",
    "\n",
    "        results[(label_1, label_2)] = res\n",
    "\n",
    "        print(f'{label_1}:{label_2}:{res.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('prombase-senbase',\n",
       "  'prombase-senbase'): tensor(3.2000e-05, dtype=torch.float64),\n",
       " ('prombase-senbase',\n",
       "  'prombase-senriver'): tensor(5.6014, dtype=torch.float64),\n",
       " ('prombase-senbase',\n",
       "  'prombase-senbase-river'): tensor(4.7680, dtype=torch.float64),\n",
       " ('prombase-senriver',\n",
       "  'prombase-senriver'): tensor(2.1001, dtype=torch.float64),\n",
       " ('prombase-senriver',\n",
       "  'prombase-senbase-river'): tensor(2.5120, dtype=torch.float64),\n",
       " ('prombase-senbase-river',\n",
       "  'prombase-senbase-river'): tensor(3.2000e-05, dtype=torch.float64),\n",
       " ('promrich-senbase',\n",
       "  'promrich-senbase'): tensor(3.2000e-05, dtype=torch.float64),\n",
       " ('promrich-senbase',\n",
       "  'promrich-senriver'): tensor(4.3168, dtype=torch.float64),\n",
       " ('promrich-senbase',\n",
       "  'promrich-senbase-river'): tensor(3.6448, dtype=torch.float64),\n",
       " ('promrich-senriver',\n",
       "  'promrich-senriver'): tensor(1.6585, dtype=torch.float64),\n",
       " ('promrich-senriver',\n",
       "  'promrich-senbase-river'): tensor(2.0875, dtype=torch.float64),\n",
       " ('promrich-senbase-river',\n",
       "  'promrich-senbase-river'): tensor(3.2000e-05, dtype=torch.float64)}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In line with expectations:\n",
    "it appears distances for base prompts between base sentences and river-sentences are smaller when context is prompted (2.5) than when it is not specified (5.6). \n",
    "For rich prompts distances between base sentences and river-sentences are smaller when context is prompted (2.1) than when it is not specified (4.3). \n",
    "Distances from base sentence to river sentences is smaller for rich prompts than base prompts\n",
    "Difference between base and river sentences is smaller for base  (4.3168-3.6448 = 2.23) than rich (5.6014-2.5120= 3.09) prompts -> giving context to base sentence has a smaller effect on the base prompt than the rich prompt results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about the money sentences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing effect of prompt (base versus rich) and context (base versus context) for distance base-money: base-prompt results\n",
    "results2: typing.Dict[typing.Tuple[str, str], float] = {}\n",
    "groups = {\n",
    "    \"prombase-senbase\": dataset_w_embeds[dataset_w_embeds[\"Set\"] == \"bank-base\"][\"embed_base\"],\n",
    "    \"prombase-senmoney\": dataset_w_embeds[dataset_w_embeds[\"Set\"] == \"bank-money\"][\"embed_base\"],\n",
    "    \"prombase-senbase-money\": dataset_w_embeds[dataset_w_embeds[\"Set\"] == \"bank-base-money\"][\"embed_base\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing effect of prompt (base versus rich) and context (base versus context) for distance base-money: rich-prompt results\n",
    "groups = {\n",
    "    \"promrich-senbase\": dataset_w_embeds[dataset_w_embeds[\"Set\"] == \"bank-base\"][\"embed_rich\"],\n",
    "    \"promrich-senmoney\": dataset_w_embeds[dataset_w_embeds[\"Set\"] == \"bank-money\"][\"embed_rich\"],\n",
    "    \"promrich-senbase-money\": dataset_w_embeds[dataset_w_embeds[\"Set\"] == \"bank-base-money\"][\"embed_rich\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "promrich-senbase:promrich-senbase:3.1999999999999965e-05\n",
      "promrich-senbase:promrich-senmoney:2.871530877718972\n",
      "promrich-senbase:promrich-senbase-money:1.8333785117074113\n",
      "promrich-senmoney:promrich-senmoney:1.8499498945289596\n",
      "promrich-senmoney:promrich-senbase-money:2.115557370752927\n",
      "promrich-senbase-money:promrich-senbase-money:3.1999999999999965e-05\n"
     ]
    }
   ],
   "source": [
    "dist = torch.nn.PairwiseDistance()\n",
    "\n",
    "for label_1, c_1 in groups.items():\n",
    "    for label_2, c_2 in groups.items():\n",
    "\n",
    "        if (\n",
    "            (label_1, label_2) in results2.keys() or \n",
    "            (label_2, label_1) in results2.keys()\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        res = sum([\n",
    "            sum(dist(\n",
    "                torch.tensor(np.array(v_1)), \n",
    "                torch.tensor(np.array(c_2.tolist()))\n",
    "                )) / len(c_2)\n",
    "            for v_1 in c_1\n",
    "        ]) / len(c_1)\n",
    "\n",
    "        results2[(label_1, label_2)] = res\n",
    "\n",
    "        print(f'{label_1}:{label_2}:{res.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('prombase-senbase',\n",
       "  'prombase-senbase'): tensor(3.2000e-05, dtype=torch.float64),\n",
       " ('prombase-senbase',\n",
       "  'prombase-senmoney'): tensor(3.4596, dtype=torch.float64),\n",
       " ('prombase-senbase',\n",
       "  'prombase-senbase-money'): tensor(2.9066, dtype=torch.float64),\n",
       " ('prombase-senmoney',\n",
       "  'prombase-senmoney'): tensor(2.1642, dtype=torch.float64),\n",
       " ('prombase-senmoney',\n",
       "  'prombase-senbase-money'): tensor(2.4597, dtype=torch.float64),\n",
       " ('prombase-senbase-money',\n",
       "  'prombase-senbase-money'): tensor(3.2000e-05, dtype=torch.float64),\n",
       " ('promrich-senbase',\n",
       "  'promrich-senbase'): tensor(3.2000e-05, dtype=torch.float64),\n",
       " ('promrich-senbase',\n",
       "  'promrich-senmoney'): tensor(2.8715, dtype=torch.float64),\n",
       " ('promrich-senbase',\n",
       "  'promrich-senbase-money'): tensor(1.8334, dtype=torch.float64),\n",
       " ('promrich-senmoney',\n",
       "  'promrich-senmoney'): tensor(1.8499, dtype=torch.float64),\n",
       " ('promrich-senmoney',\n",
       "  'promrich-senbase-money'): tensor(2.1156, dtype=torch.float64),\n",
       " ('promrich-senbase-money',\n",
       "  'promrich-senbase-money'): tensor(3.2000e-05, dtype=torch.float64)}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In line with expectations:\n",
    "it appears distances for base prompts between base sentences and money-sentences are smaller when context is prompted (2.5) than when it is not specified (3.5). \n",
    "For rich prompts distances between base sentences and money-sentences are smaller when context is prompted (2.1) than when it is not specified (2.9). \n",
    "Distances from base sentence to money sentences is smaller for rich prompts than base prompts\n",
    "**However** :Difference between base and money sentences with and without context is larger for base  (3.4596-2.4597 = 1.00) than rich (2.8715-2.1156= 0.76) prompts -> giving context to base sentence has a larger effect on the base prompt than the rich prompt results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "summarizing: giving context improves embedding-interpretation, we need further testing to verify whether rich prompting outperforms base prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perhaps we could compare whether the difference between the bank-base sentence in a river context and the bank-base sentence in a money context is larger for rich than base prompts? Similarly the distance between river and money sentences should be larger for rich prompts\n",
    "\n",
    "Reasoning: rich prompts should be more sensitive to meaning, so changing the meaning of the base sentence should have a larger influence on embeddings of rich prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prombase-senbase-river:prombase-senbase-river:3.1999999999999965e-05\n",
      "prombase-senbase-river:prombase-senbase-money:4.800173477526052\n",
      "prombase-senbase-river:promrich-senbase-river:7.295951348317239\n",
      "prombase-senbase-river:promrich-senbase-money:8.15563421229664\n",
      "prombase-senbase-money:prombase-senbase-money:3.1999999999999965e-05\n",
      "prombase-senbase-money:promrich-senbase-river:8.051872238071171\n",
      "prombase-senbase-money:promrich-senbase-money:7.145259191029507\n",
      "promrich-senbase-river:promrich-senbase-river:3.1999999999999965e-05\n",
      "promrich-senbase-river:promrich-senbase-money:3.4803490395104006\n",
      "promrich-senbase-money:promrich-senbase-money:3.1999999999999965e-05\n"
     ]
    }
   ],
   "source": [
    "#comparing effect of prompt (base versus rich) for river versus money sentences: base-sentence results\n",
    "results3: typing.Dict[typing.Tuple[str, str], float] = {}\n",
    "groups = {\n",
    "    \"prombase-senbase-river\": dataset_w_embeds[dataset_w_embeds[\"Set\"] == \"bank-base-river\"][\"embed_base\"],\n",
    "    \"prombase-senbase-money\": dataset_w_embeds[dataset_w_embeds[\"Set\"] == \"bank-base-money\"][\"embed_base\"],\n",
    "    \"promrich-senbase-river\": dataset_w_embeds[dataset_w_embeds[\"Set\"] == \"bank-base-river\"][\"embed_rich\"],\n",
    "    \"promrich-senbase-money\": dataset_w_embeds[dataset_w_embeds[\"Set\"] == \"bank-base-money\"][\"embed_rich\"]\n",
    "    }\n",
    "\n",
    "dist = torch.nn.PairwiseDistance()\n",
    "\n",
    "for label_1, c_1 in groups.items():\n",
    "    for label_2, c_2 in groups.items():\n",
    "\n",
    "        if (\n",
    "            (label_1, label_2) in results3.keys() or \n",
    "            (label_2, label_1) in results3.keys()\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        res = sum([\n",
    "            sum(dist(\n",
    "                torch.tensor(np.array(v_1)), \n",
    "                torch.tensor(np.array(c_2.tolist()))\n",
    "                )) / len(c_2)\n",
    "            for v_1 in c_1\n",
    "        ]) / len(c_1)\n",
    "\n",
    "        results3[(label_1, label_2)] = res\n",
    "\n",
    "        print(f'{label_1}:{label_2}:{res.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Against expectations:\n",
    "it appears distances for base prompts between base-river sentences and base-money-sentences (4.8) are larger than for rich prompts (3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prombase-senriver:prombase-senriver:2.10008842155786\n",
      "prombase-senriver:prombase-senmoney:5.755950055125333\n",
      "prombase-senriver:promrich-senriver:7.14581244176149\n",
      "prombase-senriver:promrich-senmoney:8.552889429688943\n",
      "prombase-senmoney:prombase-senmoney:2.1641586372910844\n",
      "prombase-senmoney:promrich-senriver:8.144890753162407\n",
      "prombase-senmoney:promrich-senmoney:7.229541950952813\n",
      "promrich-senriver:promrich-senriver:1.6584892020724247\n",
      "promrich-senriver:promrich-senmoney:4.583495704374738\n",
      "promrich-senmoney:promrich-senmoney:1.8499498945289596\n"
     ]
    }
   ],
   "source": [
    "#comparing effect of prompt (base versus rich) for river versus money sentences: base-sentence results\n",
    "results4: typing.Dict[typing.Tuple[str, str], float] = {}\n",
    "groups = {\n",
    "    \"prombase-senriver\": dataset_w_embeds[dataset_w_embeds[\"Set\"] == \"bank-river\"][\"embed_base\"],\n",
    "    \"prombase-senmoney\": dataset_w_embeds[dataset_w_embeds[\"Set\"] == \"bank-money\"][\"embed_base\"],\n",
    "    \"promrich-senriver\": dataset_w_embeds[dataset_w_embeds[\"Set\"] == \"bank-river\"][\"embed_rich\"],\n",
    "    \"promrich-senmoney\": dataset_w_embeds[dataset_w_embeds[\"Set\"] == \"bank-money\"][\"embed_rich\"]\n",
    "    }\n",
    "\n",
    "dist = torch.nn.PairwiseDistance()\n",
    "\n",
    "for label_1, c_1 in groups.items():\n",
    "    for label_2, c_2 in groups.items():\n",
    "\n",
    "        if (\n",
    "            (label_1, label_2) in results4.keys() or \n",
    "            (label_2, label_1) in results4.keys()\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        res = sum([\n",
    "            sum(dist(\n",
    "                torch.tensor(np.array(v_1)), \n",
    "                torch.tensor(np.array(c_2.tolist()))\n",
    "                )) / len(c_2)\n",
    "            for v_1 in c_1\n",
    "        ]) / len(c_1)\n",
    "\n",
    "        results4[(label_1, label_2)] = res\n",
    "\n",
    "        print(f'{label_1}:{label_2}:{res.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Against expectations:\n",
    "it appears distances for base prompts between river sentences and money-sentences (5.7) are larger than for rich prompts (4.58)\n",
    "\n",
    "Also it appears prompts have a strong influence on subsequent embeddings since the difference among river sentences within the base prompt (2.1) and the rich prompt (1.66) are rather small, while the differences among river sentences across prompts are very large (7.1), even though the difference between prompts (\"that will help me to determine semantic sentence similarity\") appears arbitrary to this difference among river sentences (which thus are rather similar when compared for the same prompt using the same context)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarizing: it appears that the base prompt in combination with context specification yield best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Context</th>\n",
       "      <th>Set</th>\n",
       "      <th>embed_base</th>\n",
       "      <th>embed_rich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I need to visit the bank today.</td>\n",
       "      <td>bank-money</td>\n",
       "      <td>bank-money</td>\n",
       "      <td>[0.4185699224472046, -0.8129321336746216, -0.7...</td>\n",
       "      <td>[0.3717159330844879, -0.28542259335517883, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm heading to the bank to withdraw some cash.</td>\n",
       "      <td>bank-money</td>\n",
       "      <td>bank-money</td>\n",
       "      <td>[0.35524073243141174, -0.5443449020385742, -0....</td>\n",
       "      <td>[0.322308748960495, -0.14055457711219788, -0.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The bank is where I'm off to.</td>\n",
       "      <td>bank-money</td>\n",
       "      <td>bank-money</td>\n",
       "      <td>[0.4175596833229065, -0.5876224637031555, -0.6...</td>\n",
       "      <td>[0.36472979187965393, -0.1458236128091812, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I have an appointment at the bank.</td>\n",
       "      <td>bank-money</td>\n",
       "      <td>bank-money</td>\n",
       "      <td>[0.3939899802207947, -0.7644816040992737, -0.7...</td>\n",
       "      <td>[0.2895117998123169, -0.27759850025177, -0.443...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Let's spend the day by the river bank.</td>\n",
       "      <td>bank-river</td>\n",
       "      <td>bank-river</td>\n",
       "      <td>[0.30943161249160767, -0.5281971096992493, -0....</td>\n",
       "      <td>[0.33497363328933716, -0.12277282774448395, -0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Sentence     Context         Set  \\\n",
       "3                 I need to visit the bank today.  bank-money  bank-money   \n",
       "4  I'm heading to the bank to withdraw some cash.  bank-money  bank-money   \n",
       "5                   The bank is where I'm off to.  bank-money  bank-money   \n",
       "6              I have an appointment at the bank.  bank-money  bank-money   \n",
       "7          Let's spend the day by the river bank.  bank-river  bank-river   \n",
       "\n",
       "                                          embed_base  \\\n",
       "3  [0.4185699224472046, -0.8129321336746216, -0.7...   \n",
       "4  [0.35524073243141174, -0.5443449020385742, -0....   \n",
       "5  [0.4175596833229065, -0.5876224637031555, -0.6...   \n",
       "6  [0.3939899802207947, -0.7644816040992737, -0.7...   \n",
       "7  [0.30943161249160767, -0.5281971096992493, -0....   \n",
       "\n",
       "                                          embed_rich  \n",
       "3  [0.3717159330844879, -0.28542259335517883, -0....  \n",
       "4  [0.322308748960495, -0.14055457711219788, -0.3...  \n",
       "5  [0.36472979187965393, -0.1458236128091812, -0....  \n",
       "6  [0.2895117998123169, -0.27759850025177, -0.443...  \n",
       "7  [0.33497363328933716, -0.12277282774448395, -0...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#does prombase do a good job to differentiate across all sets:\n",
    "\n",
    "dataset_w_embeds[~dataset_w_embeds['Set'].str.contains('base')].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     [0.4185699224472046, -0.8129321336746216, -0.7...\n",
       "4     [0.35524073243141174, -0.5443449020385742, -0....\n",
       "5     [0.4175596833229065, -0.5876224637031555, -0.6...\n",
       "6     [0.3939899802207947, -0.7644816040992737, -0.7...\n",
       "7     [0.30943161249160767, -0.5281971096992493, -0....\n",
       "8     [0.3739273250102997, -0.6068928837776184, -0.6...\n",
       "9     [0.37967318296432495, -0.7677608728408813, -0....\n",
       "10    [0.2575017213821411, -0.6640542149543762, -0.7...\n",
       "14    [0.36158478260040283, -0.7932509779930115, -0....\n",
       "15    [0.4043620526790619, -0.8143025040626526, -0.6...\n",
       "16    [0.4671706259250641, -0.78300940990448, -0.611...\n",
       "17    [0.3373933434486389, -0.7002600431442261, -0.6...\n",
       "18    [0.38493454456329346, -0.5809698104858398, -0....\n",
       "19    [0.3893470764160156, -0.5666419267654419, -0.4...\n",
       "20    [0.40476319193840027, -0.5463060140609741, -0....\n",
       "21    [0.4274798333644867, -0.7088919281959534, -0.5...\n",
       "25    [0.2471407949924469, -0.3737742006778717, -0.6...\n",
       "26    [0.4128078818321228, -0.46863067150115967, -0....\n",
       "27    [0.4216359853744507, -0.5240691304206848, -0.6...\n",
       "28    [0.3137040436267853, -0.4273701012134552, -0.4...\n",
       "29    [0.34500694274902344, -0.7240265607833862, -0....\n",
       "30    [0.2208009511232376, -0.6622047424316406, -0.6...\n",
       "31    [0.29101884365081787, -0.6744334101676941, -0....\n",
       "32    [0.3829744756221771, -0.5783100724220276, -0.6...\n",
       "36    [0.4148779511451721, -0.5118941068649292, -0.8...\n",
       "37    [0.4962657690048218, -0.4663310647010803, -0.7...\n",
       "38    [0.45782363414764404, -0.5487425327301025, -0....\n",
       "39    [0.44248178601264954, -0.6065878868103027, -0....\n",
       "40    [0.5591444373130798, -0.6455442309379578, -0.7...\n",
       "41    [0.4212707579135895, -0.7101186513900757, -0.7...\n",
       "42    [0.46598440408706665, -0.7597313523292542, -0....\n",
       "43    [0.5435842275619507, -0.6688501834869385, -0.7...\n",
       "47    [0.467471182346344, -0.7980060577392578, -0.67...\n",
       "48    [0.42602264881134033, -0.7821992039680481, -0....\n",
       "49    [0.5445923805236816, -0.7890551090240479, -0.5...\n",
       "50    [0.4337434470653534, -0.7926461696624756, -0.6...\n",
       "51    [0.5524411201477051, -0.856160581111908, -0.55...\n",
       "52    [0.614213764667511, -0.8973408341407776, -0.54...\n",
       "53    [0.5756796002388, -0.9662716388702393, -0.5524...\n",
       "54    [0.6108989715576172, -0.8640813231468201, -0.5...\n",
       "Name: embed_base, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#groupby sets, excluding base-category\n",
    "setgrouped = dataset_w_embeds[~dataset_w_embeds['Set'].str.contains('base')].groupby(\"Set\")[\"embed_base\"]\n",
    "setgrouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bank-money:bank-money:2.1641586372910844\n",
      "bank-money:bank-river:5.755950008254665\n",
      "bank-money:cool-cold:8.107997314331437\n",
      "bank-money:cool-nice:7.233491794700285\n",
      "bank-money:duck-animal:7.828895944417515\n",
      "bank-money:duck-down:9.404484968721276\n",
      "bank-money:figure-body:8.111505554415858\n",
      "bank-money:figure-number:8.060565296128399\n",
      "bank-money:trunk-car:7.007210867748952\n",
      "bank-money:trunk-tree:7.330297362712321\n",
      "bank-river:bank-river:2.10008842155786\n",
      "bank-river:cool-cold:7.8804507797566\n",
      "bank-river:cool-nice:7.115697953592645\n",
      "bank-river:duck-animal:7.1615193942651905\n",
      "bank-river:duck-down:9.008679758531105\n",
      "bank-river:figure-body:7.969254843776894\n",
      "bank-river:figure-number:7.415517898698991\n",
      "bank-river:trunk-car:6.851839628994174\n",
      "bank-river:trunk-tree:6.324327350235041\n",
      "cool-cold:cool-cold:2.111790495816015\n",
      "cool-cold:cool-nice:5.138850784483196\n",
      "cool-cold:duck-animal:7.736483663274887\n",
      "cool-cold:duck-down:8.572636189336837\n",
      "cool-cold:figure-body:7.933266086605007\n",
      "cool-cold:figure-number:7.774803675916708\n",
      "cool-cold:trunk-car:7.785890395293633\n",
      "cool-cold:trunk-tree:8.003579567023719\n",
      "cool-nice:cool-nice:2.276001691750149\n",
      "cool-nice:duck-animal:7.563563192080759\n",
      "cool-nice:duck-down:8.565086554930676\n",
      "cool-nice:figure-body:7.183579239477527\n",
      "cool-nice:figure-number:7.051291501807584\n",
      "cool-nice:trunk-car:7.0790589433733055\n",
      "cool-nice:trunk-tree:7.503441810482643\n",
      "duck-animal:duck-animal:1.4038867950808684\n",
      "duck-animal:duck-down:5.752509233121877\n",
      "duck-animal:figure-body:8.23988968737974\n",
      "duck-animal:figure-number:7.967246637231798\n",
      "duck-animal:trunk-car:7.430534953044373\n",
      "duck-animal:trunk-tree:7.581178184426787\n",
      "duck-down:duck-down:1.8664277299497833\n",
      "duck-down:figure-body:8.574174966434807\n",
      "duck-down:figure-number:8.718859139213244\n",
      "duck-down:trunk-car:8.595956056585319\n",
      "duck-down:trunk-tree:8.91778998113836\n",
      "figure-body:figure-body:2.460902044056287\n",
      "figure-body:figure-number:6.079962755097142\n",
      "figure-body:trunk-car:7.78755506191643\n",
      "figure-body:trunk-tree:8.00645249343543\n",
      "figure-number:figure-number:2.477260310560137\n",
      "figure-number:trunk-car:7.5727525748191775\n",
      "figure-number:trunk-tree:7.575246370433085\n",
      "trunk-car:trunk-car:2.276866373632762\n",
      "trunk-car:trunk-tree:5.93641968636771\n",
      "trunk-tree:trunk-tree:2.3071908669838384\n"
     ]
    }
   ],
   "source": [
    "dist = torch.nn.PairwiseDistance()\n",
    "results5: typing.Dict[typing.Tuple[str, str], float] = {}\n",
    "for label_1, c_1 in setgrouped:\n",
    "    for label_2, c_2 in setgrouped:\n",
    "\n",
    "        if (\n",
    "            (label_1, label_2) in results5.keys() or \n",
    "            (label_2, label_1) in results5.keys()\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        res = sum([\n",
    "            sum(dist(\n",
    "                torch.tensor(np.array(v_1)), \n",
    "                torch.tensor(np.array(c_2.tolist()))\n",
    "                )) / len(c_2)\n",
    "            for v_1 in c_1\n",
    "        ]) / len(c_1)\n",
    "\n",
    "        results5[(label_1, label_2)] = res\n",
    "\n",
    "        print(f'{label_1}:{label_2}:{res.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('bank-money', 'cool-nice'), tensor(7.2335, dtype=torch.float64))\n",
      "(('bank-money', 'figure-number'), tensor(8.0606, dtype=torch.float64))\n",
      "(('bank-river', 'cool-cold'), tensor(7.8805, dtype=torch.float64))\n",
      "(('bank-river', 'figure-body'), tensor(7.9693, dtype=torch.float64))\n",
      "(('cool-cold', 'cool-cold'), tensor(2.1118, dtype=torch.float64))\n",
      "(('cool-cold', 'figure-body'), tensor(7.9333, dtype=torch.float64))\n",
      "(('cool-nice', 'cool-nice'), tensor(2.2760, dtype=torch.float64))\n",
      "(('cool-nice', 'figure-number'), tensor(7.0513, dtype=torch.float64))\n",
      "(('duck-animal', 'duck-down'), tensor(5.7525, dtype=torch.float64))\n",
      "(('duck-animal', 'trunk-tree'), tensor(7.5812, dtype=torch.float64))\n",
      "(('duck-down', 'trunk-car'), tensor(8.5960, dtype=torch.float64))\n",
      "(('figure-body', 'trunk-car'), tensor(7.7876, dtype=torch.float64))\n",
      "(('figure-number', 'trunk-tree'), tensor(7.5752, dtype=torch.float64))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(3, len(results5), 4):\n",
    "    print(list(results5.items())[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "appears to work quite well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some validity checks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [01:24<00:00,  1.54s/it]\n",
      "100%|██████████| 55/55 [01:07<00:00,  1.23s/it]\n"
     ]
    }
   ],
   "source": [
    "#maybe look at the output that is embedded, did the output yield correctly or are there traces of the prompt left in the output?\n",
    "\n",
    "output_base: typing.Dict[str, np.ndarray] = {}\n",
    "output_rich: typing.Dict[str, np.ndarray] = {}\n",
    "\n",
    "for item in template_dict:\n",
    "    name = item['name']\n",
    "    template = item['template']\n",
    "    for index, row in tqdm.tqdm(dataset.iterrows(), total=len(dataset)):\n",
    "        context = row[\"Context\"]\n",
    "        sentence = row[\"Sentence\"]\n",
    "        try: \n",
    "            output = np.array(requests.post(\n",
    "                'https://inf.cl.uni-trier.de/',\n",
    "                json={'model': MODEL, 'prompt': template + context + '; Sentence: ' + sentence}\n",
    "                ).json()[\"response\"])\n",
    "        except Exception as _e:\n",
    "            logging.warning(_e)\n",
    "            output = None\n",
    "        \n",
    "        if name=='embed_base':\n",
    "            output_base[index] = output\n",
    "        if name=='embed_rich':\n",
    "            output_rich[index] = output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 10/55 [00:00<00:00, 5127.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You help me get embeddings for a sentence. I provide you a with a context and a sentence and you reply only with that exact sentence. Context = bank; Sentence = I'm going to the bank.\n",
      "You help me get embeddings for a sentence. I provide you a with a context and a sentence and you reply only with that exact sentence. Context = bank-money; Sentence = I'm going to the bank.\n",
      "You help me get embeddings for a sentence. I provide you a with a context and a sentence and you reply only with that exact sentence. Context = bank-river; Sentence = I'm going to the bank.\n",
      "You help me get embeddings for a sentence. I provide you a with a context and a sentence and you reply only with that exact sentence. Context = bank-money; Sentence = I need to visit the bank today.\n",
      "You help me get embeddings for a sentence. I provide you a with a context and a sentence and you reply only with that exact sentence. Context = bank-money; Sentence = I'm heading to the bank to withdraw some cash.\n",
      "You help me get embeddings for a sentence. I provide you a with a context and a sentence and you reply only with that exact sentence. Context = bank-money; Sentence = The bank is where I'm off to.\n",
      "You help me get embeddings for a sentence. I provide you a with a context and a sentence and you reply only with that exact sentence. Context = bank-money; Sentence = I have an appointment at the bank.\n",
      "You help me get embeddings for a sentence. I provide you a with a context and a sentence and you reply only with that exact sentence. Context = bank-river; Sentence = Let's spend the day by the river bank.\n",
      "You help me get embeddings for a sentence. I provide you a with a context and a sentence and you reply only with that exact sentence. Context = bank-river; Sentence = The river bank is a peaceful place to relax.\n",
      "You help me get embeddings for a sentence. I provide you a with a context and a sentence and you reply only with that exact sentence. Context = bank-river; Sentence = I enjoy walking along the river bank.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 10/55 [00:00<00:00, 9416.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You help me get embeddings for a sentence that will help me to determine semantic sentence similarity. I provide you a sentence and you reply only with that exact sentence. Context = bank; Sentence = I'm going to the bank.\n",
      "You help me get embeddings for a sentence that will help me to determine semantic sentence similarity. I provide you a sentence and you reply only with that exact sentence. Context = bank-money; Sentence = I'm going to the bank.\n",
      "You help me get embeddings for a sentence that will help me to determine semantic sentence similarity. I provide you a sentence and you reply only with that exact sentence. Context = bank-river; Sentence = I'm going to the bank.\n",
      "You help me get embeddings for a sentence that will help me to determine semantic sentence similarity. I provide you a sentence and you reply only with that exact sentence. Context = bank-money; Sentence = I need to visit the bank today.\n",
      "You help me get embeddings for a sentence that will help me to determine semantic sentence similarity. I provide you a sentence and you reply only with that exact sentence. Context = bank-money; Sentence = I'm heading to the bank to withdraw some cash.\n",
      "You help me get embeddings for a sentence that will help me to determine semantic sentence similarity. I provide you a sentence and you reply only with that exact sentence. Context = bank-money; Sentence = The bank is where I'm off to.\n",
      "You help me get embeddings for a sentence that will help me to determine semantic sentence similarity. I provide you a sentence and you reply only with that exact sentence. Context = bank-money; Sentence = I have an appointment at the bank.\n",
      "You help me get embeddings for a sentence that will help me to determine semantic sentence similarity. I provide you a sentence and you reply only with that exact sentence. Context = bank-river; Sentence = Let's spend the day by the river bank.\n",
      "You help me get embeddings for a sentence that will help me to determine semantic sentence similarity. I provide you a sentence and you reply only with that exact sentence. Context = bank-river; Sentence = The river bank is a peaceful place to relax.\n",
      "You help me get embeddings for a sentence that will help me to determine semantic sentence similarity. I provide you a sentence and you reply only with that exact sentence. Context = bank-river; Sentence = I enjoy walking along the river bank.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for item in template_dict:\n",
    "    name = item['name']\n",
    "    template = item['template']\n",
    "    for index, row in tqdm.tqdm(dataset[:10].iterrows(), total=len(dataset)):\n",
    "        context = row[\"Context\"]\n",
    "        sentence = row[\"Sentence\"]\n",
    "        print(template + context + '; Sentence = ' + sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array(\"I'm going to the bank.\", dtype='<U22'),\n",
       " 1: array(\"I'm going to the bank.\", dtype='<U22'),\n",
       " 2: array(\"I'm going to the bank.\", dtype='<U22'),\n",
       " 3: array('I need to visit the bank today.', dtype='<U31'),\n",
       " 4: array(\"I'm heading to the bank to withdraw some cash.\", dtype='<U46'),\n",
       " 5: array(\"The bank is where I'm off to.\", dtype='<U29'),\n",
       " 6: array('I have an appointment at the bank.', dtype='<U34'),\n",
       " 7: array(\"Let's spend the day by the river bank.\", dtype='<U38'),\n",
       " 8: array('The river bank is a peaceful place to relax.', dtype='<U44'),\n",
       " 9: array('I enjoy walking along the river bank.', dtype='<U37'),\n",
       " 10: array('We can have a picnic by the river bank.', dtype='<U39'),\n",
       " 11: array('She has a cool job.', dtype='<U19'),\n",
       " 12: array('She has a cool job.', dtype='<U19'),\n",
       " 13: array('She has a cool job.', dtype='<U19'),\n",
       " 14: array('Her job is really interesting and fun.', dtype='<U38'),\n",
       " 15: array('She works in a creative field and loves it.', dtype='<U43'),\n",
       " 16: array('That job of hers is so unique.', dtype='<U30'),\n",
       " 17: array(\"She's lucky to have such a cool profession.\", dtype='<U43'),\n",
       " 18: array('Her workplace is always chilly.', dtype='<U31'),\n",
       " 19: array('She works in a refrigerated environment.', dtype='<U40'),\n",
       " 20: array('The temperature in her office is freezing.', dtype='<U42'),\n",
       " 21: array('She needs to bundle up for her job.', dtype='<U35'),\n",
       " 22: array('You need to check the trunk.', dtype='<U28'),\n",
       " 23: array('You need to check the trunk.', dtype='<U28'),\n",
       " 24: array('You need to check the trunk.', dtype='<U28'),\n",
       " 25: array(\"Don't forget to look in the trunk of the car.\", dtype='<U45'),\n",
       " 26: array('There might be something important in the trunk.', dtype='<U48'),\n",
       " 27: array('Make sure to verify the contents of the trunk.', dtype='<U46'),\n",
       " 28: array('The trunk needs to be inspected for any damage.', dtype='<U47'),\n",
       " 29: array('Take a look at the tree trunk for any damage.', dtype='<U45'),\n",
       " 30: array('The trunk of the old tree might have some interesting carvings.',\n",
       "       dtype='<U63'),\n",
       " 31: array('Check if the tree trunk needs to be treated for pests.',\n",
       "       dtype='<U54'),\n",
       " 32: array('See if there are any unique patterns or textures on the tree trunk.',\n",
       "       dtype='<U67'),\n",
       " 33: array('I saw her duck.', dtype='<U15'),\n",
       " 34: array('I saw her duck.', dtype='<U15'),\n",
       " 35: array('I saw her duck.', dtype='<U15'),\n",
       " 36: array('Her duck was waddling in the park.', dtype='<U34'),\n",
       " 37: array('The duck she owns is so cute.', dtype='<U29'),\n",
       " 38: array('I spotted her duck by the pond.', dtype='<U31'),\n",
       " 39: array('Her duck was quacking loudly.', dtype='<U29'),\n",
       " 40: array('She ducked to avoid the flying object.', dtype='<U38'),\n",
       " 41: array('Her quick ducking saved her from the falling branch.', dtype='<U52'),\n",
       " 42: array('I noticed her sudden ducking movement.', dtype='<U38'),\n",
       " 43: array('She ducked and dodged the incoming ball.', dtype='<U40'),\n",
       " 44: array('She has a great figure.', dtype='<U23'),\n",
       " 45: array('She has a great figure.', dtype='<U23'),\n",
       " 46: array('She has a great figure.', dtype='<U23'),\n",
       " 47: array('Her body shape is very flattering.', dtype='<U34'),\n",
       " 48: array('She carries herself with grace and confidence.', dtype='<U46'),\n",
       " 49: array('Her figure is well-proportioned and attractive.', dtype='<U47'),\n",
       " 50: array('She knows how to dress to highlight her figure.', dtype='<U47'),\n",
       " 51: array('The numerical figure she presented was impressive.', dtype='<U50'),\n",
       " 52: array('Her calculations yielded a significant figure.', dtype='<U46'),\n",
       " 53: array('The data supports a substantial figure.', dtype='<U39'),\n",
       " 54: array('The figure she quoted was accurate and reliable.', dtype='<U48')}"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array(\"I'm going to the bank.\", dtype='<U22'),\n",
       " 1: array(\"I'm going to the bank.\", dtype='<U22'),\n",
       " 2: array(\"I'm going to the bank.\", dtype='<U22'),\n",
       " 3: array('I need to visit the bank today.', dtype='<U31'),\n",
       " 4: array(\"I'm heading to the bank to withdraw some cash.\", dtype='<U46'),\n",
       " 5: array(\"The bank is where I'm off to.\", dtype='<U29'),\n",
       " 6: array('I have an appointment at the bank.', dtype='<U34'),\n",
       " 7: array(\"Let's spend the day by the river bank.\", dtype='<U38'),\n",
       " 8: array('The river bank is a peaceful place to relax.', dtype='<U44'),\n",
       " 9: array('I enjoy walking along the river bank.', dtype='<U37'),\n",
       " 10: array('We can have a picnic by the river bank.', dtype='<U39'),\n",
       " 11: array('She has a cool job.', dtype='<U19'),\n",
       " 12: array('She has a nice job.', dtype='<U19'),\n",
       " 13: array('She has a cool job.', dtype='<U19'),\n",
       " 14: array('Her job is really interesting and fun.', dtype='<U38'),\n",
       " 15: array('She works in a creative field and loves it.', dtype='<U43'),\n",
       " 16: array('That job of hers is so unique.', dtype='<U30'),\n",
       " 17: array(\"She's lucky to have such a cool profession.\", dtype='<U43'),\n",
       " 18: array('Her workplace is always chilly.', dtype='<U31'),\n",
       " 19: array('She works in a refrigerated environment.', dtype='<U40'),\n",
       " 20: array('The temperature in her office is freezing.', dtype='<U42'),\n",
       " 21: array('She needs to bundle up for her job.', dtype='<U35'),\n",
       " 22: array('You need to check the trunk.', dtype='<U28'),\n",
       " 23: array('You need to check the trunk.', dtype='<U28'),\n",
       " 24: array('You need to check the trunk.', dtype='<U28'),\n",
       " 25: array(\"Don't forget to look in the trunk of the car.\", dtype='<U45'),\n",
       " 26: array('There might be something important in the trunk.', dtype='<U48'),\n",
       " 27: array('Make sure to verify the contents of the trunk.', dtype='<U46'),\n",
       " 28: array('The trunk needs to be inspected for any damage.', dtype='<U47'),\n",
       " 29: array('Take a look at the tree trunk for any damage.', dtype='<U45'),\n",
       " 30: array('The trunk of the old tree might have some interesting carvings.',\n",
       "       dtype='<U63'),\n",
       " 31: array('Check if the tree trunk needs to be treated for pests.',\n",
       "       dtype='<U54'),\n",
       " 32: array('See if there are any unique patterns or textures on the tree trunk.',\n",
       "       dtype='<U67'),\n",
       " 33: array('I saw her duck.', dtype='<U15'),\n",
       " 34: array('I saw her duck.', dtype='<U15'),\n",
       " 35: array('I saw her duck.', dtype='<U15'),\n",
       " 36: array('Her duck was waddling in the park.', dtype='<U34'),\n",
       " 37: array('The duck she owns is so cute.', dtype='<U29'),\n",
       " 38: array('I spotted her duck by the pond.', dtype='<U31'),\n",
       " 39: array('Her duck was quacking loudly.', dtype='<U29'),\n",
       " 40: array('She ducked to avoid the flying object.', dtype='<U38'),\n",
       " 41: array('Her quick ducking saved her from the falling branch.', dtype='<U52'),\n",
       " 42: array('I noticed her sudden ducking movement.', dtype='<U38'),\n",
       " 43: array('She ducked and dodged the incoming ball.', dtype='<U40'),\n",
       " 44: array('She has a great figure.', dtype='<U23'),\n",
       " 45: array('She has a great figure.', dtype='<U23'),\n",
       " 46: array('She has a great figure.', dtype='<U23'),\n",
       " 47: array('Her body shape is very flattering.', dtype='<U34'),\n",
       " 48: array('She carries herself with grace and confidence.', dtype='<U46'),\n",
       " 49: array('Her figure is well-proportioned and attractive.', dtype='<U47'),\n",
       " 50: array('She knows how to dress to highlight her figure.', dtype='<U47'),\n",
       " 51: array('The numerical figure she presented was impressive.', dtype='<U50'),\n",
       " 52: array('Her calculations yielded a significant figure.', dtype='<U46'),\n",
       " 53: array('The data supports a substantial figure.', dtype='<U39'),\n",
       " 54: array('The figure she quoted was accurate and reliable.', dtype='<U48')}"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_rich"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DefiningDebateQuality",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
