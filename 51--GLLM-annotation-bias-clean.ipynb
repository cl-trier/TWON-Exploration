{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4374869",
   "metadata": {},
   "source": [
    "This notebook compares annotations using different GLLMs with codebooks based prompts of Boukes 2024, Jaidka 2022 and Naab 2025 on their respective datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a8edc34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 645, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 1999, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_18736\\508195922.py\", line 16, in <module>\n",
      "    import src\n",
      "  File \"c:\\Users\\sstolwi\\Github\\TWON-Metrics\\src\\__init__.py\", line 1, in <module>\n",
      "    from .hf_classify import HFClassify\n",
      "  File \"c:\\Users\\sstolwi\\Github\\TWON-Metrics\\src\\hf_classify.py\", line 5, in <module>\n",
      "    import torch\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\torch\\__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\torch\\functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\torch\\nn\\__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\torch\\nn\\modules\\__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"sjoerdAzure.env\")  # Load environment variables from .env file\n",
    "import time\n",
    "\n",
    "import typing\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score, classification_report\n",
    "import krippendorff\n",
    "import yaml\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import config\n",
    "import src\n",
    "import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "#import cltrier_lib as lib\n",
    "import pyreadstat\n",
    "import yaml\n",
    "pd.set_option('display.max_colwidth', 100) \n",
    "#set up helper variables and functions:\n",
    "CFG = config.Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "278268c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data:\n",
    "\n",
    "# Jaida2024 data\n",
    "jaidka = pd.read_parquet('data/jaidka2022/TwitterDeliberativePolitics2.parquet')\n",
    "# Boukes\n",
    "boukes = pd.read_parquet('data/publicsphere/publicsphere.cardiff_prompt_classify_anon.parquet')\n",
    "boukesT = pd.read_csv('data/publicsphere/full_data.csv') # this includes the comments\n",
    "#the Boukes2024 data is a subset of this, select YT part of Boukes in line with Boukes2024:\n",
    "boukesTYT = boukesT[boukesT['Platform'] == 1]\n",
    "#MH_clemm 2024\n",
    "MHclemm = pd.read_parquet('data/MH_BClemm_data/Ideo_Val_GPT_USA_L33_70b.parquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8c56af",
   "metadata": {},
   "source": [
    "list the variables we want to use:\n",
    "**rationality** - prompt: 'rationality_simple2', 'rationality_jaidka',        \n",
    "  manual coding: \"Justification\" (Jaidka), RATIONALITY_DUMMY\n",
    "**incivility** - prompt: 'incivility_simple2', 'incivility_jaidka',  civility_jaidka         \n",
    "  manual coding: INCIVILITY_DUMMY, Incivility_tot ('Uncivil_abuse', 'Empathy_Respect'), Uncivil_abuse, \"Empathy_Respect\" (jaidka)\n",
    "**interactivity** - prompt: 'interactivity_acknowledgement_simple', interactivity_acknowledgement_jaidka       \n",
    "  manual coding: INTERACTIVITY_DUMMY, Reciprocity (Jaidka)\n",
    "**diversity/ideology** - prompt: 'political_ideology_US', 'political_ideology' (german)  -> no ideology in Jaidka\n",
    "  manual coding: LIBERAL_DUMMY, CONSERVATIVE_DUMMY\n",
    "**political_dum** - prompt: 'political_post', political_post_jaidka \n",
    "  manual coding: HAS_OPINION_DUMMY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d190ef58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model variants:\n",
    "# llama31_8b\n",
    "# llama31_70b\n",
    "# gpt4o\n",
    "# gpt4Turbo\n",
    "\n",
    "#optional:\n",
    "# gpt4 (OPenAI, microsoft)\n",
    "# llama33_70b (Meta)\n",
    "# Gemma3:22b (US, google) (based on Gemini 2)\n",
    "# \"id\":\"deepseek-r1:70b\",\"name\":\"DeepSeek-R1 (china)\n",
    "# qwen2.5:70b (china)\n",
    "# mistral-large:123b\",\"name\":\"Mistral\" (europe)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027effde",
   "metadata": {},
   "source": [
    "list the annotations we have available per dataset:\n",
    "**Jaidka**: 'rationality_simple2_Llama8b_dum', 'rationality_simple2_gpt4o_dum','rationality_jaidka_Llama8b_dum','rationality_jaidka_gpt4o_dum', 'civility_jaidka_gpt4o_dum', incivility_simple2_gpt4o_dum, incivility_jaidka_gpt4o_dum, reciprocity_jaidka_gpt4o_dum, interactivity_acknowledgement_simple_gpt4o_dum, political_post_jaidka_gpt4o_dum, political_post_gpt4o_dum\n",
    "**Boukes**: \n",
    "*rationality*: rationality_simple2_dum (+ rationality_simple_dum, rationality_combine_dum, rationality_combine_exactexample_dum, rationality_prompt_dum (aggregation of indicator prompt scores)), rationality_simple2_gpt4o_system_dum, rationality_simple2_gpt4T_system_dum, rationality_simple2_small_dum, \n",
    "*incivility*: incivility_simple2_dum (+ incivility_simple_dum, incivility_combine_dum), incivility_prompt_dum (aggregation of indicator prompt scores), incivility_simple2_gpt4o_system_dum, incivility_simple2_gpt4T_system_dum, incivility_simple2_small_dum \n",
    "*interactivity*: interactivity_acknowledgement_simple_dum (+ interactivity_acknowledgement_simple2_dum), interactivity_acknowledgement_simple_gpt4o_system_dum, interactivity_acknowledgement_simple_gpt4T_system_dum, interactivity_acknowledgement_simple_small_dum (+interactivity_acknowledgement_simple_small2_dum)\n",
    "*diversity*: political_liberal_US_dum, political_conservative_US_dum, political_liberal_US_gpt4o_system_dum, political_liberal_US_gpt4T_system_dum, political_conservative_US_gpt4o_system_dum, political_conservative_US_gpt4T_system_dum, political_liberal_US_small_dum, political_conservative_US_small_dum\n",
    "*political_dum*: political_opinion_US_dum, political_opinion_US_gpt4o_system_dum, political_opinion_US_gpt4T_system_dum, political_opinion_US_small_dum (either liberal/conservative; Boukes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b3e987",
   "metadata": {},
   "source": [
    "Update and clarify variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3d623912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text',\n",
       " 'label',\n",
       " 'GPT1',\n",
       " 'GPT2',\n",
       " 'GPT_Reconciled',\n",
       " 'political_ideology_US_L33_70b_zero',\n",
       " 'political_ideology_US_para1_L33_70b_zero',\n",
       " 'political_ideology_US_L31_8b_zero',\n",
       " 'political_ideology_US_para1_L31_8b_zero',\n",
       " 'political_ideology_US_Q25_72b_zero',\n",
       " 'political_ideology_US_para1_Q25_72b_zero',\n",
       " 'political_ideology_US_L33_70b_zero_con_dum',\n",
       " 'political_ideology_US_L33_70b_zero_lib_dum',\n",
       " 'political_ideology_US_para1_L33_70b_zero_con_dum',\n",
       " 'political_ideology_US_para1_L33_70b_zero_lib_dum',\n",
       " 'political_ideology_US_L31_8b_zero_con_dum',\n",
       " 'political_ideology_US_L31_8b_zero_lib_dum',\n",
       " 'political_ideology_US_para1_L31_8b_zero_con_dum',\n",
       " 'political_ideology_US_para1_L31_8b_zero_lib_dum',\n",
       " 'political_ideology_US_Q25_72b_zero_con_dum',\n",
       " 'political_ideology_US_Q25_72b_zero_lib_dum',\n",
       " 'political_ideology_US_para1_Q25_72b_zero_con_dum',\n",
       " 'political_ideology_US_para1_Q25_72b_zero_lib_dum']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MHclemm.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "23e3e6f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message_id</th>\n",
       "      <th>message</th>\n",
       "      <th>Constructiveness</th>\n",
       "      <th>Justification</th>\n",
       "      <th>Justification_internal</th>\n",
       "      <th>Justification_external</th>\n",
       "      <th>Relevance</th>\n",
       "      <th>Reciprocity</th>\n",
       "      <th>Empathy_Respect</th>\n",
       "      <th>Uncivil_abuse</th>\n",
       "      <th>...</th>\n",
       "      <th>political_post_jaidka_L31_8b_zero_dum</th>\n",
       "      <th>civility_jaidka_Q25_72b_zero_dum</th>\n",
       "      <th>incivility_jaidka_Q25_72b_zero_dum</th>\n",
       "      <th>incivility_simple2_Q25_72b_zero_dum</th>\n",
       "      <th>reciprocity_jaidka_Q25_72b_zero_dum</th>\n",
       "      <th>interactivity_acknowledgement_simple_Q25_72b_zero_dum</th>\n",
       "      <th>political_post_Q25_72b_zero_dum</th>\n",
       "      <th>political_post_jaidka_Q25_72b_zero_dum</th>\n",
       "      <th>rationality_jaidka_Q25_72b_zero_dum</th>\n",
       "      <th>rationality_simple2_Q25_72b_zero_dum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@USER- #GrahamCassidy will devastate #MilitaryFamilies w/ kids like Justin who need #Medicaid. P...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>@USER- The US people &amp;amp; Minnesotans must see the Senate Ethics investigation committee hearin...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>=@USER - \"we all want the same thing when you look at the big picture\"</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>@USER - A poison in our island - Rising seas caused by climate change are seeping inside a Unite...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>=@USER - hypocrite. You are A porn surfer and claim to be holier than thou.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   message_id  \\\n",
       "0           1   \n",
       "1           2   \n",
       "2           4   \n",
       "3           5   \n",
       "4           6   \n",
       "\n",
       "                                                                                               message  \\\n",
       "0  @USER- #GrahamCassidy will devastate #MilitaryFamilies w/ kids like Justin who need #Medicaid. P...   \n",
       "1  @USER- The US people &amp; Minnesotans must see the Senate Ethics investigation committee hearin...   \n",
       "2                               =@USER - \"we all want the same thing when you look at the big picture\"   \n",
       "3  @USER - A poison in our island - Rising seas caused by climate change are seeping inside a Unite...   \n",
       "4                          =@USER - hypocrite. You are A porn surfer and claim to be holier than thou.   \n",
       "\n",
       "   Constructiveness  Justification  Justification_internal  \\\n",
       "0                 0              1                       0   \n",
       "1                 0              1                       0   \n",
       "2                 0              1                       0   \n",
       "3                 0              1                       0   \n",
       "4                 0              0                       0   \n",
       "\n",
       "   Justification_external  Relevance  Reciprocity  Empathy_Respect  \\\n",
       "0                       0        1.0          1.0              1.0   \n",
       "1                       0        1.0          1.0              1.0   \n",
       "2                       0        1.0          NaN              1.0   \n",
       "3                       0        1.0          0.0              NaN   \n",
       "4                       0        NaN          0.0              0.0   \n",
       "\n",
       "   Uncivil_abuse  ... political_post_jaidka_L31_8b_zero_dum  \\\n",
       "0            1.0  ...                                     0   \n",
       "1            1.0  ...                                     0   \n",
       "2            NaN  ...                                     0   \n",
       "3            0.0  ...                                     0   \n",
       "4            NaN  ...                                     0   \n",
       "\n",
       "   civility_jaidka_Q25_72b_zero_dum incivility_jaidka_Q25_72b_zero_dum  \\\n",
       "0                                 0                                  0   \n",
       "1                                 0                                  1   \n",
       "2                                 1                                  0   \n",
       "3                                 0                                  0   \n",
       "4                                 0                                  1   \n",
       "\n",
       "   incivility_simple2_Q25_72b_zero_dum reciprocity_jaidka_Q25_72b_zero_dum  \\\n",
       "0                                    0                                   0   \n",
       "1                                    1                                   0   \n",
       "2                                    0                                   0   \n",
       "3                                    1                                   0   \n",
       "4                                    1                                   0   \n",
       "\n",
       "   interactivity_acknowledgement_simple_Q25_72b_zero_dum  \\\n",
       "0                                                      1   \n",
       "1                                                      1   \n",
       "2                                                      1   \n",
       "3                                                      1   \n",
       "4                                                      0   \n",
       "\n",
       "  political_post_Q25_72b_zero_dum political_post_jaidka_Q25_72b_zero_dum  \\\n",
       "0                               1                                      0   \n",
       "1                               1                                      0   \n",
       "2                               0                                      0   \n",
       "3                               1                                      0   \n",
       "4                               0                                      0   \n",
       "\n",
       "  rationality_jaidka_Q25_72b_zero_dum rationality_simple2_Q25_72b_zero_dum  \n",
       "0                                   1                                    0  \n",
       "1                                   1                                    0  \n",
       "2                                   0                                    0  \n",
       "3                                   1                                    1  \n",
       "4                                   1                                    0  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jaidka.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ef5d3bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "zerolist = [    'rationality_simple2_Llama8b',\n",
    " 'rationality_jaidka_Llama8b',  'rationality_jaidka_gpt4o',  'reciprocity_jaidka_gpt4o', 'civility_jaidka_gpt4o',\n",
    " 'incivility_jaidka_gpt4o',\n",
    " 'political_post_jaidka_gpt4o',\n",
    " 'constructiveness_jaidka_gpt4o',\n",
    " 'interactivity_acknowledgement_simple_gpt4o',\n",
    " 'incivility_simple2_gpt4o', 'political_post_gpt4o',\n",
    "\n",
    "\n",
    " ]\n",
    "\n",
    "\n",
    "##change column names in boukes for lowlist:\n",
    "for col in zerolist:\n",
    "    if col in jaidka.columns:\n",
    "        jaidka.rename(columns={col: col + '_zero'}, inplace=True)\n",
    "    if col + '_dum' in jaidka.columns:\n",
    "        jaidka.rename(columns={col + '_dum': col + '_zero_dum'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2037b54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowlist = ['rationality_simple2_L33_70b',\n",
    " 'civility_jaidka_L33_70b',\n",
    " 'incivility_jaidka_L33_70b',\n",
    " 'incivility_simple2_L33_70b',\n",
    " 'rationality_jaidka_L33_70b',\n",
    " 'reciprocity_jaidka_L33_70b',\n",
    " \n",
    "]\n",
    "\n",
    "#change column names in boukes for zerolist:\n",
    "for col in lowlist:\n",
    "    if col in boukes.columns:\n",
    "        boukes.rename(columns={col: col + '_low'}, inplace=True)\n",
    "    if col + '_dum' in boukes.columns:\n",
    "        boukes.rename(columns={col + '_dum': col + '_low_dum'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5b33a083",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dummy variables:\n",
    "ideolist = ['political_ideology_US_L33_70b_low', 'political_ideology_US_L33_70b_seed2_low', 'political_ideology_US_para1_L33_70b_low',\n",
    " 'political_ideology_US_para2_L33_70b_low',\n",
    " 'political_ideology_US_simpa1_L33_70b_low', 'political_ideology_US_L33_70b_seed2_run2_low',  'political_ideology_US_para1_L31_8b_low',\n",
    " 'political_ideology_US_para2_L31_8b_low',\n",
    " 'political_ideology_US_simpa1_L31_8b_low', 'political_ideology_US_L31_8b_seed2_low',  'political_ideology_US_para1_Q25_72b_zero', 'political_ideology_US_Q72b_zero', 'political_ideology_US_para2_Q25_72b_zero',\n",
    " 'political_ideology_US_simpa1_Q25_72b_zero', 'political_ideology_US_Q72b_seed2_zero', 'political_ideology_US_L33_70b_zero', 'political_ideology_US_L33_70b_zero_seed2',  'political_ideology_US_L31_8b_zero',\n",
    " 'political_ideology_US_L31_8b_zero_seed2',  'political_ideology_US_Q25_72b_low',  'political_ideology_US_Q25_72b_low_seed2',\n",
    "\n",
    "\n",
    "]\n",
    "\n",
    "#make a two dummy variable for each ideology column, one for conservative and one for liberal:\n",
    "for col in ideolist:\n",
    "    if col in boukes.columns:\n",
    "        boukes[col + '_con_dum'] = boukes[col].apply(lambda x: 1 if x == 'conservative' else 0)\n",
    "        boukes[col + '_lib_dum'] = boukes[col].apply(lambda x: 1 if x == 'liberal' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b095cf73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in civility_jaidka_L33_70b_low: ['No', 'Yes', None]\n",
      "Unique values in interactivity_acknowledgement_simple_L33_70b_low: ['No', 'Yes']\n",
      "Unique values in rationality_simple2_para1_L33_70b_low: ['No', None, 'Yes']\n",
      "Unique values in incivility_simple2_L33_70b_seed2_low: ['No', 'Yes', None]\n",
      "Unique values in interactivity_acknowledgement_simple_L33_70b_seed2_low: ['No', None, 'Yes']\n",
      "Unique values in political_post_L33_70b_seed2_low: ['non-political', 'political', None]\n",
      "Unique values in rationality_simple2_L33_70b_seed2_low: ['No', None, 'Yes']\n",
      "Unique values in political_post_para1_L33_70b_low: ['non-political', 'political', None]\n",
      "Unique values in political_post_para2_L33_70b_low: ['non-political', 'political', None]\n",
      "Unique values in political_post_simpa1_L33_70b_low: ['non-political', 'political', None]\n",
      "Unique values in rationality_simple2_para2_L33_70b_low: ['No', None, 'Yes']\n",
      "Unique values in rationality_simple2_simpa1_L33_70b_low: ['No', None, 'Yes']\n",
      "Unique values in incivility_para1_L33_70b_low: ['No', 'Yes', None]\n",
      "Unique values in incivility_para2_L33_70b_low: ['No', 'Yes', None]\n",
      "Unique values in incivility_simpa1_L33_70b_low: ['No', 'Yes', None]\n",
      "Unique values in interactivity_acknowledgement_simple_para1_L33_70b_low: ['No', None, 'Yes']\n",
      "Unique values in interactivity_acknowledgement_simple_para2_L33_70b_low: ['No', None, 'Yes']\n",
      "Unique values in interactivity_acknowledgement_simple_simpa1_L33_70b_low: ['No', None, 'Yes']\n",
      "Unique values in incivility_simple2_L33_70b_seed2_run2_low: ['No', 'Yes', None]\n",
      "Unique values in interactivity_acknowledgement_simple_L33_70b_seed2_run2_low: ['No', None, 'Yes']\n",
      "Unique values in political_post_L33_70b_seed2_run2_low: ['non-political', 'political', None]\n",
      "Unique values in rationality_simple2_L33_70b_seed2_run2_low: ['No', None, 'Yes']\n",
      "Unique values in civility_jaidka_L31_8b_low: ['No', None, 'Yes']\n",
      "Unique values in incivility_jaidka_L31_8b_low: ['No', None, 'Yes']\n",
      "Unique values in incivility_para1_L31_8b_low: ['No', None, 'Yes']\n",
      "Unique values in incivility_para2_L31_8b_low: ['No', None, 'Yes']\n",
      "Unique values in incivility_simpa1_L31_8b_low: ['No', None, 'Yes']\n",
      "Unique values in reciprocity_jaidka_L31_8b_low: ['No', None, 'Yes']\n",
      "Unique values in interactivity_acknowledgement_simple_para1_L31_8b_low: ['No', 'Yes', None]\n",
      "Unique values in interactivity_acknowledgement_simple_para2_L31_8b_low: ['No', None, 'Yes']\n",
      "Unique values in interactivity_acknowledgement_simple_simpa1_L31_8b_low: ['No', 'Yes', None]\n",
      "Unique values in political_post_L31_8b_low: ['non-political', 'political', None]\n",
      "Unique values in political_post_jaidka_L31_8b_low: ['No', 'Yes', None]\n",
      "Unique values in political_post_para1_L31_8b_low: ['non-political', 'political', None]\n",
      "Unique values in political_post_para2_L31_8b_low: ['non-political', 'political', None]\n",
      "Unique values in political_post_simpa1_L31_8b_low: ['non-political', 'political', None]\n",
      "Unique values in rationality_jaidka_L31_8b_low: ['No', 'Yes', None]\n",
      "Unique values in rationality_simple2_para1_L31_8b_low: ['No', None, 'Yes']\n",
      "Unique values in rationality_simple2_para2_L31_8b_low: ['No', None, 'Yes']\n",
      "Unique values in rationality_simple2_simpa1_L31_8b_low: ['No', None, 'Yes']\n",
      "Unique values in incivility_simple2_L31_8b_seed2_low: ['No', None, 'Yes']\n",
      "Unique values in interactivity_acknowledgement_simple_L31_8b_seed2_low: ['No', None, 'Yes']\n",
      "Unique values in political_post_L31_8b_seed2_low: ['non-political', 'political', None]\n",
      "Unique values in rationality_simple2_L31_8b_seed2_low: ['No', None, 'Yes']\n",
      "Unique values in incivility_simple2_Q72b_zero: ['No', 'Yes', None]\n",
      "Unique values in interactivity_acknowledgement_simple_Q72b_zero: ['No', None, 'Yes']\n",
      "Unique values in political_post_Q72b_zero: ['non-political', 'political', None]\n",
      "Unique values in rationality_simple2_Q72b_zero: ['No', None, 'Yes']\n",
      "Unique values in civility_jaidka_Q25_72b_zero: ['No', None, 'Yes']\n",
      "Unique values in incivility_jaidka_Q25_72b_zero: ['No', 'Yes', None]\n",
      "Unique values in incivility_para1_Q25_72b_zero: ['No', 'Yes', None]\n",
      "Unique values in reciprocity_jaidka_Q25_72b_zero: ['No', None, 'Yes']\n",
      "Unique values in interactivity_acknowledgement_simple_para1_Q25_72b_zero: ['No', None, 'Yes']\n",
      "Unique values in political_post_jaidka_Q25_72b_zero: ['No', 'Yes', None]\n",
      "Unique values in political_post_para1_Q25_72b_zero: ['non-political', 'political', None]\n",
      "Unique values in rationality_jaidka_Q25_72b_zero: ['No', 'Yes', None]\n",
      "Unique values in rationality_simple2_para1_Q25_72b_zero: ['No', None, 'Yes']\n",
      "Unique values in incivility_para2_Q25_72b_zero: ['No', 'Yes', None]\n",
      "Unique values in incivility_simpa1_Q25_72b_zero: ['No', 'Yes', None]\n",
      "Unique values in interactivity_acknowledgement_simple_para2_Q25_72b_zero: ['No', None, 'Yes']\n",
      "Unique values in interactivity_acknowledgement_simple_simpa1_Q25_72b_zero: ['No', None, 'Yes']\n",
      "Unique values in political_post_para2_Q25_72b_zero: ['non-political', 'political', None]\n",
      "Unique values in political_post_simpa1_Q25_72b_zero: ['non-political', 'political', None]\n",
      "Unique values in rationality_simple2_para2_Q25_72b_zero: ['No', None, 'Yes']\n",
      "Unique values in rationality_simple2_simpa1_Q25_72b_zero: ['No', None, 'Yes']\n",
      "Unique values in incivility_simple2_Q72b_seed2_zero: ['No', 'Yes', None]\n",
      "Unique values in interactivity_acknowledgement_simple_Q72b_seed2_zero: ['No', None, 'Yes']\n",
      "Unique values in political_post_Q72b_seed2_zero: ['non-political', 'political', None]\n",
      "Unique values in rationality_simple2_Q72b_seed2_zero: ['No', None, 'Yes']\n",
      "Unique values in incivility_simple2_L33_70b_zero: ['No', 'Yes', None]\n",
      "Unique values in interactivity_acknowledgement_simple_L33_70b_zero: ['No', None, 'Yes']\n",
      "Unique values in political_post_L33_70b_zero: ['non-political', 'political', None]\n",
      "Unique values in rationality_simple2_L33_70b_zero: ['No', None, 'Yes']\n",
      "Unique values in incivility_simple2_L33_70b_zero_seed2: ['No', 'Yes', None]\n",
      "Unique values in interactivity_acknowledgement_simple_L33_70b_zero_seed2: ['No', None, 'Yes']\n",
      "Unique values in political_post_L33_70b_zero_seed2: ['non-political', 'political', None]\n",
      "Unique values in rationality_simple2_L33_70b_zero_seed2: ['No', None, 'Yes']\n",
      "Unique values in incivility_simple2_L31_8b_zero: ['No', None, 'Yes']\n",
      "Unique values in interactivity_acknowledgement_simple_L31_8b_zero: ['No', None, 'Yes']\n",
      "Unique values in political_post_L31_8b_zero: ['non-political', 'political', None]\n",
      "Unique values in rationality_simple2_L31_8b_zero: ['No', None, 'Yes']\n",
      "Unique values in incivility_simple2_L31_8b_zero_seed2: ['No', None, 'Yes']\n",
      "Unique values in interactivity_acknowledgement_simple_L31_8b_zero_seed2: ['No', None, 'Yes']\n",
      "Unique values in political_post_L31_8b_zero_seed2: ['non-political', 'political', None]\n",
      "Unique values in rationality_simple2_L31_8b_zero_seed2: ['No', None, 'Yes']\n",
      "Unique values in incivility_simple2_Q25_72b_low: ['No', 'Yes', None]\n",
      "Unique values in interactivity_acknowledgement_simple_Q25_72b_low: ['No', None, 'Yes']\n",
      "Unique values in political_post_Q25_72b_low: ['non-political', 'political', None]\n",
      "Unique values in rationality_simple2_Q25_72b_low: ['No', None, 'Yes']\n",
      "Unique values in incivility_simple2_Q25_72b_low_seed2: ['No', 'Yes', None]\n",
      "Unique values in interactivity_acknowledgement_simple_Q25_72b_low_seed2: ['No', None, 'Yes']\n",
      "Unique values in political_post_Q25_72b_low_seed2: ['non-political', 'political', None]\n",
      "Unique values in rationality_simple2_Q25_72b_low_seed2: ['No', None, 'Yes']\n",
      "Unique values in rationality_jaidka_gpt4o_system_zero: ['No', 'Yes', None]\n",
      "Unique values in incivility_jaidka_gpt4o_system_zero: ['No', None, 'Yes']\n",
      "Unique values in civility_jaidka_gpt4o_system_zero: ['No', None, 'Yes']\n",
      "Unique values in interactivity_acknowledgement_jaidka_gpt4o_system_zero: ['No', None, 'Yes']\n",
      "Unique values in political_post_jaidka_gpt4o_system_zero: ['No', None, 'Yes']\n",
      "Unique values in incivility_para1_gpt4o_system_zero: ['No', 'Yes', None]\n",
      "Unique values in incivility_para2_gpt4o_system_zero: ['No', 'Yes', None]\n",
      "Unique values in interactivity_acknowledgement_para1_gpt4o_system_zero: ['No', None, 'Yes']\n",
      "Unique values in interactivity_acknowledgement_para2_gpt4o_system_zero: ['No', None, 'Yes']\n",
      "Unique values in incivility_simpa1_gpt4o_system_zero: ['No', 'Yes', None]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:118: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'political' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:118: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'political' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:118: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'political' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:118: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'political' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:118: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'political' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:118: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'political' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:118: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'political' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:118: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'political' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:118: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'political' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:118: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'political' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
      "C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_22164\\526396250.py:120: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n"
     ]
    }
   ],
   "source": [
    "#make dummy variables for dummy_list:\n",
    "dummy_list = [ 'civility_jaidka_L33_70b_low',\n",
    " 'interactivity_acknowledgement_simple_L33_70b_low',\n",
    " 'rationality_simple2_para1_L33_70b_low',\n",
    " 'incivility_simple2_L33_70b_seed2_low',\n",
    " 'interactivity_acknowledgement_simple_L33_70b_seed2_low',\n",
    " 'political_post_L33_70b_seed2_low',\n",
    " 'rationality_simple2_L33_70b_seed2_low',\n",
    " 'political_post_para1_L33_70b_low',\n",
    " 'political_post_para2_L33_70b_low',\n",
    " 'political_post_simpa1_L33_70b_low',\n",
    " 'rationality_simple2_para2_L33_70b_low',\n",
    " 'rationality_simple2_simpa1_L33_70b_low',\n",
    " 'incivility_para1_L33_70b_low',\n",
    " 'incivility_para2_L33_70b_low',\n",
    " 'incivility_simpa1_L33_70b_low',\n",
    " 'interactivity_acknowledgement_simple_para1_L33_70b_low',\n",
    " 'interactivity_acknowledgement_simple_para2_L33_70b_low',\n",
    " 'interactivity_acknowledgement_simple_simpa1_L33_70b_low',\n",
    " 'incivility_simple2_L33_70b_seed2_run2_low',\n",
    " 'interactivity_acknowledgement_simple_L33_70b_seed2_run2_low',\n",
    " 'political_post_L33_70b_seed2_run2_low',\n",
    " 'rationality_simple2_L33_70b_seed2_run2_low',\n",
    " 'civility_jaidka_L31_8b_low',\n",
    " 'incivility_jaidka_L31_8b_low',\n",
    " 'incivility_para1_L31_8b_low',\n",
    " 'incivility_para2_L31_8b_low',\n",
    " 'incivility_simpa1_L31_8b_low',\n",
    " 'reciprocity_jaidka_L31_8b_low',\n",
    " 'interactivity_acknowledgement_simple_para1_L31_8b_low',\n",
    " 'interactivity_acknowledgement_simple_para2_L31_8b_low',\n",
    " 'interactivity_acknowledgement_simple_simpa1_L31_8b_low',\n",
    " 'political_post_L31_8b_low',\n",
    " 'political_post_jaidka_L31_8b_low',\n",
    " 'political_post_para1_L31_8b_low',\n",
    " 'political_post_para2_L31_8b_low',\n",
    " 'political_post_simpa1_L31_8b_low',\n",
    " 'rationality_jaidka_L31_8b_low',\n",
    " 'rationality_simple2_para1_L31_8b_low',\n",
    " 'rationality_simple2_para2_L31_8b_low',\n",
    " 'rationality_simple2_simpa1_L31_8b_low',\n",
    " 'incivility_simple2_L31_8b_seed2_low',\n",
    " 'interactivity_acknowledgement_simple_L31_8b_seed2_low',\n",
    "  'political_post_L31_8b_seed2_low',\n",
    " 'rationality_simple2_L31_8b_seed2_low',\n",
    " 'incivility_simple2_Q72b_zero',\n",
    " 'interactivity_acknowledgement_simple_Q72b_zero',\n",
    " 'political_post_Q72b_zero',\n",
    " 'rationality_simple2_Q72b_zero',\n",
    " 'civility_jaidka_Q25_72b_zero',\n",
    " 'incivility_jaidka_Q25_72b_zero',\n",
    " 'incivility_para1_Q25_72b_zero',\n",
    " 'reciprocity_jaidka_Q25_72b_zero',\n",
    " 'interactivity_acknowledgement_simple_para1_Q25_72b_zero',\n",
    " 'political_post_jaidka_Q25_72b_zero',\n",
    " 'political_post_para1_Q25_72b_zero',\n",
    " 'rationality_jaidka_Q25_72b_zero',\n",
    " 'rationality_simple2_para1_Q25_72b_zero',\n",
    " 'incivility_para2_Q25_72b_zero',\n",
    " 'incivility_simpa1_Q25_72b_zero',\n",
    " 'interactivity_acknowledgement_simple_para2_Q25_72b_zero',\n",
    " 'interactivity_acknowledgement_simple_simpa1_Q25_72b_zero',\n",
    "  'political_post_para2_Q25_72b_zero',\n",
    " 'political_post_simpa1_Q25_72b_zero',\n",
    " 'rationality_simple2_para2_Q25_72b_zero',\n",
    " 'rationality_simple2_simpa1_Q25_72b_zero',\n",
    " 'incivility_simple2_Q72b_seed2_zero',\n",
    " 'interactivity_acknowledgement_simple_Q72b_seed2_zero',\n",
    "  'political_post_Q72b_seed2_zero',\n",
    " 'rationality_simple2_Q72b_seed2_zero',\n",
    " 'incivility_simple2_L33_70b_zero',\n",
    " 'interactivity_acknowledgement_simple_L33_70b_zero',\n",
    "  'political_post_L33_70b_zero',\n",
    " 'rationality_simple2_L33_70b_zero',\n",
    " 'incivility_simple2_L33_70b_zero_seed2',\n",
    " 'interactivity_acknowledgement_simple_L33_70b_zero_seed2',\n",
    "  'political_post_L33_70b_zero_seed2',\n",
    " 'rationality_simple2_L33_70b_zero_seed2',\n",
    " 'incivility_simple2_L31_8b_zero',\n",
    " 'interactivity_acknowledgement_simple_L31_8b_zero',\n",
    " 'political_post_L31_8b_zero',\n",
    " 'rationality_simple2_L31_8b_zero',\n",
    " 'incivility_simple2_L31_8b_zero_seed2',\n",
    " 'interactivity_acknowledgement_simple_L31_8b_zero_seed2',\n",
    " 'political_post_L31_8b_zero_seed2',\n",
    " 'rationality_simple2_L31_8b_zero_seed2',\n",
    " 'incivility_simple2_Q25_72b_low',\n",
    " 'interactivity_acknowledgement_simple_Q25_72b_low',\n",
    " 'political_post_Q25_72b_low',\n",
    " 'rationality_simple2_Q25_72b_low',\n",
    " 'incivility_simple2_Q25_72b_low_seed2',\n",
    " 'interactivity_acknowledgement_simple_Q25_72b_low_seed2',\n",
    " 'political_post_Q25_72b_low_seed2',\n",
    " 'rationality_simple2_Q25_72b_low_seed2',\n",
    " 'rationality_jaidka_gpt4o_system_zero',\n",
    " 'incivility_jaidka_gpt4o_system_zero',\n",
    " 'civility_jaidka_gpt4o_system_zero',\n",
    " 'interactivity_acknowledgement_jaidka_gpt4o_system_zero',\n",
    " 'political_post_jaidka_gpt4o_system_zero',\n",
    " 'incivility_para1_gpt4o_system_zero',\n",
    " 'incivility_para2_gpt4o_system_zero',\n",
    " 'interactivity_acknowledgement_para1_gpt4o_system_zero',\n",
    " 'interactivity_acknowledgement_para2_gpt4o_system_zero',\n",
    " 'incivility_simpa1_gpt4o_system_zero']\n",
    "\n",
    "#first check if which unique values are in each of these columns:\n",
    "unique_values = {}\n",
    "for col in dummy_list:\n",
    "    if col in boukes.columns:\n",
    "        unique_values[col] = boukes[col].unique().tolist()\n",
    "        print(f\"Unique values in {col}: {unique_values[col]}\")\n",
    "\n",
    "#if a column starts with political_post, make dummy for 'political' and 'non-political':\n",
    "#if a column does not start with political_post, make dummy for 'yes' and 'no':\n",
    "for col in dummy_list:\n",
    "    if col in boukes.columns:\n",
    "        if 'political_post' in col:\n",
    "            boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'political' else 0)\n",
    "        else:\n",
    "            boukes[col + '_dum'] = boukes[col].apply(lambda x: 1 if x == 'Yes' else 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ef624f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummies for jaidka:\n",
    "jaidkadum = ['incivility_jaidka_L33_70b_zero',\n",
    " 'incivility_simple2_L33_70b_zero',\n",
    " 'reciprocity_jaidka_L33_70b_zero',\n",
    " 'interactivity_acknowledgement_simple_L33_70b_zero',\n",
    " 'political_post_L33_70b_zero',\n",
    " 'political_post_jaidka_L33_70b_zero',\n",
    " 'rationality_jaidka_L33_70b_zero',\n",
    " 'rationality_simple2_L33_70b_zero',\n",
    " 'civility_jaidka_L31_8b_zero',\n",
    " 'incivility_jaidka_L31_8b_zero',\n",
    " 'incivility_simple2_L31_8b_zero',\n",
    " 'reciprocity_jaidka_L31_8b_zero',\n",
    " 'interactivity_acknowledgement_simple_L31_8b_zero',\n",
    " 'political_post_L1_8b_zero',\n",
    " 'political_post_jaidka_L31_8b_zero',\n",
    " 'civility_jaidka_Q25_72b_zero',\n",
    " 'incivility_jaidka_Q25_72b_zero',\n",
    " 'incivility_simple2_Q25_72b_zero',\n",
    " 'reciprocity_jaidka_Q25_72b_zero',\n",
    " 'interactivity_acknowledgement_simple_Q25_72b_zero',\n",
    " 'political_post_Q25_72b_zero',\n",
    " 'political_post_jaidka_Q25_72b_zero',\n",
    " 'rationality_jaidka_Q25_72b_zero',\n",
    " 'rationality_simple2_Q25_72b_zero']\n",
    "\n",
    "#if a column starts with political_post, make dummy for 'political' and 'non-political':\n",
    "#if a column does not start with political_post, make dummy for 'yes' and 'no':\n",
    "for col in jaidkadum:\n",
    "    if col in jaidka.columns:\n",
    "        if 'political_post' in col:\n",
    "            jaidka[col + '_dum'] = jaidka[col].apply(lambda x: 1 if x == 'political' else 0)\n",
    "        else:\n",
    "            jaidka[col + '_dum'] = jaidka[col].apply(lambda x: 1 if x == 'Yes' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bc4858",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the updated dataset with dummy variables:\n",
    "boukes.to_parquet('data/publicsphere/publicsphere.cardiff_prompt_classify_anon.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c42d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "MHclemm.to_parquet('data/MH_BClemm_data/Ideo_Val_GPT_USA_L33_70b.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14c9225",
   "metadata": {},
   "outputs": [],
   "source": [
    "jaidka.to_parquet('data/jaidka2022/TwitterDeliberativePolitics2.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bbd86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rationality_simple2_L33_70b_dum</th>\n",
       "      <th>rationality_jaidka_L33_70b_dum</th>\n",
       "      <th>rationality_simple2_small_dum</th>\n",
       "      <th>rationality_simple2_gpt4o_dum</th>\n",
       "      <th>rationality_simple_dum</th>\n",
       "      <th>RATIONALITY_DUMMY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rationality_simple2_L33_70b_dum</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rationality_jaidka_L33_70b_dum</th>\n",
       "      <td>0.29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rationality_simple2_small_dum</th>\n",
       "      <td>0.46</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rationality_simple2_gpt4o_dum</th>\n",
       "      <td>0.39</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rationality_simple_dum</th>\n",
       "      <td>0.71</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RATIONALITY_DUMMY</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 rationality_simple2_L33_70b_dum  \\\n",
       "rationality_simple2_L33_70b_dum                             1.00   \n",
       "rationality_jaidka_L33_70b_dum                              0.29   \n",
       "rationality_simple2_small_dum                               0.46   \n",
       "rationality_simple2_gpt4o_dum                               0.39   \n",
       "rationality_simple_dum                                      0.71   \n",
       "RATIONALITY_DUMMY                                           0.41   \n",
       "\n",
       "                                 rationality_jaidka_L33_70b_dum  \\\n",
       "rationality_simple2_L33_70b_dum                            0.29   \n",
       "rationality_jaidka_L33_70b_dum                             1.00   \n",
       "rationality_simple2_small_dum                              0.12   \n",
       "rationality_simple2_gpt4o_dum                              0.11   \n",
       "rationality_simple_dum                                     0.31   \n",
       "RATIONALITY_DUMMY                                          0.30   \n",
       "\n",
       "                                 rationality_simple2_small_dum  \\\n",
       "rationality_simple2_L33_70b_dum                           0.46   \n",
       "rationality_jaidka_L33_70b_dum                            0.12   \n",
       "rationality_simple2_small_dum                             1.00   \n",
       "rationality_simple2_gpt4o_dum                             0.54   \n",
       "rationality_simple_dum                                    0.42   \n",
       "RATIONALITY_DUMMY                                         0.25   \n",
       "\n",
       "                                 rationality_simple2_gpt4o_dum  \\\n",
       "rationality_simple2_L33_70b_dum                           0.39   \n",
       "rationality_jaidka_L33_70b_dum                            0.11   \n",
       "rationality_simple2_small_dum                             0.54   \n",
       "rationality_simple2_gpt4o_dum                             1.00   \n",
       "rationality_simple_dum                                    0.32   \n",
       "RATIONALITY_DUMMY                                         0.25   \n",
       "\n",
       "                                 rationality_simple_dum  RATIONALITY_DUMMY  \n",
       "rationality_simple2_L33_70b_dum                    0.71               0.41  \n",
       "rationality_jaidka_L33_70b_dum                     0.31               0.30  \n",
       "rationality_simple2_small_dum                      0.42               0.25  \n",
       "rationality_simple2_gpt4o_dum                      0.32               0.25  \n",
       "rationality_simple_dum                             1.00               0.33  \n",
       "RATIONALITY_DUMMY                                  0.33               1.00  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#feasability check:\n",
    "#do annotations of Llama3.3:70b correlate with gpt4o?\n",
    "boukes.loc[:, ['rationality_simple2_L33_70b_dum', 'rationality_jaidka_L33_70b_dum', 'rationality_simple2_small_dum', 'rationality_simple2_gpt4o_dum', 'rationality_simple_dum', 'RATIONALITY_DUMMY']] \\\n",
    "    .corr(method='pearson').round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e3b5e4",
   "metadata": {},
   "source": [
    "improved performance of L33_70b compared to L31_70b (default), and the two models also show the highest overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfa9a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>rationality_simple2_L33_70b_dum</th>\n",
       "      <th colspan=\"2\" halign=\"left\">0</th>\n",
       "      <th colspan=\"2\" halign=\"left\">1</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rationality_simple2_small_dum</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RATIONALITY_DUMMY</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2930</td>\n",
       "      <td>14</td>\n",
       "      <td>181</td>\n",
       "      <td>40</td>\n",
       "      <td>3165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>394</td>\n",
       "      <td>1</td>\n",
       "      <td>202</td>\n",
       "      <td>100</td>\n",
       "      <td>697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>3324</td>\n",
       "      <td>15</td>\n",
       "      <td>383</td>\n",
       "      <td>140</td>\n",
       "      <td>3862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rationality_simple2_L33_70b_dum     0        1      Total\n",
       "rationality_simple2_small_dum       0   1    0    1      \n",
       "RATIONALITY_DUMMY                                        \n",
       "0                                2930  14  181   40  3165\n",
       "1                                 394   1  202  100   697\n",
       "Total                            3324  15  383  140  3862"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#and in crosstabulations:\n",
    "pd.crosstab(boukes['RATIONALITY_DUMMY'], [boukes['rationality_simple2_L33_70b_dum'], boukes['rationality_simple2_small_dum']], margins=True, margins_name='Total')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495c50d5",
   "metadata": {},
   "source": [
    "#L33_70b and small share 100+2930=3030 correct classifications (78%) and share 40+394=434 errors (11%) and differ on 14+1+181+202=398 errors (10%)-> they differ on 48% of errors\n",
    "#L33_70b makes 2930+14+202+100=3246 correct classifications\n",
    "and 394+1+181+40=616 errors = 16%\n",
    "#small makes 2930+181+1+100=3212 correct classifications\n",
    "and 394+14+202+40=650 errors = 17%\n",
    "#we would thus expect 0.17*0.16 = only 3% overlap between errors if the models were random -> they thus do a lot better than that\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e300df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>rationality_simple2_L33_70b_dum</th>\n",
       "      <th>0</th>\n",
       "      <th colspan=\"2\" halign=\"left\">1</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rationality_simple2_gpt4o_dum</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RATIONALITY_DUMMY</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2944</td>\n",
       "      <td>205</td>\n",
       "      <td>16</td>\n",
       "      <td>3165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>395</td>\n",
       "      <td>230</td>\n",
       "      <td>72</td>\n",
       "      <td>697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>3339</td>\n",
       "      <td>435</td>\n",
       "      <td>88</td>\n",
       "      <td>3862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "rationality_simple2_L33_70b_dum     0    1     Total\n",
       "rationality_simple2_gpt4o_dum       0    0   1      \n",
       "RATIONALITY_DUMMY                                   \n",
       "0                                2944  205  16  3165\n",
       "1                                 395  230  72   697\n",
       "Total                            3339  435  88  3862"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#and in crosstabulations:\n",
    "pd.crosstab(boukes['RATIONALITY_DUMMY'], [boukes['rationality_simple2_L33_70b_dum'], boukes['rationality_simple2_gpt4o_dum']], margins=True, margins_name='Total')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e6d1fc",
   "metadata": {},
   "source": [
    "#L33_70b and gpt4o share only 16 errors (0%) and differ on 205+230=435 errors (11%) -> they differ on 96% of errors\n",
    "#L33_70b and gpt4o correctly classify 2944+72=3016 (78%)\n",
    "#so L33_70b shares the same share of correct classifications in combination with small and gpt4o, but errors overlap much more with small than with gpt4o, which makes sense, overlap between errors of L33_70b and gpt4o is equal to chance.\n",
    "#this indicates that these two models don't agree on which manual coding are actually coding errors -> together they only mark 16 comments as potentially wrong coded even though they haven't seen our annotations in their training data, so should be independently judging the rationality of the comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed644e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incivility_simple2_L33_70b_dum</th>\n",
       "      <th>incivility_jaidka_L33_70b_dum</th>\n",
       "      <th>incivility_simple2_small_dum</th>\n",
       "      <th>incivility_simple2_gpt4o_dum</th>\n",
       "      <th>INCIVILITY_DUMMY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>incivility_simple2_L33_70b_dum</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incivility_jaidka_L33_70b_dum</th>\n",
       "      <td>0.76</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incivility_simple2_small_dum</th>\n",
       "      <td>0.49</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incivility_simple2_gpt4o_dum</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INCIVILITY_DUMMY</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                incivility_simple2_L33_70b_dum  \\\n",
       "incivility_simple2_L33_70b_dum                            1.00   \n",
       "incivility_jaidka_L33_70b_dum                             0.76   \n",
       "incivility_simple2_small_dum                              0.49   \n",
       "incivility_simple2_gpt4o_dum                              0.58   \n",
       "INCIVILITY_DUMMY                                          0.54   \n",
       "\n",
       "                                incivility_jaidka_L33_70b_dum  \\\n",
       "incivility_simple2_L33_70b_dum                           0.76   \n",
       "incivility_jaidka_L33_70b_dum                            1.00   \n",
       "incivility_simple2_small_dum                             0.53   \n",
       "incivility_simple2_gpt4o_dum                             0.63   \n",
       "INCIVILITY_DUMMY                                         0.51   \n",
       "\n",
       "                                incivility_simple2_small_dum  \\\n",
       "incivility_simple2_L33_70b_dum                          0.49   \n",
       "incivility_jaidka_L33_70b_dum                           0.53   \n",
       "incivility_simple2_small_dum                            1.00   \n",
       "incivility_simple2_gpt4o_dum                            0.68   \n",
       "INCIVILITY_DUMMY                                        0.48   \n",
       "\n",
       "                                incivility_simple2_gpt4o_dum  INCIVILITY_DUMMY  \n",
       "incivility_simple2_L33_70b_dum                          0.58              0.54  \n",
       "incivility_jaidka_L33_70b_dum                           0.63              0.51  \n",
       "incivility_simple2_small_dum                            0.68              0.48  \n",
       "incivility_simple2_gpt4o_dum                            1.00              0.55  \n",
       "INCIVILITY_DUMMY                                        0.55              1.00  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#do annotations of Llama3.3:70b correlate with gpt4o?\n",
    "boukes.loc[:, ['incivility_simple2_L33_70b_dum', 'incivility_jaidka_L33_70b_dum', 'incivility_simple2_small_dum', 'incivility_simple2_gpt4o_dum', 'INCIVILITY_DUMMY']] \\\n",
    "    .corr(method='pearson').round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48145025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>political_post_L33_70b_dum</th>\n",
       "      <th>political_post_jaidka_L33_70b_dum</th>\n",
       "      <th>TopicRelevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>political_post_L33_70b_dum</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>political_post_jaidka_L33_70b_dum</th>\n",
       "      <td>0.49</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TopicRelevance</th>\n",
       "      <td>0.58</td>\n",
       "      <td>0.38</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   political_post_L33_70b_dum  \\\n",
       "political_post_L33_70b_dum                               1.00   \n",
       "political_post_jaidka_L33_70b_dum                        0.49   \n",
       "TopicRelevance                                           0.58   \n",
       "\n",
       "                                   political_post_jaidka_L33_70b_dum  \\\n",
       "political_post_L33_70b_dum                                      0.49   \n",
       "political_post_jaidka_L33_70b_dum                               1.00   \n",
       "TopicRelevance                                                  0.38   \n",
       "\n",
       "                                   TopicRelevance  \n",
       "political_post_L33_70b_dum                   0.58  \n",
       "political_post_jaidka_L33_70b_dum            0.38  \n",
       "TopicRelevance                               1.00  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#do annotations of Llama3.3:70b correlate with gpt4o?\n",
    "boukes.loc[:, ['political_post_L33_70b_dum', 'political_post_jaidka_L33_70b_dum', 'TopicRelevance']] \\\n",
    "    .corr(method='pearson').round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23db806",
   "metadata": {},
   "outputs": [],
   "source": [
    "#what is the infuence of temperature on the results of intraprompt annotation reliability?\n",
    "\n",
    "#Note the logic of our comparisons:\n",
    "#we compare the results of the same prompt with different models, and different seeds, to see if the model and/or seed influences the results.\n",
    "#we use similar options per model, but the options are not the same for all models, they differ in temperature and seed (since the same seed might mean something different for different models).\n",
    "#but since we compare intraprompt annotation reliability for the same prompt with different seeds, the difference in temperature is not a problem, the annotation might differ per output of the model for that seed/temperature, but the difference with another seed should be minimal.\n",
    "#anyway we can test the origins of intraprompt reliability by comparing the result of the same prompt with the same seed and low temperature, different seed and low temperature and same seed and zero temperature\n",
    "#if it turns out that temperature does have a larger influence, but still the influence of different models or prompts is larger, we can still conclude that the model and prompt are more important than the temperature.\n",
    "#stronger still a higher temperature intraprompt benchmark is harder to beat especially for the simpa-prompts\n",
    "#for the between model comparisons temperature per model should not be a problem, since it will only vary the result of the model, not the comparison between models, only downside of low temperature is potential slightly lower reproducibility of the exact results and potetially slightly lower performance due to less creativity, but Barry ea 2025 does not seem to suggest this is the case for such low temperatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d1eb494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incivility correlations:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incivility_simple2_gpt4o_zero_dum</th>\n",
       "      <th>incivility_simple2_gpt4o_system_zero_dum</th>\n",
       "      <th>incivility_simple2_Q72b_zero_dum</th>\n",
       "      <th>incivility_jaidka_Q25_72b_zero_dum</th>\n",
       "      <th>incivility_para1_Q25_72b_zero_dum</th>\n",
       "      <th>incivility_para2_Q25_72b_zero_dum</th>\n",
       "      <th>incivility_simpa1_Q25_72b_zero_dum</th>\n",
       "      <th>incivility_simple2_Q72b_seed2_zero_dum</th>\n",
       "      <th>incivility_simple2_L33_70b_zero_dum</th>\n",
       "      <th>incivility_simple2_L33_70b_zero_seed2_dum</th>\n",
       "      <th>incivility_simple2_L31_8b_zero_dum</th>\n",
       "      <th>incivility_simple2_L31_8b_zero_seed2_dum</th>\n",
       "      <th>incivility_jaidka_gpt4o_system_zero_dum</th>\n",
       "      <th>incivility_para1_gpt4o_system_zero_dum</th>\n",
       "      <th>incivility_para2_gpt4o_system_zero_dum</th>\n",
       "      <th>incivility_simpa1_gpt4o_system_zero_dum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>incivility_simple2_gpt4o_zero_dum</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incivility_simple2_gpt4o_system_zero_dum</th>\n",
       "      <td>0.88</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incivility_simple2_Q72b_zero_dum</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incivility_jaidka_Q25_72b_zero_dum</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incivility_para1_Q25_72b_zero_dum</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incivility_para2_Q25_72b_zero_dum</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incivility_simpa1_Q25_72b_zero_dum</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incivility_simple2_Q72b_seed2_zero_dum</th>\n",
       "      <td>0.56</td>\n",
       "      <td>0.55</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incivility_simple2_L33_70b_zero_dum</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incivility_simple2_L33_70b_zero_seed2_dum</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incivility_simple2_L31_8b_zero_dum</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incivility_simple2_L31_8b_zero_seed2_dum</th>\n",
       "      <td>0.64</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incivility_jaidka_gpt4o_system_zero_dum</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incivility_para1_gpt4o_system_zero_dum</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incivility_para2_gpt4o_system_zero_dum</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incivility_simpa1_gpt4o_system_zero_dum</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           incivility_simple2_gpt4o_zero_dum  \\\n",
       "incivility_simple2_gpt4o_zero_dum                                       1.00   \n",
       "incivility_simple2_gpt4o_system_zero_dum                                0.88   \n",
       "incivility_simple2_Q72b_zero_dum                                        0.56   \n",
       "incivility_jaidka_Q25_72b_zero_dum                                      0.60   \n",
       "incivility_para1_Q25_72b_zero_dum                                       0.55   \n",
       "incivility_para2_Q25_72b_zero_dum                                       0.51   \n",
       "incivility_simpa1_Q25_72b_zero_dum                                      0.54   \n",
       "incivility_simple2_Q72b_seed2_zero_dum                                  0.56   \n",
       "incivility_simple2_L33_70b_zero_dum                                     0.55   \n",
       "incivility_simple2_L33_70b_zero_seed2_dum                               0.55   \n",
       "incivility_simple2_L31_8b_zero_dum                                      0.64   \n",
       "incivility_simple2_L31_8b_zero_seed2_dum                                0.64   \n",
       "incivility_jaidka_gpt4o_system_zero_dum                                 0.73   \n",
       "incivility_para1_gpt4o_system_zero_dum                                  0.79   \n",
       "incivility_para2_gpt4o_system_zero_dum                                  0.82   \n",
       "incivility_simpa1_gpt4o_system_zero_dum                                 0.81   \n",
       "\n",
       "                                           incivility_simple2_gpt4o_system_zero_dum  \\\n",
       "incivility_simple2_gpt4o_zero_dum                                              0.88   \n",
       "incivility_simple2_gpt4o_system_zero_dum                                       1.00   \n",
       "incivility_simple2_Q72b_zero_dum                                               0.55   \n",
       "incivility_jaidka_Q25_72b_zero_dum                                             0.59   \n",
       "incivility_para1_Q25_72b_zero_dum                                              0.54   \n",
       "incivility_para2_Q25_72b_zero_dum                                              0.50   \n",
       "incivility_simpa1_Q25_72b_zero_dum                                             0.53   \n",
       "incivility_simple2_Q72b_seed2_zero_dum                                         0.55   \n",
       "incivility_simple2_L33_70b_zero_dum                                            0.53   \n",
       "incivility_simple2_L33_70b_zero_seed2_dum                                      0.53   \n",
       "incivility_simple2_L31_8b_zero_dum                                             0.67   \n",
       "incivility_simple2_L31_8b_zero_seed2_dum                                       0.67   \n",
       "incivility_jaidka_gpt4o_system_zero_dum                                        0.76   \n",
       "incivility_para1_gpt4o_system_zero_dum                                         0.85   \n",
       "incivility_para2_gpt4o_system_zero_dum                                         0.84   \n",
       "incivility_simpa1_gpt4o_system_zero_dum                                        0.84   \n",
       "\n",
       "                                           incivility_simple2_Q72b_zero_dum  \\\n",
       "incivility_simple2_gpt4o_zero_dum                                      0.56   \n",
       "incivility_simple2_gpt4o_system_zero_dum                               0.55   \n",
       "incivility_simple2_Q72b_zero_dum                                       1.00   \n",
       "incivility_jaidka_Q25_72b_zero_dum                                     0.87   \n",
       "incivility_para1_Q25_72b_zero_dum                                      0.96   \n",
       "incivility_para2_Q25_72b_zero_dum                                      0.92   \n",
       "incivility_simpa1_Q25_72b_zero_dum                                     0.96   \n",
       "incivility_simple2_Q72b_seed2_zero_dum                                 1.00   \n",
       "incivility_simple2_L33_70b_zero_dum                                    0.85   \n",
       "incivility_simple2_L33_70b_zero_seed2_dum                              0.85   \n",
       "incivility_simple2_L31_8b_zero_dum                                     0.55   \n",
       "incivility_simple2_L31_8b_zero_seed2_dum                               0.54   \n",
       "incivility_jaidka_gpt4o_system_zero_dum                                0.55   \n",
       "incivility_para1_gpt4o_system_zero_dum                                 0.59   \n",
       "incivility_para2_gpt4o_system_zero_dum                                 0.64   \n",
       "incivility_simpa1_gpt4o_system_zero_dum                                0.59   \n",
       "\n",
       "                                           incivility_jaidka_Q25_72b_zero_dum  \\\n",
       "incivility_simple2_gpt4o_zero_dum                                        0.60   \n",
       "incivility_simple2_gpt4o_system_zero_dum                                 0.59   \n",
       "incivility_simple2_Q72b_zero_dum                                         0.87   \n",
       "incivility_jaidka_Q25_72b_zero_dum                                       1.00   \n",
       "incivility_para1_Q25_72b_zero_dum                                        0.86   \n",
       "incivility_para2_Q25_72b_zero_dum                                        0.84   \n",
       "incivility_simpa1_Q25_72b_zero_dum                                       0.86   \n",
       "incivility_simple2_Q72b_seed2_zero_dum                                   0.87   \n",
       "incivility_simple2_L33_70b_zero_dum                                      0.80   \n",
       "incivility_simple2_L33_70b_zero_seed2_dum                                0.80   \n",
       "incivility_simple2_L31_8b_zero_dum                                       0.57   \n",
       "incivility_simple2_L31_8b_zero_seed2_dum                                 0.57   \n",
       "incivility_jaidka_gpt4o_system_zero_dum                                  0.59   \n",
       "incivility_para1_gpt4o_system_zero_dum                                   0.62   \n",
       "incivility_para2_gpt4o_system_zero_dum                                   0.67   \n",
       "incivility_simpa1_gpt4o_system_zero_dum                                  0.62   \n",
       "\n",
       "                                           incivility_para1_Q25_72b_zero_dum  \\\n",
       "incivility_simple2_gpt4o_zero_dum                                       0.55   \n",
       "incivility_simple2_gpt4o_system_zero_dum                                0.54   \n",
       "incivility_simple2_Q72b_zero_dum                                        0.96   \n",
       "incivility_jaidka_Q25_72b_zero_dum                                      0.86   \n",
       "incivility_para1_Q25_72b_zero_dum                                       1.00   \n",
       "incivility_para2_Q25_72b_zero_dum                                       0.92   \n",
       "incivility_simpa1_Q25_72b_zero_dum                                      0.94   \n",
       "incivility_simple2_Q72b_seed2_zero_dum                                  0.96   \n",
       "incivility_simple2_L33_70b_zero_dum                                     0.84   \n",
       "incivility_simple2_L33_70b_zero_seed2_dum                               0.84   \n",
       "incivility_simple2_L31_8b_zero_dum                                      0.54   \n",
       "incivility_simple2_L31_8b_zero_seed2_dum                                0.54   \n",
       "incivility_jaidka_gpt4o_system_zero_dum                                 0.54   \n",
       "incivility_para1_gpt4o_system_zero_dum                                  0.58   \n",
       "incivility_para2_gpt4o_system_zero_dum                                  0.63   \n",
       "incivility_simpa1_gpt4o_system_zero_dum                                 0.59   \n",
       "\n",
       "                                           incivility_para2_Q25_72b_zero_dum  \\\n",
       "incivility_simple2_gpt4o_zero_dum                                       0.51   \n",
       "incivility_simple2_gpt4o_system_zero_dum                                0.50   \n",
       "incivility_simple2_Q72b_zero_dum                                        0.92   \n",
       "incivility_jaidka_Q25_72b_zero_dum                                      0.84   \n",
       "incivility_para1_Q25_72b_zero_dum                                       0.92   \n",
       "incivility_para2_Q25_72b_zero_dum                                       1.00   \n",
       "incivility_simpa1_Q25_72b_zero_dum                                      0.93   \n",
       "incivility_simple2_Q72b_seed2_zero_dum                                  0.92   \n",
       "incivility_simple2_L33_70b_zero_dum                                     0.83   \n",
       "incivility_simple2_L33_70b_zero_seed2_dum                               0.83   \n",
       "incivility_simple2_L31_8b_zero_dum                                      0.51   \n",
       "incivility_simple2_L31_8b_zero_seed2_dum                                0.50   \n",
       "incivility_jaidka_gpt4o_system_zero_dum                                 0.51   \n",
       "incivility_para1_gpt4o_system_zero_dum                                  0.54   \n",
       "incivility_para2_gpt4o_system_zero_dum                                  0.59   \n",
       "incivility_simpa1_gpt4o_system_zero_dum                                 0.55   \n",
       "\n",
       "                                           incivility_simpa1_Q25_72b_zero_dum  \\\n",
       "incivility_simple2_gpt4o_zero_dum                                        0.54   \n",
       "incivility_simple2_gpt4o_system_zero_dum                                 0.53   \n",
       "incivility_simple2_Q72b_zero_dum                                         0.96   \n",
       "incivility_jaidka_Q25_72b_zero_dum                                       0.86   \n",
       "incivility_para1_Q25_72b_zero_dum                                        0.94   \n",
       "incivility_para2_Q25_72b_zero_dum                                        0.93   \n",
       "incivility_simpa1_Q25_72b_zero_dum                                       1.00   \n",
       "incivility_simple2_Q72b_seed2_zero_dum                                   0.96   \n",
       "incivility_simple2_L33_70b_zero_dum                                      0.85   \n",
       "incivility_simple2_L33_70b_zero_seed2_dum                                0.85   \n",
       "incivility_simple2_L31_8b_zero_dum                                       0.54   \n",
       "incivility_simple2_L31_8b_zero_seed2_dum                                 0.53   \n",
       "incivility_jaidka_gpt4o_system_zero_dum                                  0.53   \n",
       "incivility_para1_gpt4o_system_zero_dum                                   0.57   \n",
       "incivility_para2_gpt4o_system_zero_dum                                   0.62   \n",
       "incivility_simpa1_gpt4o_system_zero_dum                                  0.58   \n",
       "\n",
       "                                           incivility_simple2_Q72b_seed2_zero_dum  \\\n",
       "incivility_simple2_gpt4o_zero_dum                                            0.56   \n",
       "incivility_simple2_gpt4o_system_zero_dum                                     0.55   \n",
       "incivility_simple2_Q72b_zero_dum                                             1.00   \n",
       "incivility_jaidka_Q25_72b_zero_dum                                           0.87   \n",
       "incivility_para1_Q25_72b_zero_dum                                            0.96   \n",
       "incivility_para2_Q25_72b_zero_dum                                            0.92   \n",
       "incivility_simpa1_Q25_72b_zero_dum                                           0.96   \n",
       "incivility_simple2_Q72b_seed2_zero_dum                                       1.00   \n",
       "incivility_simple2_L33_70b_zero_dum                                          0.85   \n",
       "incivility_simple2_L33_70b_zero_seed2_dum                                    0.85   \n",
       "incivility_simple2_L31_8b_zero_dum                                           0.55   \n",
       "incivility_simple2_L31_8b_zero_seed2_dum                                     0.54   \n",
       "incivility_jaidka_gpt4o_system_zero_dum                                      0.55   \n",
       "incivility_para1_gpt4o_system_zero_dum                                       0.59   \n",
       "incivility_para2_gpt4o_system_zero_dum                                       0.64   \n",
       "incivility_simpa1_gpt4o_system_zero_dum                                      0.59   \n",
       "\n",
       "                                           incivility_simple2_L33_70b_zero_dum  \\\n",
       "incivility_simple2_gpt4o_zero_dum                                         0.55   \n",
       "incivility_simple2_gpt4o_system_zero_dum                                  0.53   \n",
       "incivility_simple2_Q72b_zero_dum                                          0.85   \n",
       "incivility_jaidka_Q25_72b_zero_dum                                        0.80   \n",
       "incivility_para1_Q25_72b_zero_dum                                         0.84   \n",
       "incivility_para2_Q25_72b_zero_dum                                         0.83   \n",
       "incivility_simpa1_Q25_72b_zero_dum                                        0.85   \n",
       "incivility_simple2_Q72b_seed2_zero_dum                                    0.85   \n",
       "incivility_simple2_L33_70b_zero_dum                                       1.00   \n",
       "incivility_simple2_L33_70b_zero_seed2_dum                                 1.00   \n",
       "incivility_simple2_L31_8b_zero_dum                                        0.54   \n",
       "incivility_simple2_L31_8b_zero_seed2_dum                                  0.54   \n",
       "incivility_jaidka_gpt4o_system_zero_dum                                   0.53   \n",
       "incivility_para1_gpt4o_system_zero_dum                                    0.58   \n",
       "incivility_para2_gpt4o_system_zero_dum                                    0.63   \n",
       "incivility_simpa1_gpt4o_system_zero_dum                                   0.58   \n",
       "\n",
       "                                           incivility_simple2_L33_70b_zero_seed2_dum  \\\n",
       "incivility_simple2_gpt4o_zero_dum                                               0.55   \n",
       "incivility_simple2_gpt4o_system_zero_dum                                        0.53   \n",
       "incivility_simple2_Q72b_zero_dum                                                0.85   \n",
       "incivility_jaidka_Q25_72b_zero_dum                                              0.80   \n",
       "incivility_para1_Q25_72b_zero_dum                                               0.84   \n",
       "incivility_para2_Q25_72b_zero_dum                                               0.83   \n",
       "incivility_simpa1_Q25_72b_zero_dum                                              0.85   \n",
       "incivility_simple2_Q72b_seed2_zero_dum                                          0.85   \n",
       "incivility_simple2_L33_70b_zero_dum                                             1.00   \n",
       "incivility_simple2_L33_70b_zero_seed2_dum                                       1.00   \n",
       "incivility_simple2_L31_8b_zero_dum                                              0.54   \n",
       "incivility_simple2_L31_8b_zero_seed2_dum                                        0.54   \n",
       "incivility_jaidka_gpt4o_system_zero_dum                                         0.53   \n",
       "incivility_para1_gpt4o_system_zero_dum                                          0.58   \n",
       "incivility_para2_gpt4o_system_zero_dum                                          0.63   \n",
       "incivility_simpa1_gpt4o_system_zero_dum                                         0.58   \n",
       "\n",
       "                                           incivility_simple2_L31_8b_zero_dum  \\\n",
       "incivility_simple2_gpt4o_zero_dum                                        0.64   \n",
       "incivility_simple2_gpt4o_system_zero_dum                                 0.67   \n",
       "incivility_simple2_Q72b_zero_dum                                         0.55   \n",
       "incivility_jaidka_Q25_72b_zero_dum                                       0.57   \n",
       "incivility_para1_Q25_72b_zero_dum                                        0.54   \n",
       "incivility_para2_Q25_72b_zero_dum                                        0.51   \n",
       "incivility_simpa1_Q25_72b_zero_dum                                       0.54   \n",
       "incivility_simple2_Q72b_seed2_zero_dum                                   0.55   \n",
       "incivility_simple2_L33_70b_zero_dum                                      0.54   \n",
       "incivility_simple2_L33_70b_zero_seed2_dum                                0.54   \n",
       "incivility_simple2_L31_8b_zero_dum                                       1.00   \n",
       "incivility_simple2_L31_8b_zero_seed2_dum                                 0.98   \n",
       "incivility_jaidka_gpt4o_system_zero_dum                                  0.71   \n",
       "incivility_para1_gpt4o_system_zero_dum                                   0.72   \n",
       "incivility_para2_gpt4o_system_zero_dum                                   0.69   \n",
       "incivility_simpa1_gpt4o_system_zero_dum                                  0.71   \n",
       "\n",
       "                                           incivility_simple2_L31_8b_zero_seed2_dum  \\\n",
       "incivility_simple2_gpt4o_zero_dum                                              0.64   \n",
       "incivility_simple2_gpt4o_system_zero_dum                                       0.67   \n",
       "incivility_simple2_Q72b_zero_dum                                               0.54   \n",
       "incivility_jaidka_Q25_72b_zero_dum                                             0.57   \n",
       "incivility_para1_Q25_72b_zero_dum                                              0.54   \n",
       "incivility_para2_Q25_72b_zero_dum                                              0.50   \n",
       "incivility_simpa1_Q25_72b_zero_dum                                             0.53   \n",
       "incivility_simple2_Q72b_seed2_zero_dum                                         0.54   \n",
       "incivility_simple2_L33_70b_zero_dum                                            0.54   \n",
       "incivility_simple2_L33_70b_zero_seed2_dum                                      0.54   \n",
       "incivility_simple2_L31_8b_zero_dum                                             0.98   \n",
       "incivility_simple2_L31_8b_zero_seed2_dum                                       1.00   \n",
       "incivility_jaidka_gpt4o_system_zero_dum                                        0.71   \n",
       "incivility_para1_gpt4o_system_zero_dum                                         0.72   \n",
       "incivility_para2_gpt4o_system_zero_dum                                         0.69   \n",
       "incivility_simpa1_gpt4o_system_zero_dum                                        0.71   \n",
       "\n",
       "                                           incivility_jaidka_gpt4o_system_zero_dum  \\\n",
       "incivility_simple2_gpt4o_zero_dum                                             0.73   \n",
       "incivility_simple2_gpt4o_system_zero_dum                                      0.76   \n",
       "incivility_simple2_Q72b_zero_dum                                              0.55   \n",
       "incivility_jaidka_Q25_72b_zero_dum                                            0.59   \n",
       "incivility_para1_Q25_72b_zero_dum                                             0.54   \n",
       "incivility_para2_Q25_72b_zero_dum                                             0.51   \n",
       "incivility_simpa1_Q25_72b_zero_dum                                            0.53   \n",
       "incivility_simple2_Q72b_seed2_zero_dum                                        0.55   \n",
       "incivility_simple2_L33_70b_zero_dum                                           0.53   \n",
       "incivility_simple2_L33_70b_zero_seed2_dum                                     0.53   \n",
       "incivility_simple2_L31_8b_zero_dum                                            0.71   \n",
       "incivility_simple2_L31_8b_zero_seed2_dum                                      0.71   \n",
       "incivility_jaidka_gpt4o_system_zero_dum                                       1.00   \n",
       "incivility_para1_gpt4o_system_zero_dum                                        0.81   \n",
       "incivility_para2_gpt4o_system_zero_dum                                        0.78   \n",
       "incivility_simpa1_gpt4o_system_zero_dum                                       0.79   \n",
       "\n",
       "                                           incivility_para1_gpt4o_system_zero_dum  \\\n",
       "incivility_simple2_gpt4o_zero_dum                                            0.79   \n",
       "incivility_simple2_gpt4o_system_zero_dum                                     0.85   \n",
       "incivility_simple2_Q72b_zero_dum                                             0.59   \n",
       "incivility_jaidka_Q25_72b_zero_dum                                           0.62   \n",
       "incivility_para1_Q25_72b_zero_dum                                            0.58   \n",
       "incivility_para2_Q25_72b_zero_dum                                            0.54   \n",
       "incivility_simpa1_Q25_72b_zero_dum                                           0.57   \n",
       "incivility_simple2_Q72b_seed2_zero_dum                                       0.59   \n",
       "incivility_simple2_L33_70b_zero_dum                                          0.58   \n",
       "incivility_simple2_L33_70b_zero_seed2_dum                                    0.58   \n",
       "incivility_simple2_L31_8b_zero_dum                                           0.72   \n",
       "incivility_simple2_L31_8b_zero_seed2_dum                                     0.72   \n",
       "incivility_jaidka_gpt4o_system_zero_dum                                      0.81   \n",
       "incivility_para1_gpt4o_system_zero_dum                                       1.00   \n",
       "incivility_para2_gpt4o_system_zero_dum                                       0.90   \n",
       "incivility_simpa1_gpt4o_system_zero_dum                                      0.91   \n",
       "\n",
       "                                           incivility_para2_gpt4o_system_zero_dum  \\\n",
       "incivility_simple2_gpt4o_zero_dum                                            0.82   \n",
       "incivility_simple2_gpt4o_system_zero_dum                                     0.84   \n",
       "incivility_simple2_Q72b_zero_dum                                             0.64   \n",
       "incivility_jaidka_Q25_72b_zero_dum                                           0.67   \n",
       "incivility_para1_Q25_72b_zero_dum                                            0.63   \n",
       "incivility_para2_Q25_72b_zero_dum                                            0.59   \n",
       "incivility_simpa1_Q25_72b_zero_dum                                           0.62   \n",
       "incivility_simple2_Q72b_seed2_zero_dum                                       0.64   \n",
       "incivility_simple2_L33_70b_zero_dum                                          0.63   \n",
       "incivility_simple2_L33_70b_zero_seed2_dum                                    0.63   \n",
       "incivility_simple2_L31_8b_zero_dum                                           0.69   \n",
       "incivility_simple2_L31_8b_zero_seed2_dum                                     0.69   \n",
       "incivility_jaidka_gpt4o_system_zero_dum                                      0.78   \n",
       "incivility_para1_gpt4o_system_zero_dum                                       0.90   \n",
       "incivility_para2_gpt4o_system_zero_dum                                       1.00   \n",
       "incivility_simpa1_gpt4o_system_zero_dum                                      0.89   \n",
       "\n",
       "                                           incivility_simpa1_gpt4o_system_zero_dum  \n",
       "incivility_simple2_gpt4o_zero_dum                                             0.81  \n",
       "incivility_simple2_gpt4o_system_zero_dum                                      0.84  \n",
       "incivility_simple2_Q72b_zero_dum                                              0.59  \n",
       "incivility_jaidka_Q25_72b_zero_dum                                            0.62  \n",
       "incivility_para1_Q25_72b_zero_dum                                             0.59  \n",
       "incivility_para2_Q25_72b_zero_dum                                             0.55  \n",
       "incivility_simpa1_Q25_72b_zero_dum                                            0.58  \n",
       "incivility_simple2_Q72b_seed2_zero_dum                                        0.59  \n",
       "incivility_simple2_L33_70b_zero_dum                                           0.58  \n",
       "incivility_simple2_L33_70b_zero_seed2_dum                                     0.58  \n",
       "incivility_simple2_L31_8b_zero_dum                                            0.71  \n",
       "incivility_simple2_L31_8b_zero_seed2_dum                                      0.71  \n",
       "incivility_jaidka_gpt4o_system_zero_dum                                       0.79  \n",
       "incivility_para1_gpt4o_system_zero_dum                                        0.91  \n",
       "incivility_para2_gpt4o_system_zero_dum                                        0.89  \n",
       "incivility_simpa1_gpt4o_system_zero_dum                                       1.00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate correlations between the different models for all columns ending with _dum and containing 'incivility' in boukes, start with the gpt4o model and zero temperature::\n",
    "incivility_cols = [col for col in boukes.columns if 'incivility' in col]\n",
    "incivility_cols = [col for col in incivility_cols if col.endswith('_dum')]\n",
    "incivility_cols = [col for col in incivility_cols if 'gpt4o' in col or 'L33_70b' in col or 'L31_8b' in col or 'Q25_72b' in col or 'Q72b' in col]\n",
    "incivility_cols = [col for col in incivility_cols if 'zero' in col]  \n",
    "incivility_corr = boukes[incivility_cols].corr(method='pearson').round(2)\n",
    "print(\"Incivility correlations:\")\n",
    "incivility_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d30c26f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incivility_simple2_gpt4o_system_zero_dum</th>\n",
       "      <th>incivility_simple2_Q72b_zero_dum</th>\n",
       "      <th>incivility_simple2_L33_70b_zero_dum</th>\n",
       "      <th>incivility_simple2_L31_8b_zero_dum</th>\n",
       "      <th>INCIVILITY_DUMMY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>incivility_simple2_gpt4o_system_zero_dum</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incivility_simple2_Q72b_zero_dum</th>\n",
       "      <td>0.55</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incivility_simple2_L33_70b_zero_dum</th>\n",
       "      <td>0.53</td>\n",
       "      <td>0.85</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incivility_simple2_L31_8b_zero_dum</th>\n",
       "      <td>0.67</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INCIVILITY_DUMMY</th>\n",
       "      <td>0.51</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.45</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          incivility_simple2_gpt4o_system_zero_dum  \\\n",
       "incivility_simple2_gpt4o_system_zero_dum                                      1.00   \n",
       "incivility_simple2_Q72b_zero_dum                                              0.55   \n",
       "incivility_simple2_L33_70b_zero_dum                                           0.53   \n",
       "incivility_simple2_L31_8b_zero_dum                                            0.67   \n",
       "INCIVILITY_DUMMY                                                              0.51   \n",
       "\n",
       "                                          incivility_simple2_Q72b_zero_dum  \\\n",
       "incivility_simple2_gpt4o_system_zero_dum                              0.55   \n",
       "incivility_simple2_Q72b_zero_dum                                      1.00   \n",
       "incivility_simple2_L33_70b_zero_dum                                   0.85   \n",
       "incivility_simple2_L31_8b_zero_dum                                    0.55   \n",
       "INCIVILITY_DUMMY                                                      0.47   \n",
       "\n",
       "                                          incivility_simple2_L33_70b_zero_dum  \\\n",
       "incivility_simple2_gpt4o_system_zero_dum                                 0.53   \n",
       "incivility_simple2_Q72b_zero_dum                                         0.85   \n",
       "incivility_simple2_L33_70b_zero_dum                                      1.00   \n",
       "incivility_simple2_L31_8b_zero_dum                                       0.54   \n",
       "INCIVILITY_DUMMY                                                         0.48   \n",
       "\n",
       "                                          incivility_simple2_L31_8b_zero_dum  \\\n",
       "incivility_simple2_gpt4o_system_zero_dum                                0.67   \n",
       "incivility_simple2_Q72b_zero_dum                                        0.55   \n",
       "incivility_simple2_L33_70b_zero_dum                                     0.54   \n",
       "incivility_simple2_L31_8b_zero_dum                                      1.00   \n",
       "INCIVILITY_DUMMY                                                        0.45   \n",
       "\n",
       "                                          INCIVILITY_DUMMY  \n",
       "incivility_simple2_gpt4o_system_zero_dum              0.51  \n",
       "incivility_simple2_Q72b_zero_dum                      0.47  \n",
       "incivility_simple2_L33_70b_zero_dum                   0.48  \n",
       "incivility_simple2_L31_8b_zero_dum                    0.45  \n",
       "INCIVILITY_DUMMY                                      1.00  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate correlations between the different models for all columns ending with _dum and containing 'rationality' in boukes, start with the gpt4o model and zero temperature::\n",
    "incivility_cols = [col for col in boukes.columns if 'incivility' in col]\n",
    "incivility_cols = [col for col in incivility_cols if col.endswith('_dum')]\n",
    "incivility_cols = [col for col in incivility_cols if 'gpt4o' in col or 'L33_70b' in col or 'L31_8b' in col or 'Q25_72b' in col or 'Q72b' in col]\n",
    "incivility_cols = [col for col in incivility_cols if 'zero' in col]  \n",
    "incivility_cols = [col for col in incivility_cols if 'para' not in col and 'simpa' not in col and 'seed2' not in col and 'gpt4o_zero' not in col and 'jaidka' not in col]  #remove para and simpa columns, since these are not comparable with the gpt4o model\n",
    "#add groundtruth columns:\n",
    "incivility_cols += ['INCIVILITY_DUMMY']\n",
    "incivility_corr = boukes[incivility_cols].corr(method='pearson').round(2)\n",
    "\n",
    "incivility_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a91d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model has quite a large effect on the results, comparable to the error rate of the groundtruth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "236a0c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incivility_simple2_L33_70b_low_dum</th>\n",
       "      <th>incivility_jaidka_L33_70b_low_dum</th>\n",
       "      <th>incivility_simple2_L33_70b_seed2_low_dum</th>\n",
       "      <th>incivility_para1_L33_70b_low_dum</th>\n",
       "      <th>incivility_para2_L33_70b_low_dum</th>\n",
       "      <th>incivility_simpa1_L33_70b_low_dum</th>\n",
       "      <th>incivility_simple2_L33_70b_seed2_run2_low_dum</th>\n",
       "      <th>incivility_simple2_L33_70b_zero_dum</th>\n",
       "      <th>incivility_simple2_L33_70b_zero_seed2_dum</th>\n",
       "      <th>INCIVILITY_DUMMY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>incivility_simple2_L33_70b_low_dum</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incivility_jaidka_L33_70b_low_dum</th>\n",
       "      <td>0.76</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incivility_simple2_L33_70b_seed2_low_dum</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incivility_para1_L33_70b_low_dum</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incivility_para2_L33_70b_low_dum</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incivility_simpa1_L33_70b_low_dum</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incivility_simple2_L33_70b_seed2_run2_low_dum</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incivility_simple2_L33_70b_zero_dum</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incivility_simple2_L33_70b_zero_seed2_dum</th>\n",
       "      <td>0.85</td>\n",
       "      <td>0.67</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INCIVILITY_DUMMY</th>\n",
       "      <td>0.54</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               incivility_simple2_L33_70b_low_dum  \\\n",
       "incivility_simple2_L33_70b_low_dum                                           1.00   \n",
       "incivility_jaidka_L33_70b_low_dum                                            0.76   \n",
       "incivility_simple2_L33_70b_seed2_low_dum                                     0.85   \n",
       "incivility_para1_L33_70b_low_dum                                             0.82   \n",
       "incivility_para2_L33_70b_low_dum                                             0.79   \n",
       "incivility_simpa1_L33_70b_low_dum                                            0.81   \n",
       "incivility_simple2_L33_70b_seed2_run2_low_dum                                0.85   \n",
       "incivility_simple2_L33_70b_zero_dum                                          0.85   \n",
       "incivility_simple2_L33_70b_zero_seed2_dum                                    0.85   \n",
       "INCIVILITY_DUMMY                                                             0.54   \n",
       "\n",
       "                                               incivility_jaidka_L33_70b_low_dum  \\\n",
       "incivility_simple2_L33_70b_low_dum                                          0.76   \n",
       "incivility_jaidka_L33_70b_low_dum                                           1.00   \n",
       "incivility_simple2_L33_70b_seed2_low_dum                                    0.67   \n",
       "incivility_para1_L33_70b_low_dum                                            0.68   \n",
       "incivility_para2_L33_70b_low_dum                                            0.68   \n",
       "incivility_simpa1_L33_70b_low_dum                                           0.69   \n",
       "incivility_simple2_L33_70b_seed2_run2_low_dum                               0.67   \n",
       "incivility_simple2_L33_70b_zero_dum                                         0.67   \n",
       "incivility_simple2_L33_70b_zero_seed2_dum                                   0.67   \n",
       "INCIVILITY_DUMMY                                                            0.51   \n",
       "\n",
       "                                               incivility_simple2_L33_70b_seed2_low_dum  \\\n",
       "incivility_simple2_L33_70b_low_dum                                                 0.85   \n",
       "incivility_jaidka_L33_70b_low_dum                                                  0.67   \n",
       "incivility_simple2_L33_70b_seed2_low_dum                                           1.00   \n",
       "incivility_para1_L33_70b_low_dum                                                   0.96   \n",
       "incivility_para2_L33_70b_low_dum                                                   0.94   \n",
       "incivility_simpa1_L33_70b_low_dum                                                  0.95   \n",
       "incivility_simple2_L33_70b_seed2_run2_low_dum                                      0.99   \n",
       "incivility_simple2_L33_70b_zero_dum                                                1.00   \n",
       "incivility_simple2_L33_70b_zero_seed2_dum                                          1.00   \n",
       "INCIVILITY_DUMMY                                                                   0.48   \n",
       "\n",
       "                                               incivility_para1_L33_70b_low_dum  \\\n",
       "incivility_simple2_L33_70b_low_dum                                         0.82   \n",
       "incivility_jaidka_L33_70b_low_dum                                          0.68   \n",
       "incivility_simple2_L33_70b_seed2_low_dum                                   0.96   \n",
       "incivility_para1_L33_70b_low_dum                                           1.00   \n",
       "incivility_para2_L33_70b_low_dum                                           0.94   \n",
       "incivility_simpa1_L33_70b_low_dum                                          0.95   \n",
       "incivility_simple2_L33_70b_seed2_run2_low_dum                              0.96   \n",
       "incivility_simple2_L33_70b_zero_dum                                        0.96   \n",
       "incivility_simple2_L33_70b_zero_seed2_dum                                  0.96   \n",
       "INCIVILITY_DUMMY                                                           0.48   \n",
       "\n",
       "                                               incivility_para2_L33_70b_low_dum  \\\n",
       "incivility_simple2_L33_70b_low_dum                                         0.79   \n",
       "incivility_jaidka_L33_70b_low_dum                                          0.68   \n",
       "incivility_simple2_L33_70b_seed2_low_dum                                   0.94   \n",
       "incivility_para1_L33_70b_low_dum                                           0.94   \n",
       "incivility_para2_L33_70b_low_dum                                           1.00   \n",
       "incivility_simpa1_L33_70b_low_dum                                          0.92   \n",
       "incivility_simple2_L33_70b_seed2_run2_low_dum                              0.94   \n",
       "incivility_simple2_L33_70b_zero_dum                                        0.94   \n",
       "incivility_simple2_L33_70b_zero_seed2_dum                                  0.94   \n",
       "INCIVILITY_DUMMY                                                           0.48   \n",
       "\n",
       "                                               incivility_simpa1_L33_70b_low_dum  \\\n",
       "incivility_simple2_L33_70b_low_dum                                          0.81   \n",
       "incivility_jaidka_L33_70b_low_dum                                           0.69   \n",
       "incivility_simple2_L33_70b_seed2_low_dum                                    0.95   \n",
       "incivility_para1_L33_70b_low_dum                                            0.95   \n",
       "incivility_para2_L33_70b_low_dum                                            0.92   \n",
       "incivility_simpa1_L33_70b_low_dum                                           1.00   \n",
       "incivility_simple2_L33_70b_seed2_run2_low_dum                               0.95   \n",
       "incivility_simple2_L33_70b_zero_dum                                         0.95   \n",
       "incivility_simple2_L33_70b_zero_seed2_dum                                   0.95   \n",
       "INCIVILITY_DUMMY                                                            0.48   \n",
       "\n",
       "                                               incivility_simple2_L33_70b_seed2_run2_low_dum  \\\n",
       "incivility_simple2_L33_70b_low_dum                                                      0.85   \n",
       "incivility_jaidka_L33_70b_low_dum                                                       0.67   \n",
       "incivility_simple2_L33_70b_seed2_low_dum                                                0.99   \n",
       "incivility_para1_L33_70b_low_dum                                                        0.96   \n",
       "incivility_para2_L33_70b_low_dum                                                        0.94   \n",
       "incivility_simpa1_L33_70b_low_dum                                                       0.95   \n",
       "incivility_simple2_L33_70b_seed2_run2_low_dum                                           1.00   \n",
       "incivility_simple2_L33_70b_zero_dum                                                     0.99   \n",
       "incivility_simple2_L33_70b_zero_seed2_dum                                               0.99   \n",
       "INCIVILITY_DUMMY                                                                        0.48   \n",
       "\n",
       "                                               incivility_simple2_L33_70b_zero_dum  \\\n",
       "incivility_simple2_L33_70b_low_dum                                            0.85   \n",
       "incivility_jaidka_L33_70b_low_dum                                             0.67   \n",
       "incivility_simple2_L33_70b_seed2_low_dum                                      1.00   \n",
       "incivility_para1_L33_70b_low_dum                                              0.96   \n",
       "incivility_para2_L33_70b_low_dum                                              0.94   \n",
       "incivility_simpa1_L33_70b_low_dum                                             0.95   \n",
       "incivility_simple2_L33_70b_seed2_run2_low_dum                                 0.99   \n",
       "incivility_simple2_L33_70b_zero_dum                                           1.00   \n",
       "incivility_simple2_L33_70b_zero_seed2_dum                                     1.00   \n",
       "INCIVILITY_DUMMY                                                              0.48   \n",
       "\n",
       "                                               incivility_simple2_L33_70b_zero_seed2_dum  \\\n",
       "incivility_simple2_L33_70b_low_dum                                                  0.85   \n",
       "incivility_jaidka_L33_70b_low_dum                                                   0.67   \n",
       "incivility_simple2_L33_70b_seed2_low_dum                                            1.00   \n",
       "incivility_para1_L33_70b_low_dum                                                    0.96   \n",
       "incivility_para2_L33_70b_low_dum                                                    0.94   \n",
       "incivility_simpa1_L33_70b_low_dum                                                   0.95   \n",
       "incivility_simple2_L33_70b_seed2_run2_low_dum                                       0.99   \n",
       "incivility_simple2_L33_70b_zero_dum                                                 1.00   \n",
       "incivility_simple2_L33_70b_zero_seed2_dum                                           1.00   \n",
       "INCIVILITY_DUMMY                                                                    0.48   \n",
       "\n",
       "                                               INCIVILITY_DUMMY  \n",
       "incivility_simple2_L33_70b_low_dum                         0.54  \n",
       "incivility_jaidka_L33_70b_low_dum                          0.51  \n",
       "incivility_simple2_L33_70b_seed2_low_dum                   0.48  \n",
       "incivility_para1_L33_70b_low_dum                           0.48  \n",
       "incivility_para2_L33_70b_low_dum                           0.48  \n",
       "incivility_simpa1_L33_70b_low_dum                          0.48  \n",
       "incivility_simple2_L33_70b_seed2_run2_low_dum              0.48  \n",
       "incivility_simple2_L33_70b_zero_dum                        0.48  \n",
       "incivility_simple2_L33_70b_zero_seed2_dum                  0.48  \n",
       "INCIVILITY_DUMMY                                           1.00  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate correlations between the different models for all columns ending with _dum and containing 'rationality' in boukes, start with the gpt4o model and zero temperature::\n",
    "incivility_cols = [col for col in boukes.columns if 'incivility' in col]\n",
    "incivility_cols = [col for col in incivility_cols if col.endswith('_dum')]\n",
    "incivility_cols = [col for col in incivility_cols if 'L33_70b' in col]\n",
    "#add groundtruth columns:\n",
    "incivility_cols += ['INCIVILITY_DUMMY']\n",
    "incivility_corr = boukes[incivility_cols].corr(method='pearson').round(2)\n",
    "\n",
    "incivility_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bbeb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#it appears rewording, reformatting, changing seed and temperature has about equal influence, changing to Jaidka prompt has a larger influence, the zero temperature prompt does have a better correlation with a different seed than the low temperature prompt, \n",
    "#suprisingly low correlation between incivility_simple2_L33_70b_seed2_low_dum/incivility_simple2_L33_70b_seed2_run2_low_dum and incivility_simple2_L33_70b_low_dum -> temperature can sometimes have a larger effect than expected, but correlation is still much higher than with the groundtruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3fafff6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incivility_simple2_gpt4o_zero_dum</th>\n",
       "      <th>incivility_simple2_gpt4o_system_zero_dum</th>\n",
       "      <th>incivility_jaidka_gpt4o_system_zero_dum</th>\n",
       "      <th>incivility_para1_gpt4o_system_zero_dum</th>\n",
       "      <th>incivility_para2_gpt4o_system_zero_dum</th>\n",
       "      <th>incivility_simpa1_gpt4o_system_zero_dum</th>\n",
       "      <th>INCIVILITY_DUMMY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>incivility_simple2_gpt4o_zero_dum</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incivility_simple2_gpt4o_system_zero_dum</th>\n",
       "      <td>0.88</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incivility_jaidka_gpt4o_system_zero_dum</th>\n",
       "      <td>0.73</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incivility_para1_gpt4o_system_zero_dum</th>\n",
       "      <td>0.79</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.81</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incivility_para2_gpt4o_system_zero_dum</th>\n",
       "      <td>0.82</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incivility_simpa1_gpt4o_system_zero_dum</th>\n",
       "      <td>0.81</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INCIVILITY_DUMMY</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          incivility_simple2_gpt4o_zero_dum  \\\n",
       "incivility_simple2_gpt4o_zero_dum                                      1.00   \n",
       "incivility_simple2_gpt4o_system_zero_dum                               0.88   \n",
       "incivility_jaidka_gpt4o_system_zero_dum                                0.73   \n",
       "incivility_para1_gpt4o_system_zero_dum                                 0.79   \n",
       "incivility_para2_gpt4o_system_zero_dum                                 0.82   \n",
       "incivility_simpa1_gpt4o_system_zero_dum                                0.81   \n",
       "INCIVILITY_DUMMY                                                       0.55   \n",
       "\n",
       "                                          incivility_simple2_gpt4o_system_zero_dum  \\\n",
       "incivility_simple2_gpt4o_zero_dum                                             0.88   \n",
       "incivility_simple2_gpt4o_system_zero_dum                                      1.00   \n",
       "incivility_jaidka_gpt4o_system_zero_dum                                       0.76   \n",
       "incivility_para1_gpt4o_system_zero_dum                                        0.85   \n",
       "incivility_para2_gpt4o_system_zero_dum                                        0.84   \n",
       "incivility_simpa1_gpt4o_system_zero_dum                                       0.84   \n",
       "INCIVILITY_DUMMY                                                              0.51   \n",
       "\n",
       "                                          incivility_jaidka_gpt4o_system_zero_dum  \\\n",
       "incivility_simple2_gpt4o_zero_dum                                            0.73   \n",
       "incivility_simple2_gpt4o_system_zero_dum                                     0.76   \n",
       "incivility_jaidka_gpt4o_system_zero_dum                                      1.00   \n",
       "incivility_para1_gpt4o_system_zero_dum                                       0.81   \n",
       "incivility_para2_gpt4o_system_zero_dum                                       0.78   \n",
       "incivility_simpa1_gpt4o_system_zero_dum                                      0.79   \n",
       "INCIVILITY_DUMMY                                                             0.45   \n",
       "\n",
       "                                          incivility_para1_gpt4o_system_zero_dum  \\\n",
       "incivility_simple2_gpt4o_zero_dum                                           0.79   \n",
       "incivility_simple2_gpt4o_system_zero_dum                                    0.85   \n",
       "incivility_jaidka_gpt4o_system_zero_dum                                     0.81   \n",
       "incivility_para1_gpt4o_system_zero_dum                                      1.00   \n",
       "incivility_para2_gpt4o_system_zero_dum                                      0.90   \n",
       "incivility_simpa1_gpt4o_system_zero_dum                                     0.91   \n",
       "INCIVILITY_DUMMY                                                            0.47   \n",
       "\n",
       "                                          incivility_para2_gpt4o_system_zero_dum  \\\n",
       "incivility_simple2_gpt4o_zero_dum                                           0.82   \n",
       "incivility_simple2_gpt4o_system_zero_dum                                    0.84   \n",
       "incivility_jaidka_gpt4o_system_zero_dum                                     0.78   \n",
       "incivility_para1_gpt4o_system_zero_dum                                      0.90   \n",
       "incivility_para2_gpt4o_system_zero_dum                                      1.00   \n",
       "incivility_simpa1_gpt4o_system_zero_dum                                     0.89   \n",
       "INCIVILITY_DUMMY                                                            0.50   \n",
       "\n",
       "                                          incivility_simpa1_gpt4o_system_zero_dum  \\\n",
       "incivility_simple2_gpt4o_zero_dum                                            0.81   \n",
       "incivility_simple2_gpt4o_system_zero_dum                                     0.84   \n",
       "incivility_jaidka_gpt4o_system_zero_dum                                      0.79   \n",
       "incivility_para1_gpt4o_system_zero_dum                                       0.91   \n",
       "incivility_para2_gpt4o_system_zero_dum                                       0.89   \n",
       "incivility_simpa1_gpt4o_system_zero_dum                                      1.00   \n",
       "INCIVILITY_DUMMY                                                             0.49   \n",
       "\n",
       "                                          INCIVILITY_DUMMY  \n",
       "incivility_simple2_gpt4o_zero_dum                     0.55  \n",
       "incivility_simple2_gpt4o_system_zero_dum              0.51  \n",
       "incivility_jaidka_gpt4o_system_zero_dum               0.45  \n",
       "incivility_para1_gpt4o_system_zero_dum                0.47  \n",
       "incivility_para2_gpt4o_system_zero_dum                0.50  \n",
       "incivility_simpa1_gpt4o_system_zero_dum               0.49  \n",
       "INCIVILITY_DUMMY                                      1.00  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate correlations between the different models for all columns ending with _dum and containing 'rationality' in boukes, start with the gpt4o model and zero temperature::\n",
    "incivility_cols = [col for col in boukes.columns if 'incivility' in col]\n",
    "incivility_cols = [col for col in incivility_cols if col.endswith('_dum')]\n",
    "incivility_cols = [col for col in incivility_cols if 'gpt4o' in col]\n",
    "#add groundtruth columns:\n",
    "incivility_cols += ['INCIVILITY_DUMMY']\n",
    "incivility_corr = boukes[incivility_cols].corr(method='pearson').round(2)\n",
    "\n",
    "incivility_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76472cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rationality_simple2_L33_70b_low_dum</th>\n",
       "      <th>rationality_jaidka_L33_70b_low_dum</th>\n",
       "      <th>rationality_simple2_para1_L33_70b_low_dum</th>\n",
       "      <th>rationality_simple2_L33_70b_seed2_low_dum</th>\n",
       "      <th>rationality_simple2_para2_L33_70b_low_dum</th>\n",
       "      <th>rationality_simple2_simpa1_L33_70b_low_dum</th>\n",
       "      <th>rationality_simple2_L33_70b_seed2_run2_low_dum</th>\n",
       "      <th>rationality_simple2_L33_70b_zero_dum</th>\n",
       "      <th>rationality_simple2_L33_70b_zero_seed2_dum</th>\n",
       "      <th>RATIONALITY_DUMMY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rationality_simple2_L33_70b_low_dum</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rationality_jaidka_L33_70b_low_dum</th>\n",
       "      <td>0.29</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rationality_simple2_para1_L33_70b_low_dum</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rationality_simple2_L33_70b_seed2_low_dum</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rationality_simple2_para2_L33_70b_low_dum</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rationality_simple2_simpa1_L33_70b_low_dum</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rationality_simple2_L33_70b_seed2_run2_low_dum</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rationality_simple2_L33_70b_zero_dum</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rationality_simple2_L33_70b_zero_seed2_dum</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.97</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RATIONALITY_DUMMY</th>\n",
       "      <td>0.41</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                rationality_simple2_L33_70b_low_dum  \\\n",
       "rationality_simple2_L33_70b_low_dum                                            1.00   \n",
       "rationality_jaidka_L33_70b_low_dum                                             0.29   \n",
       "rationality_simple2_para1_L33_70b_low_dum                                      0.90   \n",
       "rationality_simple2_L33_70b_seed2_low_dum                                      0.97   \n",
       "rationality_simple2_para2_L33_70b_low_dum                                      0.92   \n",
       "rationality_simple2_simpa1_L33_70b_low_dum                                     0.88   \n",
       "rationality_simple2_L33_70b_seed2_run2_low_dum                                 0.95   \n",
       "rationality_simple2_L33_70b_zero_dum                                           0.97   \n",
       "rationality_simple2_L33_70b_zero_seed2_dum                                     0.97   \n",
       "RATIONALITY_DUMMY                                                              0.41   \n",
       "\n",
       "                                                rationality_jaidka_L33_70b_low_dum  \\\n",
       "rationality_simple2_L33_70b_low_dum                                           0.29   \n",
       "rationality_jaidka_L33_70b_low_dum                                            1.00   \n",
       "rationality_simple2_para1_L33_70b_low_dum                                     0.28   \n",
       "rationality_simple2_L33_70b_seed2_low_dum                                     0.28   \n",
       "rationality_simple2_para2_L33_70b_low_dum                                     0.28   \n",
       "rationality_simple2_simpa1_L33_70b_low_dum                                    0.27   \n",
       "rationality_simple2_L33_70b_seed2_run2_low_dum                                0.29   \n",
       "rationality_simple2_L33_70b_zero_dum                                          0.28   \n",
       "rationality_simple2_L33_70b_zero_seed2_dum                                    0.28   \n",
       "RATIONALITY_DUMMY                                                             0.30   \n",
       "\n",
       "                                                rationality_simple2_para1_L33_70b_low_dum  \\\n",
       "rationality_simple2_L33_70b_low_dum                                                  0.90   \n",
       "rationality_jaidka_L33_70b_low_dum                                                   0.28   \n",
       "rationality_simple2_para1_L33_70b_low_dum                                            1.00   \n",
       "rationality_simple2_L33_70b_seed2_low_dum                                            0.92   \n",
       "rationality_simple2_para2_L33_70b_low_dum                                            0.96   \n",
       "rationality_simple2_simpa1_L33_70b_low_dum                                           0.91   \n",
       "rationality_simple2_L33_70b_seed2_run2_low_dum                                       0.91   \n",
       "rationality_simple2_L33_70b_zero_dum                                                 0.92   \n",
       "rationality_simple2_L33_70b_zero_seed2_dum                                           0.92   \n",
       "RATIONALITY_DUMMY                                                                    0.39   \n",
       "\n",
       "                                                rationality_simple2_L33_70b_seed2_low_dum  \\\n",
       "rationality_simple2_L33_70b_low_dum                                                  0.97   \n",
       "rationality_jaidka_L33_70b_low_dum                                                   0.28   \n",
       "rationality_simple2_para1_L33_70b_low_dum                                            0.92   \n",
       "rationality_simple2_L33_70b_seed2_low_dum                                            1.00   \n",
       "rationality_simple2_para2_L33_70b_low_dum                                            0.94   \n",
       "rationality_simple2_simpa1_L33_70b_low_dum                                           0.91   \n",
       "rationality_simple2_L33_70b_seed2_run2_low_dum                                       0.97   \n",
       "rationality_simple2_L33_70b_zero_dum                                                 1.00   \n",
       "rationality_simple2_L33_70b_zero_seed2_dum                                           1.00   \n",
       "RATIONALITY_DUMMY                                                                    0.40   \n",
       "\n",
       "                                                rationality_simple2_para2_L33_70b_low_dum  \\\n",
       "rationality_simple2_L33_70b_low_dum                                                  0.92   \n",
       "rationality_jaidka_L33_70b_low_dum                                                   0.28   \n",
       "rationality_simple2_para1_L33_70b_low_dum                                            0.96   \n",
       "rationality_simple2_L33_70b_seed2_low_dum                                            0.94   \n",
       "rationality_simple2_para2_L33_70b_low_dum                                            1.00   \n",
       "rationality_simple2_simpa1_L33_70b_low_dum                                           0.91   \n",
       "rationality_simple2_L33_70b_seed2_run2_low_dum                                       0.93   \n",
       "rationality_simple2_L33_70b_zero_dum                                                 0.94   \n",
       "rationality_simple2_L33_70b_zero_seed2_dum                                           0.94   \n",
       "RATIONALITY_DUMMY                                                                    0.40   \n",
       "\n",
       "                                                rationality_simple2_simpa1_L33_70b_low_dum  \\\n",
       "rationality_simple2_L33_70b_low_dum                                                   0.88   \n",
       "rationality_jaidka_L33_70b_low_dum                                                    0.27   \n",
       "rationality_simple2_para1_L33_70b_low_dum                                             0.91   \n",
       "rationality_simple2_L33_70b_seed2_low_dum                                             0.91   \n",
       "rationality_simple2_para2_L33_70b_low_dum                                             0.91   \n",
       "rationality_simple2_simpa1_L33_70b_low_dum                                            1.00   \n",
       "rationality_simple2_L33_70b_seed2_run2_low_dum                                        0.89   \n",
       "rationality_simple2_L33_70b_zero_dum                                                  0.91   \n",
       "rationality_simple2_L33_70b_zero_seed2_dum                                            0.91   \n",
       "RATIONALITY_DUMMY                                                                     0.38   \n",
       "\n",
       "                                                rationality_simple2_L33_70b_seed2_run2_low_dum  \\\n",
       "rationality_simple2_L33_70b_low_dum                                                       0.95   \n",
       "rationality_jaidka_L33_70b_low_dum                                                        0.29   \n",
       "rationality_simple2_para1_L33_70b_low_dum                                                 0.91   \n",
       "rationality_simple2_L33_70b_seed2_low_dum                                                 0.97   \n",
       "rationality_simple2_para2_L33_70b_low_dum                                                 0.93   \n",
       "rationality_simple2_simpa1_L33_70b_low_dum                                                0.89   \n",
       "rationality_simple2_L33_70b_seed2_run2_low_dum                                            1.00   \n",
       "rationality_simple2_L33_70b_zero_dum                                                      0.97   \n",
       "rationality_simple2_L33_70b_zero_seed2_dum                                                0.97   \n",
       "RATIONALITY_DUMMY                                                                         0.40   \n",
       "\n",
       "                                                rationality_simple2_L33_70b_zero_dum  \\\n",
       "rationality_simple2_L33_70b_low_dum                                             0.97   \n",
       "rationality_jaidka_L33_70b_low_dum                                              0.28   \n",
       "rationality_simple2_para1_L33_70b_low_dum                                       0.92   \n",
       "rationality_simple2_L33_70b_seed2_low_dum                                       1.00   \n",
       "rationality_simple2_para2_L33_70b_low_dum                                       0.94   \n",
       "rationality_simple2_simpa1_L33_70b_low_dum                                      0.91   \n",
       "rationality_simple2_L33_70b_seed2_run2_low_dum                                  0.97   \n",
       "rationality_simple2_L33_70b_zero_dum                                            1.00   \n",
       "rationality_simple2_L33_70b_zero_seed2_dum                                      1.00   \n",
       "RATIONALITY_DUMMY                                                               0.40   \n",
       "\n",
       "                                                rationality_simple2_L33_70b_zero_seed2_dum  \\\n",
       "rationality_simple2_L33_70b_low_dum                                                   0.97   \n",
       "rationality_jaidka_L33_70b_low_dum                                                    0.28   \n",
       "rationality_simple2_para1_L33_70b_low_dum                                             0.92   \n",
       "rationality_simple2_L33_70b_seed2_low_dum                                             1.00   \n",
       "rationality_simple2_para2_L33_70b_low_dum                                             0.94   \n",
       "rationality_simple2_simpa1_L33_70b_low_dum                                            0.91   \n",
       "rationality_simple2_L33_70b_seed2_run2_low_dum                                        0.97   \n",
       "rationality_simple2_L33_70b_zero_dum                                                  1.00   \n",
       "rationality_simple2_L33_70b_zero_seed2_dum                                            1.00   \n",
       "RATIONALITY_DUMMY                                                                     0.40   \n",
       "\n",
       "                                                RATIONALITY_DUMMY  \n",
       "rationality_simple2_L33_70b_low_dum                          0.41  \n",
       "rationality_jaidka_L33_70b_low_dum                           0.30  \n",
       "rationality_simple2_para1_L33_70b_low_dum                    0.39  \n",
       "rationality_simple2_L33_70b_seed2_low_dum                    0.40  \n",
       "rationality_simple2_para2_L33_70b_low_dum                    0.40  \n",
       "rationality_simple2_simpa1_L33_70b_low_dum                   0.38  \n",
       "rationality_simple2_L33_70b_seed2_run2_low_dum               0.40  \n",
       "rationality_simple2_L33_70b_zero_dum                         0.40  \n",
       "rationality_simple2_L33_70b_zero_seed2_dum                   0.40  \n",
       "RATIONALITY_DUMMY                                            1.00  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate correlations between the different models for all columns ending with _dum and containing 'rationality' in boukes, start with the gpt4o model and zero temperature::\n",
    "rationality_cols = [col for col in boukes.columns if 'rationality' in col]\n",
    "rationality_cols = [col for col in rationality_cols if col.endswith('_dum')]\n",
    "rationality_cols = [col for col in rationality_cols if 'L33_70b' in col]\n",
    "#add groundtruth columns:\n",
    "rationality_cols += ['RATIONALITY_DUMMY']\n",
    "rationality_corr = boukes[rationality_cols].corr(method='pearson').round(2)\n",
    "\n",
    "rationality_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0e144b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#it appears rewording, reformatting, changing seed and temperature has about equal influence, changing to Jaidka prompt has a larger influence, the zero temperature prompt does have a better correlation with a different seed than the low temperature prompt, but effects are small\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmdiv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
