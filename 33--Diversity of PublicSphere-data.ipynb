{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sjoerdstolwijk/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sjoerdstolwijk/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import typing\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import config\n",
    "import src\n",
    "import requests\n",
    "import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "import logging\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = config.Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartDate</th>\n",
       "      <th>RecordedDate</th>\n",
       "      <th>IPAddress</th>\n",
       "      <th>Finished</th>\n",
       "      <th>Coder</th>\n",
       "      <th>ID</th>\n",
       "      <th>Mark_ID</th>\n",
       "      <th>Genre</th>\n",
       "      <th>topiccode</th>\n",
       "      <th>Platform</th>\n",
       "      <th>...</th>\n",
       "      <th>dislikeCount_video</th>\n",
       "      <th>likeCount_video</th>\n",
       "      <th>date_difference</th>\n",
       "      <th>commentCount_video</th>\n",
       "      <th>replyCount_comment</th>\n",
       "      <th>topic</th>\n",
       "      <th>subscribers</th>\n",
       "      <th>HATELIST_FOCUSED_DUMMY</th>\n",
       "      <th>Time_comment_year</th>\n",
       "      <th>Time_video_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/30/2021 13:03:17</td>\n",
       "      <td>5/30/2021 13:04:17</td>\n",
       "      <td>62.194.51.29</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgyPHwv8G0cDE6-wEgl4AaABAg.8_0ZjJKSJty8_0kXGkAd2U</td>\n",
       "      <td>119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>2017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/11/2021 10:34:05</td>\n",
       "      <td>10/11/2021 10:36:46</td>\n",
       "      <td>213.127.109.191</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>Ugx2WXq9UdV8mPPjejJ4AaABAg.8yHCKV0Boe58yYRxEQEF45</td>\n",
       "      <td>282</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>195.0</td>\n",
       "      <td>3817.0</td>\n",
       "      <td>743.0</td>\n",
       "      <td>1748.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>economy</td>\n",
       "      <td>3630000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9/9/2021 18:49:48</td>\n",
       "      <td>9/9/2021 18:51:32</td>\n",
       "      <td>213.127.110.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1110578710648890000</td>\n",
       "      <td>372</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6/6/2021 16:12:46</td>\n",
       "      <td>6/6/2021 16:16:16</td>\n",
       "      <td>213.127.76.145</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgwUPFScjJ0MCeaP2F54AaABAg.8lvp3fc9Euf8lvvgsUgEgV</td>\n",
       "      <td>769</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6/13/2021 13:25:49</td>\n",
       "      <td>6/13/2021 13:27:28</td>\n",
       "      <td>213.127.82.232</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgwWKCWtSJdFvjGHvTp4AaABAg.8kUC5dGrQ2H8kUDRihE2f3</td>\n",
       "      <td>1206</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3857</th>\n",
       "      <td>8/19/2021 14:50:13</td>\n",
       "      <td>8/19/2021 14:54:28</td>\n",
       "      <td>62.194.51.29</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1152219467579100000</td>\n",
       "      <td>10000695</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3858</th>\n",
       "      <td>8/19/2021 15:10:27</td>\n",
       "      <td>8/19/2021 15:12:21</td>\n",
       "      <td>62.194.51.29</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1085362296472430000</td>\n",
       "      <td>10007008</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2019</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3859</th>\n",
       "      <td>10/6/2021 16:08:39</td>\n",
       "      <td>10/6/2021 16:10:42</td>\n",
       "      <td>213.127.113.113</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UghFY3QJ6nmT_ngCoAEC.7-H0Z7--wxd8goqpaPs-bl</td>\n",
       "      <td>20000102</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2820.0</td>\n",
       "      <td>12475.0</td>\n",
       "      <td>3803.0</td>\n",
       "      <td>4785.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>east</td>\n",
       "      <td>6740000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>2010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3860</th>\n",
       "      <td>10/15/2021 18:30:04</td>\n",
       "      <td>10/15/2021 18:35:40</td>\n",
       "      <td>213.127.109.191</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgyWabsmmnq3zam4DgZ4AaABAg</td>\n",
       "      <td>20000418</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>118.0</td>\n",
       "      <td>31761.0</td>\n",
       "      <td>1531.0</td>\n",
       "      <td>2206.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>east</td>\n",
       "      <td>6800000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>2015.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3861</th>\n",
       "      <td>11/19/2021 17:49:17</td>\n",
       "      <td>11/19/2021 17:51:04</td>\n",
       "      <td>213.127.109.191</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>UgwPOHIDyICm10k0Mvx4AaABAg</td>\n",
       "      <td>20001003</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1358.0</td>\n",
       "      <td>5740.0</td>\n",
       "      <td>2276.0</td>\n",
       "      <td>2887.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>east</td>\n",
       "      <td>549000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3862 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                StartDate         RecordedDate        IPAddress  Finished  \\\n",
       "0      5/30/2021 13:03:17   5/30/2021 13:04:17     62.194.51.29         1   \n",
       "1     10/11/2021 10:34:05  10/11/2021 10:36:46  213.127.109.191         1   \n",
       "2       9/9/2021 18:49:48    9/9/2021 18:51:32    213.127.110.0         1   \n",
       "3       6/6/2021 16:12:46    6/6/2021 16:16:16   213.127.76.145         1   \n",
       "4      6/13/2021 13:25:49   6/13/2021 13:27:28   213.127.82.232         1   \n",
       "...                   ...                  ...              ...       ...   \n",
       "3857   8/19/2021 14:50:13   8/19/2021 14:54:28     62.194.51.29         1   \n",
       "3858   8/19/2021 15:10:27   8/19/2021 15:12:21     62.194.51.29         1   \n",
       "3859   10/6/2021 16:08:39   10/6/2021 16:10:42  213.127.113.113         1   \n",
       "3860  10/15/2021 18:30:04  10/15/2021 18:35:40  213.127.109.191         1   \n",
       "3861  11/19/2021 17:49:17  11/19/2021 17:51:04  213.127.109.191         1   \n",
       "\n",
       "      Coder                                                 ID   Mark_ID  \\\n",
       "0         6  UgyPHwv8G0cDE6-wEgl4AaABAg.8_0ZjJKSJty8_0kXGkAd2U       119   \n",
       "1         6  Ugx2WXq9UdV8mPPjejJ4AaABAg.8yHCKV0Boe58yYRxEQEF45       282   \n",
       "2         6                                1110578710648890000       372   \n",
       "3         6  UgwUPFScjJ0MCeaP2F54AaABAg.8lvp3fc9Euf8lvvgsUgEgV       769   \n",
       "4         6  UgwWKCWtSJdFvjGHvTp4AaABAg.8kUC5dGrQ2H8kUDRihE2f3      1206   \n",
       "...     ...                                                ...       ...   \n",
       "3857      6                                1152219467579100000  10000695   \n",
       "3858      6                                1085362296472430000  10007008   \n",
       "3859      6        UghFY3QJ6nmT_ngCoAEC.7-H0Z7--wxd8goqpaPs-bl  20000102   \n",
       "3860      6                         UgyWabsmmnq3zam4DgZ4AaABAg  20000418   \n",
       "3861      6                         UgwPOHIDyICm10k0Mvx4AaABAg  20001003   \n",
       "\n",
       "      Genre  topiccode  Platform  ...  dislikeCount_video likeCount_video  \\\n",
       "0         0          0         1  ...                 NaN             NaN   \n",
       "1         1          2         1  ...               195.0          3817.0   \n",
       "2         2          4         2  ...                 NaN             NaN   \n",
       "3         0          0         1  ...                 NaN             NaN   \n",
       "4         0          0         1  ...                 NaN             NaN   \n",
       "...     ...        ...       ...  ...                 ...             ...   \n",
       "3857      0          4         2  ...                 NaN             NaN   \n",
       "3858      1          4         2  ...                 NaN             NaN   \n",
       "3859      0          3         1  ...              2820.0         12475.0   \n",
       "3860      2          3         1  ...               118.0         31761.0   \n",
       "3861      0          3         1  ...              1358.0          5740.0   \n",
       "\n",
       "      date_difference  commentCount_video  replyCount_comment    topic  \\\n",
       "0                 NaN                 NaN                 NaN      NaN   \n",
       "1               743.0              1748.0                 NaN  economy   \n",
       "2                 NaN                 NaN                 NaN      NaN   \n",
       "3                 NaN                 NaN                 NaN      NaN   \n",
       "4                 NaN                 NaN                 NaN      NaN   \n",
       "...               ...                 ...                 ...      ...   \n",
       "3857              NaN                 NaN                 NaN      NaN   \n",
       "3858              NaN                 NaN                 NaN      NaN   \n",
       "3859           3803.0              4785.0                 NaN     east   \n",
       "3860           1531.0              2206.0                 0.0     east   \n",
       "3861           2276.0              2887.0                 1.0     east   \n",
       "\n",
       "      subscribers  HATELIST_FOCUSED_DUMMY  Time_comment_year Time_video_year  \n",
       "0             NaN                       0               2017          2017.0  \n",
       "1       3630000.0                       0               2019          2019.0  \n",
       "2             NaN                       0               2019             NaN  \n",
       "3             NaN                       0               2018          2018.0  \n",
       "4             NaN                       0               2018          2018.0  \n",
       "...           ...                     ...                ...             ...  \n",
       "3857          NaN                       0               2019             NaN  \n",
       "3858          NaN                       0               2019             NaN  \n",
       "3859    6740000.0                       0               2018          2010.0  \n",
       "3860    6800000.0                       0               2018          2015.0  \n",
       "3861     549000.0                       0               2018          2018.0  \n",
       "\n",
       "[3862 rows x 79 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset: pd.DataFrame = pd.read_csv('data/publicsphere/full_data.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first just try pre-processing and a simple tf-ivf:\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(texts):\n",
    "    x_train = []\n",
    "    for sent in tqdm.tqdm(texts):\n",
    "        sent = re.sub(r'@[^ ]+', '', sent)  #remove all usernames\n",
    "        sent = re.sub(r'https?://[^ ]+', '', sent) #remove all hyperlinks\n",
    "        sent = re.sub(r'#', '', sent) #remove all hashtags\n",
    "        sent = re.sub(r'([A-Za-z])\\1{2,}', r'\\1', sent) #normalize language use by replacing duplicate letters by single letters\n",
    "        sent = re.sub(\"[^a-zA-Z ]\", \"\", sent) #remove all non-words\n",
    "        sent = sent.lower().split()\n",
    "        sent = [lemmatizer.lemmatize(word) for word in sent if word not in set(stop_words)]\n",
    "        sent = ' '.join(sent)\n",
    "        x_train.append(sent)\n",
    "    return x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3862/3862 [00:05<00:00, 654.85it/s] \n"
     ]
    }
   ],
   "source": [
    "X = preprocess(dataset[\"commentText\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=5000, analyzer='word', ngram_range=(1,2), stop_words='english')\n",
    "X_tfidf = tfidf.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['tfidf_embedding'] = [torch.tensor(X_tfidf[i], dtype=torch.float32).flatten().tolist() for i in range(X_tfidf.shape[0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['tfidf_embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 1.        , 0.        , ..., 0.0110684 , 0.06654491,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 1.        , ..., 0.08009685, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.0110684 , 0.08009685, ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.06654491, 0.        , ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarities = cosine_similarity(X_tfidf)\n",
    "cosine_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_documents = len(cosine_similarities)\n",
    "\n",
    "# Initialize a list to store the most similar document pairs\n",
    "top_similar_pairs = []\n",
    "\n",
    "# Iterate through all document pairs\n",
    "for i in range(num_documents):\n",
    "    for j in range(i + 1, num_documents):\n",
    "        similarity = cosine_similarities[i][j]\n",
    "        \n",
    "        # Check if the similarity is NaN or zero\n",
    "        if not np.isnan(similarity) and similarity >= 1:\n",
    "            pair = (i, j)\n",
    "            top_similar_pairs.append((similarity, pair))\n",
    "            \n",
    "# Sort the list based on similarity in descending order\n",
    "top_similar_pairs.sort(key=lambda x: x[0], reverse=True)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0000000000000002, (139, 1990)),\n",
       " (1.0000000000000002, (246, 1179)),\n",
       " (1.0000000000000002, (362, 736)),\n",
       " (1.0000000000000002, (722, 739)),\n",
       " (1.0, (21, 1856)),\n",
       " (1.0, (75, 366)),\n",
       " (1.0, (75, 1022)),\n",
       " (1.0, (75, 2122)),\n",
       " (1.0, (75, 2421)),\n",
       " (1.0, (75, 2946)),\n",
       " (1.0, (101, 850)),\n",
       " (1.0, (133, 1057)),\n",
       " (1.0, (141, 3838)),\n",
       " (1.0, (164, 1240)),\n",
       " (1.0, (164, 2182)),\n",
       " (1.0, (198, 3213)),\n",
       " (1.0, (242, 2779)),\n",
       " (1.0, (242, 3278)),\n",
       " (1.0, (259, 490)),\n",
       " (1.0, (313, 2607)),\n",
       " (1.0, (341, 352)),\n",
       " (1.0, (366, 1022)),\n",
       " (1.0, (366, 2122)),\n",
       " (1.0, (366, 2421)),\n",
       " (1.0, (366, 2946)),\n",
       " (1.0, (395, 3340)),\n",
       " (1.0, (400, 585)),\n",
       " (1.0, (400, 877)),\n",
       " (1.0, (400, 962)),\n",
       " (1.0, (400, 2099)),\n",
       " (1.0, (400, 2848)),\n",
       " (1.0, (400, 3752)),\n",
       " (1.0, (436, 3211)),\n",
       " (1.0, (487, 936)),\n",
       " (1.0, (487, 2484)),\n",
       " (1.0, (546, 911)),\n",
       " (1.0, (559, 3708)),\n",
       " (1.0, (585, 877)),\n",
       " (1.0, (585, 962)),\n",
       " (1.0, (585, 2099)),\n",
       " (1.0, (585, 2848)),\n",
       " (1.0, (585, 3752)),\n",
       " (1.0, (643, 1401)),\n",
       " (1.0, (673, 1743)),\n",
       " (1.0, (678, 2244)),\n",
       " (1.0, (678, 2481)),\n",
       " (1.0, (678, 2843)),\n",
       " (1.0, (678, 2856)),\n",
       " (1.0, (678, 2971)),\n",
       " (1.0, (702, 1392)),\n",
       " (1.0, (709, 1800)),\n",
       " (1.0, (753, 930)),\n",
       " (1.0, (753, 1564)),\n",
       " (1.0, (753, 1887)),\n",
       " (1.0, (753, 2728)),\n",
       " (1.0, (793, 2935)),\n",
       " (1.0, (813, 1872)),\n",
       " (1.0, (816, 1088)),\n",
       " (1.0, (877, 962)),\n",
       " (1.0, (877, 2099)),\n",
       " (1.0, (877, 2848)),\n",
       " (1.0, (877, 3752)),\n",
       " (1.0, (894, 1060)),\n",
       " (1.0, (914, 2707)),\n",
       " (1.0, (914, 2914)),\n",
       " (1.0, (919, 3578)),\n",
       " (1.0, (930, 1564)),\n",
       " (1.0, (930, 1887)),\n",
       " (1.0, (930, 2728)),\n",
       " (1.0, (936, 2484)),\n",
       " (1.0, (937, 1005)),\n",
       " (1.0, (937, 1192)),\n",
       " (1.0, (955, 1404)),\n",
       " (1.0, (962, 2099)),\n",
       " (1.0, (962, 2848)),\n",
       " (1.0, (962, 3752)),\n",
       " (1.0, (969, 1196)),\n",
       " (1.0, (969, 1449)),\n",
       " (1.0, (969, 1690)),\n",
       " (1.0, (969, 2245)),\n",
       " (1.0, (969, 2591)),\n",
       " (1.0, (969, 2708)),\n",
       " (1.0, (969, 2840)),\n",
       " (1.0, (969, 3368)),\n",
       " (1.0, (969, 3405)),\n",
       " (1.0, (969, 3703)),\n",
       " (1.0, (1005, 1192)),\n",
       " (1.0, (1022, 2122)),\n",
       " (1.0, (1022, 2421)),\n",
       " (1.0, (1022, 2946)),\n",
       " (1.0, (1028, 1311)),\n",
       " (1.0, (1029, 2658)),\n",
       " (1.0, (1030, 2518)),\n",
       " (1.0, (1030, 2740)),\n",
       " (1.0, (1049, 2407)),\n",
       " (1.0, (1055, 1348)),\n",
       " (1.0, (1084, 1244)),\n",
       " (1.0, (1084, 1262)),\n",
       " (1.0, (1145, 2380)),\n",
       " (1.0, (1166, 1304)),\n",
       " (1.0, (1166, 1626)),\n",
       " (1.0, (1166, 1918)),\n",
       " (1.0, (1166, 2634)),\n",
       " (1.0, (1166, 2835)),\n",
       " (1.0, (1166, 3725)),\n",
       " (1.0, (1174, 3564)),\n",
       " (1.0, (1196, 1449)),\n",
       " (1.0, (1196, 1690)),\n",
       " (1.0, (1196, 2245)),\n",
       " (1.0, (1196, 2591)),\n",
       " (1.0, (1196, 2708)),\n",
       " (1.0, (1196, 2840)),\n",
       " (1.0, (1196, 3368)),\n",
       " (1.0, (1196, 3405)),\n",
       " (1.0, (1196, 3703)),\n",
       " (1.0, (1197, 1560)),\n",
       " (1.0, (1206, 3432)),\n",
       " (1.0, (1240, 2182)),\n",
       " (1.0, (1244, 1262)),\n",
       " (1.0, (1260, 3628)),\n",
       " (1.0, (1304, 1626)),\n",
       " (1.0, (1304, 1918)),\n",
       " (1.0, (1304, 2634)),\n",
       " (1.0, (1304, 2835)),\n",
       " (1.0, (1304, 3725)),\n",
       " (1.0, (1449, 1690)),\n",
       " (1.0, (1449, 2245)),\n",
       " (1.0, (1449, 2591)),\n",
       " (1.0, (1449, 2708)),\n",
       " (1.0, (1449, 2840)),\n",
       " (1.0, (1449, 3368)),\n",
       " (1.0, (1449, 3405)),\n",
       " (1.0, (1449, 3703)),\n",
       " (1.0, (1564, 1887)),\n",
       " (1.0, (1564, 2728)),\n",
       " (1.0, (1626, 1918)),\n",
       " (1.0, (1626, 2634)),\n",
       " (1.0, (1626, 2835)),\n",
       " (1.0, (1626, 3725)),\n",
       " (1.0, (1674, 1903)),\n",
       " (1.0, (1690, 2245)),\n",
       " (1.0, (1690, 2591)),\n",
       " (1.0, (1690, 2708)),\n",
       " (1.0, (1690, 2840)),\n",
       " (1.0, (1690, 3368)),\n",
       " (1.0, (1690, 3405)),\n",
       " (1.0, (1690, 3703)),\n",
       " (1.0, (1695, 2082)),\n",
       " (1.0, (1887, 2728)),\n",
       " (1.0, (1918, 2634)),\n",
       " (1.0, (1918, 2835)),\n",
       " (1.0, (1918, 3725)),\n",
       " (1.0, (2060, 2908)),\n",
       " (1.0, (2090, 2233)),\n",
       " (1.0, (2099, 2848)),\n",
       " (1.0, (2099, 3752)),\n",
       " (1.0, (2122, 2421)),\n",
       " (1.0, (2122, 2946)),\n",
       " (1.0, (2222, 3697)),\n",
       " (1.0, (2244, 2481)),\n",
       " (1.0, (2244, 2843)),\n",
       " (1.0, (2244, 2856)),\n",
       " (1.0, (2244, 2971)),\n",
       " (1.0, (2245, 2591)),\n",
       " (1.0, (2245, 2708)),\n",
       " (1.0, (2245, 2840)),\n",
       " (1.0, (2245, 3368)),\n",
       " (1.0, (2245, 3405)),\n",
       " (1.0, (2245, 3703)),\n",
       " (1.0, (2421, 2946)),\n",
       " (1.0, (2481, 2843)),\n",
       " (1.0, (2481, 2856)),\n",
       " (1.0, (2481, 2971)),\n",
       " (1.0, (2518, 2740)),\n",
       " (1.0, (2591, 2708)),\n",
       " (1.0, (2591, 2840)),\n",
       " (1.0, (2591, 3368)),\n",
       " (1.0, (2591, 3405)),\n",
       " (1.0, (2591, 3703)),\n",
       " (1.0, (2634, 2835)),\n",
       " (1.0, (2634, 3725)),\n",
       " (1.0, (2707, 2914)),\n",
       " (1.0, (2708, 2840)),\n",
       " (1.0, (2708, 3368)),\n",
       " (1.0, (2708, 3405)),\n",
       " (1.0, (2708, 3703)),\n",
       " (1.0, (2779, 3278)),\n",
       " (1.0, (2835, 3725)),\n",
       " (1.0, (2840, 3368)),\n",
       " (1.0, (2840, 3405)),\n",
       " (1.0, (2840, 3703)),\n",
       " (1.0, (2843, 2856)),\n",
       " (1.0, (2843, 2971)),\n",
       " (1.0, (2848, 3752)),\n",
       " (1.0, (2856, 2971)),\n",
       " (1.0, (2972, 3289)),\n",
       " (1.0, (3235, 3475)),\n",
       " (1.0, (3235, 3766)),\n",
       " (1.0, (3368, 3405)),\n",
       " (1.0, (3368, 3703)),\n",
       " (1.0, (3405, 3703)),\n",
       " (1.0, (3475, 3766)),\n",
       " (1.0, (3537, 3572))]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_similar_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(139, 1990), (246, 1179), (362, 736), (722, 739), (21, 1856), (75, 366), (75, 1022), (75, 2122), (75, 2421), (75, 2946), (101, 850), (133, 1057), (141, 3838), (164, 1240), (164, 2182), (198, 3213), (242, 2779), (242, 3278), (259, 490), (313, 2607), (341, 352), (366, 1022), (366, 2122), (366, 2421), (366, 2946), (395, 3340), (400, 585), (400, 877), (400, 962), (400, 2099), (400, 2848), (400, 3752), (436, 3211), (487, 936), (487, 2484), (546, 911), (559, 3708), (585, 877), (585, 962), (585, 2099), (585, 2848), (585, 3752), (643, 1401), (673, 1743), (678, 2244), (678, 2481), (678, 2843), (678, 2856), (678, 2971), (702, 1392), (709, 1800), (753, 930), (753, 1564), (753, 1887), (753, 2728), (793, 2935), (813, 1872), (816, 1088), (877, 962), (877, 2099), (877, 2848), (877, 3752), (894, 1060), (914, 2707), (914, 2914), (919, 3578), (930, 1564), (930, 1887), (930, 2728), (936, 2484), (937, 1005), (937, 1192), (955, 1404), (962, 2099), (962, 2848), (962, 3752), (969, 1196), (969, 1449), (969, 1690), (969, 2245), (969, 2591), (969, 2708), (969, 2840), (969, 3368), (969, 3405), (969, 3703), (1005, 1192), (1022, 2122), (1022, 2421), (1022, 2946), (1028, 1311), (1029, 2658), (1030, 2518), (1030, 2740), (1049, 2407), (1055, 1348), (1084, 1244), (1084, 1262), (1145, 2380), (1166, 1304), (1166, 1626), (1166, 1918), (1166, 2634), (1166, 2835), (1166, 3725), (1174, 3564), (1196, 1449), (1196, 1690), (1196, 2245), (1196, 2591), (1196, 2708), (1196, 2840), (1196, 3368), (1196, 3405), (1196, 3703), (1197, 1560), (1206, 3432), (1240, 2182), (1244, 1262), (1260, 3628), (1304, 1626), (1304, 1918), (1304, 2634), (1304, 2835), (1304, 3725), (1449, 1690), (1449, 2245), (1449, 2591), (1449, 2708), (1449, 2840), (1449, 3368), (1449, 3405), (1449, 3703), (1564, 1887), (1564, 2728), (1626, 1918), (1626, 2634), (1626, 2835), (1626, 3725), (1674, 1903), (1690, 2245), (1690, 2591), (1690, 2708), (1690, 2840), (1690, 3368), (1690, 3405), (1690, 3703), (1695, 2082), (1887, 2728), (1918, 2634), (1918, 2835), (1918, 3725), (2060, 2908), (2090, 2233), (2099, 2848), (2099, 3752), (2122, 2421), (2122, 2946), (2222, 3697), (2244, 2481), (2244, 2843), (2244, 2856), (2244, 2971), (2245, 2591), (2245, 2708), (2245, 2840), (2245, 3368), (2245, 3405), (2245, 3703), (2421, 2946), (2481, 2843), (2481, 2856), (2481, 2971), (2518, 2740), (2591, 2708), (2591, 2840), (2591, 3368), (2591, 3405), (2591, 3703), (2634, 2835), (2634, 3725), (2707, 2914), (2708, 2840), (2708, 3368), (2708, 3405), (2708, 3703), (2779, 3278), (2835, 3725), (2840, 3368), (2840, 3405), (2840, 3703), (2843, 2856), (2843, 2971), (2848, 3752), (2856, 2971), (2972, 3289), (3235, 3475), (3235, 3766), (3368, 3405), (3368, 3703), (3405, 3703), (3475, 3766), (3537, 3572)]\n"
     ]
    }
   ],
   "source": [
    "result = [pair for value, pair in top_similar_pairs if value >= 1]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139          vote trump\n",
      "1990    Vote Trump 2020\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "246                        hell yeah fam\n",
      "1179    @TheDailyShow Hells to the Yeah.\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "362                @James Persinger \\n apple and orange.\n",
      "736    @hardball @MSNBC Just a few apples and oranges...\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "722             @hardball @KenSalazar Good grief!\n",
      "739    @NBCNews My opinion......lol.  Good grief.\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "21                     Mika is low IQ\n",
      "1856    @Rusty you still very low IQ.\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "75                                               I agree\n",
      "366    Kai Watson So you agree that Haiti is a Shithole?\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "75                                 I agree\n",
      "1022    @RealTimers @SteveSchmidtSES Agree\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "75                 I agree\n",
      "2122    Rtb boone i agree.\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "75                  I agree\n",
      "2421    Braulio V.  I agree\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "75                            I agree\n",
      "2946    at least we can agree on that\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "101                      Starts at 39:20\n",
      "850    @MeetThePress Can't start til Jan\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "133                                    Go Bernie 2016!\n",
      "1057    @FullFrontalSamB @Ilhan It's BERNIE, OKUURRRT!\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "141     Enough is enough, Diane. shut the fudge up!\n",
      "3838                       \"Woops\". \"Shut it down\".\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "164                             Exactly\n",
      "1240    @LateNightSeth ???????? exactly\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "164       Exactly\n",
      "2182    EXACTLY ?\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "198     this is so heartbreaking :(\n",
      "3213    This is so heartbreaking...\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "242                  Napoleon had help\n",
      "2779    You nedd help!\\nSeroius help!!\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "242     Napoleon had help\n",
      "3278                 Help\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "259    1st\n",
      "490    1st\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "313                      The US executes Traitors.\n",
      "2607    Libby was a traitor pardoned by a traitor.\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "341     SAVAGEEEEE\n",
      "352    Savage bill\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "366     Kai Watson So you agree that Haiti is a Shithole?\n",
      "1022                   @RealTimers @SteveSchmidtSES Agree\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "366     Kai Watson So you agree that Haiti is a Shithole?\n",
      "2122                                   Rtb boone i agree.\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "366     Kai Watson So you agree that Haiti is a Shithole?\n",
      "2421                                  Braulio V.  I agree\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "366     Kai Watson So you agree that Haiti is a Shithole?\n",
      "2946                        at least we can agree on that\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "395     @killalthedon21Â  get a life\n",
      "3340            Dion9646 get a life!\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "400    lineflyer1 Rasict trump stan ?\n",
      "585                       Trump 2020.\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "400    lineflyer1 Rasict trump stan ?\n",
      "877     @60Minutes Do Trump next Amal\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "400                       lineflyer1 Rasict trump stan ?\n",
      "962    @FaceTheNation @RepAdamSchiff Why is Trump des...\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "400                        lineflyer1 Rasict trump stan ?\n",
      "2099    \"Scientifically, not just words.\"\\n\\nPresident...\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "400     lineflyer1 Rasict trump stan ?\n",
      "2848                        Trump 2020\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "400     lineflyer1 Rasict trump stan ?\n",
      "3752       Why is Trump so cringy? >_<\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "436     @FullFrontalSamB @Huck_a_bot so very boring......\n",
      "3211                                         Too funny!!!\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "487                                    Who is this guy\n",
      "936    @TuckerCarlson @FoxNews These guys are awsome..\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "487           Who is this guy\n",
      "2484    You guys are so salty\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "546           This is no surprise at all...\n",
      "911    @FaceTheNation @RoyBlunt Surprise!!!\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "559                             Truth\n",
      "3708    Otravez 39 .....Friggin truth\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "585                      Trump 2020.\n",
      "877    @60Minutes Do Trump next Amal\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "585                                          Trump 2020.\n",
      "962    @FaceTheNation @RepAdamSchiff Why is Trump des...\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "585                                           Trump 2020.\n",
      "2099    \"Scientifically, not just words.\"\\n\\nPresident...\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "585     Trump 2020.\n",
      "2848     Trump 2020\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "585                     Trump 2020.\n",
      "3752    Why is Trump so cringy? >_<\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "643                                         learn engwish\n",
      "1401    @CBSEveningNews @CBSLARachel Something everyon...\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "673                            stupid ass\n",
      "1743    He is such a stupid unfunny prick\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "678               yes twoset\n",
      "2244    Yess Tervor is back♥\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "678     yes twoset\n",
      "2481           Yes\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "678                          yes twoset\n",
      "2843    @Richard Skipper Yes, that too.\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "678                    yes twoset\n",
      "2856    @Pat Marcy  - Yes I have.\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "678                           yes twoset\n",
      "2971    kimberly s Yes, that one. Blech.\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "702     @FullFrontalSamB @SmithDryGoods @kristencheeks...\n",
      "1392                              @ABCWorldNews Awesome ?\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "709     @FullFrontalSamB @Ilhan No thanks\n",
      "1800            Jennifer Webb Thanks Sis?\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "753    @11thHour @MSNBC @Eugene_Robinson Idiot\n",
      "930      @hardball @MSNBC @HardballChris Idiot\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "753     @11thHour @MSNBC @Eugene_Robinson Idiot\n",
      "1564                               Hes an idiot\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "753     @11thHour @MSNBC @Eugene_Robinson Idiot\n",
      "1887                                      Idiot\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "753     @11thHour @MSNBC @Eugene_Robinson Idiot\n",
      "2728                                     IDIOTS\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "793     @TheDailyShow Yeeep\n",
      "2935                YEP !!!\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "813           @TuckerCarlson Will never happen\n",
      "1872    BowelMovement...won’t happen, dipshit.\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "816     @ABCWorldNews Wow\n",
      "1088         @NBCNews Wow\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "877                        @60Minutes Do Trump next Amal\n",
      "962    @FaceTheNation @RepAdamSchiff Why is Trump des...\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "877                         @60Minutes Do Trump next Amal\n",
      "2099    \"Scientifically, not just words.\"\\n\\nPresident...\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "877     @60Minutes Do Trump next Amal\n",
      "2848                       Trump 2020\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "877     @60Minutes Do Trump next Amal\n",
      "3752      Why is Trump so cringy? >_<\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "894     @NBCNews That’s, Pierre Delecto (doofus), to you!\n",
      "1060    @colbertlateshow That’s what you get for being...\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "914     @11thHour @MSNBC MAGA 2020 https://t.co/fO5yme...\n",
      "2707                                                #MAGA\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "914     @11thHour @MSNBC MAGA 2020 https://t.co/fO5yme...\n",
      "2914                                                 MAGA\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "919         @FullFrontalSamB Need as ringtone\n",
      "3578    BRAH, BRAH..\\n\\n\\nI need u in my lief\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "930     @hardball @MSNBC @HardballChris Idiot\n",
      "1564                             Hes an idiot\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "930     @hardball @MSNBC @HardballChris Idiot\n",
      "1887                                    Idiot\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "930     @hardball @MSNBC @HardballChris Idiot\n",
      "2728                                   IDIOTS\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "936     @TuckerCarlson @FoxNews These guys are awsome..\n",
      "2484                              You guys are so salty\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "937     @LateNightSeth @Lesdoggg Loved this @LateNight...\n",
      "1005                          @LateNightSeth Loved this!!\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "937     @LateNightSeth @Lesdoggg Loved this @LateNight...\n",
      "1192                           @60Minutes I LOVED THIS!!!\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "955     @Nightline @byronpitts He’s the one ❤️ #Beto20...\n",
      "1404    @Nightline @markwayne143 @byronpitts #Beto2020...\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "962     @FaceTheNation @RepAdamSchiff Why is Trump des...\n",
      "2099    \"Scientifically, not just words.\"\\n\\nPresident...\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "962     @FaceTheNation @RepAdamSchiff Why is Trump des...\n",
      "2848                                           Trump 2020\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "962     @FaceTheNation @RepAdamSchiff Why is Trump des...\n",
      "3752                          Why is Trump so cringy? >_<\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "969       @LateNightSeth Lol!!\n",
      "1196    @colbertlateshow Lol ?\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "969            @LateNightSeth Lol!!\n",
      "1449    “And neither have you!” LOL\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "969     @LateNightSeth Lol!!\n",
      "1690        Roni Sanjaya lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "969     @LateNightSeth Lol!!\n",
      "2245                Same lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "969     @LateNightSeth Lol!!\n",
      "2591                     LoL\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "969     @LateNightSeth Lol!!\n",
      "2708                     lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "969     @LateNightSeth Lol!!\n",
      "2840                     Lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "969     @LateNightSeth Lol!!\n",
      "3368                     lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "969       @LateNightSeth Lol!!\n",
      "3405    @SuperBullaMan \\nLol ?\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "969     @LateNightSeth Lol!!\n",
      "3703                     lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1005    @LateNightSeth Loved this!!\n",
      "1192     @60Minutes I LOVED THIS!!!\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1022    @RealTimers @SteveSchmidtSES Agree\n",
      "2122                    Rtb boone i agree.\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1022    @RealTimers @SteveSchmidtSES Agree\n",
      "2421                   Braulio V.  I agree\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1022    @RealTimers @SteveSchmidtSES Agree\n",
      "2946         at least we can agree on that\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1028    @TuckerCarlson @mikeroweworks Why? Serious que...\n",
      "1311     @ABCWorldNews How about the same question to you\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1029    @patriotact @hahaaaamid @odotr22 lmaoooooo lan...\n",
      "2658                                                 Lmao\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1030    @AC360 @brianstelter Nobody cares.\n",
      "2518                     Cares about WHAT!\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1030    @AC360 @brianstelter Nobody cares.\n",
      "2740    Riddle me this. Why should I care?\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1049    @hardball @MSNBC @NicolleDWallace Losers unite\n",
      "2407        WHAT ELSE IS NEW???\\nTHE DOTARD IS A LOSER\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1055    @hardball @ericswalwell Ps... you Don’t no Any...\n",
      "1348             @NewsHour @nytdavidbrooks No they don’t.\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1084    @LastWeekTonight This is the best one. Also #r...\n",
      "1244    @FullFrontalSamB @halcyonperson @at_howard @Ma...\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1084    @LastWeekTonight This is the best one. Also #r...\n",
      "1262              @RealTimers @billmaher You are the best\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1145    @LastWeekTonight brilliant!\n",
      "2380                    Brilliant ?\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1166       @colbertlateshow Love me some #JoltinJoe\n",
      "1304    @LateNightSeth I Love You @sethmeyers ? !!!\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1166    @colbertlateshow Love me some #JoltinJoe\n",
      "1626                                  Love this.\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1166    @colbertlateshow Love me some #JoltinJoe\n",
      "1918                                   Love her!\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1166    @colbertlateshow Love me some #JoltinJoe\n",
      "2634                           I love this show!\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1166    @colbertlateshow Love me some #JoltinJoe\n",
      "2835        I love ?that name....New Bethlehem !\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1166    @colbertlateshow Love me some #JoltinJoe\n",
      "3725                   I LOVE YOUUUUUUUUUUUUUUUU\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1174    @RealTimers @WhitfordBradley @cbellantoni @Rea...\n",
      "3564     I  dont  think  we  will  ......................\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1196         @colbertlateshow Lol ?\n",
      "1449    “And neither have you!” LOL\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1196    @colbertlateshow Lol ?\n",
      "1690          Roni Sanjaya lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1196    @colbertlateshow Lol ?\n",
      "2245                  Same lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1196    @colbertlateshow Lol ?\n",
      "2591                       LoL\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1196    @colbertlateshow Lol ?\n",
      "2708                       lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1196    @colbertlateshow Lol ?\n",
      "2840                       Lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1196    @colbertlateshow Lol ?\n",
      "3368                       lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1196    @colbertlateshow Lol ?\n",
      "3405    @SuperBullaMan \\nLol ?\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1196    @colbertlateshow Lol ?\n",
      "3703                       lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1197     @AC360 GREAT INTERVIEW\n",
      "1560    What a great interview!\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1206    @AC360 @andersoncooper Perfect.\n",
      "3432                            Perfect\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1240    @LateNightSeth ???????? exactly\n",
      "2182                          EXACTLY ?\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1244    @FullFrontalSamB @halcyonperson @at_howard @Ma...\n",
      "1262              @RealTimers @billmaher You are the best\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1260    @CBSEveningNews @whyfund @weijia He’s sunk and...\n",
      "3628                  +Pasu suel do you know this icon ??\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1304    @LateNightSeth I Love You @sethmeyers ? !!!\n",
      "1626                                     Love this.\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1304    @LateNightSeth I Love You @sethmeyers ? !!!\n",
      "1918                                      Love her!\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1304    @LateNightSeth I Love You @sethmeyers ? !!!\n",
      "2634                              I love this show!\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1304    @LateNightSeth I Love You @sethmeyers ? !!!\n",
      "2835           I love ?that name....New Bethlehem !\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1304    @LateNightSeth I Love You @sethmeyers ? !!!\n",
      "3725                      I LOVE YOUUUUUUUUUUUUUUUU\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1449    “And neither have you!” LOL\n",
      "1690               Roni Sanjaya lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1449    “And neither have you!” LOL\n",
      "2245                       Same lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1449    “And neither have you!” LOL\n",
      "2591                            LoL\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1449    “And neither have you!” LOL\n",
      "2708                            lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1449    “And neither have you!” LOL\n",
      "2840                            Lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1449    “And neither have you!” LOL\n",
      "3368                            lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1449    “And neither have you!” LOL\n",
      "3405         @SuperBullaMan \\nLol ?\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1449    “And neither have you!” LOL\n",
      "3703                            lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1564    Hes an idiot\n",
      "1887           Idiot\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1564    Hes an idiot\n",
      "2728          IDIOTS\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1626    Love this.\n",
      "1918     Love her!\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1626           Love this.\n",
      "2634    I love this show!\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1626                              Love this.\n",
      "2835    I love ?that name....New Bethlehem !\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1626                   Love this.\n",
      "3725    I LOVE YOUUUUUUUUUUUUUUUU\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1674    Kira Barsmith I did. The whole thing too.\n",
      "1903                        you can be two things\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1690    Roni Sanjaya lol\n",
      "2245            Same lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1690    Roni Sanjaya lol\n",
      "2591                 LoL\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1690    Roni Sanjaya lol\n",
      "2708                 lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1690    Roni Sanjaya lol\n",
      "2840                 Lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1690    Roni Sanjaya lol\n",
      "3368                 lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1690          Roni Sanjaya lol\n",
      "3405    @SuperBullaMan \\nLol ?\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1690    Roni Sanjaya lol\n",
      "3703                 lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1695    Let all the hamiltrash Congregate ?\n",
      "2082                      Grrrrr, let's go!\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1887     Idiot\n",
      "2728    IDIOTS\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1918            Love her!\n",
      "2634    I love this show!\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1918                               Love her!\n",
      "2835    I love ?that name....New Bethlehem !\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "1918                    Love her!\n",
      "3725    I LOVE YOUUUUUUUUUUUUUUUU\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2060    Tiring leftist dogma\n",
      "2908         Leftist assh*le\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2090    You are fake news\n",
      "2233       Very fake news\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2099    \"Scientifically, not just words.\"\\n\\nPresident...\n",
      "2848                                           Trump 2020\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2099    \"Scientifically, not just words.\"\\n\\nPresident...\n",
      "3752                          Why is Trump so cringy? >_<\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2122     Rtb boone i agree.\n",
      "2421    Braulio V.  I agree\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2122               Rtb boone i agree.\n",
      "2946    at least we can agree on that\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2222                   Fucking clowns,\n",
      "3697    The bloke's a fucking clown ….\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2244    Yess Tervor is back♥\n",
      "2481                     Yes\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2244               Yess Tervor is back♥\n",
      "2843    @Richard Skipper Yes, that too.\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2244         Yess Tervor is back♥\n",
      "2856    @Pat Marcy  - Yes I have.\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2244                Yess Tervor is back♥\n",
      "2971    kimberly s Yes, that one. Blech.\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2245    Same lol\n",
      "2591         LoL\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2245    Same lol\n",
      "2708         lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2245    Same lol\n",
      "2840         Lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2245    Same lol\n",
      "3368         lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2245                  Same lol\n",
      "3405    @SuperBullaMan \\nLol ?\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2245    Same lol\n",
      "3703         lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2421              Braulio V.  I agree\n",
      "2946    at least we can agree on that\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2481                                Yes\n",
      "2843    @Richard Skipper Yes, that too.\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2481                          Yes\n",
      "2856    @Pat Marcy  - Yes I have.\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2481                                 Yes\n",
      "2971    kimberly s Yes, that one. Blech.\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2518                     Cares about WHAT!\n",
      "2740    Riddle me this. Why should I care?\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2591    LoL\n",
      "2708    lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2591    LoL\n",
      "2840    Lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2591    LoL\n",
      "3368    lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2591                       LoL\n",
      "3405    @SuperBullaMan \\nLol ?\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2591    LoL\n",
      "3703    lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2634                       I love this show!\n",
      "2835    I love ?that name....New Bethlehem !\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2634            I love this show!\n",
      "3725    I LOVE YOUUUUUUUUUUUUUUUU\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2707    #MAGA\n",
      "2914     MAGA\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2708    lol\n",
      "2840    Lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2708    lol\n",
      "3368    lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2708                       lol\n",
      "3405    @SuperBullaMan \\nLol ?\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2708    lol\n",
      "3703    lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2779    You nedd help!\\nSeroius help!!\n",
      "3278                              Help\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2835    I love ?that name....New Bethlehem !\n",
      "3725               I LOVE YOUUUUUUUUUUUUUUUU\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2840    Lol\n",
      "3368    lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2840                       Lol\n",
      "3405    @SuperBullaMan \\nLol ?\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2840    Lol\n",
      "3703    lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2843    @Richard Skipper Yes, that too.\n",
      "2856          @Pat Marcy  - Yes I have.\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2843     @Richard Skipper Yes, that too.\n",
      "2971    kimberly s Yes, that one. Blech.\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2848                     Trump 2020\n",
      "3752    Why is Trump so cringy? >_<\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2856           @Pat Marcy  - Yes I have.\n",
      "2971    kimberly s Yes, that one. Blech.\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "2972    Suck it !!!!!!!!!\n",
      "3289             You suck\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "3235           lock hem up\n",
      "3475    lock  them all  up\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "3235            lock hem up\n",
      "3766    AND LOCK HER UP!!!1\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "3368                       lol\n",
      "3405    @SuperBullaMan \\nLol ?\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "3368    lol\n",
      "3703    lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "3405    @SuperBullaMan \\nLol ?\n",
      "3703                       lol\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "3475     lock  them all  up\n",
      "3766    AND LOCK HER UP!!!1\n",
      "Name: commentText, dtype: object\n",
      "\n",
      "3537    Liberals are incorrigible\n",
      "3572                still liberal\n",
      "Name: commentText, dtype: object\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for first, second in result:\n",
    "    print(dataset[\"commentText\"][[first, second]])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hell yeah fam\n",
      "hell yeah\n",
      "vote trump\n",
      "vote trump\n",
      "mika low iq\n",
      "still low iq\n",
      "good grief\n",
      "opinionlol good grief\n",
      "persinger apple orange\n",
      "apple orange\n"
     ]
    }
   ],
   "source": [
    "print(X[246])\n",
    "print(X[1179])\n",
    "print(X[139])\n",
    "print(X[1990])\n",
    "print(X[21])\n",
    "print(X[1856])\n",
    "print(X[722])\n",
    "print(X[739])\n",
    "print(X[362])\n",
    "print(X[736])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[74], line 16\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     (model_1, model_2) \u001b[38;5;129;01min\u001b[39;00m resultsplatform\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;129;01mor\u001b[39;00m \n\u001b[1;32m      9\u001b[0m     (model_2, model_1) \u001b[38;5;129;01min\u001b[39;00m resultsplatform\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[1;32m     10\u001b[0m ):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     13\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m([\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28msum\u001b[39m(dist(\n\u001b[1;32m     15\u001b[0m         torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39marray(v_1)), \n\u001b[0;32m---> 16\u001b[0m         torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39marray(c_2\u001b[38;5;241m.\u001b[39mtolist()))\n\u001b[1;32m     17\u001b[0m         )) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(c_2)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m v_1 \u001b[38;5;129;01min\u001b[39;00m c_1\n\u001b[1;32m     19\u001b[0m ]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(c_1)\n\u001b[1;32m     21\u001b[0m resultsplatform[(model_1, model_2)] \u001b[38;5;241m=\u001b[39m res\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_2\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mres\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "grouped_data = dataset.groupby(\"Platform\")\n",
    "dist = torch.nn.PairwiseDistance()\n",
    "resultsplatform: typing.Dict[typing.Tuple[str, str], float] = {}\n",
    "for model_1, c_1 in tqdm.tqdm(grouped_data['tfidf_embedding'], total=grouped_data.ngroups):\n",
    "    for model_2, c_2 in tqdm.tqdm(grouped_data['tfidf_embedding'], total=grouped_data.ngroups):\n",
    "\n",
    "        if (\n",
    "            (model_1, model_2) in resultsplatform.keys() or \n",
    "            (model_2, model_1) in resultsplatform.keys()\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        res = sum([\n",
    "            sum(dist(\n",
    "                torch.tensor(np.array(v_1)), \n",
    "                torch.tensor(np.array(c_2.tolist()))\n",
    "                )) / len(c_2)\n",
    "            for v_1 in c_1\n",
    "        ]) / len(c_1)\n",
    "\n",
    "        resultsplatform[(model_1, model_2)] = res\n",
    "\n",
    "        print(f'{model_1}:{model_2}:{res.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = dataset.groupby(\"topiccode\")\n",
    "dist = torch.nn.PairwiseDistance()\n",
    "resultstopic: typing.Dict[typing.Tuple[str, str], float] = {}\n",
    "for model_1, c_1 in tqdm.tqdm(grouped_data['tfidf_embedding'], total=grouped_data.ngroups):\n",
    "    for model_2, c_2 in tqdm.tqdm(grouped_data['tfidf_embedding'], total=grouped_data.ngroups):\n",
    "\n",
    "        if (\n",
    "            (model_1, model_2) in resultstopic.keys() or \n",
    "            (model_2, model_1) in resultstopic.keys()\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        res = sum([\n",
    "            sum(dist(\n",
    "                torch.tensor(np.array(v_1)), \n",
    "                torch.tensor(np.array(c_2.tolist()))\n",
    "                )) / len(c_2)\n",
    "            for v_1 in c_1\n",
    "        ]) / len(c_1)\n",
    "\n",
    "        resultstopic[(model_1, model_2)] = res\n",
    "\n",
    "        print(f'{model_1}:{model_2}:{res.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = dataset.groupby(\"Genre\")\n",
    "dist = torch.nn.PairwiseDistance()\n",
    "resultsgenre: typing.Dict[typing.Tuple[str, str], float] = {}\n",
    "for model_1, c_1 in tqdm.tqdm(grouped_data['tfidf_embedding'], total=grouped_data.ngroups):\n",
    "    for model_2, c_2 in tqdm.tqdm(grouped_data['tfidf_embedding'], total=grouped_data.ngroups):\n",
    "\n",
    "        if (\n",
    "            (model_1, model_2) in resultsgenre.keys() or \n",
    "            (model_2, model_1) in resultsgenre.keys()\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        res = sum([\n",
    "            sum(dist(\n",
    "                torch.tensor(np.array(v_1)), \n",
    "                torch.tensor(np.array(c_2.tolist()))\n",
    "                )) / len(c_2)\n",
    "            for v_1 in c_1\n",
    "        ]) / len(c_1)\n",
    "\n",
    "        resultsgenre[(model_1, model_2)] = res\n",
    "\n",
    "        print(f'{model_1}:{model_2}:{res.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL: str = 'mixtral:8x7b-instruct-v0.1-q6_K' # options: 'gemma:7b-instruct-q6_K', 'gemma2:27b-instruct-q6_K', 'llama3.1:8b-instruct-q6_K', 'llama3.1:70b-instruct-q6_K', 'mistral:7b-instruct-v0.3-q6_K', 'mistral-large:123b-instruct-2407-q6_K', 'mixtral:8x7b-instruct-v0.1-q6_K', 'mixtral:8x22b-instruct-v0.1-q6_K', 'phi3:14b-medium-128k-instruct-q6_K' or 'qwen2:72b-instruct-q6_K'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_MXP: typing.Dict[str, np.ndarray] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 123/3862 [04:58<2:31:24,  2.43s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommentText\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mitems(), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataset)):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m: \n\u001b[0;32m----> 4\u001b[0m         embed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(requests\u001b[38;5;241m.\u001b[39mpost(\n\u001b[1;32m      5\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://inf.cl.uni-trier.de/embed/\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m             json\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m: MODEL, \n\u001b[1;32m      7\u001b[0m                   \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYou help me get embeddings for a sentence. I provide you a with a context and a sentence and you reply only with that exact sentence. Context = \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m context \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m; Sentence: \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m row}\n\u001b[1;32m      8\u001b[0m             )\u001b[38;5;241m.\u001b[39mjson()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m _e:\n\u001b[1;32m     10\u001b[0m         logging\u001b[38;5;241m.\u001b[39mwarning(_e)\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, data\u001b[38;5;241m=\u001b[39mdata, json\u001b[38;5;241m=\u001b[39mjson, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/site-packages/requests/adapters.py:589\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    586\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 589\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[1;32m    590\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    591\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    592\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[1;32m    593\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    594\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    595\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    596\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    597\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    598\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[1;32m    599\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    600\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    601\u001b[0m     )\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/site-packages/urllib3/connectionpool.py:789\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    790\u001b[0m     conn,\n\u001b[1;32m    791\u001b[0m     method,\n\u001b[1;32m    792\u001b[0m     url,\n\u001b[1;32m    793\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[1;32m    794\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    795\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    796\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    797\u001b[0m     retries\u001b[38;5;241m=\u001b[39mretries,\n\u001b[1;32m    798\u001b[0m     response_conn\u001b[38;5;241m=\u001b[39mresponse_conn,\n\u001b[1;32m    799\u001b[0m     preload_content\u001b[38;5;241m=\u001b[39mpreload_content,\n\u001b[1;32m    800\u001b[0m     decode_content\u001b[38;5;241m=\u001b[39mdecode_content,\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mresponse_kw,\n\u001b[1;32m    802\u001b[0m )\n\u001b[1;32m    804\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[1;32m    805\u001b[0m clean_exit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/site-packages/urllib3/connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 536\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/site-packages/urllib3/connection.py:464\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresponse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPResponse\n\u001b[1;32m    463\u001b[0m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[0;32m--> 464\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    467\u001b[0m     assert_header_parsing(httplib_response\u001b[38;5;241m.\u001b[39mmsg)\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/http/client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1427\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1428\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[1;32m   1429\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/http/client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/http/client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/socket.py:708\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 708\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    710\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/ssl.py:1252\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1250\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1251\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "context = 'social media replies to a news- or infotainment-post'\n",
    "for index, row in tqdm.tqdm(dataset[\"commentText\"].items(), total=len(dataset)):\n",
    "    try: \n",
    "        embed = np.array(requests.post(\n",
    "            'https://inf.cl.uni-trier.de/embed/',\n",
    "            json={'model': MODEL, \n",
    "                  'prompt': 'You help me get embeddings for a sentence. I provide you with a context and a sentence and you reply only with that exact sentence. Context = ' + context + '; Sentence: ' + row}\n",
    "            ).json()[\"response\"])\n",
    "    except Exception as _e:\n",
    "        logging.warning(_e)\n",
    "        embed = None\n",
    "    \n",
    "    embed_MXP[index] = embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_w_embeds = dataset.join(pd.Series(embed_MXP, name=\"embed_MXP\"))\n",
    "#dataset_w_embeds.to_parquet(f'{CFG.report_dir}/dataset.embeds.parquet')\n",
    "dataset_w_embeds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create BERT-base embeddings for each word:\n",
    "\n",
    "model_name = \"google-bert/bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create Twhin-BERT-base embeddings for each word:\n",
    "model_name = \"Twitter/twhin-bert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint at voidism/diffcse-roberta-base-sts were not used when initializing RobertaModel: ['aux_bert.embeddings.LayerNorm.bias', 'aux_bert.embeddings.LayerNorm.weight', 'aux_bert.embeddings.position_embeddings.weight', 'aux_bert.embeddings.position_ids', 'aux_bert.embeddings.token_type_embeddings.weight', 'aux_bert.embeddings.word_embeddings.weight', 'aux_bert.encoder.layer.0.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.0.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.0.attention.output.dense.bias', 'aux_bert.encoder.layer.0.attention.output.dense.weight', 'aux_bert.encoder.layer.0.attention.self.key.bias', 'aux_bert.encoder.layer.0.attention.self.key.weight', 'aux_bert.encoder.layer.0.attention.self.query.bias', 'aux_bert.encoder.layer.0.attention.self.query.weight', 'aux_bert.encoder.layer.0.attention.self.value.bias', 'aux_bert.encoder.layer.0.attention.self.value.weight', 'aux_bert.encoder.layer.0.intermediate.dense.bias', 'aux_bert.encoder.layer.0.intermediate.dense.weight', 'aux_bert.encoder.layer.0.output.LayerNorm.bias', 'aux_bert.encoder.layer.0.output.LayerNorm.weight', 'aux_bert.encoder.layer.0.output.dense.bias', 'aux_bert.encoder.layer.0.output.dense.weight', 'aux_bert.encoder.layer.1.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.1.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.1.attention.output.dense.bias', 'aux_bert.encoder.layer.1.attention.output.dense.weight', 'aux_bert.encoder.layer.1.attention.self.key.bias', 'aux_bert.encoder.layer.1.attention.self.key.weight', 'aux_bert.encoder.layer.1.attention.self.query.bias', 'aux_bert.encoder.layer.1.attention.self.query.weight', 'aux_bert.encoder.layer.1.attention.self.value.bias', 'aux_bert.encoder.layer.1.attention.self.value.weight', 'aux_bert.encoder.layer.1.intermediate.dense.bias', 'aux_bert.encoder.layer.1.intermediate.dense.weight', 'aux_bert.encoder.layer.1.output.LayerNorm.bias', 'aux_bert.encoder.layer.1.output.LayerNorm.weight', 'aux_bert.encoder.layer.1.output.dense.bias', 'aux_bert.encoder.layer.1.output.dense.weight', 'aux_bert.encoder.layer.10.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.10.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.10.attention.output.dense.bias', 'aux_bert.encoder.layer.10.attention.output.dense.weight', 'aux_bert.encoder.layer.10.attention.self.key.bias', 'aux_bert.encoder.layer.10.attention.self.key.weight', 'aux_bert.encoder.layer.10.attention.self.query.bias', 'aux_bert.encoder.layer.10.attention.self.query.weight', 'aux_bert.encoder.layer.10.attention.self.value.bias', 'aux_bert.encoder.layer.10.attention.self.value.weight', 'aux_bert.encoder.layer.10.intermediate.dense.bias', 'aux_bert.encoder.layer.10.intermediate.dense.weight', 'aux_bert.encoder.layer.10.output.LayerNorm.bias', 'aux_bert.encoder.layer.10.output.LayerNorm.weight', 'aux_bert.encoder.layer.10.output.dense.bias', 'aux_bert.encoder.layer.10.output.dense.weight', 'aux_bert.encoder.layer.11.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.11.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.11.attention.output.dense.bias', 'aux_bert.encoder.layer.11.attention.output.dense.weight', 'aux_bert.encoder.layer.11.attention.self.key.bias', 'aux_bert.encoder.layer.11.attention.self.key.weight', 'aux_bert.encoder.layer.11.attention.self.query.bias', 'aux_bert.encoder.layer.11.attention.self.query.weight', 'aux_bert.encoder.layer.11.attention.self.value.bias', 'aux_bert.encoder.layer.11.attention.self.value.weight', 'aux_bert.encoder.layer.11.intermediate.dense.bias', 'aux_bert.encoder.layer.11.intermediate.dense.weight', 'aux_bert.encoder.layer.11.output.LayerNorm.bias', 'aux_bert.encoder.layer.11.output.LayerNorm.weight', 'aux_bert.encoder.layer.11.output.dense.bias', 'aux_bert.encoder.layer.11.output.dense.weight', 'aux_bert.encoder.layer.2.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.2.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.2.attention.output.dense.bias', 'aux_bert.encoder.layer.2.attention.output.dense.weight', 'aux_bert.encoder.layer.2.attention.self.key.bias', 'aux_bert.encoder.layer.2.attention.self.key.weight', 'aux_bert.encoder.layer.2.attention.self.query.bias', 'aux_bert.encoder.layer.2.attention.self.query.weight', 'aux_bert.encoder.layer.2.attention.self.value.bias', 'aux_bert.encoder.layer.2.attention.self.value.weight', 'aux_bert.encoder.layer.2.intermediate.dense.bias', 'aux_bert.encoder.layer.2.intermediate.dense.weight', 'aux_bert.encoder.layer.2.output.LayerNorm.bias', 'aux_bert.encoder.layer.2.output.LayerNorm.weight', 'aux_bert.encoder.layer.2.output.dense.bias', 'aux_bert.encoder.layer.2.output.dense.weight', 'aux_bert.encoder.layer.3.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.3.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.3.attention.output.dense.bias', 'aux_bert.encoder.layer.3.attention.output.dense.weight', 'aux_bert.encoder.layer.3.attention.self.key.bias', 'aux_bert.encoder.layer.3.attention.self.key.weight', 'aux_bert.encoder.layer.3.attention.self.query.bias', 'aux_bert.encoder.layer.3.attention.self.query.weight', 'aux_bert.encoder.layer.3.attention.self.value.bias', 'aux_bert.encoder.layer.3.attention.self.value.weight', 'aux_bert.encoder.layer.3.intermediate.dense.bias', 'aux_bert.encoder.layer.3.intermediate.dense.weight', 'aux_bert.encoder.layer.3.output.LayerNorm.bias', 'aux_bert.encoder.layer.3.output.LayerNorm.weight', 'aux_bert.encoder.layer.3.output.dense.bias', 'aux_bert.encoder.layer.3.output.dense.weight', 'aux_bert.encoder.layer.4.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.4.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.4.attention.output.dense.bias', 'aux_bert.encoder.layer.4.attention.output.dense.weight', 'aux_bert.encoder.layer.4.attention.self.key.bias', 'aux_bert.encoder.layer.4.attention.self.key.weight', 'aux_bert.encoder.layer.4.attention.self.query.bias', 'aux_bert.encoder.layer.4.attention.self.query.weight', 'aux_bert.encoder.layer.4.attention.self.value.bias', 'aux_bert.encoder.layer.4.attention.self.value.weight', 'aux_bert.encoder.layer.4.intermediate.dense.bias', 'aux_bert.encoder.layer.4.intermediate.dense.weight', 'aux_bert.encoder.layer.4.output.LayerNorm.bias', 'aux_bert.encoder.layer.4.output.LayerNorm.weight', 'aux_bert.encoder.layer.4.output.dense.bias', 'aux_bert.encoder.layer.4.output.dense.weight', 'aux_bert.encoder.layer.5.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.5.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.5.attention.output.dense.bias', 'aux_bert.encoder.layer.5.attention.output.dense.weight', 'aux_bert.encoder.layer.5.attention.self.key.bias', 'aux_bert.encoder.layer.5.attention.self.key.weight', 'aux_bert.encoder.layer.5.attention.self.query.bias', 'aux_bert.encoder.layer.5.attention.self.query.weight', 'aux_bert.encoder.layer.5.attention.self.value.bias', 'aux_bert.encoder.layer.5.attention.self.value.weight', 'aux_bert.encoder.layer.5.intermediate.dense.bias', 'aux_bert.encoder.layer.5.intermediate.dense.weight', 'aux_bert.encoder.layer.5.output.LayerNorm.bias', 'aux_bert.encoder.layer.5.output.LayerNorm.weight', 'aux_bert.encoder.layer.5.output.dense.bias', 'aux_bert.encoder.layer.5.output.dense.weight', 'aux_bert.encoder.layer.6.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.6.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.6.attention.output.dense.bias', 'aux_bert.encoder.layer.6.attention.output.dense.weight', 'aux_bert.encoder.layer.6.attention.self.key.bias', 'aux_bert.encoder.layer.6.attention.self.key.weight', 'aux_bert.encoder.layer.6.attention.self.query.bias', 'aux_bert.encoder.layer.6.attention.self.query.weight', 'aux_bert.encoder.layer.6.attention.self.value.bias', 'aux_bert.encoder.layer.6.attention.self.value.weight', 'aux_bert.encoder.layer.6.intermediate.dense.bias', 'aux_bert.encoder.layer.6.intermediate.dense.weight', 'aux_bert.encoder.layer.6.output.LayerNorm.bias', 'aux_bert.encoder.layer.6.output.LayerNorm.weight', 'aux_bert.encoder.layer.6.output.dense.bias', 'aux_bert.encoder.layer.6.output.dense.weight', 'aux_bert.encoder.layer.7.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.7.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.7.attention.output.dense.bias', 'aux_bert.encoder.layer.7.attention.output.dense.weight', 'aux_bert.encoder.layer.7.attention.self.key.bias', 'aux_bert.encoder.layer.7.attention.self.key.weight', 'aux_bert.encoder.layer.7.attention.self.query.bias', 'aux_bert.encoder.layer.7.attention.self.query.weight', 'aux_bert.encoder.layer.7.attention.self.value.bias', 'aux_bert.encoder.layer.7.attention.self.value.weight', 'aux_bert.encoder.layer.7.intermediate.dense.bias', 'aux_bert.encoder.layer.7.intermediate.dense.weight', 'aux_bert.encoder.layer.7.output.LayerNorm.bias', 'aux_bert.encoder.layer.7.output.LayerNorm.weight', 'aux_bert.encoder.layer.7.output.dense.bias', 'aux_bert.encoder.layer.7.output.dense.weight', 'aux_bert.encoder.layer.8.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.8.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.8.attention.output.dense.bias', 'aux_bert.encoder.layer.8.attention.output.dense.weight', 'aux_bert.encoder.layer.8.attention.self.key.bias', 'aux_bert.encoder.layer.8.attention.self.key.weight', 'aux_bert.encoder.layer.8.attention.self.query.bias', 'aux_bert.encoder.layer.8.attention.self.query.weight', 'aux_bert.encoder.layer.8.attention.self.value.bias', 'aux_bert.encoder.layer.8.attention.self.value.weight', 'aux_bert.encoder.layer.8.intermediate.dense.bias', 'aux_bert.encoder.layer.8.intermediate.dense.weight', 'aux_bert.encoder.layer.8.output.LayerNorm.bias', 'aux_bert.encoder.layer.8.output.LayerNorm.weight', 'aux_bert.encoder.layer.8.output.dense.bias', 'aux_bert.encoder.layer.8.output.dense.weight', 'aux_bert.encoder.layer.9.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.9.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.9.attention.output.dense.bias', 'aux_bert.encoder.layer.9.attention.output.dense.weight', 'aux_bert.encoder.layer.9.attention.self.key.bias', 'aux_bert.encoder.layer.9.attention.self.key.weight', 'aux_bert.encoder.layer.9.attention.self.query.bias', 'aux_bert.encoder.layer.9.attention.self.query.weight', 'aux_bert.encoder.layer.9.attention.self.value.bias', 'aux_bert.encoder.layer.9.attention.self.value.weight', 'aux_bert.encoder.layer.9.intermediate.dense.bias', 'aux_bert.encoder.layer.9.intermediate.dense.weight', 'aux_bert.encoder.layer.9.output.LayerNorm.bias', 'aux_bert.encoder.layer.9.output.LayerNorm.weight', 'aux_bert.encoder.layer.9.output.dense.bias', 'aux_bert.encoder.layer.9.output.dense.weight', 'generator.lm_head.bias', 'generator.lm_head.decoder.bias', 'generator.lm_head.decoder.weight', 'generator.lm_head.dense.bias', 'generator.lm_head.dense.weight', 'generator.lm_head.layer_norm.bias', 'generator.lm_head.layer_norm.weight', 'generator.roberta.embeddings.LayerNorm.bias', 'generator.roberta.embeddings.LayerNorm.weight', 'generator.roberta.embeddings.position_embeddings.weight', 'generator.roberta.embeddings.position_ids', 'generator.roberta.embeddings.token_type_embeddings.weight', 'generator.roberta.embeddings.word_embeddings.weight', 'generator.roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'generator.roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'generator.roberta.encoder.layer.0.attention.output.dense.bias', 'generator.roberta.encoder.layer.0.attention.output.dense.weight', 'generator.roberta.encoder.layer.0.attention.self.key.bias', 'generator.roberta.encoder.layer.0.attention.self.key.weight', 'generator.roberta.encoder.layer.0.attention.self.query.bias', 'generator.roberta.encoder.layer.0.attention.self.query.weight', 'generator.roberta.encoder.layer.0.attention.self.value.bias', 'generator.roberta.encoder.layer.0.attention.self.value.weight', 'generator.roberta.encoder.layer.0.intermediate.dense.bias', 'generator.roberta.encoder.layer.0.intermediate.dense.weight', 'generator.roberta.encoder.layer.0.output.LayerNorm.bias', 'generator.roberta.encoder.layer.0.output.LayerNorm.weight', 'generator.roberta.encoder.layer.0.output.dense.bias', 'generator.roberta.encoder.layer.0.output.dense.weight', 'generator.roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'generator.roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'generator.roberta.encoder.layer.1.attention.output.dense.bias', 'generator.roberta.encoder.layer.1.attention.output.dense.weight', 'generator.roberta.encoder.layer.1.attention.self.key.bias', 'generator.roberta.encoder.layer.1.attention.self.key.weight', 'generator.roberta.encoder.layer.1.attention.self.query.bias', 'generator.roberta.encoder.layer.1.attention.self.query.weight', 'generator.roberta.encoder.layer.1.attention.self.value.bias', 'generator.roberta.encoder.layer.1.attention.self.value.weight', 'generator.roberta.encoder.layer.1.intermediate.dense.bias', 'generator.roberta.encoder.layer.1.intermediate.dense.weight', 'generator.roberta.encoder.layer.1.output.LayerNorm.bias', 'generator.roberta.encoder.layer.1.output.LayerNorm.weight', 'generator.roberta.encoder.layer.1.output.dense.bias', 'generator.roberta.encoder.layer.1.output.dense.weight', 'generator.roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'generator.roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'generator.roberta.encoder.layer.2.attention.output.dense.bias', 'generator.roberta.encoder.layer.2.attention.output.dense.weight', 'generator.roberta.encoder.layer.2.attention.self.key.bias', 'generator.roberta.encoder.layer.2.attention.self.key.weight', 'generator.roberta.encoder.layer.2.attention.self.query.bias', 'generator.roberta.encoder.layer.2.attention.self.query.weight', 'generator.roberta.encoder.layer.2.attention.self.value.bias', 'generator.roberta.encoder.layer.2.attention.self.value.weight', 'generator.roberta.encoder.layer.2.intermediate.dense.bias', 'generator.roberta.encoder.layer.2.intermediate.dense.weight', 'generator.roberta.encoder.layer.2.output.LayerNorm.bias', 'generator.roberta.encoder.layer.2.output.LayerNorm.weight', 'generator.roberta.encoder.layer.2.output.dense.bias', 'generator.roberta.encoder.layer.2.output.dense.weight', 'generator.roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'generator.roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'generator.roberta.encoder.layer.3.attention.output.dense.bias', 'generator.roberta.encoder.layer.3.attention.output.dense.weight', 'generator.roberta.encoder.layer.3.attention.self.key.bias', 'generator.roberta.encoder.layer.3.attention.self.key.weight', 'generator.roberta.encoder.layer.3.attention.self.query.bias', 'generator.roberta.encoder.layer.3.attention.self.query.weight', 'generator.roberta.encoder.layer.3.attention.self.value.bias', 'generator.roberta.encoder.layer.3.attention.self.value.weight', 'generator.roberta.encoder.layer.3.intermediate.dense.bias', 'generator.roberta.encoder.layer.3.intermediate.dense.weight', 'generator.roberta.encoder.layer.3.output.LayerNorm.bias', 'generator.roberta.encoder.layer.3.output.LayerNorm.weight', 'generator.roberta.encoder.layer.3.output.dense.bias', 'generator.roberta.encoder.layer.3.output.dense.weight', 'generator.roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'generator.roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'generator.roberta.encoder.layer.4.attention.output.dense.bias', 'generator.roberta.encoder.layer.4.attention.output.dense.weight', 'generator.roberta.encoder.layer.4.attention.self.key.bias', 'generator.roberta.encoder.layer.4.attention.self.key.weight', 'generator.roberta.encoder.layer.4.attention.self.query.bias', 'generator.roberta.encoder.layer.4.attention.self.query.weight', 'generator.roberta.encoder.layer.4.attention.self.value.bias', 'generator.roberta.encoder.layer.4.attention.self.value.weight', 'generator.roberta.encoder.layer.4.intermediate.dense.bias', 'generator.roberta.encoder.layer.4.intermediate.dense.weight', 'generator.roberta.encoder.layer.4.output.LayerNorm.bias', 'generator.roberta.encoder.layer.4.output.LayerNorm.weight', 'generator.roberta.encoder.layer.4.output.dense.bias', 'generator.roberta.encoder.layer.4.output.dense.weight', 'generator.roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'generator.roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'generator.roberta.encoder.layer.5.attention.output.dense.bias', 'generator.roberta.encoder.layer.5.attention.output.dense.weight', 'generator.roberta.encoder.layer.5.attention.self.key.bias', 'generator.roberta.encoder.layer.5.attention.self.key.weight', 'generator.roberta.encoder.layer.5.attention.self.query.bias', 'generator.roberta.encoder.layer.5.attention.self.query.weight', 'generator.roberta.encoder.layer.5.attention.self.value.bias', 'generator.roberta.encoder.layer.5.attention.self.value.weight', 'generator.roberta.encoder.layer.5.intermediate.dense.bias', 'generator.roberta.encoder.layer.5.intermediate.dense.weight', 'generator.roberta.encoder.layer.5.output.LayerNorm.bias', 'generator.roberta.encoder.layer.5.output.LayerNorm.weight', 'generator.roberta.encoder.layer.5.output.dense.bias', 'generator.roberta.encoder.layer.5.output.dense.weight', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'mlp.net.0.weight', 'mlp.net.1.bias', 'mlp.net.1.num_batches_tracked', 'mlp.net.1.running_mean', 'mlp.net.1.running_var', 'mlp.net.1.weight', 'mlp.net.3.weight', 'mlp.net.4.num_batches_tracked', 'mlp.net.4.running_mean', 'mlp.net.4.running_var']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at voidism/diffcse-roberta-base-sts and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#calculate DiffCSE embeddings:\n",
    "model_name = \"voidism/diffcse-roberta-base-sts\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for encoding sentence embeddings based on the DiffCSE approach which is based on (and refers to) SimCSE/evaluation.py \n",
    "def encode_sentence(sentence):\n",
    "    input_ids = tokenizer.encode(sentence, add_special_tokens=True, truncation=True, max_length=512, padding='max_length')\n",
    "    input_ids_tensor = torch.tensor(input_ids).unsqueeze(0)  # Add batch dimension\n",
    "    attention_mask = torch.ones_like(input_ids_tensor)  # Creating attention mask \n",
    "    with torch.no_grad():\n",
    "            outputs = model(input_ids_tensor, output_hidden_states=True, return_dict=True, attention_mask=attention_mask)\n",
    "            sentence_embedding = outputs.last_hidden_state[:, 0].cpu()\n",
    "            return sentence_embedding.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#for DiffCSE: Create embeddings for each argument and store them in a new column\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m dataset\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDiffCSE_embedding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcommentText\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(DiffCSE_encode_argument)\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[1;32m   4918\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4919\u001b[0m         func,\n\u001b[1;32m   4920\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[1;32m   4921\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[1;32m   4922\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   4923\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m-> 4924\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[1;32m   1508\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[13], line 7\u001b[0m, in \u001b[0;36mDiffCSE_encode_argument\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      5\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones_like(input_ids_tensor)  \u001b[38;5;66;03m# Creating attention mask \u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 7\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(input_ids_tensor, output_hidden_states\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, attention_mask\u001b[38;5;241m=\u001b[39mattention_mask)\n\u001b[1;32m      8\u001b[0m         sentence_embedding \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state[:, \u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m      9\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m sentence_embedding\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:835\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    826\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    828\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    829\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    830\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    833\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    834\u001b[0m )\n\u001b[0;32m--> 835\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m    836\u001b[0m     embedding_output,\n\u001b[1;32m    837\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[1;32m    838\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[1;32m    839\u001b[0m     encoder_hidden_states\u001b[38;5;241m=\u001b[39mencoder_hidden_states,\n\u001b[1;32m    840\u001b[0m     encoder_attention_mask\u001b[38;5;241m=\u001b[39mencoder_extended_attention_mask,\n\u001b[1;32m    841\u001b[0m     past_key_values\u001b[38;5;241m=\u001b[39mpast_key_values,\n\u001b[1;32m    842\u001b[0m     use_cache\u001b[38;5;241m=\u001b[39muse_cache,\n\u001b[1;32m    843\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    844\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m    845\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m    846\u001b[0m )\n\u001b[1;32m    847\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    848\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:524\u001b[0m, in \u001b[0;36mRobertaEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    513\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    514\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    515\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    521\u001b[0m         output_attentions,\n\u001b[1;32m    522\u001b[0m     )\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 524\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[1;32m    525\u001b[0m         hidden_states,\n\u001b[1;32m    526\u001b[0m         attention_mask,\n\u001b[1;32m    527\u001b[0m         layer_head_mask,\n\u001b[1;32m    528\u001b[0m         encoder_hidden_states,\n\u001b[1;32m    529\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    530\u001b[0m         past_key_value,\n\u001b[1;32m    531\u001b[0m         output_attentions,\n\u001b[1;32m    532\u001b[0m     )\n\u001b[1;32m    534\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:455\u001b[0m, in \u001b[0;36mRobertaLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    452\u001b[0m     cross_attn_present_key_value \u001b[38;5;241m=\u001b[39m cross_attention_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    453\u001b[0m     present_key_value \u001b[38;5;241m=\u001b[39m present_key_value \u001b[38;5;241m+\u001b[39m cross_attn_present_key_value\n\u001b[0;32m--> 455\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m apply_chunking_to_forward(\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeed_forward_chunk, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_size_feed_forward, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len_dim, attention_output\n\u001b[1;32m    457\u001b[0m )\n\u001b[1;32m    458\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    460\u001b[0m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/site-packages/transformers/pytorch_utils.py:236\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[0;32m--> 236\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m forward_fn(\u001b[38;5;241m*\u001b[39minput_tensors)\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:467\u001b[0m, in \u001b[0;36mRobertaLayer.feed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[0;32m--> 467\u001b[0m     intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[1;32m    468\u001b[0m     layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(intermediate_output, attention_output)\n\u001b[1;32m    469\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:366\u001b[0m, in \u001b[0;36mRobertaIntermediate.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    365\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[0;32m--> 366\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate_act_fn(hidden_states)\n\u001b[1;32m    367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Users/SjoerdStolwijk/anaconda3/envs/DefiningDebateQuality/lib/python3.12/site-packages/transformers/activations.py:79\u001b[0m, in \u001b[0;36mGELUActivation.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(\u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#for DiffCSE: Create embeddings for each argument and store them in a new column\n",
    "dataset.loc[:, 'DiffCSE_embedding'] = dataset[\"commentText\"].apply(encode_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DefiningDebateQuality",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
