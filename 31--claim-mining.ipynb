{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import typing\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import config\n",
    "import src\n",
    "\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import requests\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = config.Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGE: str = 'English'\n",
    "TOPIC: str = 'ukraine'\n",
    "GROUPER: str = 'topic'\n",
    "EXTRACTOR: str = r'\\d\\.\\s(.+)\\n'\n",
    "\n",
    "SAMPLE_SIZE: int = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'user_content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset: pd\u001b[38;5;241m.\u001b[39mDataFrame \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(CFG\u001b[38;5;241m.\u001b[39mfinal_data_files[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_content\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      2\u001b[0m dataset\n",
      "\u001b[0;31mKeyError\u001b[0m: 'user_content'"
     ]
    }
   ],
   "source": [
    "dataset: pd.DataFrame = pd.read_parquet(CFG.final_data_files[\"user_content\"])\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL: str = \"llama3:70b-instruct-q6_K\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_claim: str = \\\n",
    "    \"\"\"\n",
    "        Instruction:\n",
    "\n",
    "        You are a text annotation assitant. Analyze a collection of social media comments, enclosed in chevrons <..>. Identify and list the claims within these comments. Claims can be related to events, issues, opinions or concerns in relation to the specified topic.\n",
    "        Claims are defined as the main assertion or conclusion of an argument.\n",
    "        You summarize each claim into a short simple sentence.\n",
    "\n",
    "        Response format:\n",
    "\n",
    "        You provide only the list of claims, separated by commas, without any additional text or explanations. If no claims can be identified, return an empty list [].\n",
    "\n",
    "        Response format template:\n",
    "        \n",
    "        [\"claim 1\", \"claim 2\", \"claim 3\"]\n",
    "\t\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test generalized claim mining\n",
    "requests.post(\n",
    "                            'https://inf.cl.uni-trier.de/',\n",
    "                            json={\n",
    "                                'model': MODEL,\n",
    "                                'system': SYSTEM_claim,\n",
    "                                'prompt': f'The following set of social media posts are about '\n",
    "                                        + TOPIC + \n",
    "                                        f'. Check whether your answer only consists of a list of claims. \\n\"Posts\":\\n<{dataset[\"content\"][:5].to_list()}>'\n",
    "                                }).json()['response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply generalized claim mining to get a list of claims:\n",
    "chunked_result: typing.List[pd.DataFrame] = []\n",
    "for label, group in dataset.groupby(GROUPER):\n",
    "    for index, row in tqdm.tqdm(group.iterrows()):\n",
    "        try: \n",
    "            chunked_result.append(\n",
    "                pd.DataFrame(\n",
    "                    data=[\n",
    "                        requests.post(\n",
    "                            'https://inf.cl.uni-trier.de/',\n",
    "                            json={\n",
    "                                'model': MODEL,\n",
    "                                'system': SYSTEM_claim,\n",
    "                                'prompt': f'The following set of social media posts are about '\n",
    "                                        + TOPIC + \n",
    "                                        f'. Check whether your answer strictly adheres to the specified format. \\n\"Posts\":\\n<{row[\"text\"]}>'\n",
    "                                }).json()['response']                       \n",
    "                    ],\n",
    "                    columns=['claims']\n",
    "                )\n",
    "                .assign(label=label)\n",
    "            )\n",
    "            \n",
    "        except json.JSONDecodeError:\n",
    "            print(\"invalid json response, skipping to next batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_df = pd.concat(chunked_result, ignore_index=True)\n",
    "print(claim_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "claim_df.to_json('data/claims.by.{GROUPER}.{LANGUAGE}.json', orient=\"records\", force_ascii=False, indent=4)\n",
    "claim_df.to_parquet('data/claims.by.{GROUPER}.{LANGUAGE}.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DefiningDebateQuality",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
