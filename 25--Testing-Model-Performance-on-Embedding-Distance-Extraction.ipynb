{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this notebook compares the performance of embeddings extracted by Llama3 models on a sentence similarity task\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import config\n",
    "import typing\n",
    "import logging\n",
    "import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = config.Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at voidism/diffcse-roberta-base-sts were not used when initializing RobertaModel: ['aux_bert.embeddings.LayerNorm.bias', 'aux_bert.embeddings.LayerNorm.weight', 'aux_bert.embeddings.position_embeddings.weight', 'aux_bert.embeddings.position_ids', 'aux_bert.embeddings.token_type_embeddings.weight', 'aux_bert.embeddings.word_embeddings.weight', 'aux_bert.encoder.layer.0.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.0.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.0.attention.output.dense.bias', 'aux_bert.encoder.layer.0.attention.output.dense.weight', 'aux_bert.encoder.layer.0.attention.self.key.bias', 'aux_bert.encoder.layer.0.attention.self.key.weight', 'aux_bert.encoder.layer.0.attention.self.query.bias', 'aux_bert.encoder.layer.0.attention.self.query.weight', 'aux_bert.encoder.layer.0.attention.self.value.bias', 'aux_bert.encoder.layer.0.attention.self.value.weight', 'aux_bert.encoder.layer.0.intermediate.dense.bias', 'aux_bert.encoder.layer.0.intermediate.dense.weight', 'aux_bert.encoder.layer.0.output.LayerNorm.bias', 'aux_bert.encoder.layer.0.output.LayerNorm.weight', 'aux_bert.encoder.layer.0.output.dense.bias', 'aux_bert.encoder.layer.0.output.dense.weight', 'aux_bert.encoder.layer.1.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.1.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.1.attention.output.dense.bias', 'aux_bert.encoder.layer.1.attention.output.dense.weight', 'aux_bert.encoder.layer.1.attention.self.key.bias', 'aux_bert.encoder.layer.1.attention.self.key.weight', 'aux_bert.encoder.layer.1.attention.self.query.bias', 'aux_bert.encoder.layer.1.attention.self.query.weight', 'aux_bert.encoder.layer.1.attention.self.value.bias', 'aux_bert.encoder.layer.1.attention.self.value.weight', 'aux_bert.encoder.layer.1.intermediate.dense.bias', 'aux_bert.encoder.layer.1.intermediate.dense.weight', 'aux_bert.encoder.layer.1.output.LayerNorm.bias', 'aux_bert.encoder.layer.1.output.LayerNorm.weight', 'aux_bert.encoder.layer.1.output.dense.bias', 'aux_bert.encoder.layer.1.output.dense.weight', 'aux_bert.encoder.layer.10.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.10.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.10.attention.output.dense.bias', 'aux_bert.encoder.layer.10.attention.output.dense.weight', 'aux_bert.encoder.layer.10.attention.self.key.bias', 'aux_bert.encoder.layer.10.attention.self.key.weight', 'aux_bert.encoder.layer.10.attention.self.query.bias', 'aux_bert.encoder.layer.10.attention.self.query.weight', 'aux_bert.encoder.layer.10.attention.self.value.bias', 'aux_bert.encoder.layer.10.attention.self.value.weight', 'aux_bert.encoder.layer.10.intermediate.dense.bias', 'aux_bert.encoder.layer.10.intermediate.dense.weight', 'aux_bert.encoder.layer.10.output.LayerNorm.bias', 'aux_bert.encoder.layer.10.output.LayerNorm.weight', 'aux_bert.encoder.layer.10.output.dense.bias', 'aux_bert.encoder.layer.10.output.dense.weight', 'aux_bert.encoder.layer.11.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.11.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.11.attention.output.dense.bias', 'aux_bert.encoder.layer.11.attention.output.dense.weight', 'aux_bert.encoder.layer.11.attention.self.key.bias', 'aux_bert.encoder.layer.11.attention.self.key.weight', 'aux_bert.encoder.layer.11.attention.self.query.bias', 'aux_bert.encoder.layer.11.attention.self.query.weight', 'aux_bert.encoder.layer.11.attention.self.value.bias', 'aux_bert.encoder.layer.11.attention.self.value.weight', 'aux_bert.encoder.layer.11.intermediate.dense.bias', 'aux_bert.encoder.layer.11.intermediate.dense.weight', 'aux_bert.encoder.layer.11.output.LayerNorm.bias', 'aux_bert.encoder.layer.11.output.LayerNorm.weight', 'aux_bert.encoder.layer.11.output.dense.bias', 'aux_bert.encoder.layer.11.output.dense.weight', 'aux_bert.encoder.layer.2.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.2.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.2.attention.output.dense.bias', 'aux_bert.encoder.layer.2.attention.output.dense.weight', 'aux_bert.encoder.layer.2.attention.self.key.bias', 'aux_bert.encoder.layer.2.attention.self.key.weight', 'aux_bert.encoder.layer.2.attention.self.query.bias', 'aux_bert.encoder.layer.2.attention.self.query.weight', 'aux_bert.encoder.layer.2.attention.self.value.bias', 'aux_bert.encoder.layer.2.attention.self.value.weight', 'aux_bert.encoder.layer.2.intermediate.dense.bias', 'aux_bert.encoder.layer.2.intermediate.dense.weight', 'aux_bert.encoder.layer.2.output.LayerNorm.bias', 'aux_bert.encoder.layer.2.output.LayerNorm.weight', 'aux_bert.encoder.layer.2.output.dense.bias', 'aux_bert.encoder.layer.2.output.dense.weight', 'aux_bert.encoder.layer.3.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.3.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.3.attention.output.dense.bias', 'aux_bert.encoder.layer.3.attention.output.dense.weight', 'aux_bert.encoder.layer.3.attention.self.key.bias', 'aux_bert.encoder.layer.3.attention.self.key.weight', 'aux_bert.encoder.layer.3.attention.self.query.bias', 'aux_bert.encoder.layer.3.attention.self.query.weight', 'aux_bert.encoder.layer.3.attention.self.value.bias', 'aux_bert.encoder.layer.3.attention.self.value.weight', 'aux_bert.encoder.layer.3.intermediate.dense.bias', 'aux_bert.encoder.layer.3.intermediate.dense.weight', 'aux_bert.encoder.layer.3.output.LayerNorm.bias', 'aux_bert.encoder.layer.3.output.LayerNorm.weight', 'aux_bert.encoder.layer.3.output.dense.bias', 'aux_bert.encoder.layer.3.output.dense.weight', 'aux_bert.encoder.layer.4.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.4.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.4.attention.output.dense.bias', 'aux_bert.encoder.layer.4.attention.output.dense.weight', 'aux_bert.encoder.layer.4.attention.self.key.bias', 'aux_bert.encoder.layer.4.attention.self.key.weight', 'aux_bert.encoder.layer.4.attention.self.query.bias', 'aux_bert.encoder.layer.4.attention.self.query.weight', 'aux_bert.encoder.layer.4.attention.self.value.bias', 'aux_bert.encoder.layer.4.attention.self.value.weight', 'aux_bert.encoder.layer.4.intermediate.dense.bias', 'aux_bert.encoder.layer.4.intermediate.dense.weight', 'aux_bert.encoder.layer.4.output.LayerNorm.bias', 'aux_bert.encoder.layer.4.output.LayerNorm.weight', 'aux_bert.encoder.layer.4.output.dense.bias', 'aux_bert.encoder.layer.4.output.dense.weight', 'aux_bert.encoder.layer.5.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.5.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.5.attention.output.dense.bias', 'aux_bert.encoder.layer.5.attention.output.dense.weight', 'aux_bert.encoder.layer.5.attention.self.key.bias', 'aux_bert.encoder.layer.5.attention.self.key.weight', 'aux_bert.encoder.layer.5.attention.self.query.bias', 'aux_bert.encoder.layer.5.attention.self.query.weight', 'aux_bert.encoder.layer.5.attention.self.value.bias', 'aux_bert.encoder.layer.5.attention.self.value.weight', 'aux_bert.encoder.layer.5.intermediate.dense.bias', 'aux_bert.encoder.layer.5.intermediate.dense.weight', 'aux_bert.encoder.layer.5.output.LayerNorm.bias', 'aux_bert.encoder.layer.5.output.LayerNorm.weight', 'aux_bert.encoder.layer.5.output.dense.bias', 'aux_bert.encoder.layer.5.output.dense.weight', 'aux_bert.encoder.layer.6.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.6.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.6.attention.output.dense.bias', 'aux_bert.encoder.layer.6.attention.output.dense.weight', 'aux_bert.encoder.layer.6.attention.self.key.bias', 'aux_bert.encoder.layer.6.attention.self.key.weight', 'aux_bert.encoder.layer.6.attention.self.query.bias', 'aux_bert.encoder.layer.6.attention.self.query.weight', 'aux_bert.encoder.layer.6.attention.self.value.bias', 'aux_bert.encoder.layer.6.attention.self.value.weight', 'aux_bert.encoder.layer.6.intermediate.dense.bias', 'aux_bert.encoder.layer.6.intermediate.dense.weight', 'aux_bert.encoder.layer.6.output.LayerNorm.bias', 'aux_bert.encoder.layer.6.output.LayerNorm.weight', 'aux_bert.encoder.layer.6.output.dense.bias', 'aux_bert.encoder.layer.6.output.dense.weight', 'aux_bert.encoder.layer.7.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.7.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.7.attention.output.dense.bias', 'aux_bert.encoder.layer.7.attention.output.dense.weight', 'aux_bert.encoder.layer.7.attention.self.key.bias', 'aux_bert.encoder.layer.7.attention.self.key.weight', 'aux_bert.encoder.layer.7.attention.self.query.bias', 'aux_bert.encoder.layer.7.attention.self.query.weight', 'aux_bert.encoder.layer.7.attention.self.value.bias', 'aux_bert.encoder.layer.7.attention.self.value.weight', 'aux_bert.encoder.layer.7.intermediate.dense.bias', 'aux_bert.encoder.layer.7.intermediate.dense.weight', 'aux_bert.encoder.layer.7.output.LayerNorm.bias', 'aux_bert.encoder.layer.7.output.LayerNorm.weight', 'aux_bert.encoder.layer.7.output.dense.bias', 'aux_bert.encoder.layer.7.output.dense.weight', 'aux_bert.encoder.layer.8.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.8.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.8.attention.output.dense.bias', 'aux_bert.encoder.layer.8.attention.output.dense.weight', 'aux_bert.encoder.layer.8.attention.self.key.bias', 'aux_bert.encoder.layer.8.attention.self.key.weight', 'aux_bert.encoder.layer.8.attention.self.query.bias', 'aux_bert.encoder.layer.8.attention.self.query.weight', 'aux_bert.encoder.layer.8.attention.self.value.bias', 'aux_bert.encoder.layer.8.attention.self.value.weight', 'aux_bert.encoder.layer.8.intermediate.dense.bias', 'aux_bert.encoder.layer.8.intermediate.dense.weight', 'aux_bert.encoder.layer.8.output.LayerNorm.bias', 'aux_bert.encoder.layer.8.output.LayerNorm.weight', 'aux_bert.encoder.layer.8.output.dense.bias', 'aux_bert.encoder.layer.8.output.dense.weight', 'aux_bert.encoder.layer.9.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.9.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.9.attention.output.dense.bias', 'aux_bert.encoder.layer.9.attention.output.dense.weight', 'aux_bert.encoder.layer.9.attention.self.key.bias', 'aux_bert.encoder.layer.9.attention.self.key.weight', 'aux_bert.encoder.layer.9.attention.self.query.bias', 'aux_bert.encoder.layer.9.attention.self.query.weight', 'aux_bert.encoder.layer.9.attention.self.value.bias', 'aux_bert.encoder.layer.9.attention.self.value.weight', 'aux_bert.encoder.layer.9.intermediate.dense.bias', 'aux_bert.encoder.layer.9.intermediate.dense.weight', 'aux_bert.encoder.layer.9.output.LayerNorm.bias', 'aux_bert.encoder.layer.9.output.LayerNorm.weight', 'aux_bert.encoder.layer.9.output.dense.bias', 'aux_bert.encoder.layer.9.output.dense.weight', 'generator.lm_head.bias', 'generator.lm_head.decoder.bias', 'generator.lm_head.decoder.weight', 'generator.lm_head.dense.bias', 'generator.lm_head.dense.weight', 'generator.lm_head.layer_norm.bias', 'generator.lm_head.layer_norm.weight', 'generator.roberta.embeddings.LayerNorm.bias', 'generator.roberta.embeddings.LayerNorm.weight', 'generator.roberta.embeddings.position_embeddings.weight', 'generator.roberta.embeddings.position_ids', 'generator.roberta.embeddings.token_type_embeddings.weight', 'generator.roberta.embeddings.word_embeddings.weight', 'generator.roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'generator.roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'generator.roberta.encoder.layer.0.attention.output.dense.bias', 'generator.roberta.encoder.layer.0.attention.output.dense.weight', 'generator.roberta.encoder.layer.0.attention.self.key.bias', 'generator.roberta.encoder.layer.0.attention.self.key.weight', 'generator.roberta.encoder.layer.0.attention.self.query.bias', 'generator.roberta.encoder.layer.0.attention.self.query.weight', 'generator.roberta.encoder.layer.0.attention.self.value.bias', 'generator.roberta.encoder.layer.0.attention.self.value.weight', 'generator.roberta.encoder.layer.0.intermediate.dense.bias', 'generator.roberta.encoder.layer.0.intermediate.dense.weight', 'generator.roberta.encoder.layer.0.output.LayerNorm.bias', 'generator.roberta.encoder.layer.0.output.LayerNorm.weight', 'generator.roberta.encoder.layer.0.output.dense.bias', 'generator.roberta.encoder.layer.0.output.dense.weight', 'generator.roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'generator.roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'generator.roberta.encoder.layer.1.attention.output.dense.bias', 'generator.roberta.encoder.layer.1.attention.output.dense.weight', 'generator.roberta.encoder.layer.1.attention.self.key.bias', 'generator.roberta.encoder.layer.1.attention.self.key.weight', 'generator.roberta.encoder.layer.1.attention.self.query.bias', 'generator.roberta.encoder.layer.1.attention.self.query.weight', 'generator.roberta.encoder.layer.1.attention.self.value.bias', 'generator.roberta.encoder.layer.1.attention.self.value.weight', 'generator.roberta.encoder.layer.1.intermediate.dense.bias', 'generator.roberta.encoder.layer.1.intermediate.dense.weight', 'generator.roberta.encoder.layer.1.output.LayerNorm.bias', 'generator.roberta.encoder.layer.1.output.LayerNorm.weight', 'generator.roberta.encoder.layer.1.output.dense.bias', 'generator.roberta.encoder.layer.1.output.dense.weight', 'generator.roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'generator.roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'generator.roberta.encoder.layer.2.attention.output.dense.bias', 'generator.roberta.encoder.layer.2.attention.output.dense.weight', 'generator.roberta.encoder.layer.2.attention.self.key.bias', 'generator.roberta.encoder.layer.2.attention.self.key.weight', 'generator.roberta.encoder.layer.2.attention.self.query.bias', 'generator.roberta.encoder.layer.2.attention.self.query.weight', 'generator.roberta.encoder.layer.2.attention.self.value.bias', 'generator.roberta.encoder.layer.2.attention.self.value.weight', 'generator.roberta.encoder.layer.2.intermediate.dense.bias', 'generator.roberta.encoder.layer.2.intermediate.dense.weight', 'generator.roberta.encoder.layer.2.output.LayerNorm.bias', 'generator.roberta.encoder.layer.2.output.LayerNorm.weight', 'generator.roberta.encoder.layer.2.output.dense.bias', 'generator.roberta.encoder.layer.2.output.dense.weight', 'generator.roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'generator.roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'generator.roberta.encoder.layer.3.attention.output.dense.bias', 'generator.roberta.encoder.layer.3.attention.output.dense.weight', 'generator.roberta.encoder.layer.3.attention.self.key.bias', 'generator.roberta.encoder.layer.3.attention.self.key.weight', 'generator.roberta.encoder.layer.3.attention.self.query.bias', 'generator.roberta.encoder.layer.3.attention.self.query.weight', 'generator.roberta.encoder.layer.3.attention.self.value.bias', 'generator.roberta.encoder.layer.3.attention.self.value.weight', 'generator.roberta.encoder.layer.3.intermediate.dense.bias', 'generator.roberta.encoder.layer.3.intermediate.dense.weight', 'generator.roberta.encoder.layer.3.output.LayerNorm.bias', 'generator.roberta.encoder.layer.3.output.LayerNorm.weight', 'generator.roberta.encoder.layer.3.output.dense.bias', 'generator.roberta.encoder.layer.3.output.dense.weight', 'generator.roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'generator.roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'generator.roberta.encoder.layer.4.attention.output.dense.bias', 'generator.roberta.encoder.layer.4.attention.output.dense.weight', 'generator.roberta.encoder.layer.4.attention.self.key.bias', 'generator.roberta.encoder.layer.4.attention.self.key.weight', 'generator.roberta.encoder.layer.4.attention.self.query.bias', 'generator.roberta.encoder.layer.4.attention.self.query.weight', 'generator.roberta.encoder.layer.4.attention.self.value.bias', 'generator.roberta.encoder.layer.4.attention.self.value.weight', 'generator.roberta.encoder.layer.4.intermediate.dense.bias', 'generator.roberta.encoder.layer.4.intermediate.dense.weight', 'generator.roberta.encoder.layer.4.output.LayerNorm.bias', 'generator.roberta.encoder.layer.4.output.LayerNorm.weight', 'generator.roberta.encoder.layer.4.output.dense.bias', 'generator.roberta.encoder.layer.4.output.dense.weight', 'generator.roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'generator.roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'generator.roberta.encoder.layer.5.attention.output.dense.bias', 'generator.roberta.encoder.layer.5.attention.output.dense.weight', 'generator.roberta.encoder.layer.5.attention.self.key.bias', 'generator.roberta.encoder.layer.5.attention.self.key.weight', 'generator.roberta.encoder.layer.5.attention.self.query.bias', 'generator.roberta.encoder.layer.5.attention.self.query.weight', 'generator.roberta.encoder.layer.5.attention.self.value.bias', 'generator.roberta.encoder.layer.5.attention.self.value.weight', 'generator.roberta.encoder.layer.5.intermediate.dense.bias', 'generator.roberta.encoder.layer.5.intermediate.dense.weight', 'generator.roberta.encoder.layer.5.output.LayerNorm.bias', 'generator.roberta.encoder.layer.5.output.LayerNorm.weight', 'generator.roberta.encoder.layer.5.output.dense.bias', 'generator.roberta.encoder.layer.5.output.dense.weight', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'mlp.net.0.weight', 'mlp.net.1.bias', 'mlp.net.1.num_batches_tracked', 'mlp.net.1.running_mean', 'mlp.net.1.running_var', 'mlp.net.1.weight', 'mlp.net.3.weight', 'mlp.net.4.num_batches_tracked', 'mlp.net.4.running_mean', 'mlp.net.4.running_var']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at voidism/diffcse-roberta-base-sts and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#first calculate DiffCSE embeddings:\n",
    "model_name = \"voidism/diffcse-roberta-base-sts\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first try procedure on extracted topic argument sets from simulation data COMPTEXT24:\n",
    "LANGUAGE: str = 'English'\n",
    "GROUPER: str = 'topic'\n",
    "ARG_DIR: str = 'data/arguments'\n",
    "MODEL: str = \"llama3:70b-instruct-q6_K\" # \"mixtral:8x7b-instruct-v0.1-q6_K\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for encoding sentence embeddings based on the DiffCSE approach which is based on (and refers to) SimCSE/evaluation.py \n",
    "def DiffCSE_encode_argument(sentence):\n",
    "    input_ids = tokenizer.encode(sentence, add_special_tokens=True, truncation=True, max_length=512, padding='max_length')\n",
    "    input_ids_tensor = torch.tensor(input_ids).unsqueeze(0)  # Add batch dimension\n",
    "    attention_mask = torch.ones_like(input_ids_tensor)  # Creating attention mask \n",
    "    with torch.no_grad():\n",
    "            outputs = model(input_ids_tensor, output_hidden_states=True, return_dict=True, attention_mask=attention_mask)\n",
    "            argument_embedding = outputs.last_hidden_state[:, 0].cpu()\n",
    "            return argument_embedding.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the arguments from the .parquet file\n",
    "arguments_df = pd.read_parquet(f\"{ARG_DIR}/arguments.by.{GROUPER}.{LANGUAGE}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arguments</th>\n",
       "      <th>label</th>\n",
       "      <th>DiffCSE_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"Access to affordable healthcare is a fundam...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>[[-0.031701505184173584, 0.1383965015411377, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"The current healthcare system unfairly benef...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>[[-0.041136495769023895, 0.11384233832359314, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"High costs of healthcare create financial bu...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>[[0.0036838464438915253, 0.12259957194328308, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Pre-existing conditions should not exclude i...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>[[0.041562195867300034, 0.14262324571609497, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Universal healthcare would ensure everyone h...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>[[0.0069744773209095, 0.1994149088859558, -0.3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           arguments       label  \\\n",
       "0   [\"Access to affordable healthcare is a fundam...  healthcare   \n",
       "1   \"The current healthcare system unfairly benef...  healthcare   \n",
       "2   \"High costs of healthcare create financial bu...  healthcare   \n",
       "3   \"Pre-existing conditions should not exclude i...  healthcare   \n",
       "4   \"Universal healthcare would ensure everyone h...  healthcare   \n",
       "\n",
       "                                   DiffCSE_embedding  \n",
       "0  [[-0.031701505184173584, 0.1383965015411377, -...  \n",
       "1  [[-0.041136495769023895, 0.11384233832359314, ...  \n",
       "2  [[0.0036838464438915253, 0.12259957194328308, ...  \n",
       "3  [[0.041562195867300034, 0.14262324571609497, -...  \n",
       "4  [[0.0069744773209095, 0.1994149088859558, -0.3...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arguments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for DiffCSE: Create embeddings for each argument and store them in a new column\n",
    "arguments_df.loc[:, 'DiffCSE_embedding'] = arguments_df[\"arguments\"].apply(DiffCSE_encode_argument)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for Llama3:\n",
    "embed_Llama3: typing.Dict[str, np.ndarray] = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/206 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [00:43<00:00,  4.78it/s]\n"
     ]
    }
   ],
   "source": [
    "    name = \"embed_llama3\"\n",
    "    template = 'You help me get embeddings for a sentence. I provide you a with a context and a sentence and you reply only with that exact sentence. Context = '\n",
    "    for index, row in tqdm.tqdm(arguments_df.iterrows(), total=len(arguments_df)):\n",
    "        context = row[\"label\"]\n",
    "        sentence = row[\"arguments\"]\n",
    "        try: \n",
    "            embed = np.array(requests.post(\n",
    "                'https://inf.cl.uni-trier.de/embed/',\n",
    "                json={'model': MODEL, 'prompt': template + context + '; Sentence: ' + sentence}\n",
    "                ).json()[\"response\"])\n",
    "        except Exception as _e:\n",
    "            logging.warning(_e)\n",
    "            embed = None\n",
    "        \n",
    "        if name=='embed_llama3':\n",
    "            embed_Llama3[index] = embed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arguments</th>\n",
       "      <th>label</th>\n",
       "      <th>DiffCSE_embedding</th>\n",
       "      <th>embed_llama3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"Access to affordable healthcare is a fundam...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>[[-0.031701505184173584, 0.1383965015411377, -...</td>\n",
       "      <td>[0.5143977403640747, -0.44048359990119934, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"The current healthcare system unfairly benef...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>[[-0.041136495769023895, 0.11384233832359314, ...</td>\n",
       "      <td>[0.40946468710899353, -0.4694342613220215, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"High costs of healthcare create financial bu...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>[[0.0036838464438915253, 0.12259957194328308, ...</td>\n",
       "      <td>[0.3307845890522003, -0.531212329864502, -0.79...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Pre-existing conditions should not exclude i...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>[[0.041562195867300034, 0.14262324571609497, -...</td>\n",
       "      <td>[0.2711120843887329, -0.33552631735801697, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Universal healthcare would ensure everyone h...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>[[0.0069744773209095, 0.1994149088859558, -0.3...</td>\n",
       "      <td>[0.40233278274536133, -0.5556334257125854, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           arguments       label  \\\n",
       "0   [\"Access to affordable healthcare is a fundam...  healthcare   \n",
       "1   \"The current healthcare system unfairly benef...  healthcare   \n",
       "2   \"High costs of healthcare create financial bu...  healthcare   \n",
       "3   \"Pre-existing conditions should not exclude i...  healthcare   \n",
       "4   \"Universal healthcare would ensure everyone h...  healthcare   \n",
       "\n",
       "                                   DiffCSE_embedding  \\\n",
       "0  [[-0.031701505184173584, 0.1383965015411377, -...   \n",
       "1  [[-0.041136495769023895, 0.11384233832359314, ...   \n",
       "2  [[0.0036838464438915253, 0.12259957194328308, ...   \n",
       "3  [[0.041562195867300034, 0.14262324571609497, -...   \n",
       "4  [[0.0069744773209095, 0.1994149088859558, -0.3...   \n",
       "\n",
       "                                        embed_llama3  \n",
       "0  [0.5143977403640747, -0.44048359990119934, -0....  \n",
       "1  [0.40946468710899353, -0.4694342613220215, -0....  \n",
       "2  [0.3307845890522003, -0.531212329864502, -0.79...  \n",
       "3  [0.2711120843887329, -0.33552631735801697, -0....  \n",
       "4  [0.40233278274536133, -0.5556334257125854, -0....  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_w_embeds = arguments_df.join(pd.Series(embed_Llama3, name=\"embed_llama3\"))\n",
    "#dataset_w_embeds.to_parquet(f'{CFG.report_dir}/dataset.embeds.parquet')\n",
    "dataset_w_embeds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape embeddings to single dimension:\n",
    "dataset_w_embeds['DiffCSE_embedding'] = dataset_w_embeds['DiffCSE_embedding'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = dataset_w_embeds.groupby('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "results: typing.Dict[typing.Tuple[str, str], float] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "healthcare:healthcare:3.512138113613706\n",
      "healthcare:ukraine:4.4383741450897745\n",
      "ukraine:ukraine:4.4135212572020945\n"
     ]
    }
   ],
   "source": [
    "#for DiffCSE:\n",
    "dist = torch.nn.PairwiseDistance()\n",
    "\n",
    "for model_1, c_1 in grouped_data['DiffCSE_embedding']:\n",
    "    for model_2, c_2 in grouped_data['DiffCSE_embedding']:\n",
    "\n",
    "        if (\n",
    "            (model_1, model_2) in results.keys() or \n",
    "            (model_2, model_1) in results.keys()\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        res = sum([\n",
    "            sum(dist(\n",
    "                torch.tensor(np.array(v_1)), \n",
    "                torch.tensor(np.array(c_2.tolist()))\n",
    "                )) / len(c_2)\n",
    "            for v_1 in c_1\n",
    "        ]) / len(c_1)\n",
    "\n",
    "        results[(model_1, model_2)] = res\n",
    "\n",
    "        print(f'{model_1}:{model_2}:{res.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "healthcare:healthcare:3.8460111482448824\n",
      "healthcare:ukraine:7.980850266694351\n",
      "ukraine:ukraine:3.7148092856659054\n"
     ]
    }
   ],
   "source": [
    "#for Llama3\n",
    "dist = torch.nn.PairwiseDistance()\n",
    "results2: typing.Dict[typing.Tuple[str, str], float] = {}\n",
    "for model_1, c_1 in grouped_data['embed_llama3']:\n",
    "    for model_2, c_2 in grouped_data['embed_llama3']:\n",
    "\n",
    "        if (\n",
    "            (model_1, model_2) in results2.keys() or \n",
    "            (model_2, model_1) in results2.keys()\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        res = sum([\n",
    "            sum(dist(\n",
    "                torch.tensor(np.array(v_1)), \n",
    "                torch.tensor(np.array(c_2.tolist()))\n",
    "                )) / len(c_2)\n",
    "            for v_1 in c_1\n",
    "        ]) / len(c_1)\n",
    "\n",
    "        results2[(model_1, model_2)] = res\n",
    "\n",
    "        print(f'{model_1}:{model_2}:{res.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clearly adding context to Llama3 embeddings differentiates the arguments considerably, but this could be due to the embedding extraction overly relying on the context... what if the arguments had a similar context? If we compare the diversity of all healthcare arguments to all ukraine arguments there is hardly any difference, while the DiffCSE embeddings found a larger diversity amond ukraine arguments than among healthcare arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/206 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [00:42<00:00,  4.86it/s]\n"
     ]
    }
   ],
   "source": [
    "    #what if we change the context:\n",
    "\n",
    "    #for argument context:\n",
    "    embed_Llama3_arg_context: typing.Dict[str, np.ndarray] = {}\n",
    "\n",
    "    name = \"embed_llama3\"\n",
    "    template = 'You help me get embeddings for a sentence. I provide you a with a context and a sentence and you reply only with that exact sentence. Context = '\n",
    "    for index, row in tqdm.tqdm(arguments_df.iterrows(), total=len(arguments_df)):\n",
    "        context = 'arguments about ' + row[\"label\"]\n",
    "        sentence = row[\"arguments\"]\n",
    "        try: \n",
    "            embed = np.array(requests.post(\n",
    "                'https://inf.cl.uni-trier.de/embed/',\n",
    "                json={'model': MODEL, 'prompt': template + context + '; Sentence: ' + sentence}\n",
    "                ).json()[\"response\"])\n",
    "        except Exception as _e:\n",
    "            logging.warning(_e)\n",
    "            embed = None\n",
    "        \n",
    "        if name=='embed_llama3':\n",
    "            embed_Llama3_arg_context[index] = embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arguments</th>\n",
       "      <th>label</th>\n",
       "      <th>DiffCSE_embedding</th>\n",
       "      <th>embed_llama3</th>\n",
       "      <th>embed_Llama3_arg_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"Access to affordable healthcare is a fundam...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>[-0.031701505184173584, 0.1383965015411377, -0...</td>\n",
       "      <td>[0.5143977403640747, -0.44048359990119934, -0....</td>\n",
       "      <td>[0.49859514832496643, -0.534142255783081, -0.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"The current healthcare system unfairly benef...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>[-0.041136495769023895, 0.11384233832359314, -...</td>\n",
       "      <td>[0.40946468710899353, -0.4694342613220215, -0....</td>\n",
       "      <td>[0.40977850556373596, -0.5506035089492798, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"High costs of healthcare create financial bu...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>[0.0036838464438915253, 0.12259957194328308, -...</td>\n",
       "      <td>[0.3307845890522003, -0.531212329864502, -0.79...</td>\n",
       "      <td>[0.29485011100769043, -0.5935364365577698, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Pre-existing conditions should not exclude i...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>[0.041562195867300034, 0.14262324571609497, -0...</td>\n",
       "      <td>[0.2711120843887329, -0.33552631735801697, -0....</td>\n",
       "      <td>[0.3479368984699249, -0.47894537448883057, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Universal healthcare would ensure everyone h...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>[0.0069744773209095, 0.1994149088859558, -0.36...</td>\n",
       "      <td>[0.40233278274536133, -0.5556334257125854, -0....</td>\n",
       "      <td>[0.3797900080680847, -0.6202806234359741, -0.9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           arguments       label  \\\n",
       "0   [\"Access to affordable healthcare is a fundam...  healthcare   \n",
       "1   \"The current healthcare system unfairly benef...  healthcare   \n",
       "2   \"High costs of healthcare create financial bu...  healthcare   \n",
       "3   \"Pre-existing conditions should not exclude i...  healthcare   \n",
       "4   \"Universal healthcare would ensure everyone h...  healthcare   \n",
       "\n",
       "                                   DiffCSE_embedding  \\\n",
       "0  [-0.031701505184173584, 0.1383965015411377, -0...   \n",
       "1  [-0.041136495769023895, 0.11384233832359314, -...   \n",
       "2  [0.0036838464438915253, 0.12259957194328308, -...   \n",
       "3  [0.041562195867300034, 0.14262324571609497, -0...   \n",
       "4  [0.0069744773209095, 0.1994149088859558, -0.36...   \n",
       "\n",
       "                                        embed_llama3  \\\n",
       "0  [0.5143977403640747, -0.44048359990119934, -0....   \n",
       "1  [0.40946468710899353, -0.4694342613220215, -0....   \n",
       "2  [0.3307845890522003, -0.531212329864502, -0.79...   \n",
       "3  [0.2711120843887329, -0.33552631735801697, -0....   \n",
       "4  [0.40233278274536133, -0.5556334257125854, -0....   \n",
       "\n",
       "                            embed_Llama3_arg_context  \n",
       "0  [0.49859514832496643, -0.534142255783081, -0.9...  \n",
       "1  [0.40977850556373596, -0.5506035089492798, -0....  \n",
       "2  [0.29485011100769043, -0.5935364365577698, -0....  \n",
       "3  [0.3479368984699249, -0.47894537448883057, -0....  \n",
       "4  [0.3797900080680847, -0.6202806234359741, -0.9...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_w_embeds = dataset_w_embeds.join(pd.Series(embed_Llama3_arg_context, name=\"embed_Llama3_arg_context\"))\n",
    "#dataset_w_embeds.to_parquet(f'{CFG.report_dir}/dataset.embeds.parquet')\n",
    "dataset_w_embeds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [00:39<00:00,  5.16it/s]\n"
     ]
    }
   ],
   "source": [
    "    #what if we don't vary the context:\n",
    "\n",
    "    #for argument context:\n",
    "    embed_Llama3_constant_context: typing.Dict[str, np.ndarray] = {}\n",
    "\n",
    "    name = \"embed_llama3\"\n",
    "    template = 'You help me get embeddings for a sentence. I provide you a with a context and a sentence and you reply only with that exact sentence. Context = '\n",
    "    for index, row in tqdm.tqdm(arguments_df.iterrows(), total=len(arguments_df)):\n",
    "        context = 'viewpoints extracted from tweets'\n",
    "        sentence = row[\"arguments\"]\n",
    "        try: \n",
    "            embed = np.array(requests.post(\n",
    "                'https://inf.cl.uni-trier.de/embed/',\n",
    "                json={'model': MODEL, 'prompt': template + context + '; Sentence: ' + sentence}\n",
    "                ).json()[\"response\"])\n",
    "        except Exception as _e:\n",
    "            logging.warning(_e)\n",
    "            embed = None\n",
    "        \n",
    "        if name=='embed_llama3':\n",
    "            embed_Llama3_constant_context[index] = embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arguments</th>\n",
       "      <th>label</th>\n",
       "      <th>DiffCSE_embedding</th>\n",
       "      <th>embed_llama3</th>\n",
       "      <th>embed_Llama3_arg_context</th>\n",
       "      <th>embed_Llama3_constant_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"Access to affordable healthcare is a fundam...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>[-0.031701505184173584, 0.1383965015411377, -0...</td>\n",
       "      <td>[0.5143977403640747, -0.44048359990119934, -0....</td>\n",
       "      <td>[0.49859514832496643, -0.534142255783081, -0.9...</td>\n",
       "      <td>[0.5910554528236389, -0.5961346626281738, -0.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"The current healthcare system unfairly benef...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>[-0.041136495769023895, 0.11384233832359314, -...</td>\n",
       "      <td>[0.40946468710899353, -0.4694342613220215, -0....</td>\n",
       "      <td>[0.40977850556373596, -0.5506035089492798, -0....</td>\n",
       "      <td>[0.4684109091758728, -0.6994882225990295, -0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"High costs of healthcare create financial bu...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>[0.0036838464438915253, 0.12259957194328308, -...</td>\n",
       "      <td>[0.3307845890522003, -0.531212329864502, -0.79...</td>\n",
       "      <td>[0.29485011100769043, -0.5935364365577698, -0....</td>\n",
       "      <td>[0.4911944568157196, -0.7441452741622925, -0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Pre-existing conditions should not exclude i...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>[0.041562195867300034, 0.14262324571609497, -0...</td>\n",
       "      <td>[0.2711120843887329, -0.33552631735801697, -0....</td>\n",
       "      <td>[0.3479368984699249, -0.47894537448883057, -0....</td>\n",
       "      <td>[0.40695157647132874, -0.6734833121299744, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Universal healthcare would ensure everyone h...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>[0.0069744773209095, 0.1994149088859558, -0.36...</td>\n",
       "      <td>[0.40233278274536133, -0.5556334257125854, -0....</td>\n",
       "      <td>[0.3797900080680847, -0.6202806234359741, -0.9...</td>\n",
       "      <td>[0.48512306809425354, -0.6649637818336487, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           arguments       label  \\\n",
       "0   [\"Access to affordable healthcare is a fundam...  healthcare   \n",
       "1   \"The current healthcare system unfairly benef...  healthcare   \n",
       "2   \"High costs of healthcare create financial bu...  healthcare   \n",
       "3   \"Pre-existing conditions should not exclude i...  healthcare   \n",
       "4   \"Universal healthcare would ensure everyone h...  healthcare   \n",
       "\n",
       "                                   DiffCSE_embedding  \\\n",
       "0  [-0.031701505184173584, 0.1383965015411377, -0...   \n",
       "1  [-0.041136495769023895, 0.11384233832359314, -...   \n",
       "2  [0.0036838464438915253, 0.12259957194328308, -...   \n",
       "3  [0.041562195867300034, 0.14262324571609497, -0...   \n",
       "4  [0.0069744773209095, 0.1994149088859558, -0.36...   \n",
       "\n",
       "                                        embed_llama3  \\\n",
       "0  [0.5143977403640747, -0.44048359990119934, -0....   \n",
       "1  [0.40946468710899353, -0.4694342613220215, -0....   \n",
       "2  [0.3307845890522003, -0.531212329864502, -0.79...   \n",
       "3  [0.2711120843887329, -0.33552631735801697, -0....   \n",
       "4  [0.40233278274536133, -0.5556334257125854, -0....   \n",
       "\n",
       "                            embed_Llama3_arg_context  \\\n",
       "0  [0.49859514832496643, -0.534142255783081, -0.9...   \n",
       "1  [0.40977850556373596, -0.5506035089492798, -0....   \n",
       "2  [0.29485011100769043, -0.5935364365577698, -0....   \n",
       "3  [0.3479368984699249, -0.47894537448883057, -0....   \n",
       "4  [0.3797900080680847, -0.6202806234359741, -0.9...   \n",
       "\n",
       "                       embed_Llama3_constant_context  \n",
       "0  [0.5910554528236389, -0.5961346626281738, -0.7...  \n",
       "1  [0.4684109091758728, -0.6994882225990295, -0.6...  \n",
       "2  [0.4911944568157196, -0.7441452741622925, -0.6...  \n",
       "3  [0.40695157647132874, -0.6734833121299744, -0....  \n",
       "4  [0.48512306809425354, -0.6649637818336487, -0....  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_w_embeds = dataset_w_embeds.join(pd.Series(embed_Llama3_constant_context, name=\"embed_Llama3_constant_context\"))\n",
    "#dataset_w_embeds.to_parquet(f'{CFG.report_dir}/dataset.embeds.parquet')\n",
    "dataset_w_embeds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = dataset_w_embeds.groupby('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "healthcare:healthcare:3.3984666872173945\n",
      "healthcare:ukraine:5.409316422610467\n",
      "ukraine:ukraine:3.5329811240691726\n"
     ]
    }
   ],
   "source": [
    "#for embed_Llama3_arg_context\n",
    "dist = torch.nn.PairwiseDistance()\n",
    "results3: typing.Dict[typing.Tuple[str, str], float] = {}\n",
    "for model_1, c_1 in grouped_data['embed_Llama3_arg_context']:\n",
    "    for model_2, c_2 in grouped_data['embed_Llama3_arg_context']:\n",
    "\n",
    "        if (\n",
    "            (model_1, model_2) in results3.keys() or \n",
    "            (model_2, model_1) in results3.keys()\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        res = sum([\n",
    "            sum(dist(\n",
    "                torch.tensor(np.array(v_1)), \n",
    "                torch.tensor(np.array(c_2.tolist()))\n",
    "                )) / len(c_2)\n",
    "            for v_1 in c_1\n",
    "        ]) / len(c_1)\n",
    "\n",
    "        results3[(model_1, model_2)] = res\n",
    "\n",
    "        print(f'{model_1}:{model_2}:{res.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "healthcare:healthcare:3.1070970643153184\n",
      "healthcare:ukraine:3.8706244450564724\n",
      "ukraine:ukraine:3.188041701467152\n"
     ]
    }
   ],
   "source": [
    "#for embed_Llama3_constant_context\n",
    "dist = torch.nn.PairwiseDistance()\n",
    "results4: typing.Dict[typing.Tuple[str, str], float] = {}\n",
    "for model_1, c_1 in grouped_data['embed_Llama3_constant_context']:\n",
    "    for model_2, c_2 in grouped_data['embed_Llama3_constant_context']:\n",
    "\n",
    "        if (\n",
    "            (model_1, model_2) in results4.keys() or \n",
    "            (model_2, model_1) in results4.keys()\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        res = sum([\n",
    "            sum(dist(\n",
    "                torch.tensor(np.array(v_1)), \n",
    "                torch.tensor(np.array(c_2.tolist()))\n",
    "                )) / len(c_2)\n",
    "            for v_1 in c_1\n",
    "        ]) / len(c_1)\n",
    "\n",
    "        results4[(model_1, model_2)] = res\n",
    "\n",
    "        print(f'{model_1}:{model_2}:{res.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we make the context wording more similar, the difference between topics is smaller\n",
    "if we don't vary context at all, the difference between topics is very much smaller\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Sentences\n",
      "0  The situation remains critical and requires im...\n",
      "1  There is a need for more resources to effectiv...\n",
      "2  Cooperation between different sectors is essen...\n"
     ]
    }
   ],
   "source": [
    "#consider testing the effect of adding irrelevant context to sentences on embedding distances:\n",
    "\n",
    "#prompted chatGPT:can you give me 3 examples of sentences which have the exact same meaning regardless of whether they are used in the context of ukaïne or healthcare?\n",
    "# Define the sentences\n",
    "sentences = [\n",
    "    \"The situation remains critical and requires immediate attention.\",\n",
    "    \"There is a need for more resources to effectively address the challenges.\",\n",
    "    \"Cooperation between different sectors is essential for a successful outcome.\"\n",
    "]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(sentences, columns=['Sentences'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sn/9jbtqthn2j75rm9fpwwfrpbc0000gq/T/ipykernel_1459/2243970526.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df= df.append(df2, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "#prompted Llama3: can you give me 3 examples of sentences which have the exact same meaning regardless of whether they are used in the context of ukaïne or healthcare?\n",
    "\n",
    "sentences = [\n",
    "    \"The situation is getting out of control.\",\n",
    "    \"We need to take immediate action to address this issue.\",\n",
    "    \"The lack of resources is hindering our progress.\"\n",
    "]\n",
    "\n",
    "\n",
    "#Create a dictionary to store the data\n",
    "\n",
    "df2 = pd.DataFrame(sentences, columns=['Sentences'])\n",
    "df= df.append(df2, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The situation remains critical and requires im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There is a need for more resources to effectiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cooperation between different sectors is essen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The situation is getting out of control.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We need to take immediate action to address th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The lack of resources is hindering our progress.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentences\n",
       "0  The situation remains critical and requires im...\n",
       "1  There is a need for more resources to effectiv...\n",
       "2  Cooperation between different sectors is essen...\n",
       "3           The situation is getting out of control.\n",
       "4  We need to take immediate action to address th...\n",
       "5   The lack of resources is hindering our progress."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DefiningDebateQuality",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
