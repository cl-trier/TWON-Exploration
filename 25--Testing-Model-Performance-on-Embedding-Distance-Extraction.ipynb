{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this notebook compares the performance of embeddings extracted by Llama3 models on a sentence similarity task\n",
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import config\n",
    "import typing\n",
    "import logging\n",
    "import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = config.Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at voidism/diffcse-roberta-base-sts were not used when initializing RobertaModel: ['aux_bert.embeddings.LayerNorm.bias', 'aux_bert.embeddings.LayerNorm.weight', 'aux_bert.embeddings.position_embeddings.weight', 'aux_bert.embeddings.position_ids', 'aux_bert.embeddings.token_type_embeddings.weight', 'aux_bert.embeddings.word_embeddings.weight', 'aux_bert.encoder.layer.0.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.0.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.0.attention.output.dense.bias', 'aux_bert.encoder.layer.0.attention.output.dense.weight', 'aux_bert.encoder.layer.0.attention.self.key.bias', 'aux_bert.encoder.layer.0.attention.self.key.weight', 'aux_bert.encoder.layer.0.attention.self.query.bias', 'aux_bert.encoder.layer.0.attention.self.query.weight', 'aux_bert.encoder.layer.0.attention.self.value.bias', 'aux_bert.encoder.layer.0.attention.self.value.weight', 'aux_bert.encoder.layer.0.intermediate.dense.bias', 'aux_bert.encoder.layer.0.intermediate.dense.weight', 'aux_bert.encoder.layer.0.output.LayerNorm.bias', 'aux_bert.encoder.layer.0.output.LayerNorm.weight', 'aux_bert.encoder.layer.0.output.dense.bias', 'aux_bert.encoder.layer.0.output.dense.weight', 'aux_bert.encoder.layer.1.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.1.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.1.attention.output.dense.bias', 'aux_bert.encoder.layer.1.attention.output.dense.weight', 'aux_bert.encoder.layer.1.attention.self.key.bias', 'aux_bert.encoder.layer.1.attention.self.key.weight', 'aux_bert.encoder.layer.1.attention.self.query.bias', 'aux_bert.encoder.layer.1.attention.self.query.weight', 'aux_bert.encoder.layer.1.attention.self.value.bias', 'aux_bert.encoder.layer.1.attention.self.value.weight', 'aux_bert.encoder.layer.1.intermediate.dense.bias', 'aux_bert.encoder.layer.1.intermediate.dense.weight', 'aux_bert.encoder.layer.1.output.LayerNorm.bias', 'aux_bert.encoder.layer.1.output.LayerNorm.weight', 'aux_bert.encoder.layer.1.output.dense.bias', 'aux_bert.encoder.layer.1.output.dense.weight', 'aux_bert.encoder.layer.10.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.10.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.10.attention.output.dense.bias', 'aux_bert.encoder.layer.10.attention.output.dense.weight', 'aux_bert.encoder.layer.10.attention.self.key.bias', 'aux_bert.encoder.layer.10.attention.self.key.weight', 'aux_bert.encoder.layer.10.attention.self.query.bias', 'aux_bert.encoder.layer.10.attention.self.query.weight', 'aux_bert.encoder.layer.10.attention.self.value.bias', 'aux_bert.encoder.layer.10.attention.self.value.weight', 'aux_bert.encoder.layer.10.intermediate.dense.bias', 'aux_bert.encoder.layer.10.intermediate.dense.weight', 'aux_bert.encoder.layer.10.output.LayerNorm.bias', 'aux_bert.encoder.layer.10.output.LayerNorm.weight', 'aux_bert.encoder.layer.10.output.dense.bias', 'aux_bert.encoder.layer.10.output.dense.weight', 'aux_bert.encoder.layer.11.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.11.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.11.attention.output.dense.bias', 'aux_bert.encoder.layer.11.attention.output.dense.weight', 'aux_bert.encoder.layer.11.attention.self.key.bias', 'aux_bert.encoder.layer.11.attention.self.key.weight', 'aux_bert.encoder.layer.11.attention.self.query.bias', 'aux_bert.encoder.layer.11.attention.self.query.weight', 'aux_bert.encoder.layer.11.attention.self.value.bias', 'aux_bert.encoder.layer.11.attention.self.value.weight', 'aux_bert.encoder.layer.11.intermediate.dense.bias', 'aux_bert.encoder.layer.11.intermediate.dense.weight', 'aux_bert.encoder.layer.11.output.LayerNorm.bias', 'aux_bert.encoder.layer.11.output.LayerNorm.weight', 'aux_bert.encoder.layer.11.output.dense.bias', 'aux_bert.encoder.layer.11.output.dense.weight', 'aux_bert.encoder.layer.2.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.2.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.2.attention.output.dense.bias', 'aux_bert.encoder.layer.2.attention.output.dense.weight', 'aux_bert.encoder.layer.2.attention.self.key.bias', 'aux_bert.encoder.layer.2.attention.self.key.weight', 'aux_bert.encoder.layer.2.attention.self.query.bias', 'aux_bert.encoder.layer.2.attention.self.query.weight', 'aux_bert.encoder.layer.2.attention.self.value.bias', 'aux_bert.encoder.layer.2.attention.self.value.weight', 'aux_bert.encoder.layer.2.intermediate.dense.bias', 'aux_bert.encoder.layer.2.intermediate.dense.weight', 'aux_bert.encoder.layer.2.output.LayerNorm.bias', 'aux_bert.encoder.layer.2.output.LayerNorm.weight', 'aux_bert.encoder.layer.2.output.dense.bias', 'aux_bert.encoder.layer.2.output.dense.weight', 'aux_bert.encoder.layer.3.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.3.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.3.attention.output.dense.bias', 'aux_bert.encoder.layer.3.attention.output.dense.weight', 'aux_bert.encoder.layer.3.attention.self.key.bias', 'aux_bert.encoder.layer.3.attention.self.key.weight', 'aux_bert.encoder.layer.3.attention.self.query.bias', 'aux_bert.encoder.layer.3.attention.self.query.weight', 'aux_bert.encoder.layer.3.attention.self.value.bias', 'aux_bert.encoder.layer.3.attention.self.value.weight', 'aux_bert.encoder.layer.3.intermediate.dense.bias', 'aux_bert.encoder.layer.3.intermediate.dense.weight', 'aux_bert.encoder.layer.3.output.LayerNorm.bias', 'aux_bert.encoder.layer.3.output.LayerNorm.weight', 'aux_bert.encoder.layer.3.output.dense.bias', 'aux_bert.encoder.layer.3.output.dense.weight', 'aux_bert.encoder.layer.4.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.4.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.4.attention.output.dense.bias', 'aux_bert.encoder.layer.4.attention.output.dense.weight', 'aux_bert.encoder.layer.4.attention.self.key.bias', 'aux_bert.encoder.layer.4.attention.self.key.weight', 'aux_bert.encoder.layer.4.attention.self.query.bias', 'aux_bert.encoder.layer.4.attention.self.query.weight', 'aux_bert.encoder.layer.4.attention.self.value.bias', 'aux_bert.encoder.layer.4.attention.self.value.weight', 'aux_bert.encoder.layer.4.intermediate.dense.bias', 'aux_bert.encoder.layer.4.intermediate.dense.weight', 'aux_bert.encoder.layer.4.output.LayerNorm.bias', 'aux_bert.encoder.layer.4.output.LayerNorm.weight', 'aux_bert.encoder.layer.4.output.dense.bias', 'aux_bert.encoder.layer.4.output.dense.weight', 'aux_bert.encoder.layer.5.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.5.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.5.attention.output.dense.bias', 'aux_bert.encoder.layer.5.attention.output.dense.weight', 'aux_bert.encoder.layer.5.attention.self.key.bias', 'aux_bert.encoder.layer.5.attention.self.key.weight', 'aux_bert.encoder.layer.5.attention.self.query.bias', 'aux_bert.encoder.layer.5.attention.self.query.weight', 'aux_bert.encoder.layer.5.attention.self.value.bias', 'aux_bert.encoder.layer.5.attention.self.value.weight', 'aux_bert.encoder.layer.5.intermediate.dense.bias', 'aux_bert.encoder.layer.5.intermediate.dense.weight', 'aux_bert.encoder.layer.5.output.LayerNorm.bias', 'aux_bert.encoder.layer.5.output.LayerNorm.weight', 'aux_bert.encoder.layer.5.output.dense.bias', 'aux_bert.encoder.layer.5.output.dense.weight', 'aux_bert.encoder.layer.6.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.6.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.6.attention.output.dense.bias', 'aux_bert.encoder.layer.6.attention.output.dense.weight', 'aux_bert.encoder.layer.6.attention.self.key.bias', 'aux_bert.encoder.layer.6.attention.self.key.weight', 'aux_bert.encoder.layer.6.attention.self.query.bias', 'aux_bert.encoder.layer.6.attention.self.query.weight', 'aux_bert.encoder.layer.6.attention.self.value.bias', 'aux_bert.encoder.layer.6.attention.self.value.weight', 'aux_bert.encoder.layer.6.intermediate.dense.bias', 'aux_bert.encoder.layer.6.intermediate.dense.weight', 'aux_bert.encoder.layer.6.output.LayerNorm.bias', 'aux_bert.encoder.layer.6.output.LayerNorm.weight', 'aux_bert.encoder.layer.6.output.dense.bias', 'aux_bert.encoder.layer.6.output.dense.weight', 'aux_bert.encoder.layer.7.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.7.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.7.attention.output.dense.bias', 'aux_bert.encoder.layer.7.attention.output.dense.weight', 'aux_bert.encoder.layer.7.attention.self.key.bias', 'aux_bert.encoder.layer.7.attention.self.key.weight', 'aux_bert.encoder.layer.7.attention.self.query.bias', 'aux_bert.encoder.layer.7.attention.self.query.weight', 'aux_bert.encoder.layer.7.attention.self.value.bias', 'aux_bert.encoder.layer.7.attention.self.value.weight', 'aux_bert.encoder.layer.7.intermediate.dense.bias', 'aux_bert.encoder.layer.7.intermediate.dense.weight', 'aux_bert.encoder.layer.7.output.LayerNorm.bias', 'aux_bert.encoder.layer.7.output.LayerNorm.weight', 'aux_bert.encoder.layer.7.output.dense.bias', 'aux_bert.encoder.layer.7.output.dense.weight', 'aux_bert.encoder.layer.8.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.8.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.8.attention.output.dense.bias', 'aux_bert.encoder.layer.8.attention.output.dense.weight', 'aux_bert.encoder.layer.8.attention.self.key.bias', 'aux_bert.encoder.layer.8.attention.self.key.weight', 'aux_bert.encoder.layer.8.attention.self.query.bias', 'aux_bert.encoder.layer.8.attention.self.query.weight', 'aux_bert.encoder.layer.8.attention.self.value.bias', 'aux_bert.encoder.layer.8.attention.self.value.weight', 'aux_bert.encoder.layer.8.intermediate.dense.bias', 'aux_bert.encoder.layer.8.intermediate.dense.weight', 'aux_bert.encoder.layer.8.output.LayerNorm.bias', 'aux_bert.encoder.layer.8.output.LayerNorm.weight', 'aux_bert.encoder.layer.8.output.dense.bias', 'aux_bert.encoder.layer.8.output.dense.weight', 'aux_bert.encoder.layer.9.attention.output.LayerNorm.bias', 'aux_bert.encoder.layer.9.attention.output.LayerNorm.weight', 'aux_bert.encoder.layer.9.attention.output.dense.bias', 'aux_bert.encoder.layer.9.attention.output.dense.weight', 'aux_bert.encoder.layer.9.attention.self.key.bias', 'aux_bert.encoder.layer.9.attention.self.key.weight', 'aux_bert.encoder.layer.9.attention.self.query.bias', 'aux_bert.encoder.layer.9.attention.self.query.weight', 'aux_bert.encoder.layer.9.attention.self.value.bias', 'aux_bert.encoder.layer.9.attention.self.value.weight', 'aux_bert.encoder.layer.9.intermediate.dense.bias', 'aux_bert.encoder.layer.9.intermediate.dense.weight', 'aux_bert.encoder.layer.9.output.LayerNorm.bias', 'aux_bert.encoder.layer.9.output.LayerNorm.weight', 'aux_bert.encoder.layer.9.output.dense.bias', 'aux_bert.encoder.layer.9.output.dense.weight', 'generator.lm_head.bias', 'generator.lm_head.decoder.bias', 'generator.lm_head.decoder.weight', 'generator.lm_head.dense.bias', 'generator.lm_head.dense.weight', 'generator.lm_head.layer_norm.bias', 'generator.lm_head.layer_norm.weight', 'generator.roberta.embeddings.LayerNorm.bias', 'generator.roberta.embeddings.LayerNorm.weight', 'generator.roberta.embeddings.position_embeddings.weight', 'generator.roberta.embeddings.position_ids', 'generator.roberta.embeddings.token_type_embeddings.weight', 'generator.roberta.embeddings.word_embeddings.weight', 'generator.roberta.encoder.layer.0.attention.output.LayerNorm.bias', 'generator.roberta.encoder.layer.0.attention.output.LayerNorm.weight', 'generator.roberta.encoder.layer.0.attention.output.dense.bias', 'generator.roberta.encoder.layer.0.attention.output.dense.weight', 'generator.roberta.encoder.layer.0.attention.self.key.bias', 'generator.roberta.encoder.layer.0.attention.self.key.weight', 'generator.roberta.encoder.layer.0.attention.self.query.bias', 'generator.roberta.encoder.layer.0.attention.self.query.weight', 'generator.roberta.encoder.layer.0.attention.self.value.bias', 'generator.roberta.encoder.layer.0.attention.self.value.weight', 'generator.roberta.encoder.layer.0.intermediate.dense.bias', 'generator.roberta.encoder.layer.0.intermediate.dense.weight', 'generator.roberta.encoder.layer.0.output.LayerNorm.bias', 'generator.roberta.encoder.layer.0.output.LayerNorm.weight', 'generator.roberta.encoder.layer.0.output.dense.bias', 'generator.roberta.encoder.layer.0.output.dense.weight', 'generator.roberta.encoder.layer.1.attention.output.LayerNorm.bias', 'generator.roberta.encoder.layer.1.attention.output.LayerNorm.weight', 'generator.roberta.encoder.layer.1.attention.output.dense.bias', 'generator.roberta.encoder.layer.1.attention.output.dense.weight', 'generator.roberta.encoder.layer.1.attention.self.key.bias', 'generator.roberta.encoder.layer.1.attention.self.key.weight', 'generator.roberta.encoder.layer.1.attention.self.query.bias', 'generator.roberta.encoder.layer.1.attention.self.query.weight', 'generator.roberta.encoder.layer.1.attention.self.value.bias', 'generator.roberta.encoder.layer.1.attention.self.value.weight', 'generator.roberta.encoder.layer.1.intermediate.dense.bias', 'generator.roberta.encoder.layer.1.intermediate.dense.weight', 'generator.roberta.encoder.layer.1.output.LayerNorm.bias', 'generator.roberta.encoder.layer.1.output.LayerNorm.weight', 'generator.roberta.encoder.layer.1.output.dense.bias', 'generator.roberta.encoder.layer.1.output.dense.weight', 'generator.roberta.encoder.layer.2.attention.output.LayerNorm.bias', 'generator.roberta.encoder.layer.2.attention.output.LayerNorm.weight', 'generator.roberta.encoder.layer.2.attention.output.dense.bias', 'generator.roberta.encoder.layer.2.attention.output.dense.weight', 'generator.roberta.encoder.layer.2.attention.self.key.bias', 'generator.roberta.encoder.layer.2.attention.self.key.weight', 'generator.roberta.encoder.layer.2.attention.self.query.bias', 'generator.roberta.encoder.layer.2.attention.self.query.weight', 'generator.roberta.encoder.layer.2.attention.self.value.bias', 'generator.roberta.encoder.layer.2.attention.self.value.weight', 'generator.roberta.encoder.layer.2.intermediate.dense.bias', 'generator.roberta.encoder.layer.2.intermediate.dense.weight', 'generator.roberta.encoder.layer.2.output.LayerNorm.bias', 'generator.roberta.encoder.layer.2.output.LayerNorm.weight', 'generator.roberta.encoder.layer.2.output.dense.bias', 'generator.roberta.encoder.layer.2.output.dense.weight', 'generator.roberta.encoder.layer.3.attention.output.LayerNorm.bias', 'generator.roberta.encoder.layer.3.attention.output.LayerNorm.weight', 'generator.roberta.encoder.layer.3.attention.output.dense.bias', 'generator.roberta.encoder.layer.3.attention.output.dense.weight', 'generator.roberta.encoder.layer.3.attention.self.key.bias', 'generator.roberta.encoder.layer.3.attention.self.key.weight', 'generator.roberta.encoder.layer.3.attention.self.query.bias', 'generator.roberta.encoder.layer.3.attention.self.query.weight', 'generator.roberta.encoder.layer.3.attention.self.value.bias', 'generator.roberta.encoder.layer.3.attention.self.value.weight', 'generator.roberta.encoder.layer.3.intermediate.dense.bias', 'generator.roberta.encoder.layer.3.intermediate.dense.weight', 'generator.roberta.encoder.layer.3.output.LayerNorm.bias', 'generator.roberta.encoder.layer.3.output.LayerNorm.weight', 'generator.roberta.encoder.layer.3.output.dense.bias', 'generator.roberta.encoder.layer.3.output.dense.weight', 'generator.roberta.encoder.layer.4.attention.output.LayerNorm.bias', 'generator.roberta.encoder.layer.4.attention.output.LayerNorm.weight', 'generator.roberta.encoder.layer.4.attention.output.dense.bias', 'generator.roberta.encoder.layer.4.attention.output.dense.weight', 'generator.roberta.encoder.layer.4.attention.self.key.bias', 'generator.roberta.encoder.layer.4.attention.self.key.weight', 'generator.roberta.encoder.layer.4.attention.self.query.bias', 'generator.roberta.encoder.layer.4.attention.self.query.weight', 'generator.roberta.encoder.layer.4.attention.self.value.bias', 'generator.roberta.encoder.layer.4.attention.self.value.weight', 'generator.roberta.encoder.layer.4.intermediate.dense.bias', 'generator.roberta.encoder.layer.4.intermediate.dense.weight', 'generator.roberta.encoder.layer.4.output.LayerNorm.bias', 'generator.roberta.encoder.layer.4.output.LayerNorm.weight', 'generator.roberta.encoder.layer.4.output.dense.bias', 'generator.roberta.encoder.layer.4.output.dense.weight', 'generator.roberta.encoder.layer.5.attention.output.LayerNorm.bias', 'generator.roberta.encoder.layer.5.attention.output.LayerNorm.weight', 'generator.roberta.encoder.layer.5.attention.output.dense.bias', 'generator.roberta.encoder.layer.5.attention.output.dense.weight', 'generator.roberta.encoder.layer.5.attention.self.key.bias', 'generator.roberta.encoder.layer.5.attention.self.key.weight', 'generator.roberta.encoder.layer.5.attention.self.query.bias', 'generator.roberta.encoder.layer.5.attention.self.query.weight', 'generator.roberta.encoder.layer.5.attention.self.value.bias', 'generator.roberta.encoder.layer.5.attention.self.value.weight', 'generator.roberta.encoder.layer.5.intermediate.dense.bias', 'generator.roberta.encoder.layer.5.intermediate.dense.weight', 'generator.roberta.encoder.layer.5.output.LayerNorm.bias', 'generator.roberta.encoder.layer.5.output.LayerNorm.weight', 'generator.roberta.encoder.layer.5.output.dense.bias', 'generator.roberta.encoder.layer.5.output.dense.weight', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'mlp.net.0.weight', 'mlp.net.1.bias', 'mlp.net.1.num_batches_tracked', 'mlp.net.1.running_mean', 'mlp.net.1.running_var', 'mlp.net.1.weight', 'mlp.net.3.weight', 'mlp.net.4.num_batches_tracked', 'mlp.net.4.running_mean', 'mlp.net.4.running_var']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at voidism/diffcse-roberta-base-sts and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#first calculate DiffCSE embeddings:\n",
    "model_name = \"voidism/diffcse-roberta-base-sts\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first try procedure on extracted topic argument sets from simulation data COMPTEXT24:\n",
    "LANGUAGE: str = 'English'\n",
    "GROUPER: str = 'topic'\n",
    "ARG_DIR: str = 'data/arguments'\n",
    "MODEL: str = \"llama3:70b-instruct-q6_K\" # \"mixtral:8x7b-instruct-v0.1-q6_K\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for encoding sentence embeddings based on the DiffCSE approach which is based on (and refers to) SimCSE/evaluation.py \n",
    "def DiffCSE_encode_argument(sentence):\n",
    "    input_ids = tokenizer.encode(sentence, add_special_tokens=True, truncation=True, max_length=512, padding='max_length')\n",
    "    input_ids_tensor = torch.tensor(input_ids).unsqueeze(0)  # Add batch dimension\n",
    "    attention_mask = torch.ones_like(input_ids_tensor)  # Creating attention mask \n",
    "    with torch.no_grad():\n",
    "            outputs = model(input_ids_tensor, output_hidden_states=True, return_dict=True, attention_mask=attention_mask)\n",
    "            argument_embedding = outputs.last_hidden_state[:, 0].cpu()\n",
    "            return argument_embedding.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the arguments from the .parquet file\n",
    "arguments_df = pd.read_parquet(f\"{ARG_DIR}/arguments.by.{GROUPER}.{LANGUAGE}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arguments</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"Access to affordable healthcare is a fundam...</td>\n",
       "      <td>healthcare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"The current healthcare system unfairly benef...</td>\n",
       "      <td>healthcare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"High costs of healthcare create financial bu...</td>\n",
       "      <td>healthcare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Pre-existing conditions should not exclude i...</td>\n",
       "      <td>healthcare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Universal healthcare would ensure everyone h...</td>\n",
       "      <td>healthcare</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           arguments       label\n",
       "0   [\"Access to affordable healthcare is a fundam...  healthcare\n",
       "1   \"The current healthcare system unfairly benef...  healthcare\n",
       "2   \"High costs of healthcare create financial bu...  healthcare\n",
       "3   \"Pre-existing conditions should not exclude i...  healthcare\n",
       "4   \"Universal healthcare would ensure everyone h...  healthcare"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arguments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for DiffCSE: Create embeddings for each argument and store them in a new column\n",
    "arguments_df.loc[:, 'DiffCSE_embedding'] = arguments_df[\"arguments\"].apply(DiffCSE_encode_argument)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for Llama3:\n",
    "embed_Llama3: typing.Dict[str, np.ndarray] = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [00:54<00:00,  3.77it/s]\n"
     ]
    }
   ],
   "source": [
    "    name = \"embed_llama3\"\n",
    "    template = 'You help me get embeddings for a sentence. I provide you a with a context and a sentence and you reply only with that exact sentence. Context = '\n",
    "    for index, row in tqdm.tqdm(arguments_df.iterrows(), total=len(arguments_df)):\n",
    "        context = row[\"label\"]\n",
    "        sentence = row[\"arguments\"]\n",
    "        try: \n",
    "            embed = np.array(requests.post(\n",
    "                'https://inf.cl.uni-trier.de/embed/',\n",
    "                json={'model': MODEL, 'prompt': template + context + '; Sentence: ' + sentence}\n",
    "                ).json()[\"response\"])\n",
    "        except Exception as _e:\n",
    "            logging.warning(_e)\n",
    "            embed = None\n",
    "        \n",
    "        if name=='embed_llama3':\n",
    "            embed_Llama3[index] = embed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arguments</th>\n",
       "      <th>label</th>\n",
       "      <th>embed_llama3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"Access to affordable healthcare is a fundam...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>[0.5143977403640747, -0.44048359990119934, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"The current healthcare system unfairly benef...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>[0.40946468710899353, -0.4694342613220215, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"High costs of healthcare create financial bu...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>[0.3307845890522003, -0.531212329864502, -0.79...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Pre-existing conditions should not exclude i...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>[0.2711120843887329, -0.33552631735801697, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Universal healthcare would ensure everyone h...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>[0.40233278274536133, -0.5556334257125854, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           arguments       label  \\\n",
       "0   [\"Access to affordable healthcare is a fundam...  healthcare   \n",
       "1   \"The current healthcare system unfairly benef...  healthcare   \n",
       "2   \"High costs of healthcare create financial bu...  healthcare   \n",
       "3   \"Pre-existing conditions should not exclude i...  healthcare   \n",
       "4   \"Universal healthcare would ensure everyone h...  healthcare   \n",
       "\n",
       "                                        embed_llama3  \n",
       "0  [0.5143977403640747, -0.44048359990119934, -0....  \n",
       "1  [0.40946468710899353, -0.4694342613220215, -0....  \n",
       "2  [0.3307845890522003, -0.531212329864502, -0.79...  \n",
       "3  [0.2711120843887329, -0.33552631735801697, -0....  \n",
       "4  [0.40233278274536133, -0.5556334257125854, -0....  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_w_embeds = arguments_df.join(pd.Series(embed_Llama3, name=\"embed_llama3\"))\n",
    "#dataset_w_embeds.to_parquet(f'{CFG.report_dir}/dataset.embeds.parquet')\n",
    "dataset_w_embeds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape embeddings to single dimension:\n",
    "dataset_w_embeds['DiffCSE_embedding'] = dataset_w_embeds['DiffCSE_embedding'].apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = dataset_w_embeds.groupby('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "results: typing.Dict[typing.Tuple[str, str], float] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "healthcare:healthcare:3.512138113613706\n",
      "healthcare:ukraine:4.4383741450897745\n",
      "ukraine:ukraine:4.4135212572020945\n"
     ]
    }
   ],
   "source": [
    "#for DiffCSE:\n",
    "dist = torch.nn.PairwiseDistance()\n",
    "\n",
    "for model_1, c_1 in grouped_data['DiffCSE_embedding']:\n",
    "    for model_2, c_2 in grouped_data['DiffCSE_embedding']:\n",
    "\n",
    "        if (\n",
    "            (model_1, model_2) in results.keys() or \n",
    "            (model_2, model_1) in results.keys()\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        res = sum([\n",
    "            sum(dist(\n",
    "                torch.tensor(np.array(v_1)), \n",
    "                torch.tensor(np.array(c_2.tolist()))\n",
    "                )) / len(c_2)\n",
    "            for v_1 in c_1\n",
    "        ]) / len(c_1)\n",
    "\n",
    "        results[(model_1, model_2)] = res\n",
    "\n",
    "        print(f'{model_1}:{model_2}:{res.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "healthcare:healthcare:3.8460111482448824\n",
      "healthcare:ukraine:7.980850266694351\n",
      "ukraine:ukraine:3.7148092856659054\n"
     ]
    }
   ],
   "source": [
    "#for Llama3\n",
    "dist = torch.nn.PairwiseDistance()\n",
    "results2: typing.Dict[typing.Tuple[str, str], float] = {}\n",
    "for model_1, c_1 in grouped_data['embed_llama3']:\n",
    "    for model_2, c_2 in grouped_data['embed_llama3']:\n",
    "\n",
    "        if (\n",
    "            (model_1, model_2) in results2.keys() or \n",
    "            (model_2, model_1) in results2.keys()\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        res = sum([\n",
    "            sum(dist(\n",
    "                torch.tensor(np.array(v_1)), \n",
    "                torch.tensor(np.array(c_2.tolist()))\n",
    "                )) / len(c_2)\n",
    "            for v_1 in c_1\n",
    "        ]) / len(c_1)\n",
    "\n",
    "        results2[(model_1, model_2)] = res\n",
    "\n",
    "        print(f'{model_1}:{model_2}:{res.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "clearly adding context to Llama3 embeddings differentiates the arguments considerably, but this could be due to the embedding extraction overly relying on the context... what if the arguments had a similar context? If we compare the diversity of all healthcare arguments to all ukraine arguments there is hardly any difference, while the DiffCSE embeddings found a larger diversity amond ukraine arguments than among healthcare arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [00:45<00:00,  4.53it/s]\n"
     ]
    }
   ],
   "source": [
    "#what if we change the context:\n",
    "\n",
    "#for argument context:\n",
    "embed_Llama3_arg_context: typing.Dict[str, np.ndarray] = {}\n",
    "\n",
    "name = \"embed_llama3\"\n",
    "template = 'You help me get embeddings for a sentence. I provide you a with a context within []-square brackets and a sentence within <>-chevrons and you reply only with that exact sentence marked with the chevrons. Context = ['\n",
    "for index, row in tqdm.tqdm(arguments_df.iterrows(), total=len(arguments_df)):\n",
    "    context = 'arguments about ' + row[\"label\"]\n",
    "    sentence = row[\"arguments\"]\n",
    "    try: \n",
    "        embed = np.array(requests.post(\n",
    "            'https://inf.cl.uni-trier.de/embed/',\n",
    "            json={'model': MODEL, 'prompt': template + context + ']; Sentence: <' + sentence + '>'}\n",
    "            ).json()[\"response\"])\n",
    "    except Exception as _e:\n",
    "        logging.warning(_e)\n",
    "        embed = None\n",
    "    \n",
    "    if name=='embed_llama3':\n",
    "        embed_Llama3_arg_context[index] = embed\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arguments</th>\n",
       "      <th>label</th>\n",
       "      <th>embed_llama3</th>\n",
       "      <th>embed_Llama3_arg_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"Access to affordable healthcare is a fundam...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>[0.5143977403640747, -0.44048359990119934, -0....</td>\n",
       "      <td>[0.4892446994781494, -0.565439760684967, -0.88...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"The current healthcare system unfairly benef...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>[0.40946468710899353, -0.4694342613220215, -0....</td>\n",
       "      <td>[0.5180896520614624, -0.5761647820472717, -0.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"High costs of healthcare create financial bu...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>[0.3307845890522003, -0.531212329864502, -0.79...</td>\n",
       "      <td>[0.41686248779296875, -0.5384894013404846, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Pre-existing conditions should not exclude i...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>[0.2711120843887329, -0.33552631735801697, -0....</td>\n",
       "      <td>[0.5203405618667603, -0.5485878586769104, -0.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Universal healthcare would ensure everyone h...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>[0.40233278274536133, -0.5556334257125854, -0....</td>\n",
       "      <td>[0.48462989926338196, -0.5576851963996887, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           arguments       label  \\\n",
       "0   [\"Access to affordable healthcare is a fundam...  healthcare   \n",
       "1   \"The current healthcare system unfairly benef...  healthcare   \n",
       "2   \"High costs of healthcare create financial bu...  healthcare   \n",
       "3   \"Pre-existing conditions should not exclude i...  healthcare   \n",
       "4   \"Universal healthcare would ensure everyone h...  healthcare   \n",
       "\n",
       "                                        embed_llama3  \\\n",
       "0  [0.5143977403640747, -0.44048359990119934, -0....   \n",
       "1  [0.40946468710899353, -0.4694342613220215, -0....   \n",
       "2  [0.3307845890522003, -0.531212329864502, -0.79...   \n",
       "3  [0.2711120843887329, -0.33552631735801697, -0....   \n",
       "4  [0.40233278274536133, -0.5556334257125854, -0....   \n",
       "\n",
       "                            embed_Llama3_arg_context  \n",
       "0  [0.4892446994781494, -0.565439760684967, -0.88...  \n",
       "1  [0.5180896520614624, -0.5761647820472717, -0.9...  \n",
       "2  [0.41686248779296875, -0.5384894013404846, -0....  \n",
       "3  [0.5203405618667603, -0.5485878586769104, -0.7...  \n",
       "4  [0.48462989926338196, -0.5576851963996887, -0....  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_w_embeds = dataset_w_embeds.join(pd.Series(embed_Llama3_arg_context, name=\"embed_Llama3_arg_context\"))\n",
    "#dataset_w_embeds.to_parquet(f'{CFG.report_dir}/dataset.embeds.parquet')\n",
    "dataset_w_embeds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 206/206 [00:49<00:00,  4.19it/s]\n"
     ]
    }
   ],
   "source": [
    "    #what if we don't vary the context:\n",
    "\n",
    "    #for argument context:\n",
    "    embed_Llama3_constant_context: typing.Dict[str, np.ndarray] = {}\n",
    "\n",
    "    name = \"embed_llama3\"\n",
    "    template = 'You help me get embeddings for a sentence. I provide you a with a context within []-square brackets and a sentence within <>-chevrons and you reply only with that exact sentence marked with the chevrons. Context = ['\n",
    "    for index, row in tqdm.tqdm(arguments_df.iterrows(), total=len(arguments_df)):\n",
    "        context = 'viewpoints extracted from tweets'\n",
    "        sentence = row[\"arguments\"]\n",
    "        try: \n",
    "            embed = np.array(requests.post(\n",
    "                'https://inf.cl.uni-trier.de/embed/',\n",
    "                json={'model': MODEL, 'prompt': template + context + ']; Sentence: <' + sentence + '>'}\n",
    "                ).json()[\"response\"])\n",
    "        except Exception as _e:\n",
    "            logging.warning(_e)\n",
    "            embed = None\n",
    "        \n",
    "        if name=='embed_llama3':\n",
    "            embed_Llama3_constant_context[index] = embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arguments</th>\n",
       "      <th>label</th>\n",
       "      <th>embed_llama3</th>\n",
       "      <th>embed_Llama3_arg_context</th>\n",
       "      <th>embed_Llama3_constant_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"Access to affordable healthcare is a fundam...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>[0.5143977403640747, -0.44048359990119934, -0....</td>\n",
       "      <td>[0.4892446994781494, -0.565439760684967, -0.88...</td>\n",
       "      <td>[0.4609181880950928, -0.5663681626319885, -0.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"The current healthcare system unfairly benef...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>[0.40946468710899353, -0.4694342613220215, -0....</td>\n",
       "      <td>[0.5180896520614624, -0.5761647820472717, -0.9...</td>\n",
       "      <td>[0.5193580985069275, -0.5377117991447449, -0.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"High costs of healthcare create financial bu...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>[0.3307845890522003, -0.531212329864502, -0.79...</td>\n",
       "      <td>[0.41686248779296875, -0.5384894013404846, -0....</td>\n",
       "      <td>[0.46159040927886963, -0.5081135630607605, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Pre-existing conditions should not exclude i...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>[0.2711120843887329, -0.33552631735801697, -0....</td>\n",
       "      <td>[0.5203405618667603, -0.5485878586769104, -0.7...</td>\n",
       "      <td>[0.47894448041915894, -0.4845818877220154, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Universal healthcare would ensure everyone h...</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>[0.40233278274536133, -0.5556334257125854, -0....</td>\n",
       "      <td>[0.48462989926338196, -0.5576851963996887, -0....</td>\n",
       "      <td>[0.4409814178943634, -0.5037068724632263, -0.8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           arguments       label  \\\n",
       "0   [\"Access to affordable healthcare is a fundam...  healthcare   \n",
       "1   \"The current healthcare system unfairly benef...  healthcare   \n",
       "2   \"High costs of healthcare create financial bu...  healthcare   \n",
       "3   \"Pre-existing conditions should not exclude i...  healthcare   \n",
       "4   \"Universal healthcare would ensure everyone h...  healthcare   \n",
       "\n",
       "                                        embed_llama3  \\\n",
       "0  [0.5143977403640747, -0.44048359990119934, -0....   \n",
       "1  [0.40946468710899353, -0.4694342613220215, -0....   \n",
       "2  [0.3307845890522003, -0.531212329864502, -0.79...   \n",
       "3  [0.2711120843887329, -0.33552631735801697, -0....   \n",
       "4  [0.40233278274536133, -0.5556334257125854, -0....   \n",
       "\n",
       "                            embed_Llama3_arg_context  \\\n",
       "0  [0.4892446994781494, -0.565439760684967, -0.88...   \n",
       "1  [0.5180896520614624, -0.5761647820472717, -0.9...   \n",
       "2  [0.41686248779296875, -0.5384894013404846, -0....   \n",
       "3  [0.5203405618667603, -0.5485878586769104, -0.7...   \n",
       "4  [0.48462989926338196, -0.5576851963996887, -0....   \n",
       "\n",
       "                       embed_Llama3_constant_context  \n",
       "0  [0.4609181880950928, -0.5663681626319885, -0.7...  \n",
       "1  [0.5193580985069275, -0.5377117991447449, -0.8...  \n",
       "2  [0.46159040927886963, -0.5081135630607605, -0....  \n",
       "3  [0.47894448041915894, -0.4845818877220154, -0....  \n",
       "4  [0.4409814178943634, -0.5037068724632263, -0.8...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_w_embeds = dataset_w_embeds.join(pd.Series(embed_Llama3_constant_context, name=\"embed_Llama3_constant_context\"))\n",
    "#dataset_w_embeds.to_parquet(f'{CFG.report_dir}/dataset.embeds.parquet')\n",
    "dataset_w_embeds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = dataset_w_embeds.groupby('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "healthcare:healthcare:2.2894640520120406\n",
      "healthcare:ukraine:3.9211152842021\n",
      "ukraine:ukraine:2.4995592026647424\n"
     ]
    }
   ],
   "source": [
    "#for embed_Llama3_arg_context\n",
    "dist = torch.nn.PairwiseDistance()\n",
    "results3: typing.Dict[typing.Tuple[str, str], float] = {}\n",
    "for model_1, c_1 in grouped_data['embed_Llama3_arg_context']:\n",
    "    for model_2, c_2 in grouped_data['embed_Llama3_arg_context']:\n",
    "\n",
    "        if (\n",
    "            (model_1, model_2) in results3.keys() or \n",
    "            (model_2, model_1) in results3.keys()\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        res = sum([\n",
    "            sum(dist(\n",
    "                torch.tensor(np.array(v_1)), \n",
    "                torch.tensor(np.array(c_2.tolist()))\n",
    "                )) / len(c_2)\n",
    "            for v_1 in c_1\n",
    "        ]) / len(c_1)\n",
    "\n",
    "        results3[(model_1, model_2)] = res\n",
    "\n",
    "        print(f'{model_1}:{model_2}:{res.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "healthcare:healthcare:2.475380458318616\n",
      "healthcare:ukraine:3.087622781475221\n",
      "ukraine:ukraine:2.7385416234923095\n"
     ]
    }
   ],
   "source": [
    "#for embed_Llama3_constant_context\n",
    "dist = torch.nn.PairwiseDistance()\n",
    "results4: typing.Dict[typing.Tuple[str, str], float] = {}\n",
    "for model_1, c_1 in grouped_data['embed_Llama3_constant_context']:\n",
    "    for model_2, c_2 in grouped_data['embed_Llama3_constant_context']:\n",
    "\n",
    "        if (\n",
    "            (model_1, model_2) in results4.keys() or \n",
    "            (model_2, model_1) in results4.keys()\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        res = sum([\n",
    "            sum(dist(\n",
    "                torch.tensor(np.array(v_1)), \n",
    "                torch.tensor(np.array(c_2.tolist()))\n",
    "                )) / len(c_2)\n",
    "            for v_1 in c_1\n",
    "        ]) / len(c_1)\n",
    "\n",
    "        results4[(model_1, model_2)] = res\n",
    "\n",
    "        print(f'{model_1}:{model_2}:{res.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we make the context wording more similar, the difference between topics is smaller\n",
    "if we don't vary context at all, the difference between topics is very much smaller\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prudent way is to use Llama3 but with constant context\n",
    "#what would results look like for retrieved source?\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Sentences\n",
      "0  The situation remains critical and requires im...\n",
      "1  There is a need for more resources to effectiv...\n",
      "2  Cooperation between different sectors is essen...\n"
     ]
    }
   ],
   "source": [
    "#consider testing the effect of adding irrelevant context to sentences on embedding distances:\n",
    "\n",
    "#prompted chatGPT:can you give me 3 examples of sentences which have the exact same meaning regardless of whether they are used in the context of ukaïne or healthcare?\n",
    "# Define the sentences\n",
    "sentences = [\n",
    "    \"The situation remains critical and requires immediate attention.\",\n",
    "    \"There is a need for more resources to effectively address the challenges.\",\n",
    "    \"Cooperation between different sectors is essential for a successful outcome.\"\n",
    "]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(sentences, columns=['Sentences'])\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sn/9jbtqthn2j75rm9fpwwfrpbc0000gq/T/ipykernel_7118/2243970526.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df= df.append(df2, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "#prompted Llama3: can you give me 3 examples of sentences which have the exact same meaning regardless of whether they are used in the context of ukaïne or healthcare?\n",
    "\n",
    "sentences = [\n",
    "    \"The situation is getting out of control.\",\n",
    "    \"We need to take immediate action to address this issue.\",\n",
    "    \"The lack of resources is hindering our progress.\"\n",
    "]\n",
    "\n",
    "\n",
    "#Create a dictionary to store the data\n",
    "\n",
    "df2 = pd.DataFrame(sentences, columns=['Sentences'])\n",
    "df= df.append(df2, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sn/9jbtqthn2j75rm9fpwwfrpbc0000gq/T/ipykernel_7118/2343642554.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(df, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "#duplicate df\n",
    "df = df.append(df, ignore_index=True)\n",
    "#add irrelevant context\n",
    "context =[\"ukraine\", \"ukraine\", \"ukraine\", \"ukraine\", \"ukraine\", \"ukraine\", \"healthcare\", \"healthcare\", \"healthcare\", \"healthcare\", \"healthcare\", \"healthcare\"]\n",
    "\n",
    "df[\"context\"] = context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The situation remains critical and requires im...</td>\n",
       "      <td>ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There is a need for more resources to effectiv...</td>\n",
       "      <td>ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cooperation between different sectors is essen...</td>\n",
       "      <td>ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The situation is getting out of control.</td>\n",
       "      <td>ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We need to take immediate action to address th...</td>\n",
       "      <td>ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The lack of resources is hindering our progress.</td>\n",
       "      <td>ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The situation remains critical and requires im...</td>\n",
       "      <td>healthcare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>There is a need for more resources to effectiv...</td>\n",
       "      <td>healthcare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cooperation between different sectors is essen...</td>\n",
       "      <td>healthcare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The situation is getting out of control.</td>\n",
       "      <td>healthcare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>We need to take immediate action to address th...</td>\n",
       "      <td>healthcare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The lack of resources is hindering our progress.</td>\n",
       "      <td>healthcare</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentences     context\n",
       "0   The situation remains critical and requires im...     ukraine\n",
       "1   There is a need for more resources to effectiv...     ukraine\n",
       "2   Cooperation between different sectors is essen...     ukraine\n",
       "3            The situation is getting out of control.     ukraine\n",
       "4   We need to take immediate action to address th...     ukraine\n",
       "5    The lack of resources is hindering our progress.     ukraine\n",
       "6   The situation remains critical and requires im...  healthcare\n",
       "7   There is a need for more resources to effectiv...  healthcare\n",
       "8   Cooperation between different sectors is essen...  healthcare\n",
       "9            The situation is getting out of control.  healthcare\n",
       "10  We need to take immediate action to address th...  healthcare\n",
       "11   The lack of resources is hindering our progress.  healthcare"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:02<00:00,  5.14it/s]\n"
     ]
    }
   ],
   "source": [
    "#embed the sentences:\n",
    "embed_context_indep: typing.Dict[str, np.ndarray] = {}\n",
    "\n",
    "name = \"embed_llama3\"\n",
    "template = 'You help me get embeddings for a sentence. I provide you a with a context within []-square brackets and a sentence within <>-chevrons and you reply only with that exact sentence marked with the chevrons. Context = ['\n",
    "for index, row in tqdm.tqdm(df.iterrows(), total=len(df)):\n",
    "    context = row[\"context\"]\n",
    "    sentence = row[\"Sentences\"]\n",
    "    try: \n",
    "        embed = np.array(requests.post(\n",
    "            'https://inf.cl.uni-trier.de/embed/',\n",
    "            json={'model': MODEL, 'prompt': template + context + ']; Sentence: <' + sentence + '>'}\n",
    "            ).json()[\"response\"])\n",
    "    except Exception as _e:\n",
    "        logging.warning(_e)\n",
    "        embed = None\n",
    "    \n",
    "    if name=='embed_llama3':\n",
    "        embed_context_indep[index] = embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentences</th>\n",
       "      <th>context</th>\n",
       "      <th>embed_context_indep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The situation remains critical and requires im...</td>\n",
       "      <td>ukraine</td>\n",
       "      <td>[0.4959905743598938, -0.8566449284553528, -0.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>There is a need for more resources to effectiv...</td>\n",
       "      <td>ukraine</td>\n",
       "      <td>[0.6272997856140137, -0.8298850655555725, -0.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cooperation between different sectors is essen...</td>\n",
       "      <td>ukraine</td>\n",
       "      <td>[0.5689340829849243, -0.7365984916687012, -0.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The situation is getting out of control.</td>\n",
       "      <td>ukraine</td>\n",
       "      <td>[0.45812100172042847, -0.8505119681358337, -1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We need to take immediate action to address th...</td>\n",
       "      <td>ukraine</td>\n",
       "      <td>[0.5990078449249268, -0.8402009010314941, -0.9...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Sentences  context  \\\n",
       "0  The situation remains critical and requires im...  ukraine   \n",
       "1  There is a need for more resources to effectiv...  ukraine   \n",
       "2  Cooperation between different sectors is essen...  ukraine   \n",
       "3           The situation is getting out of control.  ukraine   \n",
       "4  We need to take immediate action to address th...  ukraine   \n",
       "\n",
       "                                 embed_context_indep  \n",
       "0  [0.4959905743598938, -0.8566449284553528, -0.9...  \n",
       "1  [0.6272997856140137, -0.8298850655555725, -0.9...  \n",
       "2  [0.5689340829849243, -0.7365984916687012, -0.8...  \n",
       "3  [0.45812100172042847, -0.8505119681358337, -1....  \n",
       "4  [0.5990078449249268, -0.8402009010314941, -0.9...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#join data\n",
    "df = df.join(pd.Series(embed_context_indep, name='embed_context_indep'))\n",
    "#group data\n",
    "dfgrouped=df.groupby('context')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "healthcare:healthcare:2.040649500684983\n",
      "healthcare:ukraine:6.05392772452196\n",
      "ukraine:ukraine:1.9972082912005538\n"
     ]
    }
   ],
   "source": [
    "#calculate distances between sentences\n",
    "\n",
    "dist = torch.nn.PairwiseDistance()\n",
    "results5: typing.Dict[typing.Tuple[str, str], float] = {}\n",
    "for model_1, c_1 in dfgrouped['embed_context_indep']:\n",
    "    for model_2, c_2 in dfgrouped['embed_context_indep']:\n",
    "\n",
    "        if (\n",
    "            (model_1, model_2) in results5.keys() or \n",
    "            (model_2, model_1) in results5.keys()\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        res = sum([\n",
    "            sum(dist(\n",
    "                torch.tensor(np.array(v_1)), \n",
    "                torch.tensor(np.array(c_2.tolist()))\n",
    "                )) / len(c_2)\n",
    "            for v_1 in c_1\n",
    "        ]) / len(c_1)\n",
    "\n",
    "        results5[(model_1, model_2)] = res\n",
    "\n",
    "        print(f'{model_1}:{model_2}:{res.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the irrelevant context has a very strong effect on the embeddings of the sentences, even though the meaning should be similar...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 128/206 [16:09<10:41,  8.22s/it]WARNING:root:Expecting value: line 1 column 1 (char 0)\n",
      " 70%|███████   | 145/206 [20:05<23:40, 23.29s/it]WARNING:root:Expecting value: line 1 column 1 (char 0)\n",
      "100%|██████████| 206/206 [28:36<00:00,  8.33s/it]\n"
     ]
    }
   ],
   "source": [
    "#some validity checks\n",
    "#maybe look at the output that is embedded, did the output yield correctly or are there traces of the prompt left in the output?\n",
    "\n",
    "output_llama3: typing.Dict[str, np.ndarray] = {}\n",
    "name = \"embed_llama3\"\n",
    "template = 'You help me get embeddings for a sentence. I provide you a with a context and a sentence and you reply only with that exact sentence. Context = '\n",
    "\n",
    "for index, row in tqdm.tqdm(arguments_df.iterrows(), total=len(arguments_df)):\n",
    "    context = 'arguments about ' + row[\"label\"]\n",
    "    sentence = row[\"arguments\"]\n",
    "    try: \n",
    "        output = np.array(requests.post(\n",
    "            'https://inf.cl.uni-trier.de/',\n",
    "            json={'model': MODEL, 'prompt': template + context + '; Sentence: ' + sentence}\n",
    "            ).json()[\"response\"])\n",
    "    except Exception as _e:\n",
    "        logging.warning(_e)\n",
    "        output = None\n",
    "    \n",
    "    if name=='embed_llama3':\n",
    "        output_llama3[index] = output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: array(\"Here is the embedding for the sentence:\\n\\n['access', 'to', 'affordable', 'healthcare', 'is', 'a', 'fundamental', 'right']\\n\\nLet me know if you need anything else!\",\n",
       "       dtype='<U160'),\n",
       " 1: array('\"The current healthcare system unfairly benefits the wealthy\"',\n",
       "       dtype='<U61'),\n",
       " 2: array('Here is the sentence with its corresponding embedding:\\n\\n\"High costs of healthcare create financial burden for many families\"\\n\\n[[-0.0329, 0.0452, -0.0314, ..., 0.0123, -0.0411, 0.0167]]',\n",
       "       dtype='<U184'),\n",
       " 3: array(\"Here is the embedding for the given sentence:\\n\\n`[-0.053, -0.107, 0.141, ..., 0.041, 0.117, -0.085]`\\n\\nPlease note that the actual embedding values will depend on the specific language model and its parameters used to generate them. The above response is a placeholder, and you may need to use a library like Hugging Face's Transformers or spaCy to get the actual embeddings.\\n\\nIf you want me to assist with generating embeddings using a specific library or model, please let me know!\",\n",
       "       dtype='<U481'),\n",
       " 4: array('Here is the embedding for the given sentence:\\n\\n\"Universal healthcare would ensure everyone has access to medical services\"\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U162'),\n",
       " 5: array('\"Mental health should be treated equally to physical health in healthcare coverage\"',\n",
       "       dtype='<U83'),\n",
       " 6: array('Here is the embedding for the sentence:\\n\\n[-0.0304, -0.0361, -0.0239, ..., 0.0117, 0.0085, -0.0173]\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U138'),\n",
       " 7: array('Here are the embeddings for the given sentence:\\n\\n[-0.038353, 0.145507, -0.131911, ..., 0.104988, 0.044944, -0.036129]\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U157'),\n",
       " 8: array('Here are the embeddings for the given sentence:\\n\\n`[[-0.068, 0.144, -0.135, ..., 0.032, 0.092, -0.011],\\n [-0.044, 0.181, -0.113, ..., -0.013, 0.082, -0.024],\\n [0.035, 0.123, -0.164, ..., -0.041, 0.121, -0.049],\\n [0.027, 0.156, -0.139, ..., 0.053, 0.093, -0.022],\\n [-0.071, 0.145, -0.125, ..., 0.033, 0.085, -0.017],\\n [-0.041, 0.185, -0.108, ..., -0.011, 0.081, -0.021],\\n [0.038, 0.129, -0.159, ..., -0.043, 0.119, -0.047],\\n [0.024, 0.161, -0.136, ..., 0.056, 0.096, -0.025]]`\\n\\nNote: The embeddings are in the form of a 2D numpy array, where each row represents the embedding for a word in the sentence. The actual values may vary depending on the specific model and library used to generate the embeddings.',\n",
       "       dtype='<U705'),\n",
       " 9: array('Here are the embeddings for the given sentence:\\n\\n`[[-0.0376, -0.0263, 0.0551, ..., 0.0219, -0.0408, 0.0162],\\n [-0.0304, -0.0435, 0.0359, ..., 0.0182, -0.0317, 0.0224],\\n [0.0413, -0.0381, 0.0113, ..., 0.0366, -0.0234, 0.0288],\\n ...,\\n [-0.0249, 0.0122, -0.0512, ..., 0.0445, -0.0194, 0.0408],\\n [0.0331, 0.0213, 0.0496, ..., 0.0117, -0.0353, 0.0179],\\n [-0.0165, 0.0452, -0.0363, ..., 0.0294, -0.0308, 0.0261]]`\\n\\nPlease note that these embeddings are in the form of a matrix where each row represents a word in the sentence and each column represents a feature or dimension. The exact values may vary depending on the specific language model or embedding algorithm used.',\n",
       "       dtype='<U666'),\n",
       " 10: array('Here is the embedding for the given sentence:\\n\\n[-0.052143547, 0.10449219, -0.03221581, ..., -0.01646093, -0.03027344, 0.06213379]\\n\\nPlease note that the actual output will be a vector of numbers (typically 100-400 dimensions) representing the sentence embedding. The above response is a placeholder and not an actual output.',\n",
       "       dtype='<U323'),\n",
       " 11: array('Here is the embedding for the sentence:\\n\\n[\"Health\", -0.108], [\"disparities\", -0.136], [\"exist\", 0.115], [\"along\", 0.154], [\"racial\", 0.184], [\"and\", 0.134], [\"ethnic\", 0.199], [\"lines\", 0.165], [\"requiring\", 0.194], [\"targeted\", 0.223], [\"solutions\", 0.242]',\n",
       "       dtype='<U257'),\n",
       " 12: array('\"The COVID-19 pandemic has highlighted the importance of a robust public health infrastructure\"',\n",
       "       dtype='<U95'),\n",
       " 13: array('\"Greater investment in medical research is needed to address persistent health issues\"',\n",
       "       dtype='<U86'),\n",
       " 15: array('\"The current healthcare system prioritizes profits over people',\n",
       "       dtype='<U62'),\n",
       " 17: array('Here is the embedding for the sentence:\\n\\n\"High costs of healthcare prevent many people from receiving necessary treatments\"\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U163'),\n",
       " 18: array('Here is the embedding for the given sentence:\\n\\n\"Pre-existing conditions should not affect one\\'s ability to receive healthcare coverage\"\\n\\nEmbedding:\\n[-0.038194, -0.044941, 0.053982, ..., 0.024391, 0.041946, 0.035156]\\n\\nPlease let me know if you need anything else!',\n",
       "       dtype='<U262'),\n",
       " 19: array('\"Mental health should be treated with the same importance as physical health',\n",
       "       dtype='<U76'),\n",
       " 21: array('Here is the embedding for the given sentence:\\n\\n Telemedicine can improve access to care, especially in rural areas',\n",
       "       dtype='<U114'),\n",
       " 22: array('Here are the embeddings for the given sentence:\\n\\n`[-0.052, -0.144, 0.132, ..., 0.244, -0.116, 0.088]`\\n\\n(Note: The actual embedding values will depend on the specific model and library used to generate them. The above is a placeholder representation.)',\n",
       "       dtype='<U250'),\n",
       " 23: array('Here is the embedding for the sentence:\\n\\n[-0.054, -0.132, 0.098, ..., -0.032, 0.146, 0.038]',\n",
       "       dtype='<U91'),\n",
       " 24: array('Here is the embedding for the sentence:\\n\\n\"A single-payer system could simplify healthcare administration and lower costs\"\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U161'),\n",
       " 25: array('\"Healthcare should be viewed as a public good, not a commodity\"',\n",
       "       dtype='<U63'),\n",
       " 28: array('Here is the sentence with its corresponding embedding:\\n\\n\"High costs of healthcare lead to medical debt and bankruptcy\"\\n\\nEmbedding:\\n[-0.0375, 0.0559, -0.0142, ..., 0.0234, 0.0117, -0.0531]\\n\\nPlease note that the exact values may vary depending on the model and library used to generate the embeddings.',\n",
       "       dtype='<U299'),\n",
       " 29: array('Here is the embedding for the given sentence:\\n\\n[[-0.03086912, -0.03252832, 0.04495508, ..., 0.02439062, 0.02050781, -0.04394531],\\n [-0.01341895, 0.01660156, 0.0357666, ..., 0.02148838, -0.03613379, 0.00494387],\\n [0.01861914, -0.00391016, 0.02639355, ..., 0.03345508, 0.01069922, 0.03147266],\\n ...,\\n [-0.01187952, 0.04049805, 0.01281152, ..., 0.03841992, 0.02439062, -0.01501855],\\n [0.00859091, 0.00299023, 0.04495508, ..., -0.00391016, 0.03488379, -0.02050781],\\n [-0.01281152, 0.01660156, -0.03086912, ..., -0.00509277, 0.02439062, 0.04394531]]',\n",
       "       dtype='<U544'),\n",
       " 30: array('Here is the sentence with its corresponding embedding:\\n\\n\"Expanded Medicaid programs can help low-income individuals access care\"\\n\\nEmbedding: [-0.037, -0.044, 0.035, ..., 0.023, 0.051, -0.013]',\n",
       "       dtype='<U191'),\n",
       " 31: array('Here is the embedding for the given sentence:\\n\\n\"Universal healthcare systems ensure everyone has insurance\"',\n",
       "       dtype='<U107'),\n",
       " 32: array('Here is the embedding for the sentence:\\n\\n\"Preventive care can save money in the long run\"\\n\\nPlease let me know if you need anything else!',\n",
       "       dtype='<U136'),\n",
       " 33: array(\"Here is the embedding for the given sentence:\\n\\n[-0.054, -0.138, -0.122, ..., 0.114, 0.102, 0.178]\\n\\nPlease let me know what you'd like to do next!\",\n",
       "       dtype='<U145'),\n",
       " 34: array('\"The US lags behind other developed countries in healthcare outcomes\"',\n",
       "       dtype='<U69'),\n",
       " 35: array('Here is the sentence with its corresponding embedding:\\n\\n\"Pharmaceutical companies have too much influence over healthcare policy\"\\n\\n Embedding: [-0.054, -0.103, 0.041, ..., 0.067, 0.019, -0.011]',\n",
       "       dtype='<U193'),\n",
       " 36: array('Here is the sentence with its corresponding embedding:\\n\\n\"Telemedicine has become increasingly important during the COVID-19 pandemic\"\\n\\nEmbedding:\\n[-0.032, -0.016, 0.044, ..., -0.012, 0.035, -0.019]\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U237'),\n",
       " 37: array('Here is the embedding for the sentence:\\n\\n`[[-0.0406, -0.0249, -0.0337, ..., -0.0193, -0.0422, 0.0301],\\n [-0.0475, -0.0114, 0.001, ..., -0.0506, 0.0348, 0.0122],\\n [0.0222, -0.0139, 0.0164, ..., -0.0053, -0.017, 0.0261],\\n ...,\\n [-0.0355, 0.0282, 0.0096, ..., 0.0368, -0.0191, 0.0127],\\n [0.0409, 0.0161, -0.013, ..., 0.0224, 0.0156, -0.0065],\\n [-0.021, -0.0073, -0.0208, ..., 0.0022, 0.0115, 0.0239]]`\\n\\nPlease note that the embedding is a 2D array of size (sequence_length, embedding_dim) where sequence_length is the number of words in the sentence and embedding_dim is the dimensionality of the embedding space. In this case, I used a popular language model to generate the embeddings, but you can use any other method or library to get the embeddings.\\n\\nPlease let me know if you need anything else!',\n",
       "       dtype='<U798'),\n",
       " 38: array('Here is the embedding for the given sentence:\\n\\nChronic conditions require ongoing, expensive treatments',\n",
       "       dtype='<U103'),\n",
       " 39: array('Here is the embedding for the given sentence:\\n\\n[-0.054, 0.141, -0.114, ..., 0.032, -0.071, 0.145]',\n",
       "       dtype='<U97'),\n",
       " 40: array('Here is the sentence with its corresponding embedding:\\n\\n\"Public health initiatives can address societal determinants of health\"\\n\\nEmbedding:\\n[-0.035, -0.016, 0.042, ..., 0.023, 0.019, -0.011]\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U230'),\n",
       " 41: array('\"The healthcare system should prioritize patient-centered care\"',\n",
       "       dtype='<U63'),\n",
       " 42: array('Here is the embedding for the given sentence:\\n\\n[-0.0503, -0.1034, 0.1445, ..., -0.0341, 0.1167, -0.0779]\\n\\nPlease note that the actual embedding values will vary depending on the specific language model and library used to generate them. The above response is a placeholder representation of an embedding vector.',\n",
       "       dtype='<U311'),\n",
       " 43: array('Here are the embeddings for the sentence:\\n\\n[\"access\", -0.036, 0.144, ..., -0.072],\\n[\"to\", -0.012, 0.234, ..., -0.156],\\n[\"affordable\", 0.051, 0.192, ..., 0.038],\\n[\"healthcare\", 0.142, -0.101, ..., 0.181],\\n[\"is\", -0.023, 0.156, ..., -0.191],\\n[\"a\", -0.012, 0.234, ..., -0.156],\\n[\"major\", 0.145, -0.021, ..., 0.185],\\n[\"concern\", 0.182, -0.131, ..., 0.159],\\n[\"for\", -0.023, 0.156, ..., -0.191],\\n[\"many\", 0.041, 0.151, ..., 0.118],\\n[\"Americans\", 0.161, -0.081, ..., 0.199]',\n",
       "       dtype='<U466'),\n",
       " 44: array('Here is the embedding for the given sentence:\\n\\n[-0.0526, -0.1449, 0.1735, ..., -0.0331, -0.0123, 0.0157]\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U144'),\n",
       " 45: array('\"There is a need for comprehensive reform in the healthcare industry\"',\n",
       "       dtype='<U69'),\n",
       " 46: array('Here is the sentence with its corresponding embedding:\\n\\n\"Expanding Medicaid can help provide coverage for more low-income individuals\"\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U174'),\n",
       " 47: array('Here is the embedding for the given sentence:\\n\\n[\"pre-existing\", \"conditions\", \"should\", \"not\", \"prevent\", \"people\", \"from\", \"obtaining\", \"health\", \"insurance\"]',\n",
       "       dtype='<U159'),\n",
       " 48: array('\"The high cost of prescription drugs is a significant barrier to healthcare access\"',\n",
       "       dtype='<U83'),\n",
       " 49: array('\"Mental health services should be integrated into mainstream healthcare\"',\n",
       "       dtype='<U72'),\n",
       " 50: array('Here is the embedding for the given sentence:\\n\\n\"Preventive care can significantly reduce long-term healthcare costs\"\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U156'),\n",
       " 51: array('Here is the embedding for the given sentence:\\n\\n[\"Telemedicine\", -0.038194, -0.134515, 0.114019, ..., -0.044944]\\n[\"has\", -0.071429, 0.050781, 0.115217, ..., -0.036364]\\n[\"become\", -0.046875, 0.109375, 0.140625, ..., 0.023438]\\n[\"increasingly\", 0.058594, 0.130435, 0.143066, ..., -0.035938]\\n[\"important\", -0.03125, 0.15625, 0.140625, ..., -0.011719]\\n[\"especially\", 0.050781, 0.109375, 0.128906, ..., -0.039063]\\n[\"during\", -0.0625, 0.125, 0.140625, ..., -0.030469]\\n[\"the\", -0.078125, 0.09375, 0.109375, ..., -0.04375]\\n[\"COVID-19\", 0.171875, 0.203125, 0.234375, ..., 0.015625]\\n[\"pandemic\", 0.1875, 0.21875, 0.25, ..., 0.03125]\\n\\nNote: The actual output would be a vector of floating point numbers for each word in the sentence, but I\\'ve represented it here as a list of words with their corresponding vector values truncated to 6 decimal places for brevity.',\n",
       "       dtype='<U850'),\n",
       " 52: array('Here is the embedding for the given sentence:\\n\\n[-0.038194, -0.042945, -0.05369, ..., -0.024193, 0.015831, 0.034969]',\n",
       "       dtype='<U115'),\n",
       " 53: array('Here is the embedding for the given sentence:\\n\\n[[-0.0375, -0.0517, -0.0334, ..., -0.0328, 0.0211, -0.0119],\\n [-0.0303, -0.0402, -0.0236, ..., -0.0365, 0.0254, -0.0098],\\n [0.0147, 0.0109, 0.0269, ..., -0.0021, 0.0345, 0.0153],\\n ...,\\n [-0.0282, -0.0446, -0.0171, ..., -0.0234, 0.0388, -0.005],\\n [0.0427, 0.0365, 0.0619, ..., -0.0163, 0.0523, 0.0212],\\n [-0.0356, -0.0503, -0.0332, ..., -0.0318, 0.0206, -0.0124]]',\n",
       "       dtype='<U409'),\n",
       " 54: array('Here is the embedding for the given sentence:\\n\\n[-0.055, -0.032, 0.019, ..., -0.041, 0.035, -0.025]\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U138'),\n",
       " 55: array('Here is the embedding for the sentence:\\n\\n\" Investing in public health can help prevent the spread of diseases and reduce healthcare costs \"',\n",
       "       dtype='<U139'),\n",
       " 56: array('\"The healthcare workforce faces significant challenges, including burnout and staffing shortages\"',\n",
       "       dtype='<U97'),\n",
       " 59: array('Here is the sentence with its embedding:\\n\\n\"High costs of medical treatments and prescription drugs are prohibitive for many individuals\"\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U176'),\n",
       " 60: array('Here is the embedding for the given sentence:\\n\\n\"Universal healthcare would ensure everyone has access to necessary medical services\"\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U172'),\n",
       " 61: array(\"Here is the embedding for the given sentence:\\n\\n`[-0.055, 0.144, -0.134, ..., -0.018, 0.041, -0.06]`\\n\\nPlease note that I'm generating a random embedding for demonstration purposes only. In a real-world scenario, you would use a pre-trained language model or a sentence embedding algorithm to generate the embeddings.\\n\\nIf you want me to help with something else, feel free to ask!\",\n",
       "       dtype='<U378'),\n",
       " 62: array('Here is the embedding for the given sentence:\\n\\n[-0.0507, -0.0362, 0.0714, ..., 0.0325, -0.0453, 0.0239]\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U143'),\n",
       " 65: array('Here is the sentence with its embedding:\\n\\n\"The healthcare industry needs reform to improve patient outcomes and satisfaction\"\\n\\nEmbedding:\\n[-0.034383, 0.139479, -0.135941, ..., 0.024219, -0.022342, 0.061465]',\n",
       "       dtype='<U206'),\n",
       " 66: array('Here is the sentence with its corresponding embedding:\\n\\n\"Greater investment in public health initiatives can lead to a healthier population\"\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U180'),\n",
       " 69: array('Here is the embedding for the given sentence:\\n\\n[[-0.0603, 0.0441, -0.0536, ..., 0.0327, 0.0305, -0.0114],\\n [-0.0358, 0.0409, -0.0382, ..., 0.0231, 0.0269, -0.0163],\\n [0.0419, 0.0186, -0.0477, ..., 0.0205, 0.0219, -0.0144],\\n [-0.0448, 0.0552, -0.0301, ..., 0.0363, 0.0329, -0.0137],\\n [0.0526, 0.0233, -0.0615, ..., 0.0354, 0.0335, -0.0158],\\n [-0.0112, 0.0461, -0.0404, ..., 0.0249, 0.0283, -0.0177],\\n [0.0453, 0.0396, -0.0324, ..., 0.0275, 0.0313, -0.0145],\\n [-0.0338, 0.0514, -0.0428, ..., 0.0341, 0.0367, -0.0169],\\n [0.0382, 0.0305, -0.0506, ..., 0.0253, 0.0295, -0.0189],\\n [-0.0594, 0.0448, -0.0351, ..., 0.0319, 0.0347, -0.0132],\\n [0.0218, 0.0406, -0.0435, ..., 0.0233, 0.0267, -0.0154],\\n [-0.0444, 0.0541, -0.0313, ..., 0.0359, 0.0382, -0.0148]]\\n\\nPlease note that the exact values may vary depending on the specific embedding model and its configuration used to generate these embeddings.',\n",
       "       dtype='<U892'),\n",
       " 70: array('\"Expanding public health insurance options will lead to better patient care\"',\n",
       "       dtype='<U76'),\n",
       " 71: array('Here is the embedding for the sentence:\\n\\n[-0.054, -0.034, 0.052, ..., -0.011, -0.006]',\n",
       "       dtype='<U85'),\n",
       " 72: array('Here is the sentence with its corresponding embeddings:\\n\\n\"The government must ensure healthcare accessibility and affordability for all\"\\n\\nEmbeddings:\\n[[-0.074, -0.138, 0.032, ..., 0.042, -0.098, 0.082],\\n [-0.118, 0.154, -0.178, ..., 0.012, 0.034, 0.112],\\n [0.086, 0.024, -0.166, ..., -0.104, 0.156, -0.032],\\n ...,\\n [-0.044, 0.168, 0.118, ..., -0.006, 0.094, 0.076],\\n [-0.012, 0.106, -0.134, ..., 0.066, -0.082, 0.102],\\n [0.052, -0.184, 0.162, ..., 0.092, 0.136, -0.118]]\\n\\nPlease note that the actual embeddings values may vary based on the model and its configuration used to generate them.',\n",
       "       dtype='<U590'),\n",
       " 73: array('Here is the embedding for the sentence:\\n\\n\" Investments in preventive care can significantly reduce long-term healthcare costs \"\\n\\nEmbedding:\\n[-0.073, -0.011, 0.045, ..., 0.041, -0.068, 0.011]',\n",
       "       dtype='<U190'),\n",
       " 74: array('\"Mental health services should be integrated into mainstream healthcare systems',\n",
       "       dtype='<U79'),\n",
       " 76: array('Here are the embeddings for the sentence:\\n\\n[-0.03795412, -0.04494531, 0.04394531, ..., 0.01172093, 0.02148047, -0.05371094]\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U163'),\n",
       " 77: array('\"The pharmaceutical industry has too much influence over healthcare policy\"',\n",
       "       dtype='<U75'),\n",
       " 82: array('Here is the sentence with its corresponding embeddings:\\n\\n\"Expanding Medicaid and improving access to mental health services are crucial\"\\n\\n Embeddings: \\n\\n[[-0.04039327, -0.06050983, 0.04511398, ..., -0.03613068, 0.03222557, -0.01951355],\\n [-0.04494537, 0.01629345, -0.01238929, ..., 0.02448951, 0.04687995, 0.02149119],\\n [0.05612994, -0.01861014, 0.04394956, ..., -0.02059221, -0.03351412, -0.04980933],\\n ...,\\n [-0.03050846, 0.04099083, 0.01452001, ..., -0.01218994, -0.04495037, 0.01861014],\\n [0.02448951, 0.04687995, 0.02149119, ..., 0.01951355, 0.04039327, 0.06050983]]\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U611'),\n",
       " 83: array('Here is the sentence with its corresponding embedding:\\n\\n\"Pharmaceutical companies should be held accountable for price gouging\"\\n\\n[vector representation of the sentence]',\n",
       "       dtype='<U168'),\n",
       " 84: array('Here is the sentence with its corresponding embeddings:\\n\\n\"Pre-existing conditions should not exclude individuals from healthcare coverage\"\\n\\nEmbeddings:\\n[-0.038, 0.044, -0.035, ..., 0.061, -0.015, 0.032]\\n\\nNote: The embeddings are a 1-D array of floats, typically with 128 or 256 dimensions. I\\'m showing only the first few elements for brevity.',\n",
       "       dtype='<U342'),\n",
       " 85: array('\"A single-payer system can ensure universal coverage and reduce costs\"',\n",
       "       dtype='<U70'),\n",
       " 86: array('Here are the embeddings for the given sentence:\\n\\n` Preventive care is essential to improving public health and reducing healthcare costs`\\n\\nEmbeddings:\\n```\\n[[-0.038194, 0.042393, -0.044945, ..., -0.03281, 0.016602, 0.023529],\\n [-0.018597, 0.010742, 0.036133, ..., -0.006794, 0.003918, 0.004883],\\n [0.012195, 0.03027, -0.02451, ..., 0.040984, 0.009359, 0.015625],\\n ...,\\n [-0.008789, 0.011719, 0.021484, ..., 0.005859, 0.007812, 0.012695],\\n [0.016602, -0.019531, 0.006836, ..., 0.008789, -0.003906, 0.011719]]\\n```\\nNote: The above embeddings are based on the BERT-base model and have been truncated for brevity. In reality, the embedding vector would be a much larger matrix with 768 dimensions.',\n",
       "       dtype='<U691'),\n",
       " 87: array('Here is the sentence with its corresponding embedding:\\n\\n\"Telehealth services can improve access to healthcare, especially in rural areas\"\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U177'),\n",
       " 88: array('\"Chronic diseases such as diabetes and heart disease need to be better managed through healthcare policies\"',\n",
       "       dtype='<U107'),\n",
       " 90: array('\"The current healthcare system favors the wealthy and leaves out the poor\"',\n",
       "       dtype='<U74'),\n",
       " 91: array('Here is the embedding for the sentence:\\n\\n[-0.067, -0.053, -0.045, ..., 0.062, 0.015, -0.011]',\n",
       "       dtype='<U92'),\n",
       " 92: array('\"There should be universal healthcare coverage for all citizens\"',\n",
       "       dtype='<U64'),\n",
       " 93: array('Here is the embedding for the given sentence:\\n\\n[-0.054, 0.044, -0.016, ..., 0.032, 0.011, -0.035]',\n",
       "       dtype='<U97'),\n",
       " 94: array('Here is the sentence with its corresponding embedding:\\n\\n\"Chronic illnesses and mental health conditions require ongoing and often expensive treatments\"\\n\\n[Vector representation of the sentence]',\n",
       "       dtype='<U192'),\n",
       " 95: array('\"The pharmaceutical industry has too much power and influence over healthcare policies\"',\n",
       "       dtype='<U87'),\n",
       " 96: array('\"There is a need for greater transparency in healthcare pricing\"',\n",
       "       dtype='<U64'),\n",
       " 97: array('Here are the embeddings for the sentence:\\n\\n[\"Telemedicine\", -0.0447, 0.1364],\\n[\"and\", -0.1046, 0.0405],\\n[\"virtual\", -0.1449, 0.2351],\\n[\"care\", -0.1749, 0.1345],\\n[\"options\", -0.1558, 0.2037],\\n[\"can\", -0.1144, 0.1013],\\n[\"improve\", -0.1642, 0.2436],\\n[\"access\", -0.2041, 0.2219],\\n[\"to\", -0.1345, 0.0608],\\n[\"healthcare\", -0.2347, 0.3124],\\n[\"services\", -0.2543, 0.2711]\\n\\nPlease note that the embeddings are based on a pre-trained language model and might not exactly capture the context of \"arguments about healthcare\". If you need more accurate embeddings, please provide more information or context about the specific arguments being referred to.',\n",
       "       dtype='<U642'),\n",
       " 98: array(\"Here is the embedding for the given sentence:\\n\\n[-0.055, 0.033, -0.021, ..., 0.042, -0.019, 0.051]\\n\\nNote: The actual embedding values will depend on the specific language model or algorithm used to generate them. The above response is a representation of what the output might look like. If you need actual embeddings, please specify the language model or library you'd like me to use (e.g., BERT, RoBERTa, Word2Vec, etc.).\",\n",
       "       dtype='<U422'),\n",
       " 99: array('Here is the embedding for the given sentence:\\n\\n[-0.056, -0.124, 0.136, ..., 0.044, 0.104, -0.032]',\n",
       "       dtype='<U97'),\n",
       " 100: array('Here is the embedding for the sentence:\\n\\n[\"Health\", -0.1282, -0.3439], [\"disparities\", 0.2511, -0.2153], [\"exist\", -0.1434, -0.1445], [\"along\", 0.1446, 0.1747], [\"racial\", 0.1419, -0.1922], [\"and\", -0.2218, -0.1451], [\"ethnic\", 0.2403, -0.2454], [\"lines\", 0.1845, 0.1356], [\"requiring\", -0.1635, -0.1149], [\"targeted\", 0.1939, -0.1757], [\"interventions\", 0.2551, -0.2349]',\n",
       "       dtype='<U371'),\n",
       " 101: array('\"The government should play a larger role in regulating and funding healthcare\"',\n",
       "       dtype='<U79'),\n",
       " 104: array('Here is the sentence with its embedding:\\n\\n\"High cost of healthcare leads to medical debt and bankruptcy\"\\n\\nEmbedding:\\n[-0.070312, -0.044944, 0.032239, ..., -0.016129, 0.030273, -0.023919]\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U226'),\n",
       " 105: array('Here is the embedding for the sentence:\\n\\n[0.04888395, -0.04494531, -0.03448241, ..., 0.04980469, 0.0361338, -0.02441177]',\n",
       "       dtype='<U120'),\n",
       " 106: array('Here is the embedding for the sentence:\\n\\n[\"Universal\", \"healthcare\", \"would\", \"ensure\", \"everyone\", \"has\", \"access\", \"to\", \"necessary\", \"medical\", \"care\"]\\n\\nEmbeddings:\\n[[0.0775, 0.0412], [0.0348, -0.0193], [-0.0049, 0.0304], [0.0456, -0.0111], [0.0679, 0.0503], [0.0483, 0.0125], [0.0357, 0.0162], [0.0428, -0.0241], [0.0811, 0.0296], [0.0514, 0.0089], [-0.0025, 0.0417], [0.0613, 0.0462]]\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U429'),\n",
       " 107: array('Here is the sentence with its corresponding embedding:\\n\\n\"The government should have a larger role in regulating healthcare\"\\n\\nEmbedding:\\n[-0.0365, 0.0471, -0.0413, ..., 0.0229, -0.0446, 0.0508]\\n\\nLet me know if you\\'d like me to explain what this embedding represents or if you have any further requests!',\n",
       "       dtype='<U301'),\n",
       " 108: array('Here is the embedding for the sentence:\\n\\n\"Pharmaceutical companies should be held accountable for high drug prices\"\\n\\nEmbedding: [-0.038, 0.044, -0.028, ..., 0.016, 0.042, 0.011]\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U217'),\n",
       " 110: array('Here are the embeddings for the sentence:\\n\\n`[[-0.055, 0.141], [-0.103, 0.034], [0.016, -0.119], ..., [0.144, -0.024], [0.035, -0.115]]`\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U175'),\n",
       " 111: array('Here is the sentence with its corresponding embedding:\\n\\n\"Telemedicine can improve access to healthcare in rural areas\"\\n\\nEmbedding:\\n[-0.050463, -0.041189, 0.082531, ..., -0.016499, 0.024902, 0.062501]',\n",
       "       dtype='<U199'),\n",
       " 112: array('Here is the embedding for the sentence:\\n\\n[-0.0351, -0.0343, 0.0272, ..., -0.0124, -0.0087, 0.0169]',\n",
       "       dtype='<U98'),\n",
       " 113: array('\"Healthcare inequality disproportionately affects marginalized communities\"',\n",
       "       dtype='<U75'),\n",
       " 116: array('Here is the embedding for the given sentence:\\n\\n[-0.0508, 0.1235, -0.0247, ..., -0.0112, 0.0439, 0.0211]',\n",
       "       dtype='<U103'),\n",
       " 117: array('\"There is a need for comprehensive, universal healthcare coverage\"',\n",
       "       dtype='<U66'),\n",
       " 119: array('Here is the embedding for the sentence:\\n\\n\"Telehealth services can improve access to care, especially in rural areas\"',\n",
       "       dtype='<U116'),\n",
       " 121: array('Here is the embedding for the given sentence:\\n\\n[-0.035995, -0.042194, 0.05371, ...]',\n",
       "       dtype='<U83'),\n",
       " 122: array('Here is the sentence with its corresponding embedding:\\n\\n\"Health disparities must be addressed to ensure equitable healthcare access and outcomes\"\\n\\nLet me know when you\\'re ready for the next one!',\n",
       "       dtype='<U194'),\n",
       " 123: array('\" Investing in public health infrastructure is crucial for preventing the spread of diseases \"',\n",
       "       dtype='<U94'),\n",
       " 124: array('Here is the embedding for the sentence:\\n\\n\"Ukraine is experiencing a natural gas shortage due to Russia cutting off supplies\"\\n\\nPlease let me know if you need anything else!',\n",
       "       dtype='<U171'),\n",
       " 125: array('\"The EU should implement sanctions on Russia for using energy as a political weapon\"',\n",
       "       dtype='<U84'),\n",
       " 126: array('Here are the embeddings for the given sentence:\\n\\n\"Support for Ukraine in the face of Russian aggression is crucial\"\\n\\nEmbeddings:\\n[[0.03551953, 0.05355371, 0.04534571, ..., -0.0242041 , 0.03067091, -0.0405459 ]]\\n[[0.04142187, 0.04980469, 0.03684211, ..., -0.01176471, 0.03125    , -0.04545509]]\\n... (each word in the sentence has a corresponding embedding vector)\\n\\nPlease let me know if you need anything else!',\n",
       "       dtype='<U409'),\n",
       " 127: array('Here is the sentence with its corresponding embedding:\\n\\n\"NATO allies should increase their defense spending to counteract Russian threats\"\\n\\nEmbedding:\\n[-0.038194, 0.044921, -0.023529, ..., 0.03125, -0.035156, -0.039062]',\n",
       "       dtype='<U219'),\n",
       " 128: array('Here is the embedding for the sentence:\\n\\n\"Ukraine\\'s sovereignty and territorial integrity must be respected and protected\"\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U162'),\n",
       " 129: array('Here is the embedding for the given sentence:\\n\\n\"The US and its allies should provide military aid to Ukraine to help defend against Russian attacks\"\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U188'),\n",
       " 130: array(\"Here is the embedding for the given sentence:\\n\\n Russia's actions in Ukraine are a threat to international peace and security\",\n",
       "       dtype='<U124'),\n",
       " 131: array('Here is the embedding for the given sentence:\\n\\n\"The conflict in Ukraine highlights the need for energy independence and diversification\"\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U176'),\n",
       " 132: array('Here is the sentence with its corresponding embedding:\\n\\n\"The international community must hold Russia accountable for its actions in Ukraine\"\\n\\nEmbedding:\\n[-0.0375, 0.0524, -0.0352, ..., 0.0219, -0.0441, 0.0117]',\n",
       "       dtype='<U210'),\n",
       " 133: array('\"The situation in Ukraine requires a strong and united response from the West\"',\n",
       "       dtype='<U78'),\n",
       " 134: array('Here is the sentence with its corresponding embedding:\\n\\n\"The US should provide military aid to Ukraine\"\\n\\nEmbedding:\\n[-0.038194, 0.044922, -0.05539, 0.071064, -0.03349, -0.02451, 0.046392, -0.06125, 0.053882, 0.032795, ...]',\n",
       "       dtype='<U222'),\n",
       " 135: array(\"Here are the embeddings for the given sentence:\\n\\n` Russia's aggression is a threat to Ukraine and Europe`\\n\\nEmbeddings:\\n```\\n[[-0.038, 0.044, -0.046, ..., 0.042, -0.034, 0.048],\\n [-0.04, 0.024, -0.066, ..., 0.032, -0.054, 0.018],\\n [0.016, 0.036, -0.022, ..., 0.046, -0.014, 0.034],\\n ...,\\n [0.03, 0.012, -0.048, ..., 0.05, -0.022, 0.042],\\n [-0.026, 0.04, -0.054, ..., 0.036, -0.038, 0.024]]\\n```\\nLet me know if you need anything else!\",\n",
       "       dtype='<U430'),\n",
       " 136: array('Here is the embedding for the given sentence:\\n\\n[\"Ukraine\", \"needs\", \"support\", \"from\", \"the\", \"international\", \"community\", \"to\", \"defend\", \"itself\"]\\n\\nEmbedding:\\n[[-0.038194, 0.13421, ...], \\n [-0.06098, -0.01212, ...], \\n [0.045189, 0.02456, ...], \\n [-0.01639, 0.04424, ...], \\n [-0.05515, -0.0324, ...], \\n [-0.02948, 0.09164, ...], \\n [-0.04298, 0.07095, ...], \\n [0.01175, 0.05311, ...], \\n [-0.06379, 0.05535, ...], \\n [-0.0489, 0.02469, ...]]\\n\\nPlease note that the embedding values are truncated for brevity. In reality, each word would have a vector of around 100-300 dimensions depending on the model used.',\n",
       "       dtype='<U606'),\n",
       " 137: array('Here is the embedding for the sentence:\\n\\n\"The US should stand with its allies in supporting Ukraine\"\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U140'),\n",
       " 138: array('Here is the embedding for the given sentence:\\n\\n\"Congress should allocate funds for military aid to Ukraine\"\\n\\n(Note: I\\'m assuming you want me to respond with the original sentence, not the embedding values. If you need the actual embedding values, please let me know the desired embedding model and dimensionality.)',\n",
       "       dtype='<U314'),\n",
       " 139: array('Here are the embeddings for the given sentence:\\n\\n**Sentence Embeddings:**\\n\\nUsing the BERT-based `sentence-transformers` library, I generated the following sentence embeddings:\\n\\n`[-0.077, 0.141, -0.144, ..., 0.053, -0.198, 0.118]`\\n\\nThese are 384-dimensional embeddings, which can be used for various NLP tasks such as clustering, classification, or semantic search.\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U404'),\n",
       " 140: array('Here is the embedding for the sentence:\\n\\n\"Russia\\'s actions in Ukraine are illegal and violate human rights\"',\n",
       "       dtype='<U107'),\n",
       " 141: array('Here are the embeddings for the given sentence:\\n\\n**Sentence Embeddings:**\\n`[0.038, -0.032, 0.018, ..., -0.041, 0.026, -0.012]`\\n\\n**Token Embeddings:**\\n\\n* \"US\": `[0.071, -0.013, 0.045, ...]`\\n* \"support\": `[-0.019, 0.053, -0.038, ...]`\\n* \"for\": `[0.041, 0.011, -0.027, ...]`\\n* \"Ukraine\": `[0.049, -0.032, 0.068, ...]`\\n* \"is\": `[-0.013, 0.031, -0.015, ...]`\\n* \"essential\": `[0.059, -0.043, 0.051, ...]`\\n* \"for\": `[0.041, 0.011, -0.027, ...]`\\n* \"maintaining\": `[-0.023, 0.061, -0.035, ...]`\\n* \"democracy\": `[0.053, -0.039, 0.063, ...]`\\n* \"and\": `[0.017, 0.019, -0.029, ...]`\\n* \"stability\": `[0.043, -0.025, 0.051, ...]`\\n* \"in\": `[-0.011, 0.027, -0.021, ...]`\\n* \"Europe\": `[0.055, -0.031, 0.065, ...]`\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U735'),\n",
       " 143: array('\"Ukraine has the right to defend itself against Russian aggression\"',\n",
       "       dtype='<U67'),\n",
       " 144: array('\"The US should provide military aid to Ukraine to help defend against Russian aggression\"',\n",
       "       dtype='<U89'),\n",
       " 145: array('Here is the embedding for the given sentence:\\n\\n[-0.035327, 0.13464, -0.02441, ..., -0.01291, 0.01562, -0.01115]',\n",
       "       dtype='<U111'),\n",
       " 146: array('Here are the embeddings for the given sentence:\\n\\n[\"President\", -0.044, -0.124], [\"Biden\\'s\", 0.016, -0.133], [\"decision\", -0.032, -0.143], [\"to\", 0.035, -0.114], [\"send\", -0.013, -0.144], [\"military\", 0.046, -0.154], [\"aid\", -0.011, -0.134], [\"to\", 0.035, -0.114], [\"Ukraine\", 0.051, -0.164], [\"is\", 0.025, -0.104], [\"a\", 0.02, -0.094], [\"step\", -0.038, -0.124], [\"in\", 0.03, -0.114], [\"the\", 0.024, -0.104], [\"right\", -0.042, -0.144], [\"direction\", -0.016, -0.134]]\\n\\nPlease note that the embeddings are in the format [word, x-coordinate, y-coordinate] and represent the sentence\\'s semantic meaning in a 2D vector space.',\n",
       "       dtype='<U619'),\n",
       " 147: array('Here is the sentence with embeddings:\\n\\n\"The conflict in Ukraine has led to a humanitarian crisis that requires immediate attention and support from the international community\"\\n\\nEmbeddings:\\n[[-0.032, 0.045, ..., -0.012],\\n [-0.023, 0.011, ..., 0.034],\\n ...,\\n [0.017, -0.039, ..., 0.051]]\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U326'),\n",
       " 148: array('Here is the embedding for the given sentence:\\n\\n\"Russia\\'s actions in Ukraine are a threat to global security and stability\"',\n",
       "       dtype='<U122'),\n",
       " 149: array('Here is the embedding for the sentence:\\n\\n\"The US should take a strong stance against Russia\\'s aggression in Ukraine\"\\n\\nEmbedding:\\n[-0.024509, -0.135955, 0.043951, ..., 0.044951, -0.02309, 0.011819]',\n",
       "       dtype='<U196'),\n",
       " 150: array('Here is the embedding for the given sentence:\\n\\n\"The US must continue to support Ukraine as it defends itself against Russian attacks\"\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U173'),\n",
       " 151: array('Here is the sentence with its embeddings:\\n\\n\"The conflict in Ukraine is not just a regional issue, but a global one that requires international cooperation and action\"\\n\\nEmbeddings:\\n[[-0.038194, 0.044922, -0.015609, ...], \\n [-0.036133, 0.041039, -0.011871, ...], \\n [...], \\n ..., \\n [0.053489, -0.009879, 0.02391, ...]]\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U355'),\n",
       " 153: array(\"Here are the embeddings for the given sentence:\\n\\n```\\n[-0.006335, 0.011235, -0.002835, ...]\\n```\\n\\nPlease note that the actual output would be a list of floating point numbers representing the vector embedding of the input sentence. The length and values of this list depend on the specific language model or embedding algorithm used.\\n\\nIf you'd like, I can provide more information on how to interpret these embeddings or suggest ways to use them in your project. Just let me know!\",\n",
       "       dtype='<U478'),\n",
       " 154: None,\n",
       " 155: array('Here are the embeddings for the given sentence:\\n\\n**Sentence Embeddings:**\\n```\\n[-0.035, -0.011, 0.025, ..., 0.041, -0.069, 0.023]\\n```\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U172'),\n",
       " 156: array('Here is the embedding for the given sentence:\\n\\n\"The US and its allies should take concrete steps to deter Russia from further aggression towards Ukraine\"\\n\\nPlease let me know if you need anything else!',\n",
       "       dtype='<U200'),\n",
       " 157: array('\"NATO should consider offering membership to Ukraine to strengthen its security\"',\n",
       "       dtype='<U80'),\n",
       " 158: array('\"Economic sanctions against Russia may be an effective way to prevent military action in Ukraine\"',\n",
       "       dtype='<U97'),\n",
       " 159: array('Here is the sentence with its corresponding embedding:\\n\\n\"Diplomatic efforts should be intensified to find a peaceful solution to the crisis in Ukraine\"\\n\\nEmbedding:\\n[-0.0775, 0.1514, -0.1411, ..., -0.0339, -0.1492, 0.1446]',\n",
       "       dtype='<U221'),\n",
       " 160: array('Here is the sentence with its corresponding embedding:\\n\\n\"The sovereignty and territorial integrity of Ukraine must be respected by all countries\"\\n\\nEmbedding:\\n[-0.038194, -0.044943, 0.051769, ...] (vector length may vary depending on the model)',\n",
       "       dtype='<U243'),\n",
       " 161: array('\"The conflict in eastern Ukraine has resulted in a significant humanitarian crisis, requiring international aid and support\"',\n",
       "       dtype='<U124'),\n",
       " 162: array('Here is the embedding for the given sentence:\\n\\n\"Ukraine\\'s struggle for democracy and independence deserves the backing of the international community\"\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U190'),\n",
       " 163: array('Here is the embedding for the sentence:\\n\\n\"Russia\\'s annexation of Crimea in 2014 was illegal and violated international law\"\\n\\nLet me know what you need next!',\n",
       "       dtype='<U156'),\n",
       " 164: array(\"Here is the embedding for the given sentence:\\n\\n[-0.06093, -0.03333, 0.02418, ..., 0.04119, -0.01129, 0.05371]\\n\\nNote: The actual embedding vector will be a long sequence of numbers, but I've truncated it here for brevity.\",\n",
       "       dtype='<U220'),\n",
       " 165: array('\"The US and its allies should provide military aid to Ukraine to help it defend itself against Russian aggression\"',\n",
       "       dtype='<U114'),\n",
       " 166: array('\"The international community should hold Russia accountable for its actions in Ukraine, including through targeted sanctions and other measures\"',\n",
       "       dtype='<U144'),\n",
       " 169: array('\"The international community should take action to stop Russia\\'s aggression in Ukraine\"',\n",
       "       dtype='<U87'),\n",
       " 170: array('Here are the embeddings for the given sentence:\\n\\n[[-0.030, 0.044, -0.016, ...], [-0.018, 0.051, -0.011, ...], ..., [0.042, -0.019, 0.013, ...]]\\n\\nThese embeddings represent the semantic meaning of the sentence in a vector space. Each word in the sentence is replaced with its corresponding vector representation, which captures its context-specific meaning.\\n\\nHere\\'s the sentence broken down into individual words with their corresponding embeddings:\\n\\n1. \"US\" : [-0.030, 0.044, -0.016, ...]\\n2. \"support\" : [-0.018, 0.051, -0.011, ...]\\n3. \"for\" : [0.012, -0.035, 0.023, ...]\\n4. \"Ukraine\" : [0.041, -0.025, 0.019, ...]\\n5. \"is\" : [-0.005, 0.017, -0.013, ...]\\n6. \"crucial\" : [0.053, -0.031, 0.029, ...]\\n7. \"for\" : [0.012, -0.035, 0.023, ...]\\n8. \"upholding\" : [-0.021, 0.049, -0.015, ...]\\n9. \"democracy\" : [0.036, -0.022, 0.018, ...]\\n10. \"and\" : [0.008, -0.011, 0.016, ...]\\n11. \"human\" : [-0.012, 0.039, -0.009, ...]\\n12. \"rights\" : [0.025, -0.028, 0.021, ...]\\n13. \"worldwide\" : [0.042, -0.019, 0.013, ...]\\n\\nThese embeddings can be used for various NLP tasks such as text classification, sentiment analysis, and semantic search.',\n",
       "       dtype='<U1120'),\n",
       " 171: array('Here is the embedded sentence:\\n\\n\"The US should lead the international community in holding Russia accountable for its actions in Ukraine\"\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U177'),\n",
       " 172: array('Here is the sentence with its corresponding embedding:\\n\\n\"Congress should approve funding for military aid to Ukraine\"',\n",
       "       dtype='<U117'),\n",
       " 173: None,\n",
       " 174: array('Here is the embedding for the sentence:\\n\\n\"The US and its allies should impose sanctions on Russia for its actions in Ukraine\"\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U165'),\n",
       " 175: array(\"Here are the embeddings for the given sentence:\\n\\n**Sentence Embeddings:**\\n```\\n[-0.0705, -0.0441, 0.0329, ..., -0.0203, 0.0117, -0.0092]\\n```\\n\\nLet me know if you'd like me to generate embeddings using a specific model or have any further requests!\",\n",
       "       dtype='<U245'),\n",
       " 176: array('Here is the sentence with embeddings:\\n\\n\"The US should work with its allies to provide military aid to Ukraine and support its efforts to defend its sovereignty\"\\n\\nEmbeddings:\\n[[-0.06093, 0.03441, -0.03581, ...], \\n [-0.04149, 0.04731, -0.03091, ...], \\n [0.01562, 0.04099, -0.04809, ...], \\n ..., \\n [-0.02515, -0.01039, 0.02417, ...]]\\n\\nPlease note that the embeddings are in a numerical format and represent the semantic meaning of each word in the sentence. The exact values may vary depending on the model used to generate them.',\n",
       "       dtype='<U526'),\n",
       " 177: array('Here is the embedding for the given sentence:\\n\\n\"Russia\\'s aggression in Ukraine threatens the stability of Europe and the world\"\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U167'),\n",
       " 178: array('Here is the embedding for the sentence:\\n\\n[-0.064, 0.142, -0.114, ..., 0.118, -0.174, 0.044]',\n",
       "       dtype='<U91'),\n",
       " 179: array('\"The international community must send a clear message to Russia that its actions in Ukraine are unacceptable and will not be tolerated\"',\n",
       "       dtype='<U136'),\n",
       " 181: array(\"Here is the embedding for the given sentence:\\n\\n[[-0.062, 0.044, -0.038, ..., 0.032, 0.056, 0.098],\\n [-0.048, 0.031, -0.024, ..., 0.011, 0.042, 0.066],\\n [0.035, 0.013, -0.019, ..., 0.017, 0.051, 0.093],\\n ...,\\n [-0.061, 0.039, -0.032, ..., 0.031, 0.058, 0.101],\\n [0.043, 0.016, -0.022, ..., 0.019, 0.053, 0.096]]\\n\\nThis is a 1x768 matrix where each row corresponds to a token in the sentence (in this case, Russia', s, aggression, towards, Ukraine, must, be, confronted) and each column represents a dimension in the embedding space.\",\n",
       "       dtype='<U530'),\n",
       " 182: array('\"The international community has a role in supporting Ukraine\"',\n",
       "       dtype='<U62'),\n",
       " 183: array('Here is the embedding for the sentence:\\n\\n\"Congressional action is needed for Ukraine aid\"\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U129'),\n",
       " 184: array('Here is the sentence with its corresponding embedding:\\n\\n\"Janet Yellen has urged for the passing of the Ukraine aid bill\"\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U160'),\n",
       " 185: array('Here is the embedding for the given sentence:\\n\\n\"The G7 should act together to support Ukraine and hold Russia accountable\"\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U162'),\n",
       " 186: array('Here is the embedding for the given sentence:\\n\\n\"Unity and support from the US and international community are crucial for justice and peace in Ukraine\"\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U191'),\n",
       " 187: array('Here is the embedding for the given sentence:\\n\\n\"It\\'s time for action, not just debate, on the Ukraine aid bill\"\\n\\nEmbedding:\\n[-0.05438281  0.13671875 -0.10253906 ...  0.03344726 -0.01171875\\n  0.04394531]\\n\\nPlease note that embeddings are numerical representations of text in a high-dimensional space, and they can be used as input features for machine learning models. The specific values of the embedding will depend on the language model or embedding algorithm used to generate them.',\n",
       "       dtype='<U483'),\n",
       " 188: array('Here is the sentence embedding for:\\n\\n\"The US must prioritize its foreign policy interests and stand with Ukraine\"\\n\\n[0.03632893, 0.03224441, -0.01234581, ..., 0.04193511, -0.02234519, 0.05123459]\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U234'),\n",
       " 189: array('Here are the embeddings for the given sentence:\\n\\n\"The situation in Ukraine is a matter of human rights and democracy\"\\n\\nEmbeddings:\\n[[0.045509, -0.031994, 0.033454, ..., 0.046879, 0.020512, 0.041024]]\\n\\nNote: The actual embedding values are omitted for brevity. In a real scenario, you would receive the numerical vector representation of the sentence.',\n",
       "       dtype='<U350'),\n",
       " 190: array('Here is the embedding for the given sentence:\\n\\n\"The US should lead the international community in supporting Ukraine\"\\n\\nPlease note that I\\'ll be using a pre-trained language model (e.g., BERT, RoBERTa) to generate the embeddings. If you have any specific requirements or preferences for the model, please let me know!\\n\\nHere are the embeddings:\\n```\\n[-0.0741, 0.0522, -0.0355, ..., -0.0163, 0.0119, 0.0347]\\n```\\nThese are the sentence embeddings, a fixed-size vector representing the semantic meaning of the input sentence. If you need anything else (e.g., token-level embeddings), please ask!',\n",
       "       dtype='<U589'),\n",
       " 191: array('Here is the embedding for the sentence:\\n\\n\"Russia\\'s actions in Ukraine are a threat to peace and stability\"',\n",
       "       dtype='<U106'),\n",
       " 192: array('Here is the embedding for the sentence:\\n\\n\"Congress must not delay in providing aid to Ukraine\"\\n\\nEmbedding:\\n[-0.030149, -0.036509, -0.022493, 0.019306, 0.044949, -0.012709, ...]',\n",
       "       dtype='<U176'),\n",
       " 193: array('Here is the embedding for the given sentence:\\n\\n\"The US has an interest in promoting peace and security in Europe\"\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U153'),\n",
       " 194: array('\"The Kremlin\\'s aggression towards Ukraine is unacceptable and must be stopped\"',\n",
       "       dtype='<U78'),\n",
       " 195: array('Here are the embeddings for the given sentence:\\n\\n[\"Ukraine\", -0.053, -0.046, ...], \\n[\"is\", 0.039, 0.018, ...], \\n[\"facing\", 0.041, -0.016, ...], \\n[\"aggression\", -0.035, 0.056, ...], \\n[\"from\", -0.011, 0.026, ...], \\n[\"Russia\", 0.061, 0.038, ...]\\n\\nNote: The embeddings are represented as a list of lists, where each sublist contains the word and its corresponding vector representation.',\n",
       "       dtype='<U382'),\n",
       " 197: array('Here is the sentence embedding for:\\n\\n\"The US needs to take action and support Ukraine in its time of need\"\\n\\n[-0.05439043, 0.14112012, -0.03369531, ..., 0.04494338, 0.01560938, 0.04211035]',\n",
       "       dtype='<U187'),\n",
       " 198: array('\"There is a need for the international community to unite against Russian aggression\"',\n",
       "       dtype='<U85'),\n",
       " 199: array('Here is the embedding for the given sentence:\\n\\n[\"The\", \"-0.0773, -0.0446, 0.0619, ...],\\n[\"US\", \"0.0454, -0.0122, 0.0111, ...\"],\\n[\"has\", \"-0.0405, 0.0168, -0.0067, ...\"],\\n[\"a\", \"-0.0354, -0.0153, 0.0319, ...\"],\\n[\"crucial\", \"0.1432, -0.0701, 0.0426, ...\"],\\n[\"role\", \"0.1155, 0.0408, -0.0257, ...\"],\\n[\"to\", \"-0.0533, 0.0269, -0.0145, ...\"],\\n[\"play\", \"0.1012, 0.0444, -0.0111, ...\"],\\n[\"in\", \"-0.0564, 0.0328, -0.0176, ...\"],\\n[\"supporting\", \"0.1337, -0.0519, 0.0385, ...\"],\\n[\"Ukraine\\'s\", \"0.1552, -0.0801, 0.0553, ...\"],\\n[\"efforts\", \"0.1218, 0.0439, -0.0211, ...\"],\\n[\"to\", \"-0.0533, 0.0269, -0.0145, ...\"],\\n[\"defend\", \"0.1404, -0.0463, 0.0247, ...\"],\\n[\"its\", \"-0.0412, 0.0199, -0.0104, ...\"],\\n[\"sovereignty\", \"0.1841, -0.0605, 0.0438, ...\"]]\\n\\nNote: The embeddings are represented as a list of lists, where each inner list contains the word and its corresponding vector representation. The vector values are truncated for brevity.',\n",
       "       dtype='<U924'),\n",
       " 200: array('Here is the embedding for the given sentence:\\n\\n\"Janet Yellen, the US Treasury Secretary, urges Congress to pass the Ukraine aid bill\"\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U173'),\n",
       " 201: array('Here are the embeddings for the sentence:\\n\\n\"Congressional action is necessary to support Ukraine and hold Russia accountable\"\\n\\nEmbeddings:\\n```\\n[[-0.0327, -0.0164, 0.0431, ..., -0.0119, -0.0355, 0.0243],\\n [-0.0398, 0.0129, 0.0547, ..., -0.0152, -0.0441, 0.0335],\\n [0.0114, 0.0303, 0.0198, ..., 0.0311, 0.0531, -0.0169],\\n ...,\\n [-0.0245, 0.0401, -0.0182, ..., 0.0267, 0.0051, -0.0503],\\n [0.0456, -0.0098, 0.0291, ..., -0.0214, 0.0639, 0.0045]]\\n```\\nLet me know if you need anything else!',\n",
       "       dtype='<U484'),\n",
       " 202: array('Here is the sentence with its corresponding embedding:\\n\\n\"The G7 must act together to ensure that aid reaches Ukraine\"\\n\\nEmbedding:\\n[-0.030593, -0.04539, 0.04147, ..., 0.03615, -0.04434, 0.03412]\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U233'),\n",
       " 203: array('Here is the embedding for the given sentence:\\n\\n Standing together with Ukraine is crucial for upholding human rights peace and democracy worldwide',\n",
       "       dtype='<U146'),\n",
       " 204: array('Here is the embedding for the sentence:\\n\\n\"The aid bill must be passed urgently to provide support for Ukraine\"\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U150'),\n",
       " 205: array('Here is the sentence with its corresponding embedding:\\n\\n\"Debate has ended, and it\\'s time for action to be taken\"\\n\\n[Embedding: -0.0541, 0.0424, 0.0613, ..., -0.0169, 0.0092, 0.0115]\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U220'),\n",
       " 206: array('\"Unity and support from the US and the international community are crucial for justice and peace in Ukraine\"',\n",
       "       dtype='<U108'),\n",
       " 207: array('Here is the embedding for the sentence:\\n\\n\"The US should provide Ukraine with more military aid\"\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U135'),\n",
       " 208: array('Here are the embeddings for the sentence:\\n\\n\"Russia is blocking vital supplies from reaching Ukraine\"\\n\\nEmbeddings:\\n[-0.038194, -0.042951, 0.044921, ..., 0.032809, -0.023489, 0.011719]',\n",
       "       dtype='<U182'),\n",
       " 209: array('Here is the embedding for the given sentence:\\n\\n\"The conflict in Ukraine threatens regional stability\"\\n\\nNote: I\\'m using a pre-trained language model to generate the embeddings. If you need specific details about the model or the embedding format, please let me know!',\n",
       "       dtype='<U265'),\n",
       " 210: array('\"Ukraine needs international support to defend itself against Russian aggression\"',\n",
       "       dtype='<U81'),\n",
       " 211: array('Here is the embedding for the given sentence:\\n\\n\"The US and its allies should increase sanctions on Russia to change its behavior towards Ukraine\"\\n\\n Embedding:\\n[-0.016144, 0.013811, -0.011342, ..., -0.005344, -0.010375, 0.011219]',\n",
       "       dtype='<U228'),\n",
       " 212: array('Here are the embeddings for the given sentence:\\n\\n\"The humanitarian situation in Ukraine is worsening due to the ongoing conflict\"\\n\\nEmbeddings:\\n```\\n[-0.038194, -0.042453, 0.049135, ..., 0.024789, 0.036114, 0.009812]\\n```',\n",
       "       dtype='<U218'),\n",
       " 213: array('Here is the embedding for the given sentence:\\n\\n\"The international community must take action to ensure peace and justice in Ukraine\"\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U172'),\n",
       " 215: array('\"The US should lead efforts to resolve the conflict in Ukraine peacefully and diplomatically\"',\n",
       "       dtype='<U93'),\n",
       " 216: array('Here is the embedding for the given sentence:\\n\\n\"The situation in Ukraine requires immediate attention from the international community\"\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U175'),\n",
       " 217: array('Here is the embedding for the given sentence:\\n\\n\"The US and its allies should provide military aid to Ukraine to help deter further Russian aggression\"\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U190'),\n",
       " 218: array('Here is the sentence with its embedding:\\n\\n\"The conflict in Ukraine has resulted in a large number of civilian casualties and displaced persons\"\\n\\nEmbedding:\\n[-0.071, 0.044, -0.053, ..., 0.019, 0.011, -0.021] (768 dimensions)',\n",
       "       dtype='<U223'),\n",
       " 219: array('Here is the embedding for the given sentence:\\n\\n\"The international community should hold Russia accountable for its actions in Ukraine\"\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U174'),\n",
       " 220: array('\"The situation in Ukraine is a test of the West\\' s resolve to uphold democratic values and principles\"',\n",
       "       dtype='<U102'),\n",
       " 221: array('\"The US should provide Ukraine with military aid\"', dtype='<U49'),\n",
       " 222: array('Here are the embeddings for the given sentence:\\n\\n[\"Continued\", -0.05, -0.21]\\n[\"Russian\", -0.11, 0.15]\\n[\"aggression\", -0.13, 0.22]\\n[\"towards\", -0.24, -0.16]\\n[\"Ukraine\", -0.33, 0.39]\\n[\"is\", -0.28, -0.35]\\n[\"a\", -0.34, -0.18]\\n[\"threat\", -0.17, 0.14]\\n[\"to\", -0.19, -0.25]\\n[\"international\", -0.26, 0.05]\\n[\"peace\", 0.01, -0.31]\\n[\"and\", -0.15, -0.29]\\n[\"security\", -0.12, 0.04]\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U408'),\n",
       " 223: array('Here is the embedding for the given sentence:\\n\\n[-0.0305, -0.0364, 0.0488, ..., 0.0231, -0.0556, 0.0719]\\n\\nPlease let me know if you need anything else!',\n",
       "       dtype='<U150'),\n",
       " 224: array('Here is the sentence with its corresponding embedding:\\n\\n\"US foreign policy should prioritize supporting democratic allies like Ukraine against authoritarian regimes like Russia\"\\n\\nEmbedding:\\n[-0.038194, -0.044921, 0.035156, ..., 0.023459, -0.011719, 0.041991]\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U298'),\n",
       " 225: array('\"Congressional inaction on Ukraine aid risks emboldening Putin and undermining US credibility as a global leader\"',\n",
       "       dtype='<U113'),\n",
       " 227: array('Here is the embedding for the sentence:\\n\\n\"Russia\\'s actions in Ukraine are a threat to international security\"\\n\\nEmbedding: [-0.054, 0.113, -0.144, ..., -0.045, 0.102]',\n",
       "       dtype='<U165'),\n",
       " 228: array('\"The US and the international community should take action to hold Russia accountable for its actions\"',\n",
       "       dtype='<U102'),\n",
       " 230: array(\"Here are the embeddings for the given sentence:\\n\\n`['the', 'situation', 'in', 'ukraine', 'is', 'critical', 'and', 'requires', 'immediate', 'attention']`\\n\\n**Word Embeddings (using Word2Vec):**\\n\\n1. the: [-0.011, 0.024, -0.032, ...]\\n2. situation: [0.035, -0.041, 0.019, ...]\\n3. in: [-0.023, 0.031, -0.015, ...]\\n4. ukraine: [0.051, -0.033, 0.047, ...]\\n5. is: [0.012, -0.011, -0.027, ...]\\n6. critical: [0.067, -0.039, 0.053, ...]\\n7. and: [-0.017, 0.021, -0.019, ...]\\n8. requires: [0.043, -0.029, 0.037, ...]\\n9. immediate: [0.059, -0.035, 0.049, ...]\\n10. attention: [0.071, -0.041, 0.063, ...]\\n\\n**Sentence Embedding (using SentenceTransformers):**\\n\\n[-0.021, 0.031, -0.019, ..., 0.051, -0.033, 0.047]\",\n",
       "       dtype='<U692'),\n",
       " 231: array('\"The US should prioritize its foreign policy goals to include supporting Ukraine\"',\n",
       "       dtype='<U81'),\n",
       " 232: array('\"The conflict in Ukraine has regional implications and requires a coordinated response\"',\n",
       "       dtype='<U87'),\n",
       " 233: array('Here is the embedded sentence:\\n\\n\"The G7 should take the lead in providing aid and support to Ukraine\"\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U141'),\n",
       " 234: array('\"The international community must uphold human rights, peace, and democracy in Ukraine\"',\n",
       "       dtype='<U87'),\n",
       " 235: array('Here is the embedding for the given sentence:\\n\\n\"The US should work with its allies to manage risks and ensure stability in the region\"\\n\\nEmbedding:\\n[-0.06034375, 0.01171875, 0.04492188, ..., -0.04101562, 0.03613281, 0.05322266]\\n\\nLet me know if you need anything else!',\n",
       "       dtype='<U266'),\n",
       " 236: array('Here are the embeddings for the given sentence:\\n\\n`[\"the\", -0.052, -0.342], [\"time\", -0.204, 0.234], [\"for\", -0.138, -0.242], [\"debate\", -0.194, -0.102], [\"is\", -0.108, -0.166], [\"over;\", -0.226, -0.278], [\"it\\'s\", -0.146, -0.206], [\"time\", -0.204, 0.234], [\"for\", -0.138, -0.242], [\"action\", -0.106, 0.15], [\"to\", -0.114, -0.198], [\"support\", -0.172, 0.06], [\"Ukraine\", -0.182, -0.122]]`\\n\\nPlease note that the embeddings are in the format of `[word, x-coordinate, y-coordinate]`. The x and y coordinates represent the word\\'s position in a high-dimensional vector space where semantically similar words are closer together.',\n",
       "       dtype='<U621'),\n",
       " 237: array('Here are the embeddings for the sentence:\\n\\n\"Urgent aid is needed to help Ukraine defend against Russian aggression\"\\n\\nPlease let me know what kind of embedding you need (e.g. word-level, sentence-level, specific library like BERT/RoBERTa/etc.) and I\\'ll provide them accordingly.',\n",
       "       dtype='<U277'),\n",
       " 238: array('\"Justice and peace in Ukraine are dependent on the unity and support of the international community\"',\n",
       "       dtype='<U100')}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_llama3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...the prompt clearly failed..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:34<00:00,  1.75s/it]\n"
     ]
    }
   ],
   "source": [
    "#what if we add delimitters to the prompt?:\n",
    "\n",
    "\n",
    "output_llama3: typing.Dict[str, np.ndarray] = {}\n",
    "name = \"embed_llama3\"\n",
    "template = 'You help me get embeddings for a sentence. I provide you a with a context within []-square brackets and a sentence within <>-chevrons and you reply only with that exact sentence marked with the chevrons. Context = ['\n",
    "\n",
    "for index, row in tqdm.tqdm(arguments_df[5:25].iterrows(), total=len(arguments_df[5:25])):\n",
    "    context = 'arguments about ' + row[\"label\"]\n",
    "    sentence = row[\"arguments\"]\n",
    "    try: \n",
    "        output = np.array(requests.post(\n",
    "            'https://inf.cl.uni-trier.de/',\n",
    "            json={'model': MODEL, 'prompt': template + context + ']; Sentence: <' + sentence + '>'}\n",
    "            ).json()[\"response\"])\n",
    "    except Exception as _e:\n",
    "        logging.warning(_e)\n",
    "        output = None\n",
    "    \n",
    "    if name=='embed_llama3':\n",
    "        output_llama3[index] = output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: array('<\"Mental health should be treated equally to physical health in healthcare coverage\">',\n",
       "       dtype='<U85'),\n",
       " 6: array('< \"The pharmaceutical industry has too much influence over healthcare policy\">',\n",
       "       dtype='<U78'),\n",
       " 7: array('< \"Telemedicine is a crucial innovation for improving access to care\">',\n",
       "       dtype='<U70'),\n",
       " 8: array('<\"Preventative care measures can reduce overall healthcare costs\">',\n",
       "       dtype='<U66'),\n",
       " 9: array('< \"Chronic disease management is often neglected in current healthcare models\" >',\n",
       "       dtype='<U80'),\n",
       " 10: array('< \"Rural communities face unique challenges in accessing quality healthcare\">',\n",
       "       dtype='<U77'),\n",
       " 11: array('< \"Health disparities exist along racial and ethnic lines, requiring targeted solutions\">',\n",
       "       dtype='<U89'),\n",
       " 12: array('<\"The COVID-19 pandemic has highlighted the importance of a robust public health infrastructure\">',\n",
       "       dtype='<U97'),\n",
       " 13: array('< \"Greater investment in medical research is needed to address persistent health issues\" >',\n",
       "       dtype='<U90'),\n",
       " 15: array('<\"The current healthcare system prioritizes profits over people\">',\n",
       "       dtype='<U65'),\n",
       " 17: array('< \"High costs of healthcare prevent many people from receiving necessary treatments\">',\n",
       "       dtype='<U85'),\n",
       " 18: array('<\"Pre--existing conditions should not affect one\\'s ability to receive healthcare coverage\">',\n",
       "       dtype='<U91'),\n",
       " 19: array('<\"Mental health should be treated with the same importance as physical health\">',\n",
       "       dtype='<U79'),\n",
       " 21: array('< Telemedicine can improve access to care, especially in rural areas >',\n",
       "       dtype='<U70'),\n",
       " 22: array('<\"Preventive care is crucial for maintaining overall health and reducing healthcare costs\">',\n",
       "       dtype='<U91'),\n",
       " 23: array('< \"Chronic conditions require ongoing, often expensive treatments\" >',\n",
       "       dtype='<U68'),\n",
       " 24: array('< A single-payer system could simplify healthcare administration and lower costs >',\n",
       "       dtype='<U82'),\n",
       " 25: array('< \"Healthcare should be viewed as a public good, not a commodity\">',\n",
       "       dtype='<U66'),\n",
       " 28: array('< \"High costs of healthcare lead to medical debt and bankruptcy\">',\n",
       "       dtype='<U65'),\n",
       " 29: array('<\"Pre--existing conditions should not affect healthcare coverage\">',\n",
       "       dtype='<U66')}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_llama3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "much better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:52<00:00,  2.61s/it]\n"
     ]
    }
   ],
   "source": [
    "output_llama3: typing.Dict[str, np.ndarray] = {}\n",
    "name = \"embed_llama3\"\n",
    "template = 'You help me get embeddings for a sentence. I provide you a with a context within []-square brackets and a sentence within <>-chevrons and you reply only with that exact sentence marked with the chevrons. Context = ['\n",
    "\n",
    "for index, row in tqdm.tqdm(arguments_df[5:25].iterrows(), total=len(arguments_df[5:25])):\n",
    "    context = 'viewpoints extracted from tweets'\n",
    "    sentence = row[\"arguments\"]\n",
    "    try: \n",
    "        output = np.array(requests.post(\n",
    "            'https://inf.cl.uni-trier.de/',\n",
    "            json={'model': MODEL, 'prompt': template + context + ']; Sentence: <' + sentence + '>'}\n",
    "            ).json()[\"response\"])\n",
    "    except Exception as _e:\n",
    "        logging.warning(_e)\n",
    "        output = None\n",
    "    \n",
    "    if name=='embed_llama3':\n",
    "        output_llama3[index] = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5: array('< \"Mental health should be treated equally to physical health in healthcare coverage\">',\n",
       "       dtype='<U86'),\n",
       " 6: array('< \"The pharmaceutical industry has too much influence over healthcare policy\">',\n",
       "       dtype='<U78'),\n",
       " 7: array('< \"Telemedicine is a crucial innovation for improving access to care\">',\n",
       "       dtype='<U70'),\n",
       " 8: array('<\"Preventative care measures can reduce overall healthcare costs>',\n",
       "       dtype='<U65'),\n",
       " 9: array('< \"Chronic disease management is often neglected in current healthcare models\">',\n",
       "       dtype='<U79'),\n",
       " 10: array('<\"Rural communities face unique challenges in accessing quality healthcare\">',\n",
       "       dtype='<U76'),\n",
       " 11: array('< \"Health disparities exist along racial and ethnic lines, requiring targeted solutions\">',\n",
       "       dtype='<U89'),\n",
       " 12: array('< \"The COVID-19 pandemic has highlighted the importance of a robust public health infrastructure\">',\n",
       "       dtype='<U98'),\n",
       " 13: array('< \"Greater investment in medical research is needed to address persistent health issues\">',\n",
       "       dtype='<U89'),\n",
       " 15: array('< \"The current healthcare system prioritizes profits over people\">',\n",
       "       dtype='<U66'),\n",
       " 17: array('< \"High costs of healthcare prevent many people from receiving necessary treatments\">',\n",
       "       dtype='<U85'),\n",
       " 18: array('<\"Pre-Existing Conditions Should Not Affect One\\'s Ability To Receive Healthcare Coverage\">',\n",
       "       dtype='<U90'),\n",
       " 19: array('<\"Mental health should be treated with the same importance as physical health\">',\n",
       "       dtype='<U79'),\n",
       " 21: array('< \"Telemedicine can improve access to care, especially in rural areas\">',\n",
       "       dtype='<U71'),\n",
       " 22: array('< \"Preventive care is crucial for maintaining overall health and reducing healthcare costs\">',\n",
       "       dtype='<U92'),\n",
       " 23: array('< \"Chronic conditions require ongoing, often expensive treatments\">',\n",
       "       dtype='<U67'),\n",
       " 24: array('< \"A single-payer system could simplify healthcare administration and lower costs\">',\n",
       "       dtype='<U83'),\n",
       " 25: array('< \"Healthcare should be viewed as a public good, not a commodity\">',\n",
       "       dtype='<U66'),\n",
       " 28: array('< \"High costs of healthcare lead to medical debt and bankruptcy\">',\n",
       "       dtype='<U65'),\n",
       " 29: array('< \"Pre-existing conditions should not affect healthcare coverage\">',\n",
       "       dtype='<U66')}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_llama3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DefiningDebateQuality",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
