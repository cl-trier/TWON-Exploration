{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2032.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2032.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2032.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_2648\\2092300082.py\", line 5, in <module>\n",
      "    import src\n",
      "  File \"c:\\Users\\sstolwi\\Github\\TWON-Metrics\\src\\__init__.py\", line 1, in <module>\n",
      "    from .hf_classify import HFClassify\n",
      "  File \"c:\\Users\\sstolwi\\Github\\TWON-Metrics\\src\\hf_classify.py\", line 5, in <module>\n",
      "    import torch\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\torch\\__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\torch\\functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\torch\\nn\\__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\torch\\nn\\modules\\__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import typing\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import config\n",
    "import src\n",
    "import requests\n",
    "import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "import cltrier_lib as lib\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score, classification_report\n",
    "import krippendorff\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = config.Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('interactivity_acknowledgement', WindowsPath('data/prompts_classify/interactivity_acknowledgement.json')), ('political_ideology', WindowsPath('data/prompts_classify/political_ideology.json')), ('political_ideology_GER', WindowsPath('data/prompts_classify/political_ideology_GER.json')), ('political_ideology_GER2', WindowsPath('data/prompts_classify/political_ideology_GER2.json')), ('political_ideology_GER3', WindowsPath('data/prompts_classify/political_ideology_GER3.json')), ('political_ideology_US', WindowsPath('data/prompts_classify/political_ideology_US.json')), ('political_negativity', WindowsPath('data/prompts_classify/political_negativity.json')), ('rationality_background_info', WindowsPath('data/prompts_classify/rationality_background_info.json')), ('rationality_external_evidence', WindowsPath('data/prompts_classify/rationality_external_evidence.json')), ('rationality_reasoning', WindowsPath('data/prompts_classify/rationality_reasoning.json')), ('rationality_topic_relevance', WindowsPath('data/prompts_classify/rationality_topic_relevance.json'))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG.prompt_classify_files.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL: str = 'llama3.1:70b-instruct-q6_K' # options: 'gemma:7b-instruct-q6_K', 'gemma2:27b-instruct-q6_K', 'llama3.1:8b-instruct-q6_K', 'llama3.1:70b-instruct-q6_K', 'mistral:7b-instruct-v0.3-q6_K', 'mistral-large:123b-instruct-2407-q6_K', 'mixtral:8x7b-instruct-v0.1-q6_K', 'mixtral:8x22b-instruct-v0.1-q6_K', 'phi3:14b-medium-128k-instruct-q6_K' or 'qwen2:72b-instruct-q6_K'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pol_label</th>\n",
       "      <th>neg_label</th>\n",
       "      <th>neg3_label</th>\n",
       "      <th>ideo_label</th>\n",
       "      <th>GPT_Pol1</th>\n",
       "      <th>GPT_Pol2</th>\n",
       "      <th>GPT_Neg1</th>\n",
       "      <th>GPT_Neg2</th>\n",
       "      <th>GPT_Neg_3Way1</th>\n",
       "      <th>GPT_Neg_3Way2</th>\n",
       "      <th>GPT_Ideo1</th>\n",
       "      <th>GPT_Ideo2</th>\n",
       "      <th>Pol_Recon</th>\n",
       "      <th>Neg_Recon</th>\n",
       "      <th>Neg3_Recon</th>\n",
       "      <th>Ideo_Recon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@thatleechi17 @KlemmChr @AndiScheuer @victorperli Ich würde sagen Sie vergleichen maximal kenntn...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Glauben Sie nur nicht, dass Menschen die nicht dem Bundestag angehören, nichts zu sagen hätten. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Das ist ja das Mindeste. \\r\\n\\r\\nDass das aber das alles möglich ist trotz der Situation der Uig...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Challen81690499 @c_lindner @rbrinkhaus @NowaboFM Na na na... TW</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ich sage: #DANKE!!!\\r\\nhttps://t.co/0pVneqXwTC\\r\\n#afd #btw #btw17 #btw2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>@rehbergkk Ihr Denkfehler, in der Tat!</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>Die Bundesregierung spricht von „Einwanderung in die Sozialsysteme“ und erteilt gleichzeitig Arb...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>Im #EU Parlament sitzen teilweise echt Verrückte https://t.co/wy2v0pYWLB</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>@StBrandner @M_HarderKuehnel Du natürlich! &lt;U+0001F60E&gt;&lt;U+0001F600&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>@har41637914 @Gothdad Nein. Das ist eine ganz falsche Wahrnehmung. Es gibt auch keine derartigen...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                    text  \\\n",
       "0    @thatleechi17 @KlemmChr @AndiScheuer @victorperli Ich würde sagen Sie vergleichen maximal kenntn...   \n",
       "1    Glauben Sie nur nicht, dass Menschen die nicht dem Bundestag angehören, nichts zu sagen hätten. ...   \n",
       "2    Das ist ja das Mindeste. \\r\\n\\r\\nDass das aber das alles möglich ist trotz der Situation der Uig...   \n",
       "3                                       @Challen81690499 @c_lindner @rbrinkhaus @NowaboFM Na na na... TW   \n",
       "4                            Ich sage: #DANKE!!!\\r\\nhttps://t.co/0pVneqXwTC\\r\\n#afd #btw #btw17 #btw2017   \n",
       "..                                                                                                   ...   \n",
       "695                                                               @rehbergkk Ihr Denkfehler, in der Tat!   \n",
       "696  Die Bundesregierung spricht von „Einwanderung in die Sozialsysteme“ und erteilt gleichzeitig Arb...   \n",
       "697                             Im #EU Parlament sitzen teilweise echt Verrückte https://t.co/wy2v0pYWLB   \n",
       "698                                  @StBrandner @M_HarderKuehnel Du natürlich! <U+0001F60E><U+0001F600>   \n",
       "699  @har41637914 @Gothdad Nein. Das ist eine ganz falsche Wahrnehmung. Es gibt auch keine derartigen...   \n",
       "\n",
       "     pol_label  neg_label  neg3_label  ideo_label  GPT_Pol1  GPT_Pol2  \\\n",
       "0            1          1           0           1         1         1   \n",
       "1            1          0           1           1         1         1   \n",
       "2            1          1           0           1         1         1   \n",
       "3            0          0           1           1         1         0   \n",
       "4            1          0           2           2         1         1   \n",
       "..         ...        ...         ...         ...       ...       ...   \n",
       "695          0          1           0           1         0         0   \n",
       "696          1          1           0           0         1         1   \n",
       "697          1          1           0           1         1         1   \n",
       "698          0          0           1           1         0         0   \n",
       "699          0          1           0           1         0         0   \n",
       "\n",
       "     GPT_Neg1  GPT_Neg2  GPT_Neg_3Way1  GPT_Neg_3Way2  GPT_Ideo1  GPT_Ideo2  \\\n",
       "0           1         1              0              0          1          1   \n",
       "1           0         0              1              1          1          1   \n",
       "2           1         1              0              0          0          0   \n",
       "3           0         0              1              1          1          1   \n",
       "4           0         0              2              2          2          2   \n",
       "..        ...       ...            ...            ...        ...        ...   \n",
       "695         1         1              0              0          1          1   \n",
       "696         0         1              0              0          0          0   \n",
       "697         1         1              0              0          1          1   \n",
       "698         0         0              2              2          1          1   \n",
       "699         1         1              0              0          1          1   \n",
       "\n",
       "     Pol_Recon  Neg_Recon  Neg3_Recon  Ideo_Recon  \n",
       "0            1          1           0           1  \n",
       "1            1          0           1           1  \n",
       "2            1          1           0           0  \n",
       "3            0          0           1           1  \n",
       "4            1          0           2           2  \n",
       "..         ...        ...         ...         ...  \n",
       "695          0          1           0           1  \n",
       "696          1          1           0           0  \n",
       "697          1          1           0           1  \n",
       "698          0          0           2           1  \n",
       "699          0          1           0           1  \n",
       "\n",
       "[700 rows x 17 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "MHdata: pd.DataFrame = pd.read_csv('data/MH_BClemm_data/germany_val_all.csv') \n",
    "MHdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change options to low temperature (0,1) and compare result:\n",
    "options_low = \"\"\"\n",
    "seed: 42\n",
    "temperature: 0.1\n",
    "\"\"\"\n",
    "\n",
    "options_low = yaml.safe_load(options_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "classifying political_ideology: 100%|██████████| 700/700 [49:31<00:00,  4.24s/it]  \n"
     ]
    }
   ],
   "source": [
    "#the _label variables are the reconciled and definitive annotation values for the variables\n",
    "#what does Llama3.1 predict for political orientation?\n",
    "predictions: typing.Dict[str, pd.Series] = {\n",
    "    label: (\n",
    "        src.PromptClassify\n",
    "        .from_json(path)\n",
    "        (MHdata[\"text\"], MODEL, options=options_low)\n",
    "    )\n",
    "    for label, path in CFG.prompt_classify_files.items() if label == 'political_ideology'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'political_ideology': 0           neutral\n",
       " 1           neutral\n",
       " 2           liberal\n",
       " 3           neutral\n",
       " 4      conservative\n",
       "            ...     \n",
       " 695         neutral\n",
       " 696         liberal\n",
       " 697    conservative\n",
       " 698         neutral\n",
       " 699         neutral\n",
       " Name: political_ideology, Length: 700, dtype: object}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions #note that these are based on llama3.1:70b-instruct-q6_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "political_ideology\n",
      "neutral         474\n",
      "liberal         145\n",
      "conservative     81\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#join to the dataset:\n",
    "for _, preds in predictions.items():\n",
    "    print(preds.value_counts())\n",
    "    print(\"-\" * 42)\n",
    "    # Convert Series to DataFrame\n",
    "    preds_df = preds.to_frame()\n",
    "    # Rename the column in preds_df to 'Llama31_ideology'\n",
    "    preds_df = preds_df.rename(columns={preds_df.columns[0]: 'Llama31_ideology_low'})\n",
    "    MHdata = MHdata.join(preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "political_ideology\n",
      "neutral         454\n",
      "liberal         159\n",
      "conservative     87\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#join to the dataset:\n",
    "for _, preds in predictions.items():\n",
    "    print(preds.value_counts())\n",
    "    print(\"-\" * 42)\n",
    "    # Convert Series to DataFrame\n",
    "    preds_df = preds.to_frame()\n",
    "    # Rename the column in preds_df to 'Llama31_ideology'\n",
    "    preds_df = preds_df.rename(columns={preds_df.columns[0]: 'Llama31_ideology'})\n",
    "    MHdata = MHdata.join(preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#missing values in low temperature ideology:\n",
    "MHdata.Llama31_ideology_low.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MHdata.Llama31_ideology.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama31_ideology</th>\n",
       "      <th>conservative</th>\n",
       "      <th>liberal</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ideo_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>94</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>56</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama31_ideology  conservative  liberal  neutral\n",
       "ideo_label                                      \n",
       "0                            4       94       17\n",
       "1                           26       56      421\n",
       "2                           57        9       16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#does Llama political ideology differ from manual political ideology ?\n",
    "#make a crosstab to see if there are differences:\n",
    "pd.crosstab(MHdata.loc[:, 'ideo_label'], MHdata.loc[:, 'Llama31_ideology'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama31_ideology_low</th>\n",
       "      <th>conservative</th>\n",
       "      <th>liberal</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ideo_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>47</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama31_ideology_low  conservative  liberal  neutral\n",
       "ideo_label                                          \n",
       "0                                3       91       21\n",
       "1                               23       47      433\n",
       "2                               55        7       20"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#does Llama political ideology low differ from manual political ideology ?\n",
    "#make a crosstab to see if there are differences:\n",
    "pd.crosstab(MHdata.loc[:, 'ideo_label'], MHdata.loc[:, 'Llama31_ideology_low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the political ideology labels to numbers:\n",
    "MHdata['Llama_ideo_score'] = MHdata['Llama31_ideology'].map({'liberal': 0, 'neutral': 1, 'conservative': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "MHdata['Llama_ideo_score_low'] = MHdata['Llama31_ideology_low'].map({'liberal': 0, 'neutral': 1, 'conservative': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama_ideo_score</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ideo_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>421</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama_ideo_score   0    1   2\n",
       "ideo_label                   \n",
       "0                 94   17   4\n",
       "1                 56  421  26\n",
       "2                  9   16  57"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(MHdata.loc[:, 'ideo_label'], MHdata.loc[:, 'Llama_ideo_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama_ideo_score</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT_Ideo1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115</td>\n",
       "      <td>49</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>381</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama_ideo_score    0    1   2\n",
       "GPT_Ideo1                     \n",
       "0                 115   49  11\n",
       "1                  29  381  13\n",
       "2                  15   24  63"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#and how does Llama3.1 perform compared to GPT\n",
    "#make a crosstab to see if there are differences:\n",
    "pd.crosstab(MHdata.loc[:, 'GPT_Ideo1'], MHdata.loc[:, 'Llama_ideo_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_human_column_pairs = [\n",
    "    (\"ideo_label\", \"Llama_ideo_score\"),\n",
    "    (\"ideo_label\", \"GPT_Ideo1\")\n",
    "# (\"TopicRelevance\", \"rationality_topic_relevance\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.82      0.69       115\n",
      "           1       0.93      0.84      0.88       503\n",
      "           2       0.66      0.70      0.67        82\n",
      "\n",
      "    accuracy                           0.82       700\n",
      "   macro avg       0.72      0.78      0.75       700\n",
      "weighted avg       0.84      0.82      0.82       700\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.6206909689737066\n",
      "krippendorf(ideo_label): 0.6192039671924076\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.92      0.73       115\n",
      "           1       0.96      0.81      0.88       503\n",
      "           2       0.69      0.85      0.76        82\n",
      "\n",
      "    accuracy                           0.83       700\n",
      "   macro avg       0.75      0.86      0.79       700\n",
      "weighted avg       0.87      0.83      0.84       700\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.6679290188227158\n",
      "krippendorf(ideo_label): 0.6646610493129983\n"
     ]
    }
   ],
   "source": [
    "print(\"Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\")\n",
    "\n",
    "for human_col, llm_col in llm_human_column_pairs:\n",
    "    subset = MHdata[[human_col, llm_col]].dropna()\n",
    "    human = subset[human_col].tolist()\n",
    "    llm = subset[llm_col].tolist()\n",
    "    \n",
    "    print(\"---\")\n",
    "    print(f\"{classification_report(human, llm)}\")\n",
    "    print(f\"cohen_kappa_score({human_col}): {cohen_kappa_score(human, llm)}\")\n",
    "    print(f\"krippendorf({human_col}): {krippendorff.alpha(np.array([human, llm]), level_of_measurement=\"nominal\")}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Llama did ok, but GPT4 did better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low temperature Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.79      0.70       115\n",
      "           1       0.91      0.86      0.89       503\n",
      "           2       0.68      0.67      0.67        82\n",
      "\n",
      "    accuracy                           0.83       700\n",
      "   macro avg       0.74      0.77      0.75       700\n",
      "weighted avg       0.84      0.83      0.83       700\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.6289335453713074\n",
      "krippendorf(ideo_label): 0.6284897871397188\n"
     ]
    }
   ],
   "source": [
    "llm_human_column_pairs = [\n",
    "    (\"ideo_label\", \"Llama_ideo_score_low\"),\n",
    "#   (\"ideo_label\", \"GPT_Ideo1\")\n",
    "# (\"TopicRelevance\", \"rationality_topic_relevance\"),\n",
    "]\n",
    "print(\"low temperature Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\")\n",
    "\n",
    "for human_col, llm_col in llm_human_column_pairs:\n",
    "    subset = MHdata[[human_col, llm_col]].dropna()\n",
    "    human = subset[human_col].tolist()\n",
    "    llm = subset[llm_col].tolist()\n",
    "    \n",
    "    print(\"---\")\n",
    "    print(f\"{classification_report(human, llm)}\")\n",
    "    print(f\"cohen_kappa_score({human_col}): {cohen_kappa_score(human, llm)}\")\n",
    "    print(f\"krippendorf({human_col}): {krippendorff.alpha(np.array([human, llm]), level_of_measurement=\"nominal\")}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#very similar performance for low temperature english prompt of Llama3.1 compared to default temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "classifying political_ideology_GER: 100%|██████████| 700/700 [06:46<00:00,  1.72it/s]\n"
     ]
    }
   ],
   "source": [
    "#what if we translate the prompt first \n",
    "#what does Llama3.1 predict for political orientation?\n",
    "predictions: typing.Dict[str, pd.Series] = {\n",
    "    label: (\n",
    "        src.PromptClassify\n",
    "        .from_json(path)\n",
    "        (MHdata[\"text\"], model=MODEL, options=options_low)\n",
    "    )\n",
    "    for label, path in CFG.prompt_classify_files.items() if label == 'political_ideology_GER'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "political_ideology_GER\n",
      "Mitte     564\n",
      "Links      83\n",
      "Rechts     38\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#join to the dataset:\n",
    "for _, preds in predictions.items():\n",
    "    print(preds.value_counts())\n",
    "    print(\"-\" * 42)\n",
    "    # Convert Series to DataFrame\n",
    "    preds_df = preds.to_frame()\n",
    "    # Rename the column in preds_df to 'Llama31_ideology'\n",
    "    preds_df = preds_df.rename(columns={preds_df.columns[0]: 'Llama31_ideo_GER_low'})\n",
    "    MHdata = MHdata.join(preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "political_ideology_GER\n",
      "Mitte     505\n",
      "Links      97\n",
      "Rechts     48\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#join to the dataset:\n",
    "for _, preds in predictions.items():\n",
    "    print(preds.value_counts())\n",
    "    print(\"-\" * 42)\n",
    "    # Convert Series to DataFrame\n",
    "    preds_df = preds.to_frame()\n",
    "    # Rename the column in preds_df to 'Llama31_ideology'\n",
    "    preds_df = preds_df.rename(columns={preds_df.columns[0]: 'Llama31_ideo_GER'})\n",
    "    MHdata = MHdata.join(preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MHdata.Llama31_ideo_GER.isna().sum()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(15)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MHdata.Llama31_ideo_GER_low.isna().sum()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the political ideology labels to numbers:\n",
    "MHdata['Llama_ideoGER_score'] = MHdata['Llama31_ideo_GER'].map({'Links': 0, 'Mitte': 1, 'Rechts': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the political ideology labels to numbers:\n",
    "MHdata['Llama_ideoGER_score_low'] = MHdata['Llama31_ideo_GER_low'].map({'Links': 0, 'Mitte': 1, 'Rechts': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama_ideoGER_score</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ideo_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>421</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama_ideoGER_score  0.0  1.0  2.0\n",
       "ideo_label                        \n",
       "0                     59   51    0\n",
       "1                     32  421   11\n",
       "2                      6   33   37"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#does Llama political ideology differ from manual political ideology ?\n",
    "#make a crosstab to see if there are differences:\n",
    "pd.crosstab(MHdata.loc[:, 'ideo_label'], MHdata.loc[:, 'Llama_ideoGER_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama_ideoGER_score_low</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ideo_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>474</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama_ideoGER_score_low  0.0  1.0  2.0\n",
       "ideo_label                            \n",
       "0                         62   51    0\n",
       "1                         20  474    3\n",
       "2                          1   39   35"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#does Llama political ideology differ from manual political ideology ?\n",
    "#make a crosstab to see if there are differences:\n",
    "pd.crosstab(MHdata.loc[:, 'ideo_label'], MHdata.loc[:, 'Llama_ideoGER_score_low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "571"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "62+474+35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "685"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "564+83+38\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.35766423357664"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#percent agreement ideoGER_low:\n",
    "100*571/685"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama31_ideo_GER</th>\n",
       "      <th>Links</th>\n",
       "      <th>Mitte</th>\n",
       "      <th>Rechts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama31_ideology</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>conservative</th>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal</th>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>19</td>\n",
       "      <td>399</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama31_ideo_GER  Links  Mitte  Rechts\n",
       "Llama31_ideology                      \n",
       "conservative          8     26      43\n",
       "liberal              70     80       0\n",
       "neutral              19    399       5"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#and compared to the english prompt:\n",
    "pd.crosstab(MHdata.loc[:, 'Llama31_ideology'], MHdata.loc[:, 'Llama31_ideo_GER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_human_column_pairs = [\n",
    "    (\"ideo_label\", \"Llama_ideoGER_score\"),\n",
    "    (\"Llama_ideo_score\", \"Llama_ideoGER_score\")\n",
    "# (\"TopicRelevance\", \"rationality_topic_relevance\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_human_column_pairs = [\n",
    "    (\"ideo_label\", \"Llama_ideoGER_score_low\"),\n",
    "# (\"TopicRelevance\", \"rationality_topic_relevance\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Options low: Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.55      0.63       113\n",
      "           1       0.84      0.95      0.89       497\n",
      "           2       0.92      0.47      0.62        75\n",
      "\n",
      "    accuracy                           0.83       685\n",
      "   macro avg       0.84      0.66      0.72       685\n",
      "weighted avg       0.83      0.83      0.82       685\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.5580345014941591\n",
      "krippendorf(ideo_label): 0.5540933207998926\n"
     ]
    }
   ],
   "source": [
    "print(\"Options low: Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\")\n",
    "\n",
    "for human_col, llm_col in llm_human_column_pairs:\n",
    "    subset = MHdata[[human_col, llm_col]].dropna()\n",
    "    human = subset[human_col].tolist()\n",
    "    llm = subset[llm_col].tolist()\n",
    "    \n",
    "    print(\"---\")\n",
    "    print(f\"{classification_report(human, llm)}\")\n",
    "    print(f\"cohen_kappa_score({human_col}): {cohen_kappa_score(human, llm)}\")\n",
    "    print(f\"krippendorf({human_col}): {krippendorff.alpha(np.array([human, llm]), level_of_measurement=\"nominal\")}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "considerably better reliability and less missing values than without low temperature setting, but still not as good as the english prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.54      0.57       110\n",
      "           1       0.83      0.91      0.87       464\n",
      "           2       0.77      0.49      0.60        76\n",
      "\n",
      "    accuracy                           0.80       650\n",
      "   macro avg       0.74      0.64      0.68       650\n",
      "weighted avg       0.79      0.80      0.79       650\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.5027665619859429\n",
      "krippendorf(ideo_label): 0.5012600784626177\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.47      0.57       150\n",
      "           1       0.79      0.94      0.86       423\n",
      "           2       0.90      0.56      0.69        77\n",
      "\n",
      "    accuracy                           0.79       650\n",
      "   macro avg       0.80      0.66      0.70       650\n",
      "weighted avg       0.79      0.79      0.77       650\n",
      "\n",
      "cohen_kappa_score(Llama_ideo_score): 0.5294771793809241\n",
      "krippendorf(Llama_ideo_score): 0.5233547200012763\n"
     ]
    }
   ],
   "source": [
    "print(\"Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\")\n",
    "\n",
    "for human_col, llm_col in llm_human_column_pairs:\n",
    "    subset = MHdata[[human_col, llm_col]].dropna()\n",
    "    human = subset[human_col].tolist()\n",
    "    llm = subset[llm_col].tolist()\n",
    "    \n",
    "    print(\"---\")\n",
    "    print(f\"{classification_report(human, llm)}\")\n",
    "    print(f\"cohen_kappa_score({human_col}): {cohen_kappa_score(human, llm)}\")\n",
    "    print(f\"krippendorf({human_col}): {krippendorff.alpha(np.array([human, llm]), level_of_measurement=\"nominal\")}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unexpectedly, the german prompt did much worse than the english prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data to parquet\n",
    "MHdata.to_parquet('data/MH_BClemm_data/germany_val_all_llama.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "classifying political_ideology_GER: 100%|██████████| 700/700 [12:55<00:00,  1.11s/it]\n"
     ]
    }
   ],
   "source": [
    "#what if we adapt ideology labels further:\n",
    "#what does Llama3.1 predict for political orientation?\n",
    "predictions: typing.Dict[str, pd.Series] = {\n",
    "    label: (\n",
    "        src.PromptClassify\n",
    "        .from_json(path)\n",
    "        (MHdata[\"text\"], MODEL)\n",
    "    )\n",
    "    for label, path in CFG.prompt_classify_files.items() if label == 'political_ideology_GER2'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "political_ideology_GER\n",
      "Mittlere Mitte    420\n",
      "Linksliberal      148\n",
      "Konservativ        46\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#join to the dataset:\n",
    "for _, preds in predictions.items():\n",
    "    print(preds.value_counts())\n",
    "    print(\"-\" * 42)\n",
    "    # Convert Series to DataFrame\n",
    "    preds_df = preds.to_frame()\n",
    "    # Rename the column in preds_df to 'Llama31_ideology'\n",
    "    preds_df = preds_df.rename(columns={preds_df.columns[0]: 'Llama31_ideo_GER2'})\n",
    "    MHdata = MHdata.join(preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the political ideology labels to numbers:\n",
    "MHdata['Llama_ideoGER_score2'] = MHdata['Llama31_ideo_GER2'].map({'Linksliberal': 0, 'Mittlere Mitte': 1, 'Konservativ': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(86)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MHdata['Llama_ideoGER_score2'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama_ideoGER_score2</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ideo_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>370</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama_ideoGER_score2  0.0  1.0  2.0\n",
       "ideo_label                         \n",
       "0                      75   29    4\n",
       "1                      60  370   13\n",
       "2                      13   21   29"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#does Llama political ideology differ from manual political ideology ?\n",
    "#make a crosstab to see if there are differences:\n",
    "pd.crosstab(MHdata.loc[:, 'ideo_label'], MHdata.loc[:, 'Llama_ideoGER_score2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama31_ideo_GER2</th>\n",
       "      <th>Konservativ</th>\n",
       "      <th>Linksliberal</th>\n",
       "      <th>Mittlere Mitte</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama31_ideo_GER</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Links</th>\n",
       "      <td>7</td>\n",
       "      <td>63</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mitte</th>\n",
       "      <td>11</td>\n",
       "      <td>72</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rechts</th>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama31_ideo_GER2  Konservativ  Linksliberal  Mittlere Mitte\n",
       "Llama31_ideo_GER                                            \n",
       "Links                        7            63              20\n",
       "Mitte                       11            72             375\n",
       "Rechts                      27             3               5"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#and compared to the GER1 prompt:\n",
    "pd.crosstab(MHdata.loc[:, 'Llama31_ideo_GER'], MHdata.loc[:, 'Llama31_ideo_GER2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_human_column_pairs = [\n",
    "    (\"ideo_label\", \"Llama_ideoGER_score2\"),\n",
    "    (\"Llama_ideoGER_score\", \"Llama_ideoGER_score2\")\n",
    "# (\"TopicRelevance\", \"rationality_topic_relevance\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.69      0.59       108\n",
      "           1       0.88      0.84      0.86       443\n",
      "           2       0.63      0.46      0.53        63\n",
      "\n",
      "    accuracy                           0.77       614\n",
      "   macro avg       0.67      0.66      0.66       614\n",
      "weighted avg       0.79      0.77      0.78       614\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.5003894126262686\n",
      "krippendorf(ideo_label): 0.4990361593355478\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.46      0.70      0.55        90\n",
      "         1.0       0.94      0.82      0.87       458\n",
      "         2.0       0.60      0.77      0.68        35\n",
      "\n",
      "    accuracy                           0.80       583\n",
      "   macro avg       0.66      0.76      0.70       583\n",
      "weighted avg       0.84      0.80      0.81       583\n",
      "\n",
      "cohen_kappa_score(Llama_ideoGER_score): 0.5178914320153615\n",
      "krippendorf(Llama_ideoGER_score): 0.5133874210630646\n"
     ]
    }
   ],
   "source": [
    "print(\"Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\")\n",
    "\n",
    "for human_col, llm_col in llm_human_column_pairs:\n",
    "    subset = MHdata[[human_col, llm_col]].dropna()\n",
    "    human = subset[human_col].tolist()\n",
    "    llm = subset[llm_col].tolist()\n",
    "    \n",
    "    print(\"---\")\n",
    "    print(f\"{classification_report(human, llm)}\")\n",
    "    print(f\"cohen_kappa_score({human_col}): {cohen_kappa_score(human, llm)}\")\n",
    "    print(f\"krippendorf({human_col}): {krippendorff.alpha(np.array([human, llm]), level_of_measurement=\"nominal\")}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No improvement of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data to parquet\n",
    "MHdata.to_parquet('data/MH_BClemm_data/germany_val_all_llama.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "classifying political_ideology_GER3: 100%|██████████| 700/700 [42:05<00:00,  3.61s/it]  \n"
     ]
    }
   ],
   "source": [
    "#final try to improve German language prompt:\n",
    "#what does Llama3.1 predict for political orientation?\n",
    "predictions: typing.Dict[str, pd.Series] = {\n",
    "    label: (\n",
    "        src.PromptClassify\n",
    "        .from_json(path)\n",
    "        (MHdata[\"text\"], MODEL, options=options_low)\n",
    "    )\n",
    "    for label, path in CFG.prompt_classify_files.items() if label == 'political_ideology_GER3'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "political_ideology_GER3\n",
      "Moderate       513\n",
      "Liberal         87\n",
      "Konservativ     45\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#join to the dataset:\n",
    "for _, preds in predictions.items():\n",
    "    print(preds.value_counts())\n",
    "    print(\"-\" * 42)\n",
    "    # Convert Series to DataFrame\n",
    "    preds_df = preds.to_frame()\n",
    "    # Rename the column in preds_df to 'Llama31_ideology'\n",
    "    preds_df = preds_df.rename(columns={preds_df.columns[0]: 'Llama31_ideo_GER3'})\n",
    "    MHdata = MHdata.join(preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the political ideology labels to numbers:\n",
    "MHdata['Llama_ideoGER_score3'] = MHdata['Llama31_ideo_GER3'].map({'Liberal': 0, 'Moderate': 1, 'Konservativ': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(55)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MHdata['Llama_ideoGER_score3'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama_ideoGER_score3</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ideo_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>441</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama_ideoGER_score3  0.0  1.0  2.0\n",
       "ideo_label                         \n",
       "0                      59   46    0\n",
       "1                      23  441    9\n",
       "2                       5   26   36"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#does Llama political ideology differ from manual political ideology ?\n",
    "#make a crosstab to see if there are differences:\n",
    "pd.crosstab(MHdata.loc[:, 'ideo_label'], MHdata.loc[:, 'Llama_ideoGER_score3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.56      0.61       105\n",
      "           1       0.86      0.93      0.89       473\n",
      "           2       0.80      0.54      0.64        67\n",
      "\n",
      "    accuracy                           0.83       645\n",
      "   macro avg       0.78      0.68      0.72       645\n",
      "weighted avg       0.82      0.83      0.82       645\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.5639350973168099\n",
      "krippendorf(ideo_label): 0.562640078693097\n"
     ]
    }
   ],
   "source": [
    "llm_human_column_pairs = [\n",
    "    (\"ideo_label\", \"Llama_ideoGER_score3\"),\n",
    "#   (\"Llama_ideoGER_score\", \"Llama_ideoGER_score2\")\n",
    "# (\"TopicRelevance\", \"rationality_topic_relevance\"),\n",
    "]\n",
    "print(\"Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\")\n",
    "\n",
    "for human_col, llm_col in llm_human_column_pairs:\n",
    "    subset = MHdata[[human_col, llm_col]].dropna()\n",
    "    human = subset[human_col].tolist()\n",
    "    llm = subset[llm_col].tolist()\n",
    "    \n",
    "    print(\"---\")\n",
    "    print(f\"{classification_report(human, llm)}\")\n",
    "    print(f\"cohen_kappa_score({human_col}): {cohen_kappa_score(human, llm)}\")\n",
    "    print(f\"krippendorf({human_col}): {krippendorff.alpha(np.array([human, llm]), level_of_measurement=\"nominal\")}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best performing German Llama3.1 model so far, but did not reduce (but increased) number of missing classifications, and still performance is inferior to english language prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join to parquet data:\n",
    "#save data to parquet\n",
    "MHdatapar= pd.read_parquet('data/MH_BClemm_data/germany_val_all_llama.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pol_label</th>\n",
       "      <th>neg_label</th>\n",
       "      <th>neg3_label</th>\n",
       "      <th>ideo_label</th>\n",
       "      <th>GPT_Pol1</th>\n",
       "      <th>GPT_Pol2</th>\n",
       "      <th>GPT_Neg1</th>\n",
       "      <th>GPT_Neg2</th>\n",
       "      <th>GPT_Neg_3Way1</th>\n",
       "      <th>...</th>\n",
       "      <th>Llama31_ideo_GER</th>\n",
       "      <th>Llama_ideoGER_score</th>\n",
       "      <th>Llama31_ideo_GER2</th>\n",
       "      <th>Llama_ideoGER_score2</th>\n",
       "      <th>Llama31_ideo_GER3</th>\n",
       "      <th>Llama_ideoGER_score3</th>\n",
       "      <th>Llama31_ideology_low</th>\n",
       "      <th>Llama_ideo_score_low</th>\n",
       "      <th>Llama31_ideo_GER_low</th>\n",
       "      <th>Llama_ideoGER_score_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@thatleechi17 @KlemmChr @AndiScheuer @victorperli Ich würde sagen Sie vergleichen maximal kenntn...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mittlere Mitte</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Glauben Sie nur nicht, dass Menschen die nicht dem Bundestag angehören, nichts zu sagen hätten. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mittlere Mitte</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>liberal</td>\n",
       "      <td>0</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Das ist ja das Mindeste. \\r\\n\\r\\nDass das aber das alles möglich ist trotz der Situation der Uig...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Linksliberal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>liberal</td>\n",
       "      <td>0</td>\n",
       "      <td>Links</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Challen81690499 @c_lindner @rbrinkhaus @NowaboFM Na na na... TW</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mittlere Mitte</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ich sage: #DANKE!!!\\r\\nhttps://t.co/0pVneqXwTC\\r\\n#afd #btw #btw17 #btw2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Rechts</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Konservativ</td>\n",
       "      <td>2.0</td>\n",
       "      <td>conservative</td>\n",
       "      <td>2</td>\n",
       "      <td>Rechts</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  text  \\\n",
       "0  @thatleechi17 @KlemmChr @AndiScheuer @victorperli Ich würde sagen Sie vergleichen maximal kenntn...   \n",
       "1  Glauben Sie nur nicht, dass Menschen die nicht dem Bundestag angehören, nichts zu sagen hätten. ...   \n",
       "2  Das ist ja das Mindeste. \\r\\n\\r\\nDass das aber das alles möglich ist trotz der Situation der Uig...   \n",
       "3                                     @Challen81690499 @c_lindner @rbrinkhaus @NowaboFM Na na na... TW   \n",
       "4                          Ich sage: #DANKE!!!\\r\\nhttps://t.co/0pVneqXwTC\\r\\n#afd #btw #btw17 #btw2017   \n",
       "\n",
       "   pol_label  neg_label  neg3_label  ideo_label  GPT_Pol1  GPT_Pol2  GPT_Neg1  \\\n",
       "0          1          1           0           1         1         1         1   \n",
       "1          1          0           1           1         1         1         0   \n",
       "2          1          1           0           1         1         1         1   \n",
       "3          0          0           1           1         1         0         0   \n",
       "4          1          0           2           2         1         1         0   \n",
       "\n",
       "   GPT_Neg2  GPT_Neg_3Way1  ...  Llama31_ideo_GER  Llama_ideoGER_score  \\\n",
       "0         1              0  ...             Mitte                  1.0   \n",
       "1         0              1  ...             Mitte                  1.0   \n",
       "2         1              0  ...             Mitte                  1.0   \n",
       "3         0              1  ...             Mitte                  1.0   \n",
       "4         0              2  ...            Rechts                  2.0   \n",
       "\n",
       "   Llama31_ideo_GER2  Llama_ideoGER_score2  Llama31_ideo_GER3  \\\n",
       "0     Mittlere Mitte                   1.0           Moderate   \n",
       "1     Mittlere Mitte                   1.0           Moderate   \n",
       "2       Linksliberal                   0.0           Moderate   \n",
       "3     Mittlere Mitte                   1.0           Moderate   \n",
       "4               None                   NaN        Konservativ   \n",
       "\n",
       "   Llama_ideoGER_score3  Llama31_ideology_low Llama_ideo_score_low  \\\n",
       "0                   1.0               neutral                    1   \n",
       "1                   1.0               liberal                    0   \n",
       "2                   1.0               liberal                    0   \n",
       "3                   1.0               neutral                    1   \n",
       "4                   2.0          conservative                    2   \n",
       "\n",
       "   Llama31_ideo_GER_low Llama_ideoGER_score_low  \n",
       "0                 Mitte                     1.0  \n",
       "1                 Mitte                     1.0  \n",
       "2                 Links                     0.0  \n",
       "3                 Mitte                     1.0  \n",
       "4                Rechts                     2.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MHdatapar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "MHdatapar = MHdatapar.join(MHdata.loc[:, ['Llama31_ideo_GER3', 'Llama_ideoGER_score3', 'Llama31_ideology_low', 'Llama_ideo_score_low', 'Llama31_ideo_GER_low' ,'Llama_ideoGER_score_low']])   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "MHdatapar.to_parquet('data/MH_BClemm_data/germany_val_all_llama.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmdiv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
