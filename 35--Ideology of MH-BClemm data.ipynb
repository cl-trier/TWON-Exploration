{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2288.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 640, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2288.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\base_events.py\", line 1992, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.12_3.12.2288.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\sstolwi\\AppData\\Local\\Temp\\ipykernel_11908\\4121844092.py\", line 5, in <module>\n",
      "    import src\n",
      "  File \"c:\\Users\\sstolwi\\Github\\TWON-Metrics\\src\\__init__.py\", line 1, in <module>\n",
      "    from .hf_classify import HFClassify\n",
      "  File \"c:\\Users\\sstolwi\\Github\\TWON-Metrics\\src\\hf_classify.py\", line 5, in <module>\n",
      "    import torch\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\torch\\__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\torch\\functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\torch\\nn\\__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\torch\\nn\\modules\\__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "c:\\Users\\sstolwi\\Github\\llmdiv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import typing\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import config\n",
    "import src\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"sjoerdAzure.env\")  # Load environment variables from .env file\n",
    "import time\n",
    "import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "import cltrier_lib as lib\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score, classification_report\n",
    "import krippendorff\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up helper variables and functions:\n",
    "CFG = config.Config()\n",
    "\n",
    "def load_json(path: str):\n",
    "    with open(path, encoding='utf-8') as fp:\n",
    "        return json.load(fp)\n",
    "    \n",
    "#set option variables:\n",
    "\n",
    "#set options to low temperature (0,1):\n",
    "options_low_str = \"\"\"\n",
    "seed: 42\n",
    "temperature: 0.1\n",
    "\"\"\"\n",
    "\n",
    "options_low = yaml.safe_load(options_low_str)\n",
    "\n",
    "MODELsmall: str = 'llama3.1:8b-instruct-q6_K' # options: 'gemma:7b-instruct-q6_K', 'gemma2:27b-instruct-q6_K', 'llama3.1:8b-instruct-q6_K', 'llama3.1:70b-instruct-q6_K', 'mistral:7b-instruct-v0.3-q6_K', 'mistral-large:123b-instruct-2407-q6_K', 'mixtral:8x7b-instruct-v0.1-q6_K', 'mixtral:8x22b-instruct-v0.1-q6_K', 'phi3:14b-medium-128k-instruct-q6_K' or 'qwen2:72b-instruct-q6_K'\n",
    "MODELlarge: str = 'llama3.1:70b-instruct-q6_K' # options: 'gemma:7b-instruct-q6_K', 'gemma2:27b-instruct-q6_K', 'llama3.1:8b-instruct-q6_K', 'llama3.1:70b-instruct-q6_K', 'mistral:7b-instruct-v0.3-q6_K', 'mistral-large:123b-instruct-2407-q6_K', 'mixtral:8x7b-instruct-v0.1-q6_K', 'mixtral:8x22b-instruct-v0.1-q6_K', 'phi3:14b-medium-128k-instruct-q6_K' or 'qwen2:72b-instruct-q6_K'\n",
    "MODELgpt4o = \"nf-gpt-4o-2024-08-06\" # in principe is er nu van elk model een nf (no filter) en een normale versie beschikbaar, de no filter versies zijn alleen voor onderzoekers beschikbaar voor analyze van content die niet door de filter heen zou komen.\n",
    "MODELgpt4T = \"nf-gpt-4-turbo\" # Can be gpt-35-turbo, gpt-4-turbo, gpt-4 or Meta-Llama-3-8B-Instruct.\n",
    "MODELgpt4 = \"nf-gpt-4\" # Can be gpt-35-turbo, gpt-4-turbo, gpt-4 or Meta-Llama-3-8B-Instruct.\n",
    "\n",
    "options_zero_str = \"\"\"\n",
    "seed: 42\n",
    "temperature: 0\n",
    "\"\"\"\n",
    "options_zero = yaml.safe_load(options_zero_str)\n",
    "\n",
    "temperature_0 : int = 0\n",
    "SEED: int = 42\n",
    "MAX10: int = 10\n",
    "TOPP1: int = 1\n",
    "\n",
    "\n",
    "options_large_str = \"\"\"\n",
    "seed: 42\n",
    "temperature: 0\n",
    "num_predict: 2000\n",
    "\"\"\"\n",
    "options_large = yaml.safe_load(options_large_str)\n",
    "\n",
    "#load environment variables:\n",
    "api_key = os.environ.get('sjoerd_key')\n",
    "\n",
    "#setttings:\n",
    "api_endpoint = \"https://ai-research-proxy.azurewebsites.net/chat/completions\"\n",
    "####### API REQUEST FORMATTING ######\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer \" + api_key\n",
    "}#set up helper variables and functions:\n",
    "CFG = config.Config()\n",
    "\n",
    "def load_json(path: str):\n",
    "    with open(path, encoding='utf-8') as fp:\n",
    "        return json.load(fp)\n",
    "    \n",
    "#set option variables:\n",
    "\n",
    "#set options to low temperature (0,1):\n",
    "options_low_str = \"\"\"\n",
    "seed: 42\n",
    "temperature: 0.1\n",
    "\"\"\"\n",
    "\n",
    "options_low = yaml.safe_load(options_low_str)\n",
    "\n",
    "MODELsmall: str = 'llama3.1:8b-instruct-q6_K' # options: 'gemma:7b-instruct-q6_K', 'gemma2:27b-instruct-q6_K', 'llama3.1:8b-instruct-q6_K', 'llama3.1:70b-instruct-q6_K', 'mistral:7b-instruct-v0.3-q6_K', 'mistral-large:123b-instruct-2407-q6_K', 'mixtral:8x7b-instruct-v0.1-q6_K', 'mixtral:8x22b-instruct-v0.1-q6_K', 'phi3:14b-medium-128k-instruct-q6_K' or 'qwen2:72b-instruct-q6_K'\n",
    "MODELlarge: str = 'llama3.1:70b-instruct-q6_K' # options: 'gemma:7b-instruct-q6_K', 'gemma2:27b-instruct-q6_K', 'llama3.1:8b-instruct-q6_K', 'llama3.1:70b-instruct-q6_K', 'mistral:7b-instruct-v0.3-q6_K', 'mistral-large:123b-instruct-2407-q6_K', 'mixtral:8x7b-instruct-v0.1-q6_K', 'mixtral:8x22b-instruct-v0.1-q6_K', 'phi3:14b-medium-128k-instruct-q6_K' or 'qwen2:72b-instruct-q6_K'\n",
    "MODELgpt4o = \"nf-gpt-4o-2024-08-06\" # in principe is er nu van elk model een nf (no filter) en een normale versie beschikbaar, de no filter versies zijn alleen voor onderzoekers beschikbaar voor analyze van content die niet door de filter heen zou komen.\n",
    "MODELgpt4T = \"nf-gpt-4-turbo\" # Can be gpt-35-turbo, gpt-4-turbo, gpt-4 or Meta-Llama-3-8B-Instruct.\n",
    "\n",
    "options_zero_str = \"\"\"\n",
    "seed: 42\n",
    "temperature: 0\n",
    "\"\"\"\n",
    "options_zero = yaml.safe_load(options_zero_str)\n",
    "\n",
    "temperature_0 : int = 0\n",
    "SEED: int = 42\n",
    "MAX10: int = 10\n",
    "TOPP1: int = 1\n",
    "\n",
    "\n",
    "options_large_str = \"\"\"\n",
    "seed: 42\n",
    "temperature: 0\n",
    "num_predict: 2000\n",
    "\"\"\"\n",
    "options_large = yaml.safe_load(options_large_str)\n",
    "\n",
    "#load environment variables:\n",
    "api_key = os.environ.get('sjoerd_key')\n",
    "\n",
    "#setttings:\n",
    "api_endpoint = \"https://ai-research-proxy.azurewebsites.net/chat/completions\"\n",
    "api_endpoint_embed = \"https://ai-research-proxy.azurewebsites.net/embeddings\"\n",
    "####### API REQUEST FORMATTING ######\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer \" + api_key\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('civility_jaidka', WindowsPath('data/prompts_classify/civility_jaidka.json')), ('constructiveness_jaidka', WindowsPath('data/prompts_classify/constructiveness_jaidka.json')), ('diversity_disagreement', WindowsPath('data/prompts_classify/diversity_disagreement.json')), ('diversity_disagreement_edit', WindowsPath('data/prompts_classify/diversity_disagreement_edit.json')), ('diversity_ideological_direction', WindowsPath('data/prompts_classify/diversity_ideological_direction.json')), ('diversity_positiondum', WindowsPath('data/prompts_classify/diversity_positiondum.json')), ('incivility_allcaps', WindowsPath('data/prompts_classify/incivility_allcaps.json')), ('incivility_attackreputation', WindowsPath('data/prompts_classify/incivility_attackreputation.json')), ('incivility_combine', WindowsPath('data/prompts_classify/incivility_combine.json')), ('incivility_jaidka', WindowsPath('data/prompts_classify/incivility_jaidka.json')), ('incivility_namecalling', WindowsPath('data/prompts_classify/incivility_namecalling.json')), ('incivility_namecalling_edit', WindowsPath('data/prompts_classify/incivility_namecalling_edit.json')), ('incivility_question_intelligence', WindowsPath('data/prompts_classify/incivility_question_intelligence.json')), ('incivility_sarcasm', WindowsPath('data/prompts_classify/incivility_sarcasm.json')), ('incivility_simple', WindowsPath('data/prompts_classify/incivility_simple.json')), ('incivility_simple2', WindowsPath('data/prompts_classify/incivility_simple2.json')), ('incivility_vulgarity', WindowsPath('data/prompts_classify/incivility_vulgarity.json')), ('interactivity_acknowledgement', WindowsPath('data/prompts_classify/interactivity_acknowledgement.json')), ('interactivity_acknowledgement_jaidka', WindowsPath('data/prompts_classify/interactivity_acknowledgement_jaidka.json')), ('interactivity_acknowledgement_simple', WindowsPath('data/prompts_classify/interactivity_acknowledgement_simple.json')), ('interactivity_acknowledgement_simple2', WindowsPath('data/prompts_classify/interactivity_acknowledgement_simple2.json')), ('intolerance_discrimination', WindowsPath('data/prompts_classify/intolerance_discrimination.json')), ('intolerance_rights', WindowsPath('data/prompts_classify/intolerance_rights.json')), ('intolerance_violence', WindowsPath('data/prompts_classify/intolerance_violence.json')), ('political_ideology', WindowsPath('data/prompts_classify/political_ideology.json')), ('political_ideology_ext', WindowsPath('data/prompts_classify/political_ideology_ext.json')), ('political_ideology_GER', WindowsPath('data/prompts_classify/political_ideology_GER.json')), ('political_ideology_GER2', WindowsPath('data/prompts_classify/political_ideology_GER2.json')), ('political_ideology_GER3', WindowsPath('data/prompts_classify/political_ideology_GER3.json')), ('political_ideology_US', WindowsPath('data/prompts_classify/political_ideology_US.json')), ('political_negativity', WindowsPath('data/prompts_classify/political_negativity.json')), ('political_post', WindowsPath('data/prompts_classify/political_post.json')), ('political_post_GER', WindowsPath('data/prompts_classify/political_post_GER.json')), ('political_post_jaidka', WindowsPath('data/prompts_classify/political_post_jaidka.json')), ('rationality_background_info', WindowsPath('data/prompts_classify/rationality_background_info.json')), ('rationality_background_info_edit', WindowsPath('data/prompts_classify/rationality_background_info_edit.json')), ('rationality_combine', WindowsPath('data/prompts_classify/rationality_combine.json')), ('rationality_external_evidence', WindowsPath('data/prompts_classify/rationality_external_evidence.json')), ('rationality_external_evidence_edit', WindowsPath('data/prompts_classify/rationality_external_evidence_edit.json')), ('rationality_jaidka', WindowsPath('data/prompts_classify/rationality_jaidka.json')), ('rationality_reasoning', WindowsPath('data/prompts_classify/rationality_reasoning.json')), ('rationality_reasoning_edit', WindowsPath('data/prompts_classify/rationality_reasoning_edit.json')), ('rationality_simple', WindowsPath('data/prompts_classify/rationality_simple.json')), ('rationality_simple2', WindowsPath('data/prompts_classify/rationality_simple2.json')), ('rationality_topic_relevance', WindowsPath('data/prompts_classify/rationality_topic_relevance.json'))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG.prompt_classify_files.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL: str = 'llama3.1:70b-instruct-q6_K' # options: 'gemma:7b-instruct-q6_K', 'gemma2:27b-instruct-q6_K', 'llama3.1:8b-instruct-q6_K', 'llama3.1:70b-instruct-q6_K', 'mistral:7b-instruct-v0.3-q6_K', 'mistral-large:123b-instruct-2407-q6_K', 'mixtral:8x7b-instruct-v0.1-q6_K', 'mixtral:8x22b-instruct-v0.1-q6_K', 'phi3:14b-medium-128k-instruct-q6_K' or 'qwen2:72b-instruct-q6_K'\n",
    "MODELsmall: str = 'llama3.1:8b-instruct-q6_K'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pol_label</th>\n",
       "      <th>neg_label</th>\n",
       "      <th>neg3_label</th>\n",
       "      <th>ideo_label</th>\n",
       "      <th>GPT_Pol1</th>\n",
       "      <th>GPT_Pol2</th>\n",
       "      <th>GPT_Neg1</th>\n",
       "      <th>GPT_Neg2</th>\n",
       "      <th>GPT_Neg_3Way1</th>\n",
       "      <th>GPT_Neg_3Way2</th>\n",
       "      <th>GPT_Ideo1</th>\n",
       "      <th>GPT_Ideo2</th>\n",
       "      <th>Pol_Recon</th>\n",
       "      <th>Neg_Recon</th>\n",
       "      <th>Neg3_Recon</th>\n",
       "      <th>Ideo_Recon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@thatleechi17 @KlemmChr @AndiScheuer @victorpe...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Glauben Sie nur nicht, dass Menschen die nicht...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Das ist ja das Mindeste. \\r\\n\\r\\nDass das aber...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Challen81690499 @c_lindner @rbrinkhaus @Nowab...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ich sage: #DANKE!!!\\r\\nhttps://t.co/0pVneqXwTC...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>@rehbergkk Ihr Denkfehler, in der Tat!</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>Die Bundesregierung spricht von „Einwanderung ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>Im #EU Parlament sitzen teilweise echt Verrück...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>@StBrandner @M_HarderKuehnel Du natürlich! &lt;U+...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>@har41637914 @Gothdad Nein. Das ist eine ganz ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  pol_label  neg_label  \\\n",
       "0    @thatleechi17 @KlemmChr @AndiScheuer @victorpe...          1          1   \n",
       "1    Glauben Sie nur nicht, dass Menschen die nicht...          1          0   \n",
       "2    Das ist ja das Mindeste. \\r\\n\\r\\nDass das aber...          1          1   \n",
       "3    @Challen81690499 @c_lindner @rbrinkhaus @Nowab...          0          0   \n",
       "4    Ich sage: #DANKE!!!\\r\\nhttps://t.co/0pVneqXwTC...          1          0   \n",
       "..                                                 ...        ...        ...   \n",
       "695             @rehbergkk Ihr Denkfehler, in der Tat!          0          1   \n",
       "696  Die Bundesregierung spricht von „Einwanderung ...          1          1   \n",
       "697  Im #EU Parlament sitzen teilweise echt Verrück...          1          1   \n",
       "698  @StBrandner @M_HarderKuehnel Du natürlich! <U+...          0          0   \n",
       "699  @har41637914 @Gothdad Nein. Das ist eine ganz ...          0          1   \n",
       "\n",
       "     neg3_label  ideo_label  GPT_Pol1  GPT_Pol2  GPT_Neg1  GPT_Neg2  \\\n",
       "0             0           1         1         1         1         1   \n",
       "1             1           1         1         1         0         0   \n",
       "2             0           1         1         1         1         1   \n",
       "3             1           1         1         0         0         0   \n",
       "4             2           2         1         1         0         0   \n",
       "..          ...         ...       ...       ...       ...       ...   \n",
       "695           0           1         0         0         1         1   \n",
       "696           0           0         1         1         0         1   \n",
       "697           0           1         1         1         1         1   \n",
       "698           1           1         0         0         0         0   \n",
       "699           0           1         0         0         1         1   \n",
       "\n",
       "     GPT_Neg_3Way1  GPT_Neg_3Way2  GPT_Ideo1  GPT_Ideo2  Pol_Recon  Neg_Recon  \\\n",
       "0                0              0          1          1          1          1   \n",
       "1                1              1          1          1          1          0   \n",
       "2                0              0          0          0          1          1   \n",
       "3                1              1          1          1          0          0   \n",
       "4                2              2          2          2          1          0   \n",
       "..             ...            ...        ...        ...        ...        ...   \n",
       "695              0              0          1          1          0          1   \n",
       "696              0              0          0          0          1          1   \n",
       "697              0              0          1          1          1          1   \n",
       "698              2              2          1          1          0          0   \n",
       "699              0              0          1          1          0          1   \n",
       "\n",
       "     Neg3_Recon  Ideo_Recon  \n",
       "0             0           1  \n",
       "1             1           1  \n",
       "2             0           0  \n",
       "3             1           1  \n",
       "4             2           2  \n",
       "..          ...         ...  \n",
       "695           0           1  \n",
       "696           0           0  \n",
       "697           0           1  \n",
       "698           2           1  \n",
       "699           0           1  \n",
       "\n",
       "[700 rows x 17 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "MHdata: pd.DataFrame = pd.read_csv('data/MH_BClemm_data/germany_val_all.csv') \n",
    "MHdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change options to low temperature (0,1) and compare result:\n",
    "options_low = \"\"\"\n",
    "seed: 42\n",
    "temperature: 0.1\n",
    "\"\"\"\n",
    "\n",
    "options_low = yaml.safe_load(options_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "classifying political_ideology: 100%|██████████| 700/700 [25:11<00:00,  2.16s/it]\n"
     ]
    }
   ],
   "source": [
    "#the _label variables are the reconciled and definitive annotation values for the variables\n",
    "#what does Llama3.1 predict for political orientation?\n",
    "predictions: typing.Dict[str, pd.Series] = {\n",
    "    label: (\n",
    "        src.PromptClassify\n",
    "        .from_json(path)\n",
    "        (MHdata[\"text\"], MODEL, options=options_low)\n",
    "    )\n",
    "    for label, path in CFG.prompt_classify_files.items() if label == 'political_ideology'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'political_ideology': 0           neutral\n",
       " 1           neutral\n",
       " 2           liberal\n",
       " 3           neutral\n",
       " 4      conservative\n",
       "            ...     \n",
       " 695         neutral\n",
       " 696         liberal\n",
       " 697    conservative\n",
       " 698         neutral\n",
       " 699         neutral\n",
       " Name: political_ideology, Length: 700, dtype: object}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions #note that these are based on llama3.1:70b-instruct-q6_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "political_ideology\n",
      "neutral         466\n",
      "liberal         151\n",
      "conservative     83\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#join to the dataset:\n",
    "for _, preds in predictions.items():\n",
    "    print(preds.value_counts())\n",
    "    print(\"-\" * 42)\n",
    "    # Convert Series to DataFrame\n",
    "    preds_df = preds.to_frame()\n",
    "    # Rename the column in preds_df to 'Llama31_ideology'\n",
    "    preds_df = preds_df.rename(columns={preds_df.columns[0]: 'Llama31_ideology_low'})\n",
    "    MHdata = MHdata.join(preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "political_ideology\n",
      "neutral         454\n",
      "liberal         159\n",
      "conservative     87\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#join to the dataset:\n",
    "for _, preds in predictions.items():\n",
    "    print(preds.value_counts())\n",
    "    print(\"-\" * 42)\n",
    "    # Convert Series to DataFrame\n",
    "    preds_df = preds.to_frame()\n",
    "    # Rename the column in preds_df to 'Llama31_ideology'\n",
    "    preds_df = preds_df.rename(columns={preds_df.columns[0]: 'Llama31_ideology'})\n",
    "    MHdata = MHdata.join(preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#missing values in low temperature ideology:\n",
    "MHdata.Llama31_ideology_low.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MHdata.Llama31_ideology.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama31_ideology</th>\n",
       "      <th>conservative</th>\n",
       "      <th>liberal</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ideo_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>94</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>56</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama31_ideology  conservative  liberal  neutral\n",
       "ideo_label                                      \n",
       "0                            4       94       17\n",
       "1                           26       56      421\n",
       "2                           57        9       16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#does Llama political ideology differ from manual political ideology ?\n",
    "#make a crosstab to see if there are differences:\n",
    "pd.crosstab(MHdata.loc[:, 'ideo_label'], MHdata.loc[:, 'Llama31_ideology'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama31_ideology_low</th>\n",
       "      <th>conservative</th>\n",
       "      <th>liberal</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ideo_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>47</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama31_ideology_low  conservative  liberal  neutral\n",
       "ideo_label                                          \n",
       "0                                3       91       21\n",
       "1                               23       47      433\n",
       "2                               55        7       20"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#does Llama political ideology low differ from manual political ideology ?\n",
    "#make a crosstab to see if there are differences:\n",
    "pd.crosstab(MHdata.loc[:, 'ideo_label'], MHdata.loc[:, 'Llama31_ideology_low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the political ideology labels to numbers:\n",
    "MHdata['Llama_ideo_score'] = MHdata['Llama31_ideology'].map({'liberal': 0, 'neutral': 1, 'conservative': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MHdata['Llama_ideo_score_low'] = MHdata['Llama31_ideology_low'].map({'liberal': 0, 'neutral': 1, 'conservative': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama_ideo_score</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ideo_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>421</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama_ideo_score   0    1   2\n",
       "ideo_label                   \n",
       "0                 94   17   4\n",
       "1                 56  421  26\n",
       "2                  9   16  57"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(MHdata.loc[:, 'ideo_label'], MHdata.loc[:, 'Llama_ideo_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama_ideo_score</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT_Ideo1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115</td>\n",
       "      <td>49</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>381</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama_ideo_score    0    1   2\n",
       "GPT_Ideo1                     \n",
       "0                 115   49  11\n",
       "1                  29  381  13\n",
       "2                  15   24  63"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#and how does Llama3.1 perform compared to GPT\n",
    "#make a crosstab to see if there are differences:\n",
    "pd.crosstab(MHdata.loc[:, 'GPT_Ideo1'], MHdata.loc[:, 'Llama_ideo_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_human_column_pairs = [\n",
    "    (\"ideo_label\", \"Llama_ideo_score\"),\n",
    "    (\"ideo_label\", \"GPT_Ideo1\")\n",
    "# (\"TopicRelevance\", \"rationality_topic_relevance\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.82      0.69       115\n",
      "           1       0.93      0.84      0.88       503\n",
      "           2       0.66      0.70      0.67        82\n",
      "\n",
      "    accuracy                           0.82       700\n",
      "   macro avg       0.72      0.78      0.75       700\n",
      "weighted avg       0.84      0.82      0.82       700\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.6206909689737066\n",
      "krippendorf(ideo_label): 0.6192039671924076\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.92      0.73       115\n",
      "           1       0.96      0.81      0.88       503\n",
      "           2       0.69      0.85      0.76        82\n",
      "\n",
      "    accuracy                           0.83       700\n",
      "   macro avg       0.75      0.86      0.79       700\n",
      "weighted avg       0.87      0.83      0.84       700\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.6679290188227158\n",
      "krippendorf(ideo_label): 0.6646610493129983\n"
     ]
    }
   ],
   "source": [
    "print(\"Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\")\n",
    "\n",
    "for human_col, llm_col in llm_human_column_pairs:\n",
    "    subset = MHdata[[human_col, llm_col]].dropna()\n",
    "    human = subset[human_col].tolist()\n",
    "    llm = subset[llm_col].tolist()\n",
    "    \n",
    "    print(\"---\")\n",
    "    print(f\"{classification_report(human, llm)}\")\n",
    "    print(f\"cohen_kappa_score({human_col}): {cohen_kappa_score(human, llm)}\")\n",
    "    print(f\"krippendorf({human_col}): {krippendorff.alpha(np.array([human, llm]), level_of_measurement=\"nominal\")}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Llama did ok, but GPT4 did better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low temperature Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.79      0.70       115\n",
      "           1       0.91      0.86      0.89       503\n",
      "           2       0.68      0.67      0.67        82\n",
      "\n",
      "    accuracy                           0.83       700\n",
      "   macro avg       0.74      0.77      0.75       700\n",
      "weighted avg       0.84      0.83      0.83       700\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.6289335453713074\n",
      "krippendorf(ideo_label): 0.6284897871397188\n"
     ]
    }
   ],
   "source": [
    "llm_human_column_pairs = [\n",
    "    (\"ideo_label\", \"Llama_ideo_score_low\"),\n",
    "#   (\"ideo_label\", \"GPT_Ideo1\")\n",
    "# (\"TopicRelevance\", \"rationality_topic_relevance\"),\n",
    "]\n",
    "print(\"low temperature Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\")\n",
    "\n",
    "for human_col, llm_col in llm_human_column_pairs:\n",
    "    subset = MHdata[[human_col, llm_col]].dropna()\n",
    "    human = subset[human_col].tolist()\n",
    "    llm = subset[llm_col].tolist()\n",
    "    \n",
    "    print(\"---\")\n",
    "    print(f\"{classification_report(human, llm)}\")\n",
    "    print(f\"cohen_kappa_score({human_col}): {cohen_kappa_score(human, llm)}\")\n",
    "    print(f\"krippendorf({human_col}): {krippendorff.alpha(np.array([human, llm]), level_of_measurement=\"nominal\")}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#very similar performance for low temperature english prompt of Llama3.1 compared to default temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "classifying political_ideology_GER: 100%|██████████| 700/700 [29:47<00:00,  2.55s/it]  \n"
     ]
    }
   ],
   "source": [
    "#what if we translate the prompt first \n",
    "#what does Llama3.1 predict for political orientation?\n",
    "predictions2: typing.Dict[str, pd.Series] = {\n",
    "    label: (\n",
    "        src.PromptClassify\n",
    "        .from_json(path)\n",
    "        (MHdata[\"text\"], model=MODEL, options=options_low)\n",
    "    )\n",
    "    for label, path in CFG.prompt_classify_files.items() if label == 'political_ideology_GER'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "political_ideology_GER\n",
      "Mitte     564\n",
      "Links      82\n",
      "Rechts     39\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#join to the dataset:\n",
    "for _, preds in predictions2.items():\n",
    "    print(preds.value_counts())\n",
    "    print(\"-\" * 42)\n",
    "    # Convert Series to DataFrame\n",
    "    preds_df = preds.to_frame()\n",
    "    # Rename the column in preds_df to 'Llama31_ideology'\n",
    "    preds_df = preds_df.rename(columns={preds_df.columns[0]: 'Llama31_ideo_GER_low'})\n",
    "    MHdata = MHdata.join(preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "political_ideology_GER\n",
      "Mitte     505\n",
      "Links      97\n",
      "Rechts     48\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#join to the dataset:\n",
    "for _, preds in predictions.items():\n",
    "    print(preds.value_counts())\n",
    "    print(\"-\" * 42)\n",
    "    # Convert Series to DataFrame\n",
    "    preds_df = preds.to_frame()\n",
    "    # Rename the column in preds_df to 'Llama31_ideology'\n",
    "    preds_df = preds_df.rename(columns={preds_df.columns[0]: 'Llama31_ideo_GER'})\n",
    "    MHdata = MHdata.join(preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MHdata.Llama31_ideo_GER.isna().sum()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(15)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MHdata.Llama31_ideo_GER_low.isna().sum()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the political ideology labels to numbers:\n",
    "MHdata['Llama_ideoGER_score'] = MHdata['Llama31_ideo_GER'].map({'Links': 0, 'Mitte': 1, 'Rechts': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the political ideology labels to numbers:\n",
    "MHdata['Llama_ideoGER_score_low'] = MHdata['Llama31_ideo_GER_low'].map({'Links': 0, 'Mitte': 1, 'Rechts': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama_ideoGER_score</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ideo_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>421</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama_ideoGER_score  0.0  1.0  2.0\n",
       "ideo_label                        \n",
       "0                     59   51    0\n",
       "1                     32  421   11\n",
       "2                      6   33   37"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#does Llama political ideology differ from manual political ideology ?\n",
    "#make a crosstab to see if there are differences:\n",
    "pd.crosstab(MHdata.loc[:, 'ideo_label'], MHdata.loc[:, 'Llama_ideoGER_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama_ideoGER_score_low</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ideo_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>474</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama_ideoGER_score_low  0.0  1.0  2.0\n",
       "ideo_label                            \n",
       "0                         62   51    0\n",
       "1                         20  474    3\n",
       "2                          1   39   35"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#does Llama political ideology differ from manual political ideology ?\n",
    "#make a crosstab to see if there are differences:\n",
    "pd.crosstab(MHdata.loc[:, 'ideo_label'], MHdata.loc[:, 'Llama_ideoGER_score_low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.35766423357664"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#percent agreement ideoGER_low:\n",
    "100*571/685"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama31_ideo_GER</th>\n",
       "      <th>Links</th>\n",
       "      <th>Mitte</th>\n",
       "      <th>Rechts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama31_ideology</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>conservative</th>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal</th>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>19</td>\n",
       "      <td>399</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama31_ideo_GER  Links  Mitte  Rechts\n",
       "Llama31_ideology                      \n",
       "conservative          8     26      43\n",
       "liberal              70     80       0\n",
       "neutral              19    399       5"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#and compared to the english prompt:\n",
    "pd.crosstab(MHdata.loc[:, 'Llama31_ideology'], MHdata.loc[:, 'Llama31_ideo_GER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_human_column_pairs = [\n",
    "    (\"ideo_label\", \"Llama_ideoGER_score\"),\n",
    "    (\"Llama_ideo_score\", \"Llama_ideoGER_score\")\n",
    "# (\"TopicRelevance\", \"rationality_topic_relevance\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_human_column_pairs = [\n",
    "    (\"ideo_label\", \"Llama_ideoGER_score_low\"),\n",
    "# (\"TopicRelevance\", \"rationality_topic_relevance\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Options low: Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.55      0.63       113\n",
      "           1       0.84      0.95      0.89       497\n",
      "           2       0.92      0.47      0.62        75\n",
      "\n",
      "    accuracy                           0.83       685\n",
      "   macro avg       0.84      0.66      0.72       685\n",
      "weighted avg       0.83      0.83      0.82       685\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.5580345014941591\n",
      "krippendorf(ideo_label): 0.5540933207998926\n"
     ]
    }
   ],
   "source": [
    "print(\"Options low: Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\")\n",
    "\n",
    "for human_col, llm_col in llm_human_column_pairs:\n",
    "    subset = MHdata[[human_col, llm_col]].dropna()\n",
    "    human = subset[human_col].tolist()\n",
    "    llm = subset[llm_col].tolist()\n",
    "    \n",
    "    print(\"---\")\n",
    "    print(f\"{classification_report(human, llm)}\")\n",
    "    print(f\"cohen_kappa_score({human_col}): {cohen_kappa_score(human, llm)}\")\n",
    "    print(f\"krippendorf({human_col}): {krippendorff.alpha(np.array([human, llm]), level_of_measurement=\"nominal\")}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "considerably better reliability and less missing values than without low temperature setting, but still not as good as the english prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.54      0.57       110\n",
      "           1       0.83      0.91      0.87       464\n",
      "           2       0.77      0.49      0.60        76\n",
      "\n",
      "    accuracy                           0.80       650\n",
      "   macro avg       0.74      0.64      0.68       650\n",
      "weighted avg       0.79      0.80      0.79       650\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.5027665619859429\n",
      "krippendorf(ideo_label): 0.5012600784626177\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.47      0.57       150\n",
      "           1       0.79      0.94      0.86       423\n",
      "           2       0.90      0.56      0.69        77\n",
      "\n",
      "    accuracy                           0.79       650\n",
      "   macro avg       0.80      0.66      0.70       650\n",
      "weighted avg       0.79      0.79      0.77       650\n",
      "\n",
      "cohen_kappa_score(Llama_ideo_score): 0.5294771793809241\n",
      "krippendorf(Llama_ideo_score): 0.5233547200012763\n"
     ]
    }
   ],
   "source": [
    "print(\"Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\")\n",
    "\n",
    "for human_col, llm_col in llm_human_column_pairs:\n",
    "    subset = MHdata[[human_col, llm_col]].dropna()\n",
    "    human = subset[human_col].tolist()\n",
    "    llm = subset[llm_col].tolist()\n",
    "    \n",
    "    print(\"---\")\n",
    "    print(f\"{classification_report(human, llm)}\")\n",
    "    print(f\"cohen_kappa_score({human_col}): {cohen_kappa_score(human, llm)}\")\n",
    "    print(f\"krippendorf({human_col}): {krippendorff.alpha(np.array([human, llm]), level_of_measurement=\"nominal\")}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unexpectedly, the german prompt did much worse than the english prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MHdatapar = pd.read_parquet('data/MH_BClemm_data/germany_val_all_llama.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add new columns to MHdatapar:\n",
    "#MHdatapar = MHdatapar.join(MHdata.loc[:, ['Llama31_ideology', 'Llama31_ideology_low', 'Llama_ideo_score', 'Llama_ideo_score_low', 'Llama31_ideo_GER', 'Llama31_ideo_GER_low', 'Llama_ideoGER_score', 'Llama_ideoGER_score_low']])\n",
    "MHdatapar = MHdatapar.join(MHdata.loc[:, ['Llama31_ideology_low', 'Llama_ideo_score_low', 'Llama31_ideo_GER_low', 'Llama_ideoGER_score_low']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "classifying political_ideology_GER2: 100%|██████████| 700/700 [38:35<00:00,  3.31s/it]  \n"
     ]
    }
   ],
   "source": [
    "#what if we adapt ideology labels further:\n",
    "#what does Llama3.1 predict for political orientation?\n",
    "predictions: typing.Dict[str, pd.Series] = {\n",
    "    label: (\n",
    "        src.PromptClassify\n",
    "        .from_json(path)\n",
    "        (MHdata[\"text\"], MODEL, options=options_low)\n",
    "    )\n",
    "    for label, path in CFG.prompt_classify_files.items() if label == 'political_ideology_GER2'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "political_ideology_GER2\n",
      "Mittlere Mitte    486\n",
      "Linksliberal      140\n",
      "Konservativ        42\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#join to the dataset:\n",
    "for _, preds in predictions.items():\n",
    "    print(preds.value_counts())\n",
    "    print(\"-\" * 42)\n",
    "    # Convert Series to DataFrame\n",
    "    preds_df = preds.to_frame()\n",
    "    # Rename the column in preds_df to 'Llama31_ideology'\n",
    "    preds_df = preds_df.rename(columns={preds_df.columns[0]: 'Llama31_ideo_GER2_low'})\n",
    "    MHdatapar = MHdatapar.join(preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the political ideology labels to numbers:\n",
    "MHdatapar['Llama_ideoGER_score2_low'] = MHdatapar['Llama31_ideo_GER2'].map({'Linksliberal': 0, 'Mittlere Mitte': 1, 'Konservativ': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MHdatapar['Llama_ideoGER_score2_low'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama_ideoGER_score2_low</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ideo_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>436</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama_ideoGER_score2_low  0.0  1.0  2.0\n",
       "ideo_label                             \n",
       "0                          90   24    0\n",
       "1                          44  436    6\n",
       "2                           6   26   36"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#does Llama political ideology differ from manual political ideology ?\n",
    "#make a crosstab to see if there are differences:\n",
    "pd.crosstab(MHdatapar.loc[:, 'ideo_label'], MHdatapar.loc[:, 'Llama_ideoGER_score2_low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama_ideoGER_score2</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ideo_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>370</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama_ideoGER_score2  0.0  1.0  2.0\n",
       "ideo_label                         \n",
       "0                      75   29    4\n",
       "1                      60  370   13\n",
       "2                      13   21   29"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#does Llama political ideology differ from manual political ideology ?\n",
    "#make a crosstab to see if there are differences:\n",
    "pd.crosstab(MHdata.loc[:, 'ideo_label'], MHdata.loc[:, 'Llama_ideoGER_score2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama31_ideo_GER2</th>\n",
       "      <th>Konservativ</th>\n",
       "      <th>Linksliberal</th>\n",
       "      <th>Mittlere Mitte</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama31_ideo_GER</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Links</th>\n",
       "      <td>7</td>\n",
       "      <td>63</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mitte</th>\n",
       "      <td>11</td>\n",
       "      <td>72</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rechts</th>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama31_ideo_GER2  Konservativ  Linksliberal  Mittlere Mitte\n",
       "Llama31_ideo_GER                                            \n",
       "Links                        7            63              20\n",
       "Mitte                       11            72             375\n",
       "Rechts                      27             3               5"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#and compared to the GER1 prompt:\n",
    "pd.crosstab(MHdata.loc[:, 'Llama31_ideo_GER'], MHdata.loc[:, 'Llama31_ideo_GER2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_human_column_pairs = [\n",
    "    (\"ideo_label\", \"Llama_ideoGER_score2\"),\n",
    "    (\"Llama_ideoGER_score\", \"Llama_ideoGER_score2\")\n",
    "# (\"TopicRelevance\", \"rationality_topic_relevance\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.69      0.59       108\n",
      "           1       0.88      0.84      0.86       443\n",
      "           2       0.63      0.46      0.53        63\n",
      "\n",
      "    accuracy                           0.77       614\n",
      "   macro avg       0.67      0.66      0.66       614\n",
      "weighted avg       0.79      0.77      0.78       614\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.5003894126262686\n",
      "krippendorf(ideo_label): 0.4990361593355478\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.46      0.70      0.55        90\n",
      "         1.0       0.94      0.82      0.87       458\n",
      "         2.0       0.60      0.77      0.68        35\n",
      "\n",
      "    accuracy                           0.80       583\n",
      "   macro avg       0.66      0.76      0.70       583\n",
      "weighted avg       0.84      0.80      0.81       583\n",
      "\n",
      "cohen_kappa_score(Llama_ideoGER_score): 0.5178914320153615\n",
      "krippendorf(Llama_ideoGER_score): 0.5133874210630646\n"
     ]
    }
   ],
   "source": [
    "print(\"Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\")\n",
    "\n",
    "for human_col, llm_col in llm_human_column_pairs:\n",
    "    subset = MHdata[[human_col, llm_col]].dropna()\n",
    "    human = subset[human_col].tolist()\n",
    "    llm = subset[llm_col].tolist()\n",
    "    \n",
    "    print(\"---\")\n",
    "    print(f\"{classification_report(human, llm)}\")\n",
    "    print(f\"cohen_kappa_score({human_col}): {cohen_kappa_score(human, llm)}\")\n",
    "    print(f\"krippendorf({human_col}): {krippendorff.alpha(np.array([human, llm]), level_of_measurement=\"nominal\")}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No improvement of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data to parquet\n",
    "MHdatapar.to_parquet('data/MH_BClemm_data/germany_val_all_llama.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "classifying political_ideology_GER3:   0%|          | 0/700 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "classifying political_ideology_GER3: 100%|██████████| 700/700 [45:29<00:00,  3.90s/it]  \n"
     ]
    }
   ],
   "source": [
    "#final try to improve German language prompt:\n",
    "#what does Llama3.1 predict for political orientation?\n",
    "predictions: typing.Dict[str, pd.Series] = {\n",
    "    label: (\n",
    "        src.PromptClassify\n",
    "        .from_json(path)\n",
    "        (MHdata[\"text\"], MODEL, options=options_low)\n",
    "    )\n",
    "    for label, path in CFG.prompt_classify_files.items() if label == 'political_ideology_GER3'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "political_ideology_GER3\n",
      "Moderate       504\n",
      "Liberal         96\n",
      "Konservativ     49\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#join to the dataset:\n",
    "for _, preds in predictions.items():\n",
    "    print(preds.value_counts())\n",
    "    print(\"-\" * 42)\n",
    "    # Convert Series to DataFrame\n",
    "    preds_df = preds.to_frame()\n",
    "    # Rename the column in preds_df to 'Llama31_ideology'\n",
    "    preds_df = preds_df.rename(columns={preds_df.columns[0]: 'Llama31_ideo_GER3'})\n",
    "    MHdatapar = MHdatapar.join(preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the political ideology labels to numbers:\n",
    "MHdatapar['Llama_ideoGER_score3'] = MHdatapar['Llama31_ideo_GER3'].map({'Liberal': 0, 'Moderate': 1, 'Konservativ': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(51)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MHdatapar['Llama_ideoGER_score3'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama_ideoGER_score3</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ideo_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td>432</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama_ideoGER_score3  0.0  1.0  2.0\n",
       "ideo_label                         \n",
       "0                      60   47    1\n",
       "1                      31  432   12\n",
       "2                       5   25   36"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new run:\n",
    "#does Llama political ideology differ from manual political ideology ?\n",
    "#make a crosstab to see if there are differences:\n",
    "pd.crosstab(MHdatapar.loc[:, 'ideo_label'], MHdatapar.loc[:, 'Llama_ideoGER_score3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama_ideoGER_score3</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ideo_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>441</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama_ideoGER_score3  0.0  1.0  2.0\n",
       "ideo_label                         \n",
       "0                      59   46    0\n",
       "1                      23  441    9\n",
       "2                       5   26   36"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#does Llama political ideology differ from manual political ideology ?\n",
    "#make a crosstab to see if there are differences:\n",
    "pd.crosstab(MHdata.loc[:, 'ideo_label'], MHdata.loc[:, 'Llama_ideoGER_score3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.56      0.61       105\n",
      "           1       0.86      0.93      0.89       473\n",
      "           2       0.80      0.54      0.64        67\n",
      "\n",
      "    accuracy                           0.83       645\n",
      "   macro avg       0.78      0.68      0.72       645\n",
      "weighted avg       0.82      0.83      0.82       645\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.5639350973168099\n",
      "krippendorf(ideo_label): 0.562640078693097\n"
     ]
    }
   ],
   "source": [
    "llm_human_column_pairs = [\n",
    "    (\"ideo_label\", \"Llama_ideoGER_score3\"),\n",
    "#   (\"Llama_ideoGER_score\", \"Llama_ideoGER_score2\")\n",
    "# (\"TopicRelevance\", \"rationality_topic_relevance\"),\n",
    "]\n",
    "print(\"Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\")\n",
    "\n",
    "for human_col, llm_col in llm_human_column_pairs:\n",
    "    subset = MHdata[[human_col, llm_col]].dropna()\n",
    "    human = subset[human_col].tolist()\n",
    "    llm = subset[llm_col].tolist()\n",
    "    \n",
    "    print(\"---\")\n",
    "    print(f\"{classification_report(human, llm)}\")\n",
    "    print(f\"cohen_kappa_score({human_col}): {cohen_kappa_score(human, llm)}\")\n",
    "    print(f\"krippendorf({human_col}): {krippendorff.alpha(np.array([human, llm]), level_of_measurement=\"nominal\")}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best performing German Llama3.1 model so far, but did not reduce (but increased) number of missing classifications, and still performance is inferior to english language prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pol_label</th>\n",
       "      <th>neg_label</th>\n",
       "      <th>neg3_label</th>\n",
       "      <th>ideo_label</th>\n",
       "      <th>GPT_Pol1</th>\n",
       "      <th>GPT_Pol2</th>\n",
       "      <th>GPT_Neg1</th>\n",
       "      <th>GPT_Neg2</th>\n",
       "      <th>GPT_Neg_3Way1</th>\n",
       "      <th>...</th>\n",
       "      <th>Llama31_ideology_low</th>\n",
       "      <th>Llama_ideo_score_low</th>\n",
       "      <th>Llama31_ideo_GER_low</th>\n",
       "      <th>Llama_ideoGER_score_low</th>\n",
       "      <th>Llama31_ideo_GER2_low</th>\n",
       "      <th>Llama_ideoGER_score2_low</th>\n",
       "      <th>Llama31_ideo_GER3</th>\n",
       "      <th>Llama_ideoGER_score3</th>\n",
       "      <th>Llama31_ideo_EXT</th>\n",
       "      <th>Llama_ideoEXT_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@thatleechi17 @KlemmChr @AndiScheuer @victorpe...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mittlere Mitte</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Glauben Sie nur nicht, dass Menschen die nicht...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>liberal</td>\n",
       "      <td>0</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mittlere Mitte</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Das ist ja das Mindeste. \\r\\n\\r\\nDass das aber...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>liberal</td>\n",
       "      <td>0</td>\n",
       "      <td>Links</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Linksliberal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Left</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Challen81690499 @c_lindner @rbrinkhaus @Nowab...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mittlere Mitte</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ich sage: #DANKE!!!\\r\\nhttps://t.co/0pVneqXwTC...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>conservative</td>\n",
       "      <td>2</td>\n",
       "      <td>Rechts</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Konservativ</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Right</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  pol_label  neg_label  \\\n",
       "0  @thatleechi17 @KlemmChr @AndiScheuer @victorpe...          1          1   \n",
       "1  Glauben Sie nur nicht, dass Menschen die nicht...          1          0   \n",
       "2  Das ist ja das Mindeste. \\r\\n\\r\\nDass das aber...          1          1   \n",
       "3  @Challen81690499 @c_lindner @rbrinkhaus @Nowab...          0          0   \n",
       "4  Ich sage: #DANKE!!!\\r\\nhttps://t.co/0pVneqXwTC...          1          0   \n",
       "\n",
       "   neg3_label  ideo_label  GPT_Pol1  GPT_Pol2  GPT_Neg1  GPT_Neg2  \\\n",
       "0           0           1         1         1         1         1   \n",
       "1           1           1         1         1         0         0   \n",
       "2           0           1         1         1         1         1   \n",
       "3           1           1         1         0         0         0   \n",
       "4           2           2         1         1         0         0   \n",
       "\n",
       "   GPT_Neg_3Way1  ...  Llama31_ideology_low  Llama_ideo_score_low  \\\n",
       "0              0  ...               neutral                     1   \n",
       "1              1  ...               liberal                     0   \n",
       "2              0  ...               liberal                     0   \n",
       "3              1  ...               neutral                     1   \n",
       "4              2  ...          conservative                     2   \n",
       "\n",
       "   Llama31_ideo_GER_low  Llama_ideoGER_score_low  Llama31_ideo_GER2_low  \\\n",
       "0                 Mitte                      1.0         Mittlere Mitte   \n",
       "1                 Mitte                      1.0         Mittlere Mitte   \n",
       "2                 Links                      0.0           Linksliberal   \n",
       "3                 Mitte                      1.0         Mittlere Mitte   \n",
       "4                Rechts                      2.0                   None   \n",
       "\n",
       "   Llama_ideoGER_score2_low  Llama31_ideo_GER3 Llama_ideoGER_score3  \\\n",
       "0                       1.0           Moderate                  1.0   \n",
       "1                       1.0           Moderate                  1.0   \n",
       "2                       0.0            Liberal                  0.0   \n",
       "3                       1.0           Moderate                  1.0   \n",
       "4                       NaN        Konservativ                  2.0   \n",
       "\n",
       "  Llama31_ideo_EXT Llama_ideoEXT_score  \n",
       "0          Neutral                 1.0  \n",
       "1          Neutral                 1.0  \n",
       "2             Left                 0.0  \n",
       "3          Neutral                 1.0  \n",
       "4            Right                 2.0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MHdatapar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MHdatapar = MHdatapar.join(MHdata.loc[:, ['Llama31_ideo_GER3', 'Llama_ideoGER_score3', 'Llama31_ideology_low', 'Llama_ideo_score_low', 'Llama31_ideo_GER_low' ,'Llama_ideoGER_score_low']])   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "MHdatapar.to_parquet('data/MH_BClemm_data/germany_val_all_llama.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "classifying political_ideology_ext: 100%|██████████| 700/700 [25:46<00:00,  2.21s/it]\n"
     ]
    }
   ],
   "source": [
    "#what about Simon's more expansive english ideology prompt?\n",
    "#what does Llama3.1 predict for political orientation?\n",
    "predictions2: typing.Dict[str, pd.Series] = {\n",
    "    label: (\n",
    "        src.PromptClassify\n",
    "        .from_json(path)\n",
    "        (MHdata[\"text\"], MODEL, options=options_low)\n",
    "    )\n",
    "    for label, path in CFG.prompt_classify_files.items() if label == 'political_ideology_ext'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'political_ideology_ext': 0      Neutral\n",
       " 1      Neutral\n",
       " 2         Left\n",
       " 3      Neutral\n",
       " 4        Right\n",
       "         ...   \n",
       " 695    Neutral\n",
       " 696       Left\n",
       " 697      Right\n",
       " 698    Neutral\n",
       " 699    Neutral\n",
       " Name: political_ideology_ext, Length: 700, dtype: object}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MHdatapar=pd.read_parquet('data/MH_BClemm_data/germany_val_all_llama.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'pol_label', 'neg_label', 'neg3_label', 'ideo_label',\n",
       "       'GPT_Pol1', 'GPT_Pol2', 'GPT_Neg1', 'GPT_Neg2', 'GPT_Neg_3Way1',\n",
       "       'GPT_Neg_3Way2', 'GPT_Ideo1', 'GPT_Ideo2', 'Pol_Recon', 'Neg_Recon',\n",
       "       'Neg3_Recon', 'Ideo_Recon', 'Llama31_ideology', 'Llama_ideo_score',\n",
       "       'Llama31_ideo_GER', 'Llama_ideoGER_score', 'Llama31_ideo_GER2',\n",
       "       'Llama_ideoGER_score2', 'Llama31_ideo_GER3', 'Llama_ideoGER_score3',\n",
       "       'Llama31_ideology_low', 'Llama_ideo_score_low', 'Llama31_ideo_GER_low',\n",
       "       'Llama_ideoGER_score_low'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MHdatapar.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "political_ideology_ext\n",
      "Neutral    438\n",
      "Left       163\n",
      "Right       98\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#run2\n",
    "#join to the dataset:\n",
    "for _, preds in predictions2.items():\n",
    "    print(preds.value_counts())\n",
    "    print(\"-\" * 42)\n",
    "    # Convert Series to DataFrame\n",
    "    preds_df = preds.to_frame()\n",
    "    # Rename the column in preds_df to 'Llama31_ideology'\n",
    "    preds_df = preds_df.rename(columns={preds_df.columns[0]: 'Llama31_ideo_EXT'})\n",
    "    MHdatapar = MHdatapar.join(preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "political_ideology_ext\n",
      "Neutral    440\n",
      "Left       162\n",
      "Right       97\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#join to the dataset:\n",
    "for _, preds in predictions2.items():\n",
    "    print(preds.value_counts())\n",
    "    print(\"-\" * 42)\n",
    "    # Convert Series to DataFrame\n",
    "    preds_df = preds.to_frame()\n",
    "    # Rename the column in preds_df to 'Llama31_ideology'\n",
    "    preds_df = preds_df.rename(columns={preds_df.columns[0]: 'Llama31_ideo_EXT'})\n",
    "    MHdatapar = MHdatapar.join(preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the political ideology labels to numbers:\n",
    "MHdatapar['Llama_ideoEXT_score'] = MHdatapar['Llama31_ideo_EXT'].map({'Left': 0, 'Neutral': 1, 'Right': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MHdata['Llama_ideoEXT_score'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.83      0.69       115\n",
      "           1       0.93      0.82      0.87       503\n",
      "           2       0.60      0.72      0.65        81\n",
      "\n",
      "    accuracy                           0.81       699\n",
      "   macro avg       0.71      0.79      0.74       699\n",
      "weighted avg       0.84      0.81      0.82       699\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.6110119022899242\n",
      "krippendorf(ideo_label): 0.6086761112191166\n"
     ]
    }
   ],
   "source": [
    "llm_human_column_pairs = [\n",
    "    (\"ideo_label\", \"Llama_ideoEXT_score\"),\n",
    "#   (\"Llama_ideoGER_score\", \"Llama_ideoGER_score2\")\n",
    "# (\"TopicRelevance\", \"rationality_topic_relevance\"),\n",
    "]\n",
    "print(\"Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\")\n",
    "\n",
    "for human_col, llm_col in llm_human_column_pairs:\n",
    "    subset = MHdata[[human_col, llm_col]].dropna()\n",
    "    human = subset[human_col].tolist()\n",
    "    llm = subset[llm_col].tolist()\n",
    "    \n",
    "    print(\"---\")\n",
    "    print(f\"{classification_report(human, llm)}\")\n",
    "    print(f\"cohen_kappa_score({human_col}): {cohen_kappa_score(human, llm)}\")\n",
    "    print(f\"krippendorf({human_col}): {krippendorff.alpha(np.array([human, llm]), level_of_measurement=\"nominal\")}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8358226037195995"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#percent agreement\n",
    "(0.59*115+0.93*503+0.60*81)/699\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#very similar (but slightly worse) than the original shorter english prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how about zero temperature?\n",
    "#change options to low temperature (0,1) and compare result:\n",
    "options_zero = \"\"\"\n",
    "seed: 42\n",
    "temperature: 0\n",
    "\"\"\"\n",
    "\n",
    "options_zero = yaml.safe_load(options_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "classifying political_ideology:   0%|          | 0/700 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "classifying political_ideology: 100%|██████████| 700/700 [22:21<00:00,  1.92s/it]\n",
      "classifying political_post: 100%|██████████| 700/700 [22:02<00:00,  1.89s/it]\n",
      "classifying political_post_GER: 100%|██████████| 700/700 [22:11<00:00,  1.90s/it]\n"
     ]
    }
   ],
   "source": [
    "#the _label variables are the reconciled and definitive annotation values for the variables\n",
    "#what does Llama3.1 predict for political orientation?\n",
    "predictions: typing.Dict[str, pd.Series] = {\n",
    "    label: (\n",
    "        src.PromptClassify\n",
    "        .from_json(path)\n",
    "        (MHdata[\"text\"], MODEL, options=options_zero)\n",
    "    )\n",
    "    for label, path in CFG.prompt_classify_files.items() if label in ['political_ideology', 'political_post', 'political_post_GER']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'political_ideology': 0           neutral\n",
       " 1           neutral\n",
       " 2           liberal\n",
       " 3           neutral\n",
       " 4      conservative\n",
       "            ...     \n",
       " 695         neutral\n",
       " 696         liberal\n",
       " 697    conservative\n",
       " 698         neutral\n",
       " 699         neutral\n",
       " Name: political_ideology, Length: 700, dtype: object,\n",
       " 'political_post': 0          political\n",
       " 1          political\n",
       " 2          political\n",
       " 3          political\n",
       " 4          political\n",
       "            ...      \n",
       " 695        political\n",
       " 696        political\n",
       " 697        political\n",
       " 698    non-political\n",
       " 699        political\n",
       " Name: political_post, Length: 700, dtype: object,\n",
       " 'political_post_GER': 0      political\n",
       " 1      political\n",
       " 2      political\n",
       " 3      political\n",
       " 4      political\n",
       "          ...    \n",
       " 695    political\n",
       " 696    political\n",
       " 697    political\n",
       " 698    political\n",
       " 699    political\n",
       " Name: political_post_GER, Length: 700, dtype: object}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "political_ideology\n",
      "neutral         471\n",
      "liberal         149\n",
      "conservative     80\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------\n",
      "political_post\n",
      "political        518\n",
      "non-political    182\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------\n",
      "political_post_GER\n",
      "political        591\n",
      "non-political    109\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#join to the dataset:\n",
    "for _, preds in predictions.items():\n",
    "    print(preds.value_counts())\n",
    "    print(\"-\" * 42)\n",
    "    # Convert Series to DataFrame\n",
    "    preds_df = preds.to_frame()\n",
    "    # Rename the column in preds_df to 'Llama31_ideology'\n",
    "    preds_df = preds_df.rename(columns={'political_ideology':'Llama31_ideology_zero', 'political_post':'Llama31_political_zero', 'political_post_GER': 'Llama31_political_GER_zero'})\n",
    "    MHdatapar = MHdatapar.join(preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the political ideology labels to numbers:\n",
    "MHdatapar['Llama31_ideology_zero_score'] = MHdatapar['Llama31_ideology_zero'].map({'liberal': 0, 'neutral': 1, 'conservative': 2})\n",
    "MHdatapar['Llama31_political_zero_score'] = MHdatapar['Llama31_political_zero'].map({'non-political': 0, 'political': 1})\n",
    "MHdatapar['Llama31_political_GER_zero_score'] = MHdatapar['Llama31_political_GER_zero'].map({'non-political': 0, 'political': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama_ideo_score_low</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama31_ideology_zero_score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>145</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>462</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama_ideo_score_low           0    1   2\n",
       "Llama31_ideology_zero_score              \n",
       "0                            145    2   2\n",
       "1                              6  462   3\n",
       "2                              0    2  78"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new run:\n",
    "#and how does Llama3.1 perform with zero compared to low temperature?\n",
    "#make a crosstab to see if there are differences:\n",
    "pd.crosstab(MHdatapar.loc[:, 'Llama31_ideology_zero_score'], MHdatapar.loc[:, 'Llama_ideo_score_low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama_ideo_score_low</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama31_ideology_zero_score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>143</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>466</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama_ideo_score_low           0    1   2\n",
       "Llama31_ideology_zero_score              \n",
       "0                            143    5   2\n",
       "1                              2  466   1\n",
       "2                              0    3  78"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#and how does Llama3.1 perform with zero compared to low temperature?\n",
    "#make a crosstab to see if there are differences:\n",
    "pd.crosstab(MHdatapar.loc[:, 'Llama31_ideology_zero_score'], MHdatapar.loc[:, 'Llama_ideo_score_low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pol_label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama31_political_zero</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>non-political</th>\n",
       "      <td>157</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>political</th>\n",
       "      <td>45</td>\n",
       "      <td>473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pol_label                 0    1\n",
       "Llama31_political_zero          \n",
       "non-political           157   25\n",
       "political                45  473"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new run:\n",
    "#and how did Llama3.1 perform in classifying political ?\n",
    "pd.crosstab(MHdatapar.loc[:, 'Llama31_political_zero'], MHdatapar.loc[:, 'pol_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pol_label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama31_political_zero</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>non-political</th>\n",
       "      <td>143</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>political</th>\n",
       "      <td>59</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pol_label                 0    1\n",
       "Llama31_political_zero          \n",
       "non-political           143   21\n",
       "political                59  477"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#and how did Llama3.1 perform in classifying political ?\n",
    "pd.crosstab(MHdatapar.loc[:, 'Llama31_political_zero'], MHdatapar.loc[:, 'pol_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama31_political_GER_zero</th>\n",
       "      <th>non-political</th>\n",
       "      <th>political</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama31_political_zero</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>non-political</th>\n",
       "      <td>108</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>political</th>\n",
       "      <td>1</td>\n",
       "      <td>517</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama31_political_GER_zero  non-political  political\n",
       "Llama31_political_zero                              \n",
       "non-political                         108         74\n",
       "political                               1        517"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new run:\n",
    "#does it matter whether we specify the German context in the Llama3.1 prompt when classifying political ?\n",
    "pd.crosstab(MHdatapar.loc[:, 'Llama31_political_zero'], MHdatapar.loc[:, 'Llama31_political_GER_zero'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama31_political_GER_zero</th>\n",
       "      <th>non-political</th>\n",
       "      <th>political</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama31_political_zero</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>non-political</th>\n",
       "      <td>110</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>political</th>\n",
       "      <td>1</td>\n",
       "      <td>535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama31_political_GER_zero  non-political  political\n",
       "Llama31_political_zero                              \n",
       "non-political                         110         54\n",
       "political                               1        535"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#does it matter whether we specify the German context in the Llama3.1 prompt when classifying political ?\n",
    "pd.crosstab(MHdatapar.loc[:, 'Llama31_political_zero'], MHdatapar.loc[:, 'Llama31_political_GER_zero'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.81      0.70       115\n",
      "           1       0.92      0.86      0.89       503\n",
      "           2       0.70      0.68      0.69        82\n",
      "\n",
      "    accuracy                           0.83       700\n",
      "   macro avg       0.75      0.78      0.76       700\n",
      "weighted avg       0.84      0.83      0.83       700\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.6368661505196345\n",
      "krippendorf(ideo_label): 0.6362597554687432\n",
      "percent_agreement(ideo_label): 83.00%\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.78      0.82       202\n",
      "           1       0.91      0.95      0.93       498\n",
      "\n",
      "    accuracy                           0.90       700\n",
      "   macro avg       0.89      0.86      0.87       700\n",
      "weighted avg       0.90      0.90      0.90       700\n",
      "\n",
      "cohen_kappa_score(pol_label): 0.7490679667335818\n",
      "krippendorf(pol_label): 0.7489901164698163\n",
      "percent_agreement(pol_label): 90.00%\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.49      0.64       202\n",
      "           1       0.83      0.98      0.90       498\n",
      "\n",
      "    accuracy                           0.84       700\n",
      "   macro avg       0.87      0.74      0.77       700\n",
      "weighted avg       0.85      0.84      0.82       700\n",
      "\n",
      "cohen_kappa_score(pol_label): 0.5445227565874333\n",
      "krippendorf(pol_label): 0.5332246758730244\n",
      "percent_agreement(pol_label): 83.86%\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.97      0.80       202\n",
      "           1       0.98      0.82      0.90       498\n",
      "\n",
      "    accuracy                           0.86       700\n",
      "   macro avg       0.84      0.89      0.85       700\n",
      "weighted avg       0.90      0.86      0.87       700\n",
      "\n",
      "cohen_kappa_score(pol_label): 0.7046649612733604\n",
      "krippendorf(pol_label): 0.7005126471748071\n",
      "percent_agreement(pol_label): 86.43%\n"
     ]
    }
   ],
   "source": [
    "#new run:\n",
    "#evaluete respective performance :\n",
    "llm_human_column_pairs = [\n",
    "    (\"ideo_label\", \"Llama31_ideology_zero_score\"),\n",
    "    (\"pol_label\", \"Llama31_political_zero_score\"),\n",
    "    (\"pol_label\", \"Llama31_political_GER_zero_score\"),\n",
    "    (\"pol_label\", \"GPT_Pol1\")\n",
    "]\n",
    "print(\"Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\")\n",
    "\n",
    "for human_col, llm_col in llm_human_column_pairs:\n",
    "    subset = MHdatapar[[human_col, llm_col]].dropna()\n",
    "    human = subset[human_col].tolist()\n",
    "    llm = subset[llm_col].tolist()\n",
    "\n",
    "    # Calculate percent agreement\n",
    "    agreement = np.sum(np.array(human) == np.array(llm))/len(np.array(human)) * 100\n",
    "\n",
    "    print(\"---\")\n",
    "    print(f\"{classification_report(human, llm)}\")\n",
    "    print(f\"cohen_kappa_score({human_col}): {cohen_kappa_score(human, llm)}\")\n",
    "    print(f\"krippendorf({human_col}): {krippendorff.alpha(np.array([human, llm]), level_of_measurement=\"nominal\")}\")\n",
    "    print(f\"percent_agreement({human_col}): {agreement:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.81      0.70       115\n",
      "           1       0.92      0.85      0.88       503\n",
      "           2       0.69      0.68      0.69        82\n",
      "\n",
      "    accuracy                           0.83       700\n",
      "   macro avg       0.74      0.78      0.76       700\n",
      "weighted avg       0.84      0.83      0.83       700\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.6320606774080042\n",
      "krippendorf(ideo_label): 0.6313698931428036\n",
      "percent_agreement(ideo_label): 82.71%\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.71      0.78       202\n",
      "           1       0.89      0.96      0.92       498\n",
      "\n",
      "    accuracy                           0.89       700\n",
      "   macro avg       0.88      0.83      0.85       700\n",
      "weighted avg       0.88      0.89      0.88       700\n",
      "\n",
      "cohen_kappa_score(pol_label): 0.7051762624773616\n",
      "krippendorf(pol_label): 0.7042627178657873\n",
      "percent_agreement(pol_label): 88.57%\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.50      0.65       202\n",
      "           1       0.83      0.98      0.90       498\n",
      "\n",
      "    accuracy                           0.84       700\n",
      "   macro avg       0.87      0.74      0.77       700\n",
      "weighted avg       0.85      0.84      0.83       700\n",
      "\n",
      "cohen_kappa_score(pol_label): 0.5541043063079607\n",
      "krippendorf(pol_label): 0.543577745708063\n",
      "percent_agreement(pol_label): 84.14%\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.97      0.80       202\n",
      "           1       0.98      0.82      0.90       498\n",
      "\n",
      "    accuracy                           0.86       700\n",
      "   macro avg       0.84      0.89      0.85       700\n",
      "weighted avg       0.90      0.86      0.87       700\n",
      "\n",
      "cohen_kappa_score(pol_label): 0.7046649612733604\n",
      "krippendorf(pol_label): 0.7005126471748071\n",
      "percent_agreement(pol_label): 86.43%\n"
     ]
    }
   ],
   "source": [
    "#evaluete respective performance :\n",
    "llm_human_column_pairs = [\n",
    "    (\"ideo_label\", \"Llama31_ideology_zero_score\"),\n",
    "    (\"pol_label\", \"Llama31_political_zero_score\"),\n",
    "    (\"pol_label\", \"Llama31_political_GER_zero_score\"),\n",
    "    (\"pol_label\", \"GPT_Pol1\")\n",
    "]\n",
    "print(\"Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\")\n",
    "\n",
    "for human_col, llm_col in llm_human_column_pairs:\n",
    "    subset = MHdatapar[[human_col, llm_col]].dropna()\n",
    "    human = subset[human_col].tolist()\n",
    "    llm = subset[llm_col].tolist()\n",
    "\n",
    "    # Calculate percent agreement\n",
    "    agreement = np.sum(np.array(human) == np.array(llm))/len(np.array(human)) * 100\n",
    "\n",
    "    print(\"---\")\n",
    "    print(f\"{classification_report(human, llm)}\")\n",
    "    print(f\"cohen_kappa_score({human_col}): {cohen_kappa_score(human, llm)}\")\n",
    "    print(f\"krippendorf({human_col}): {krippendorff.alpha(np.array([human, llm]), level_of_measurement=\"nominal\")}\")\n",
    "    print(f\"percent_agreement({human_col}): {agreement:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#llama3.1 beats GPT4 on classifying political posts, in German, even without mentioning this is German content referring to the German political system\n",
    "#in fact, when we do mention the political context, performance fall slightly below that of GPT4..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "classifying political_ideology:   0%|          | 0/700 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "classifying political_ideology: 100%|██████████| 700/700 [01:46<00:00,  6.60it/s]\n",
      "classifying political_post: 100%|██████████| 700/700 [01:40<00:00,  6.96it/s]\n"
     ]
    }
   ],
   "source": [
    "#what is the effect of using a smaller model?\n",
    "#what does Llama3.1 predict for political orientation and ideology?\n",
    "predictions2: typing.Dict[str, pd.Series] = {\n",
    "    label: (\n",
    "        src.PromptClassify\n",
    "        .from_json(path)\n",
    "        (MHdata[\"text\"], model=MODELsmall, options=options_zero)\n",
    "    )\n",
    "    for label, path in CFG.prompt_classify_files.items() if label in ['political_ideology', 'political_post']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'political_ideology': 0      conservative\n",
       " 1           liberal\n",
       " 2           liberal\n",
       " 3           neutral\n",
       " 4      conservative\n",
       "            ...     \n",
       " 695         neutral\n",
       " 696         liberal\n",
       " 697    conservative\n",
       " 698         neutral\n",
       " 699         neutral\n",
       " Name: political_ideology, Length: 700, dtype: object,\n",
       " 'political_post': 0          political\n",
       " 1          political\n",
       " 2          political\n",
       " 3      non-political\n",
       " 4          political\n",
       "            ...      \n",
       " 695        political\n",
       " 696        political\n",
       " 697        political\n",
       " 698    non-political\n",
       " 699        political\n",
       " Name: political_post, Length: 700, dtype: object}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "political_ideology\n",
      "neutral         502\n",
      "liberal         110\n",
      "conservative     79\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------\n",
      "political_post\n",
      "political        486\n",
      "non-political    205\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#join to the dataset:\n",
    "for label, preds in predictions2.items():\n",
    "    print(preds.value_counts())\n",
    "    print(\"-\" * 42)\n",
    "    # Convert Series to DataFrame\n",
    "    preds_df = preds.to_frame()\n",
    "    # Rename the column in preds_df to include the label\n",
    "    preds_df.columns = [f'Llama31_{label}_8b']\n",
    "    MHdatapar = MHdatapar.join(preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Llama31_political_post_8b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>non-political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>non-political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>political</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Llama31_political_post_8b\n",
       "0                   political\n",
       "1                   political\n",
       "2                   political\n",
       "3               non-political\n",
       "4                   political\n",
       "..                        ...\n",
       "695                 political\n",
       "696                 political\n",
       "697                 political\n",
       "698             non-political\n",
       "699                 political\n",
       "\n",
       "[700 rows x 1 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pol_label</th>\n",
       "      <th>neg_label</th>\n",
       "      <th>neg3_label</th>\n",
       "      <th>ideo_label</th>\n",
       "      <th>GPT_Pol1</th>\n",
       "      <th>GPT_Pol2</th>\n",
       "      <th>GPT_Neg1</th>\n",
       "      <th>GPT_Neg2</th>\n",
       "      <th>GPT_Neg_3Way1</th>\n",
       "      <th>...</th>\n",
       "      <th>Llama31_ideology_zero</th>\n",
       "      <th>Llama31_political_zero</th>\n",
       "      <th>Llama31_political_GER_zero</th>\n",
       "      <th>Llama31_ideology_zero_score</th>\n",
       "      <th>Llama31_political_zero_score</th>\n",
       "      <th>Llama31_political_GER_zero_score</th>\n",
       "      <th>Llama31_political_ideology_8b</th>\n",
       "      <th>Llama31_political_post_8b</th>\n",
       "      <th>Llama31_ideology_8b_score</th>\n",
       "      <th>Llama31_political_8b_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@thatleechi17 @KlemmChr @AndiScheuer @victorpe...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>political</td>\n",
       "      <td>political</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>conservative</td>\n",
       "      <td>political</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Glauben Sie nur nicht, dass Menschen die nicht...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>political</td>\n",
       "      <td>political</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>liberal</td>\n",
       "      <td>political</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Das ist ja das Mindeste. \\r\\n\\r\\nDass das aber...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>liberal</td>\n",
       "      <td>political</td>\n",
       "      <td>political</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>liberal</td>\n",
       "      <td>political</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Challen81690499 @c_lindner @rbrinkhaus @Nowab...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>political</td>\n",
       "      <td>political</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>non-political</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ich sage: #DANKE!!!\\r\\nhttps://t.co/0pVneqXwTC...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>conservative</td>\n",
       "      <td>political</td>\n",
       "      <td>political</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>conservative</td>\n",
       "      <td>political</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  pol_label  neg_label  \\\n",
       "0  @thatleechi17 @KlemmChr @AndiScheuer @victorpe...          1          1   \n",
       "1  Glauben Sie nur nicht, dass Menschen die nicht...          1          0   \n",
       "2  Das ist ja das Mindeste. \\r\\n\\r\\nDass das aber...          1          1   \n",
       "3  @Challen81690499 @c_lindner @rbrinkhaus @Nowab...          0          0   \n",
       "4  Ich sage: #DANKE!!!\\r\\nhttps://t.co/0pVneqXwTC...          1          0   \n",
       "\n",
       "   neg3_label  ideo_label  GPT_Pol1  GPT_Pol2  GPT_Neg1  GPT_Neg2  \\\n",
       "0           0           1         1         1         1         1   \n",
       "1           1           1         1         1         0         0   \n",
       "2           0           1         1         1         1         1   \n",
       "3           1           1         1         0         0         0   \n",
       "4           2           2         1         1         0         0   \n",
       "\n",
       "   GPT_Neg_3Way1  ...  Llama31_ideology_zero  Llama31_political_zero  \\\n",
       "0              0  ...                neutral               political   \n",
       "1              1  ...                neutral               political   \n",
       "2              0  ...                liberal               political   \n",
       "3              1  ...                neutral               political   \n",
       "4              2  ...           conservative               political   \n",
       "\n",
       "   Llama31_political_GER_zero  Llama31_ideology_zero_score  \\\n",
       "0                   political                            1   \n",
       "1                   political                            1   \n",
       "2                   political                            0   \n",
       "3                   political                            1   \n",
       "4                   political                            2   \n",
       "\n",
       "   Llama31_political_zero_score  Llama31_political_GER_zero_score  \\\n",
       "0                             1                                 1   \n",
       "1                             1                                 1   \n",
       "2                             1                                 1   \n",
       "3                             1                                 1   \n",
       "4                             1                                 1   \n",
       "\n",
       "   Llama31_political_ideology_8b Llama31_political_post_8b  \\\n",
       "0                   conservative                 political   \n",
       "1                        liberal                 political   \n",
       "2                        liberal                 political   \n",
       "3                        neutral             non-political   \n",
       "4                   conservative                 political   \n",
       "\n",
       "  Llama31_ideology_8b_score Llama31_political_8b_score  \n",
       "0                       2.0                        1.0  \n",
       "1                       0.0                        1.0  \n",
       "2                       0.0                        1.0  \n",
       "3                       1.0                        0.0  \n",
       "4                       2.0                        1.0  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MHdatapar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the political ideology labels to numbers:\n",
    "MHdatapar['Llama31_ideology_8b_score'] = MHdatapar['Llama31_political_ideology_8b'].map({'liberal': 0, 'neutral': 1, 'conservative': 2})\n",
    "MHdatapar['Llama31_political_8b_score'] = MHdatapar['Llama31_political_post_8b'].map({'non-political': 0, 'political': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ideo_label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama31_political_ideology_8b</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>conservative</th>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal</th>\n",
       "      <td>61</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>42</td>\n",
       "      <td>426</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ideo_label                      0    1   2\n",
       "Llama31_political_ideology_8b             \n",
       "conservative                    8   35  36\n",
       "liberal                        61   38  11\n",
       "neutral                        42  426  34"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new run:\n",
    "#and how does the smaller model perform compared to the larger model?\n",
    "#make a crosstab to see if there are differences:\n",
    "pd.crosstab(MHdatapar.loc[:, 'Llama31_political_ideology_8b'], MHdatapar.loc[:, 'ideo_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ideo_label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama31_political_ideology_8b</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>conservative</th>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal</th>\n",
       "      <td>61</td>\n",
       "      <td>37</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>42</td>\n",
       "      <td>429</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ideo_label                      0    1   2\n",
       "Llama31_political_ideology_8b             \n",
       "conservative                    9   33  35\n",
       "liberal                        61   37  13\n",
       "neutral                        42  429  34"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#and how did Llama3.1 8b perform in classifying political ?\n",
    "pd.crosstab(MHdatapar.loc[:, 'Llama31_political_ideology_8b'], MHdatapar.loc[:, 'ideo_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama31_ideology_zero</th>\n",
       "      <th>conservative</th>\n",
       "      <th>liberal</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama31_political_ideology_8b</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>conservative</th>\n",
       "      <td>48</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal</th>\n",
       "      <td>7</td>\n",
       "      <td>79</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>23</td>\n",
       "      <td>56</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama31_ideology_zero          conservative  liberal  neutral\n",
       "Llama31_political_ideology_8b                                \n",
       "conservative                             48       10       21\n",
       "liberal                                   7       79       24\n",
       "neutral                                  23       56      423"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new run:\n",
    "#and how did Llama3.1 8b perform in classifying political compared to large model ?\n",
    "pd.crosstab(MHdatapar.loc[:, 'Llama31_political_ideology_8b'], MHdatapar.loc[:, 'Llama31_ideology_zero'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama31_ideology_zero</th>\n",
       "      <th>conservative</th>\n",
       "      <th>liberal</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama31_political_ideology_8b</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>conservative</th>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal</th>\n",
       "      <td>11</td>\n",
       "      <td>79</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>23</td>\n",
       "      <td>57</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama31_ideology_zero          conservative  liberal  neutral\n",
       "Llama31_political_ideology_8b                                \n",
       "conservative                             46       11       20\n",
       "liberal                                  11       79       21\n",
       "neutral                                  23       57      425"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#and how did Llama3.1 8b perform in classifying political compared to large model ?\n",
    "pd.crosstab(MHdatapar.loc[:, 'Llama31_political_ideology_8b'], MHdatapar.loc[:, 'Llama31_ideology_zero'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pol_label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama31_political_post_8b</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>non-political</th>\n",
       "      <td>167</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>political</th>\n",
       "      <td>35</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pol_label                    0    1\n",
       "Llama31_political_post_8b          \n",
       "non-political              167   38\n",
       "political                   35  451"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new run:\n",
    "#and how did Llama3.1 8b perform in classifying political ?\n",
    "pd.crosstab(MHdatapar.loc[:, 'Llama31_political_post_8b'], MHdatapar.loc[:, 'pol_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pol_label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama31_political_post_8b</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>non-political</th>\n",
       "      <td>147</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>political</th>\n",
       "      <td>54</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pol_label                    0    1\n",
       "Llama31_political_post_8b          \n",
       "non-political              147   16\n",
       "political                   54  475"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#and how did Llama3.1 8b perform in classifying political ?\n",
    "pd.crosstab(MHdatapar.loc[:, 'Llama31_political_post_8b'], MHdatapar.loc[:, 'pol_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pol_label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama31_political_post_8b</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>non-political</th>\n",
       "      <td>167</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>political</th>\n",
       "      <td>35</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pol_label                    0    1\n",
       "Llama31_political_post_8b          \n",
       "non-political              167   38\n",
       "political                   35  451"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new run:\n",
    "#and how did Llama3.1 8b perform in classifying political ?\n",
    "pd.crosstab(MHdatapar.loc[:, 'Llama31_political_post_8b'], MHdatapar.loc[:, 'pol_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama31_political_zero</th>\n",
       "      <th>non-political</th>\n",
       "      <th>political</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama31_political_post_8b</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>non-political</th>\n",
       "      <td>126</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>political</th>\n",
       "      <td>37</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama31_political_zero     non-political  political\n",
       "Llama31_political_post_8b                          \n",
       "non-political                        126         37\n",
       "political                             37        492"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#and how did Llama3.1 8b perform in classifying political compared to large model ?\n",
    "pd.crosstab(MHdatapar.loc[:, 'Llama31_political_post_8b'], MHdatapar.loc[:, 'Llama31_political_zero'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.81      0.70       115\n",
      "           1       0.92      0.86      0.89       503\n",
      "           2       0.70      0.68      0.69        82\n",
      "\n",
      "    accuracy                           0.83       700\n",
      "   macro avg       0.75      0.78      0.76       700\n",
      "weighted avg       0.84      0.83      0.83       700\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.6368661505196345\n",
      "krippendorf(ideo_label): 0.6362597554687432\n",
      "percent_agreement(ideo_label): 83.00%\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.55      0.55       111\n",
      "           1       0.85      0.85      0.85       499\n",
      "           2       0.46      0.44      0.45        81\n",
      "\n",
      "    accuracy                           0.76       691\n",
      "   macro avg       0.62      0.62      0.62       691\n",
      "weighted avg       0.76      0.76      0.76       691\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.4428863485847562\n",
      "krippendorf(ideo_label): 0.4432801188268013\n",
      "percent_agreement(ideo_label): 75.69%\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.78      0.82       202\n",
      "           1       0.91      0.95      0.93       498\n",
      "\n",
      "    accuracy                           0.90       700\n",
      "   macro avg       0.89      0.86      0.87       700\n",
      "weighted avg       0.90      0.90      0.90       700\n",
      "\n",
      "cohen_kappa_score(pol_label): 0.7490679667335818\n",
      "krippendorf(pol_label): 0.7489901164698163\n",
      "percent_agreement(pol_label): 90.00%\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.83      0.82       202\n",
      "           1       0.93      0.92      0.93       489\n",
      "\n",
      "    accuracy                           0.89       691\n",
      "   macro avg       0.87      0.87      0.87       691\n",
      "weighted avg       0.89      0.89      0.89       691\n",
      "\n",
      "cohen_kappa_score(pol_label): 0.7457727916458772\n",
      "krippendorf(pol_label): 0.745950985950986\n",
      "percent_agreement(pol_label): 89.44%\n"
     ]
    }
   ],
   "source": [
    "#new run:\n",
    "#evaluete respective performance:\n",
    "llm_human_column_pairs = [\n",
    "    (\"ideo_label\", \"Llama31_ideology_zero_score\"),\n",
    "    (\"ideo_label\", \"Llama31_ideology_8b_score\"),\n",
    "    (\"pol_label\", \"Llama31_political_zero_score\"),\n",
    "    (\"pol_label\", \"Llama31_political_8b_score\")\n",
    "]\n",
    "print(\"Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\")\n",
    "\n",
    "for human_col, llm_col in llm_human_column_pairs:\n",
    "    subset = MHdatapar[[human_col, llm_col]].dropna()\n",
    "    human = subset[human_col].tolist()\n",
    "    llm = subset[llm_col].tolist()\n",
    "\n",
    "    # Calculate percent agreement\n",
    "    agreement = np.sum(np.array(human) == np.array(llm))/len(np.array(human)) * 100\n",
    "\n",
    "    print(\"---\")\n",
    "    print(f\"{classification_report(human, llm)}\")\n",
    "    print(f\"cohen_kappa_score({human_col}): {cohen_kappa_score(human, llm)}\")\n",
    "    print(f\"krippendorf({human_col}): {krippendorff.alpha(np.array([human, llm]), level_of_measurement=\"nominal\")}\")\n",
    "    print(f\"percent_agreement({human_col}): {agreement:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.81      0.70       115\n",
      "           1       0.92      0.85      0.88       503\n",
      "           2       0.69      0.68      0.69        82\n",
      "\n",
      "    accuracy                           0.83       700\n",
      "   macro avg       0.74      0.78      0.76       700\n",
      "weighted avg       0.84      0.83      0.83       700\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.6320606774080042\n",
      "krippendorf(ideo_label): 0.6313698931428036\n",
      "percent_agreement(ideo_label): 82.71%\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.54      0.55       112\n",
      "           1       0.85      0.86      0.85       499\n",
      "           2       0.45      0.43      0.44        82\n",
      "\n",
      "    accuracy                           0.76       693\n",
      "   macro avg       0.62      0.61      0.61       693\n",
      "weighted avg       0.75      0.76      0.76       693\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.44429806976344577\n",
      "krippendorf(ideo_label): 0.444657923314677\n",
      "percent_agreement(ideo_label): 75.76%\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.71      0.78       202\n",
      "           1       0.89      0.96      0.92       498\n",
      "\n",
      "    accuracy                           0.89       700\n",
      "   macro avg       0.88      0.83      0.85       700\n",
      "weighted avg       0.88      0.89      0.88       700\n",
      "\n",
      "cohen_kappa_score(pol_label): 0.7051762624773616\n",
      "krippendorf(pol_label): 0.7042627178657873\n",
      "percent_agreement(pol_label): 88.57%\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.73      0.81       201\n",
      "           1       0.90      0.97      0.93       491\n",
      "\n",
      "    accuracy                           0.90       692\n",
      "   macro avg       0.90      0.85      0.87       692\n",
      "weighted avg       0.90      0.90      0.90       692\n",
      "\n",
      "cohen_kappa_score(pol_label): 0.7400757665189255\n",
      "krippendorf(pol_label): 0.7392533936651584\n",
      "percent_agreement(pol_label): 89.88%\n"
     ]
    }
   ],
   "source": [
    "#evaluete respective performance:\n",
    "llm_human_column_pairs = [\n",
    "    (\"ideo_label\", \"Llama31_ideology_zero_score\"),\n",
    "    (\"ideo_label\", \"Llama31_ideology_8b_score\"),\n",
    "    (\"pol_label\", \"Llama31_political_zero_score\"),\n",
    "    (\"pol_label\", \"Llama31_political_8b_score\")\n",
    "]\n",
    "print(\"Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\")\n",
    "\n",
    "for human_col, llm_col in llm_human_column_pairs:\n",
    "    subset = MHdatapar[[human_col, llm_col]].dropna()\n",
    "    human = subset[human_col].tolist()\n",
    "    llm = subset[llm_col].tolist()\n",
    "\n",
    "    # Calculate percent agreement\n",
    "    agreement = np.sum(np.array(human) == np.array(llm))/len(np.array(human)) * 100\n",
    "\n",
    "    print(\"---\")\n",
    "    print(f\"{classification_report(human, llm)}\")\n",
    "    print(f\"cohen_kappa_score({human_col}): {cohen_kappa_score(human, llm)}\")\n",
    "    print(f\"krippendorf({human_col}): {krippendorff.alpha(np.array([human, llm]), level_of_measurement=\"nominal\")}\")\n",
    "    print(f\"percent_agreement({human_col}): {agreement:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the 8b model did worse than the 70b model for ideology, but better for political..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:02,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:53,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [02:37, 12.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [03:00,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [03:53,  7.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [05:39, 12.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [06:00,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [06:53,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [08:35, 12.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [08:56,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [09:50,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [11:32, 12.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "52it [11:53,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56it [13:37, 12.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [13:59,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64it [14:51,  6.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [16:34, 12.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "72it [16:55,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76it [18:39, 12.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80it [19:01,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "84it [19:54,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "88it [21:36, 12.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "92it [21:59,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "96it [22:52,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [24:35, 12.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "104it [24:56,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "108it [25:52,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "112it [27:34, 12.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "116it [27:55,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "120it [29:39, 12.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "124it [30:02,  5.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "128it [30:55,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "132it [32:38, 12.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "136it [32:59,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "140it [33:52,  6.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "144it [35:36, 12.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "148it [35:57,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "152it [36:51,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "156it [38:33, 12.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160it [38:54,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [40:38, 12.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168it [40:59,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172it [41:54,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [43:36, 12.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180it [43:57,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "184it [44:52,  7.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "188it [46:34, 12.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192it [46:58,  5.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "196it [47:51,  7.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [49:33, 12.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "204it [49:55,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "208it [51:39, 12.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "212it [52:00,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "216it [52:53,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "220it [54:35, 12.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [54:57,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "228it [55:50,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "232it [57:32, 12.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "236it [57:53,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "240it [59:37, 12.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "244it [59:59,  5.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "248it [1:00:53,  7.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "252it [1:02:35, 12.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "256it [1:02:56,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "260it [1:03:50,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "264it [1:05:32, 12.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "268it [1:05:53,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "272it [1:07:39, 12.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "276it [1:08:00,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "280it [1:08:53,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "284it [1:10:36, 12.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "288it [1:10:57,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "292it [1:11:50,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "296it [1:13:32, 12.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [1:13:53,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "304it [1:15:37, 12.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "308it [1:15:59,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "312it [1:16:52,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "316it [1:18:34, 12.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "320it [1:18:55,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "324it [1:20:39, 12.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "328it [1:21:00,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "332it [1:21:53,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [1:23:35, 12.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "340it [1:23:56,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "344it [1:24:52,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "348it [1:26:34, 12.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "352it [1:26:55,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "356it [1:28:40, 12.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "360it [1:29:01,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "364it [1:29:54,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "368it [1:31:36, 12.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "372it [1:31:57,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "376it [1:32:52,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "380it [1:34:34, 12.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "384it [1:34:56,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "388it [1:35:50,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "392it [1:37:34, 12.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "396it [1:37:56,  5.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [1:38:50,  7.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "404it [1:40:32, 12.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "408it [1:40:54,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "412it [1:42:38, 12.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "416it [1:42:59,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "420it [1:43:52,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "424it [1:45:34, 12.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "428it [1:45:58,  5.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "432it [1:46:51,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "436it [1:48:33, 12.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "440it [1:48:54,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "444it [1:50:38, 12.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "448it [1:50:59,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "452it [1:51:53,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "456it [1:53:35, 12.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "460it [1:53:56,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "464it [1:54:50,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "468it [1:56:32, 12.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "472it [1:56:53,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "476it [1:58:37, 12.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "480it [1:58:59,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "484it [1:59:52,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "488it [2:01:34, 12.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "492it [2:01:55,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "496it [2:03:39, 12.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [2:04:00,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "504it [2:04:54,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "508it [2:06:37, 12.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "512it [2:06:58,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "516it [2:07:50,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "520it [2:09:33, 12.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "524it [2:09:55,  5.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "528it [2:11:39, 12.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "532it [2:12:00,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "536it [2:12:53,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "540it [2:14:35, 12.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "544it [2:14:56,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "548it [2:15:51,  7.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "552it [2:17:33, 12.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "556it [2:17:54,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "560it [2:19:38, 12.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "564it [2:19:59,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "568it [2:20:52,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "572it [2:22:34, 12.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "576it [2:22:55,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "580it [2:24:39, 12.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "584it [2:25:00,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "588it [2:25:53,  6.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "592it [2:27:35, 12.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "596it [2:27:56,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600it [2:28:50,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "604it [2:30:32, 12.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "608it [2:30:54,  5.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "612it [2:32:38, 12.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "616it [2:33:00,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "620it [2:33:52,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "624it [2:35:34, 12.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "628it [2:35:55,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "632it [2:37:39, 12.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "636it [2:38:00,  5.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "640it [2:38:53,  6.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "644it [2:40:35, 12.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "648it [2:40:57,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "652it [2:41:50,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "656it [2:43:34, 12.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "660it [2:43:55,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "664it [2:45:39, 12.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "668it [2:46:01,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "672it [2:46:53,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "676it [2:48:35, 12.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "680it [2:48:57,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "684it [2:49:49,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "688it [2:51:32, 12.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "692it [2:51:53,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "696it [2:53:37, 12.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "700it [2:53:58, 14.91s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:53,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [02:35, 12.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [02:56,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [04:40, 12.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [05:02,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [05:55,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [07:37, 12.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [07:59,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [08:52,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [10:34, 12.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [10:56,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [12:40, 12.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "52it [13:01,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56it [13:54,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [15:38, 12.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64it [16:00,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [16:53,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "72it [18:35, 12.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76it [18:57,  5.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80it [20:41, 12.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "84it [21:02,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "88it [21:55,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "92it [23:37, 12.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "96it [23:59,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [24:54,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "104it [26:36, 12.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "108it [26:58,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "112it [28:41, 12.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "116it [29:02,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "120it [29:57,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "124it [31:39, 12.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "128it [32:01,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "132it [32:54,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "136it [34:37, 12.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "140it [34:59,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "144it [35:52,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "148it [37:34, 12.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "152it [37:57,  5.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "156it [39:41, 12.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160it [40:02,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [40:56,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168it [42:38, 12.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172it [43:00,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [43:53,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180it [45:35, 12.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "184it [45:59,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "188it [46:52,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192it [48:34, 12.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "196it [48:55,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [50:40, 12.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "204it [51:01,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "208it [51:55,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "212it [53:38, 12.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "216it [54:02,  6.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "220it [54:55,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [56:38, 12.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "228it [56:59,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "232it [57:52,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "236it [59:35, 12.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "240it [59:56,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "244it [1:01:40, 12.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "248it [1:02:02,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "252it [1:02:55,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "256it [1:04:38, 12.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "260it [1:04:59,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "264it [1:05:54,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "268it [1:07:37, 12.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "272it [1:07:58,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "276it [1:08:51,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "280it [1:10:35, 12.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "284it [1:10:59,  6.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "288it [1:11:52,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "292it [1:13:36, 12.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "296it [1:13:57,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [1:15:41, 12.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "304it [1:16:03,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "308it [1:16:56,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "312it [1:18:38, 12.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "316it [1:18:59,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "320it [1:19:52,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "324it [1:21:34, 12.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "328it [1:21:56,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "332it [1:23:40, 12.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [1:24:02,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "340it [1:24:59,  8.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "343it [1:25:05,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "347it [1:25:58,  6.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "351it [1:26:52,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "355it [1:28:34, 12.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "359it [1:28:56,  5.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "363it [1:30:40, 12.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "367it [1:31:01,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "371it [1:31:54,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "375it [1:33:36, 12.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "379it [1:33:58,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "383it [1:34:51,  6.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [1:36:34, 12.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "391it [1:36:55,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "395it [1:38:39, 12.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "399it [1:39:00,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "403it [1:39:53,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "407it [1:41:35, 12.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "411it [1:41:57,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "415it [1:42:51,  7.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "419it [1:44:34, 12.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "423it [1:44:56,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "427it [1:46:40, 12.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "431it [1:47:01,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "435it [1:47:54,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "439it [1:49:37, 12.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "443it [1:49:58,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "447it [1:50:51,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "451it [1:52:33, 12.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "455it [1:52:55,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "459it [1:54:39, 12.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "463it [1:55:03,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "467it [1:55:56,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "471it [1:57:39, 12.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "475it [1:58:00,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "479it [1:58:55,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "483it [2:00:39, 12.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "487it [2:01:00,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "491it [2:01:53,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "495it [2:03:36, 12.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "499it [2:03:57,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "503it [2:04:52,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "507it [2:06:34, 12.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "511it [2:06:56,  5.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "515it [2:08:40, 12.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "519it [2:09:04,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "523it [2:09:57,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "527it [2:11:41, 12.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "531it [2:12:02,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "535it [2:12:57,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [2:14:39, 12.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "543it [2:15:00,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "547it [2:15:53,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "551it [2:17:35, 12.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "555it [2:17:57,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "559it [2:19:41, 12.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "563it [2:20:02,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "567it [2:20:55,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "571it [2:22:37, 12.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "575it [2:22:59,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "579it [2:23:52,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "583it [2:25:34, 12.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "587it [2:25:56,  5.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "591it [2:27:40, 12.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "595it [2:28:02,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "599it [2:28:55,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "603it [2:30:37, 12.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "607it [2:30:59,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "611it [2:31:51,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "615it [2:33:34, 12.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "619it [2:33:57,  5.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "623it [2:35:40, 12.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "627it [2:36:02,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "631it [2:36:55,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "635it [2:38:37, 12.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "639it [2:38:59,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "643it [2:39:53,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "647it [2:41:35, 12.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "651it [2:41:56,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "655it [2:43:40, 12.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "659it [2:44:03,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "663it [2:44:57,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "667it [2:46:39, 12.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "671it [2:47:01,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "675it [2:47:54,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "679it [2:49:36, 12.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "683it [2:49:58,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "687it [2:50:51,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "691it [2:52:34, 12.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "695it [2:52:55,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "699it [2:54:39, 12.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "700it [2:54:58, 15.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      index political_ideology political_post\n",
      "0         0            neutral            NaN\n",
      "1         1            neutral            NaN\n",
      "2         2            liberal            NaN\n",
      "3         3            neutral            NaN\n",
      "4         4       conservative            NaN\n",
      "...     ...                ...            ...\n",
      "1395    695                NaN  non-political\n",
      "1396    696                NaN      political\n",
      "1397    697                NaN      political\n",
      "1398    698                NaN  non-political\n",
      "1399    699                NaN  non-political\n",
      "\n",
      "[1400 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#what about GPT4o, GPT4Turbo and GPT4?\n",
    "\n",
    "#classify messages using gpt4o:\n",
    "MHGPTrun1 = ['political_ideology', 'political_post']\n",
    "  \n",
    "\n",
    "chunked_result: typing.List[pd.DataFrame] = []\n",
    "\n",
    "for label, path in CFG.prompt_classify_files.items():\n",
    "    if label in MHGPTrun1: \n",
    "        template = load_json(path).get('template')\n",
    "        classes = load_json(path).get('classes')\n",
    "        for index, row in tqdm.tqdm(MHdata[\"text\"].items()):\n",
    "            retry_count = 0\n",
    "            max_retries = 10\n",
    "            \n",
    "            while retry_count < max_retries:\n",
    "                try: \n",
    "                    response = requests.post(\n",
    "                            url=api_endpoint,\n",
    "                            headers=headers,\n",
    "                            json={\n",
    "                                'model': MODELgpt4,\n",
    "                                'messages': [\n",
    "                                    {\n",
    "                                        \"role\": \"system\",\n",
    "                                        \"content\": template\n",
    "                                    },\n",
    "                                    {\n",
    "                                        \"role\": \"user\",\n",
    "                                        \"content\": template.format(text=row)\n",
    "                                    }\n",
    "                                ],\n",
    "                                'temperature': temperature_0,  \n",
    "                                'seed': SEED,\n",
    "                                \"max_tokens\": MAX10\n",
    "                            }\n",
    "                        )  \n",
    "\n",
    "                    if response.status_code == 200:\n",
    "                        data_response = response.json()\n",
    "                        chunked_result.append(\n",
    "                        pd.DataFrame(\n",
    "                            data=[[index, classes.get(data_response[\"choices\"][0][\"message\"][\"content\"], None)]],                                \n",
    "                            columns=['index', label]\n",
    "                            )\n",
    "                        )\n",
    "                        break  # Exit the retry loop on success\n",
    "                    elif response.status_code == 429:\n",
    "                        retry_count += 1\n",
    "                        wait_time = 1 + (3 * retry_count * retry_count)\n",
    "                        print(f\"Rate limit exceeded. Retrying in {wait_time} seconds...\")\n",
    "                        print(response.text)\n",
    "                        time.sleep(wait_time)\n",
    "                    elif response.status_code == 500:\n",
    "                        retry_count += 1\n",
    "                        wait_time = 20\n",
    "                        print(f\"Failed to connect to API. Status code: {response.status_code}. Retrying in {wait_time} seconds...\")\n",
    "                        print(response.text)\n",
    "                        time.sleep(wait_time)\n",
    "                    else:\n",
    "                        print(f\"Failed to connect to API. Status code: {response.status_code}\")\n",
    "                        print(response.text)\n",
    "                        break\n",
    "                except requests.exceptions.RequestException as e:   \n",
    "                    print(f\"Failed to connect to API: {e}\")\n",
    "                    retry_count += 1\n",
    "                    wait_time = 60\n",
    "                    print(f\"Retrying in {wait_time} seconds...\")\n",
    "                    time.sleep(wait_time)                 \n",
    "                \n",
    "\n",
    "\n",
    "classifications3 = pd.concat(chunked_result, ignore_index=True)\n",
    "print(classifications3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:07,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [00:18,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45it [01:18,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [01:30,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "75it [01:59,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "90it [02:57,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "105it [03:09,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "120it [04:08,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "135it [04:23,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "150it [05:21,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "165it [05:35,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180it [06:04,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "195it [07:03,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "215it [07:21,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "230it [08:20,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "245it [08:33,  2.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "261it [09:04,  1.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "280it [10:08,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "295it [10:20,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "310it [11:18,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "325it [11:29,  2.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "340it [11:58,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "355it [13:47,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "370it [13:58,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "389it [15:03,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "404it [15:15,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "419it [16:15,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "434it [16:27,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "449it [17:27,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "464it [17:40,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "479it [18:11,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "494it [19:09,  1.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "509it [19:20,  2.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "524it [20:20,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "539it [20:31,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "556it [21:03,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "571it [22:01,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "586it [22:14,  2.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "612it [23:24,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "627it [23:36,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "642it [24:04,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "657it [25:03,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "672it [25:15,  2.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "687it [26:14,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "700it [26:26,  2.27s/it]\n",
      "2it [00:02,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:30,  1.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [02:20,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47it [02:32,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "62it [03:33,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "77it [03:46,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "92it [04:45,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "107it [04:57,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "122it [05:56,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "137it [06:08,  1.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "151it [06:40,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "179it [07:50,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "194it [08:03,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "196it [08:25,  4.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "232it [10:38,  1.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "240it [10:47,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 22 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 22 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 22 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "255it [11:46,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "270it [11:58,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "285it [12:57,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [13:09,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "314it [13:37,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 13 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 13 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 13 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "339it [14:46,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "354it [15:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "369it [16:00,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "399it [16:25,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "414it [18:16,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "429it [18:28,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "444it [20:18,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "459it [20:32,  1.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "474it [21:30,  1.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "489it [21:43,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "504it [22:42,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "519it [22:54,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "534it [23:53,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "549it [24:06,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "564it [24:37,  1.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "585it [25:42,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600it [25:55,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "615it [26:55,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "630it [27:07,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "644it [27:39,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "688it [29:05,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 26 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 21 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4-turbo\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4-turbo. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('458a82d2-0fe2-4c40-9dd0-d54c5b85a0b0', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "700it [30:52,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      index political_ideology political_post\n",
      "0         0            neutral            NaN\n",
      "1         1            neutral            NaN\n",
      "2         2            liberal            NaN\n",
      "3         3            neutral            NaN\n",
      "4         4       conservative            NaN\n",
      "...     ...                ...            ...\n",
      "1395    695                NaN  non-political\n",
      "1396    696                NaN      political\n",
      "1397    697                NaN      political\n",
      "1398    698                NaN  non-political\n",
      "1399    699                NaN  non-political\n",
      "\n",
      "[1400 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#what about GPT4o, GPT4Turbo and GPT4?\n",
    "\n",
    "#classify messages using gpt4o:\n",
    "MHGPTrun1 = ['political_ideology', 'political_post']\n",
    "  \n",
    "\n",
    "chunked_result2: typing.List[pd.DataFrame] = []\n",
    "\n",
    "for label, path in CFG.prompt_classify_files.items():\n",
    "    if label in MHGPTrun1: \n",
    "        template = load_json(path).get('template')\n",
    "        classes = load_json(path).get('classes')\n",
    "        for index, row in tqdm.tqdm(MHdata[\"text\"].items()):\n",
    "            retry_count = 0\n",
    "            max_retries = 10\n",
    "            \n",
    "            while retry_count < max_retries:\n",
    "                try: \n",
    "                    response = requests.post(\n",
    "                            url=api_endpoint,\n",
    "                            headers=headers,\n",
    "                            json={\n",
    "                                'model': MODELgpt4T,\n",
    "                                'messages': [\n",
    "                                    {\n",
    "                                        \"role\": \"system\",\n",
    "                                        \"content\": template\n",
    "                                    },\n",
    "                                    {\n",
    "                                        \"role\": \"user\",\n",
    "                                        \"content\": template.format(text=row)\n",
    "                                    }\n",
    "                                ],\n",
    "                                'temperature': temperature_0,  \n",
    "                                'seed': SEED,\n",
    "                                \"max_tokens\": MAX10\n",
    "                            }\n",
    "                        )  \n",
    "\n",
    "                    if response.status_code == 200:\n",
    "                        data_response = response.json()\n",
    "                        chunked_result2.append(\n",
    "                        pd.DataFrame(\n",
    "                            data=[[index, classes.get(data_response[\"choices\"][0][\"message\"][\"content\"], None)]],                                \n",
    "                            columns=['index', label]\n",
    "                            )\n",
    "                        )\n",
    "                        break  # Exit the retry loop on success\n",
    "                    elif response.status_code == 429:\n",
    "                        retry_count += 1\n",
    "                        wait_time = 1 + (3 * retry_count * retry_count)\n",
    "                        print(f\"Rate limit exceeded. Retrying in {wait_time} seconds...\")\n",
    "                        print(response.text)\n",
    "                        time.sleep(wait_time)\n",
    "                    elif response.status_code == 500:\n",
    "                        retry_count += 1\n",
    "                        wait_time = 20\n",
    "                        print(f\"Failed to connect to API. Status code: {response.status_code}. Retrying in {wait_time} seconds...\")\n",
    "                        print(response.text)\n",
    "                        time.sleep(wait_time)\n",
    "                    else:\n",
    "                        print(f\"Failed to connect to API. Status code: {response.status_code}\")\n",
    "                        print(response.text)\n",
    "                        break\n",
    "                except requests.exceptions.RequestException as e:   \n",
    "                    print(f\"Failed to connect to API: {e}\")\n",
    "                    retry_count += 1\n",
    "                    wait_time = 60\n",
    "                    print(f\"Retrying in {wait_time} seconds...\")\n",
    "                    time.sleep(wait_time)                 \n",
    "                \n",
    "\n",
    "\n",
    "classifications2 = pd.concat(chunked_result2, ignore_index=True)\n",
    "print(classifications2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "700it [04:51,  2.40it/s]\n",
      "138it [00:54,  3.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "397it [02:48,  2.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "594it [04:12,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4o-2024-08-06\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4o-2024-08-06. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('717f00f7-34de-499b-96a8-0e12308b6b72', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded token rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "700it [05:39,  2.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      index political_ideology political_post\n",
      "0         0            neutral            NaN\n",
      "1         1            neutral            NaN\n",
      "2         2            liberal            NaN\n",
      "3         3            neutral            NaN\n",
      "4         4       conservative            NaN\n",
      "...     ...                ...            ...\n",
      "1395    695                NaN  non-political\n",
      "1396    696                NaN      political\n",
      "1397    697                NaN      political\n",
      "1398    698                NaN  non-political\n",
      "1399    699                NaN  non-political\n",
      "\n",
      "[1400 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#what about GPT4o, GPT4Turbo and GPT4?\n",
    "\n",
    "#classify messages using gpt4o:\n",
    "MHGPTrun1 = ['political_ideology', 'political_post']\n",
    "  \n",
    "\n",
    "chunked_result3: typing.List[pd.DataFrame] = []\n",
    "\n",
    "for label, path in CFG.prompt_classify_files.items():\n",
    "    if label in MHGPTrun1: \n",
    "        template = load_json(path).get('template')\n",
    "        classes = load_json(path).get('classes')\n",
    "        for index, row in tqdm.tqdm(MHdata[\"text\"].items()):\n",
    "            retry_count = 0\n",
    "            max_retries = 10\n",
    "            \n",
    "            while retry_count < max_retries:\n",
    "                try: \n",
    "                    response = requests.post(\n",
    "                            url=api_endpoint,\n",
    "                            headers=headers,\n",
    "                            json={\n",
    "                                'model': MODELgpt4o,\n",
    "                                'messages': [\n",
    "                                    {\n",
    "                                        \"role\": \"system\",\n",
    "                                        \"content\": template\n",
    "                                    },\n",
    "                                    {\n",
    "                                        \"role\": \"user\",\n",
    "                                        \"content\": template.format(text=row)\n",
    "                                    }\n",
    "                                ],\n",
    "                                'temperature': temperature_0,  \n",
    "                                'seed': SEED,\n",
    "                                \"max_tokens\": MAX10\n",
    "                            }\n",
    "                        )  \n",
    "\n",
    "                    if response.status_code == 200:\n",
    "                        data_response = response.json()\n",
    "                        chunked_result3.append(\n",
    "                        pd.DataFrame(\n",
    "                            data=[[index, classes.get(data_response[\"choices\"][0][\"message\"][\"content\"], None)]],                                \n",
    "                            columns=['index', label]\n",
    "                            )\n",
    "                        )\n",
    "                        break  # Exit the retry loop on success\n",
    "                    elif response.status_code == 429:\n",
    "                        retry_count += 1\n",
    "                        wait_time = 1 + (3 * retry_count * retry_count)\n",
    "                        print(f\"Rate limit exceeded. Retrying in {wait_time} seconds...\")\n",
    "                        print(response.text)\n",
    "                        time.sleep(wait_time)\n",
    "                    elif response.status_code == 500:\n",
    "                        retry_count += 1\n",
    "                        wait_time = 20\n",
    "                        print(f\"Failed to connect to API. Status code: {response.status_code}. Retrying in {wait_time} seconds...\")\n",
    "                        print(response.text)\n",
    "                        time.sleep(wait_time)\n",
    "                    else:\n",
    "                        print(f\"Failed to connect to API. Status code: {response.status_code}\")\n",
    "                        print(response.text)\n",
    "                        break\n",
    "                except requests.exceptions.RequestException as e:   \n",
    "                    print(f\"Failed to connect to API: {e}\")\n",
    "                    retry_count += 1\n",
    "                    wait_time = 60\n",
    "                    print(f\"Retrying in {wait_time} seconds...\")\n",
    "                    time.sleep(wait_time)                 \n",
    "                \n",
    "\n",
    "\n",
    "classifications1 = pd.concat(chunked_result3, ignore_index=True)\n",
    "print(classifications1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-Ahbb3pqIaEzZ3DHfv8F3dZxLZxV2D',\n",
       " 'choices': [{'finish_reason': 'stop',\n",
       "   'index': 0,\n",
       "   'message': {'content': '1',\n",
       "    'role': 'assistant',\n",
       "    'tool_calls': None,\n",
       "    'function_call': None}}],\n",
       " 'created': 1734955989,\n",
       " 'model': 'gpt-4',\n",
       " 'object': 'chat.completion',\n",
       " 'system_fingerprint': None,\n",
       " 'usage': {'prompt_tokens': 1407,\n",
       "  'completion_tokens': 1,\n",
       "  'total_tokens': 1408},\n",
       " 'service_tier': None}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "political_post_gpt4o = classifications1.loc[:, [\"index\", \"political_post\"]].dropna()\n",
    "political_post_gpt4o.set_index('index', drop=True, inplace=True)\n",
    "MHdatapar = MHdatapar.join(political_post_gpt4o, rsuffix='_gpt4o')\n",
    "political_ideology_gpt4o = classifications1.loc[:, [\"index\", \"political_ideology\"]].dropna()\n",
    "political_ideology_gpt4o.set_index('index', drop=True, inplace=True)\n",
    "MHdatapar = MHdatapar.join(political_ideology_gpt4o, rsuffix='_gpt4o')\n",
    "\n",
    "MHdatapar = MHdatapar.rename(columns={\n",
    "    'political_post': 'political_post_gpt4o',\n",
    "    'political_ideology': 'political_ideology_gpt4o'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "political_post_gpt4T = classifications2.loc[:, [\"index\", \"political_post\"]].dropna()\n",
    "political_post_gpt4T.set_index('index', drop=True, inplace=True)\n",
    "MHdatapar = MHdatapar.join(political_post_gpt4T, rsuffix='_gpt4T')\n",
    "political_ideology_gpt4T = classifications2.loc[:, [\"index\", \"political_ideology\"]].dropna()\n",
    "political_ideology_gpt4T.set_index('index', drop=True, inplace=True)\n",
    "MHdatapar = MHdatapar.join(political_ideology_gpt4T, rsuffix='_gpt4T')\n",
    "\n",
    "MHdatapar = MHdatapar.rename(columns={\n",
    "    'political_post': 'political_post_gpt4T',\n",
    "    'political_ideology': 'political_ideology_gpt4T'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "political_post_gpt4 = classifications3.loc[:, [\"index\", \"political_post\"]].dropna()\n",
    "political_post_gpt4.set_index('index', drop=True, inplace=True)\n",
    "MHdatapar = MHdatapar.join(political_post_gpt4, rsuffix='_gpt4')\n",
    "political_ideology_gpt4 = classifications3.loc[:, [\"index\", \"political_ideology\"]].dropna()\n",
    "political_ideology_gpt4.set_index('index', drop=True, inplace=True)\n",
    "MHdatapar = MHdatapar.join(political_ideology_gpt4, rsuffix='_gpt4')\n",
    "\n",
    "MHdatapar = MHdatapar.rename(columns={\n",
    "    'political_post': 'political_post_gpt4',\n",
    "    'political_ideology': 'political_ideology_gpt4'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pol_label</th>\n",
       "      <th>neg_label</th>\n",
       "      <th>neg3_label</th>\n",
       "      <th>ideo_label</th>\n",
       "      <th>GPT_Pol1</th>\n",
       "      <th>GPT_Pol2</th>\n",
       "      <th>GPT_Neg1</th>\n",
       "      <th>GPT_Neg2</th>\n",
       "      <th>GPT_Neg_3Way1</th>\n",
       "      <th>...</th>\n",
       "      <th>Pol_Recon</th>\n",
       "      <th>Neg_Recon</th>\n",
       "      <th>Neg3_Recon</th>\n",
       "      <th>Ideo_Recon</th>\n",
       "      <th>political_post_gpt4o</th>\n",
       "      <th>political_ideology_gpt4o</th>\n",
       "      <th>political_post_gpt4T</th>\n",
       "      <th>political_ideology_gpt4T</th>\n",
       "      <th>political_post_gpt4</th>\n",
       "      <th>political_ideology_gpt4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@thatleechi17 @KlemmChr @AndiScheuer @victorpe...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>political</td>\n",
       "      <td>neutral</td>\n",
       "      <td>political</td>\n",
       "      <td>neutral</td>\n",
       "      <td>political</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Glauben Sie nur nicht, dass Menschen die nicht...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>political</td>\n",
       "      <td>neutral</td>\n",
       "      <td>political</td>\n",
       "      <td>neutral</td>\n",
       "      <td>political</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Das ist ja das Mindeste. \\r\\n\\r\\nDass das aber...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>political</td>\n",
       "      <td>liberal</td>\n",
       "      <td>political</td>\n",
       "      <td>liberal</td>\n",
       "      <td>political</td>\n",
       "      <td>liberal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Challen81690499 @c_lindner @rbrinkhaus @Nowab...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>non-political</td>\n",
       "      <td>neutral</td>\n",
       "      <td>non-political</td>\n",
       "      <td>neutral</td>\n",
       "      <td>non-political</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ich sage: #DANKE!!!\\r\\nhttps://t.co/0pVneqXwTC...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>political</td>\n",
       "      <td>conservative</td>\n",
       "      <td>political</td>\n",
       "      <td>conservative</td>\n",
       "      <td>political</td>\n",
       "      <td>conservative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  pol_label  neg_label  \\\n",
       "0  @thatleechi17 @KlemmChr @AndiScheuer @victorpe...          1          1   \n",
       "1  Glauben Sie nur nicht, dass Menschen die nicht...          1          0   \n",
       "2  Das ist ja das Mindeste. \\r\\n\\r\\nDass das aber...          1          1   \n",
       "3  @Challen81690499 @c_lindner @rbrinkhaus @Nowab...          0          0   \n",
       "4  Ich sage: #DANKE!!!\\r\\nhttps://t.co/0pVneqXwTC...          1          0   \n",
       "\n",
       "   neg3_label  ideo_label  GPT_Pol1  GPT_Pol2  GPT_Neg1  GPT_Neg2  \\\n",
       "0           0           1         1         1         1         1   \n",
       "1           1           1         1         1         0         0   \n",
       "2           0           1         1         1         1         1   \n",
       "3           1           1         1         0         0         0   \n",
       "4           2           2         1         1         0         0   \n",
       "\n",
       "   GPT_Neg_3Way1  ...  Pol_Recon  Neg_Recon  Neg3_Recon  Ideo_Recon  \\\n",
       "0              0  ...          1          1           0           1   \n",
       "1              1  ...          1          0           1           1   \n",
       "2              0  ...          1          1           0           0   \n",
       "3              1  ...          0          0           1           1   \n",
       "4              2  ...          1          0           2           2   \n",
       "\n",
       "   political_post_gpt4o  political_ideology_gpt4o  political_post_gpt4T  \\\n",
       "0             political                   neutral             political   \n",
       "1             political                   neutral             political   \n",
       "2             political                   liberal             political   \n",
       "3         non-political                   neutral         non-political   \n",
       "4             political              conservative             political   \n",
       "\n",
       "  political_ideology_gpt4T political_post_gpt4 political_ideology_gpt4  \n",
       "0                  neutral           political                 neutral  \n",
       "1                  neutral           political                 neutral  \n",
       "2                  liberal           political                 liberal  \n",
       "3                  neutral       non-political                 neutral  \n",
       "4             conservative           political            conservative  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MHdatapar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "MHdatapar.loc[:, 'political_post_gpt4o_dum'] = MHdatapar.loc[:, 'political_post_gpt4o'].map({\"political\": 1, \"non-political\":0}).fillna(0).astype(int)\n",
    "MHdatapar.loc[:, 'political_ideology_gpt4o_score'] = MHdatapar.loc[:, 'political_ideology_gpt4o'].map({'liberal': 0, 'neutral': 1, 'conservative': 2})\n",
    "MHdatapar.loc[:, 'political_post_gpt4T_dum'] = MHdatapar.loc[:, 'political_post_gpt4T'].map({\"political\": 1, \"non-political\":0}).fillna(0).astype(int)\n",
    "MHdatapar.loc[:, 'political_ideology_gpt4T_score'] = MHdatapar.loc[:, 'political_ideology_gpt4T'].map({'liberal': 0, 'neutral': 1, 'conservative': 2})\n",
    "MHdatapar.loc[:, 'political_post_gpt4_dum'] = MHdatapar.loc[:, 'political_post_gpt4'].map({\"political\": 1, \"non-political\":0}).fillna(0).astype(int)\n",
    "MHdatapar.loc[:, 'political_ideology_gpt4_score'] = MHdatapar.loc[:, 'political_ideology_gpt4'].map({'liberal': 0, 'neutral': 1, 'conservative': 2})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.88      0.74       115\n",
      "           1       0.94      0.83      0.88       503\n",
      "           2       0.63      0.76      0.69        82\n",
      "\n",
      "    accuracy                           0.83       700\n",
      "   macro avg       0.74      0.82      0.77       700\n",
      "weighted avg       0.85      0.83      0.84       700\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.6507203891972806\n",
      "krippendorf(ideo_label): 0.6489503850713998\n",
      "percent_agreement(ideo_label): 82.86%\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.86      0.64       115\n",
      "           1       0.94      0.79      0.86       503\n",
      "           2       0.66      0.70      0.68        82\n",
      "\n",
      "    accuracy                           0.79       700\n",
      "   macro avg       0.71      0.78      0.73       700\n",
      "weighted avg       0.84      0.79      0.80       700\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.5845664012062011\n",
      "krippendorf(ideo_label): 0.5793190744093153\n",
      "percent_agreement(ideo_label): 78.86%\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.88      0.70       115\n",
      "           1       0.95      0.78      0.86       503\n",
      "           2       0.57      0.78      0.66        82\n",
      "\n",
      "    accuracy                           0.80       700\n",
      "   macro avg       0.70      0.81      0.74       700\n",
      "weighted avg       0.84      0.80      0.81       700\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.605882422911157\n",
      "krippendorf(ideo_label): 0.6014412939545503\n",
      "percent_agreement(ideo_label): 79.71%\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.92      0.73       115\n",
      "           1       0.96      0.81      0.88       503\n",
      "           2       0.69      0.85      0.76        82\n",
      "\n",
      "    accuracy                           0.83       700\n",
      "   macro avg       0.75      0.86      0.79       700\n",
      "weighted avg       0.87      0.83      0.84       700\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.6679290188227158\n",
      "krippendorf(ideo_label): 0.6646610493129983\n",
      "percent_agreement(ideo_label): 83.14%\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.99      0.75       202\n",
      "           1       0.99      0.73      0.84       498\n",
      "\n",
      "    accuracy                           0.81       700\n",
      "   macro avg       0.80      0.86      0.80       700\n",
      "weighted avg       0.88      0.81      0.82       700\n",
      "\n",
      "cohen_kappa_score(pol_label): 0.6052235813114097\n",
      "krippendorf(pol_label): 0.5912994929789597\n",
      "percent_agreement(pol_label): 80.71%\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.96      0.78       202\n",
      "           1       0.98      0.80      0.88       498\n",
      "\n",
      "    accuracy                           0.85       700\n",
      "   macro avg       0.82      0.88      0.83       700\n",
      "weighted avg       0.89      0.85      0.85       700\n",
      "\n",
      "cohen_kappa_score(pol_label): 0.6708213205822375\n",
      "krippendorf(pol_label): 0.6652294191447632\n",
      "percent_agreement(pol_label): 84.71%\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.97      0.79       202\n",
      "           1       0.98      0.80      0.88       498\n",
      "\n",
      "    accuracy                           0.85       700\n",
      "   macro avg       0.82      0.88      0.83       700\n",
      "weighted avg       0.89      0.85      0.85       700\n",
      "\n",
      "cohen_kappa_score(pol_label): 0.6751654817357196\n",
      "krippendorf(pol_label): 0.6692700899229231\n",
      "percent_agreement(pol_label): 84.86%\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.97      0.80       202\n",
      "           1       0.98      0.82      0.90       498\n",
      "\n",
      "    accuracy                           0.86       700\n",
      "   macro avg       0.84      0.89      0.85       700\n",
      "weighted avg       0.90      0.86      0.87       700\n",
      "\n",
      "cohen_kappa_score(pol_label): 0.7046649612733604\n",
      "krippendorf(pol_label): 0.7005126471748071\n",
      "percent_agreement(pol_label): 86.43%\n"
     ]
    }
   ],
   "source": [
    "#evaluete respective performance:\n",
    "llm_human_column_pairs = [\n",
    "    (\"ideo_label\", \"political_ideology_gpt4o_score\"),\n",
    "     (\"ideo_label\", \"political_ideology_gpt4T_score\"),\n",
    "      (\"ideo_label\", \"political_ideology_gpt4_score\"),\n",
    "    (\"ideo_label\", \"GPT_Ideo1\"),\n",
    "    (\"pol_label\", \"political_post_gpt4o_dum\"),\n",
    "    (\"pol_label\", \"political_post_gpt4T_dum\"),\n",
    "    (\"pol_label\", \"political_post_gpt4_dum\"),\n",
    "    (\"pol_label\", \"GPT_Pol1\")\n",
    "]\n",
    "print(\"Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\")\n",
    "\n",
    "for human_col, llm_col in llm_human_column_pairs:\n",
    "    subset = MHdatapar[[human_col, llm_col]].dropna()\n",
    "    human = subset[human_col].tolist()\n",
    "    llm = subset[llm_col].tolist()\n",
    "\n",
    "    # Calculate percent agreement\n",
    "    agreement = np.sum(np.array(human) == np.array(llm))/len(np.array(human)) * 100\n",
    "\n",
    "    print(\"---\")\n",
    "    print(f\"{classification_report(human, llm)}\")\n",
    "    print(f\"cohen_kappa_score({human_col}): {cohen_kappa_score(human, llm)}\")\n",
    "    print(f\"krippendorf({human_col}): {krippendorff.alpha(np.array([human, llm]), level_of_measurement=\"nominal\")}\")\n",
    "    print(f\"percent_agreement({human_col}): {agreement:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPT4 in MH paper outperforms GPT4o and GPT4T on both variables, but also GPT4 on Azure..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data to parquet\n",
    "MHdatapar.to_parquet('data/MH_BClemm_data/germany_val_all_llama.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'pol_label', 'neg_label', 'neg3_label', 'ideo_label',\n",
       "       'GPT_Pol1', 'GPT_Pol2', 'GPT_Neg1', 'GPT_Neg2', 'GPT_Neg_3Way1',\n",
       "       'GPT_Neg_3Way2', 'GPT_Ideo1', 'GPT_Ideo2', 'Pol_Recon', 'Neg_Recon',\n",
       "       'Neg3_Recon', 'Ideo_Recon', 'political_post_gpt4o',\n",
       "       'political_ideology_gpt4o', 'political_post_gpt4T',\n",
       "       'political_ideology_gpt4T', 'political_post_gpt4',\n",
       "       'political_ideology_gpt4', 'political_post_gpt4o_dum',\n",
       "       'political_ideology_gpt4o_score', 'political_post_gpt4T_dum',\n",
       "       'political_ideology_gpt4T_score', 'political_post_gpt4_dum',\n",
       "       'political_ideology_gpt4_score', 'Llama31_ideology_low',\n",
       "       'Llama_ideo_score_low', 'Llama31_ideo_GER_low',\n",
       "       'Llama_ideoGER_score_low', 'Llama31_ideo_GER2_low',\n",
       "       'Llama_ideoGER_score2_low', 'Llama31_ideo_GER3', 'Llama_ideoGER_score3',\n",
       "       'Llama31_ideo_EXT', 'Llama_ideoEXT_score', 'Llama31_ideology_zero',\n",
       "       'Llama31_political_zero', 'Llama31_political_GER_zero',\n",
       "       'Llama31_ideology_zero_score', 'Llama31_political_zero_score',\n",
       "       'Llama31_political_GER_zero_score', 'Llama31_political_ideology_8b',\n",
       "       'Llama31_political_post_8b', 'Llama31_ideology_8b_score',\n",
       "       'Llama31_political_8b_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MHdatapar.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add ada embeddings to MHdatapar:\n",
    "from tqdm import tqdm          #run these lines to run the ADA progress bar\n",
    "tqdm.pandas()\n",
    "\n",
    "def get_ada_embedding(text):\n",
    "    retry_count = 0\n",
    "    max_retries = 10\n",
    "    while retry_count < max_retries:\n",
    "        try:\n",
    "            response = requests.post(\n",
    "                url=api_endpoint_embed,\n",
    "                headers=headers,\n",
    "                json={\n",
    "                    \"model\": \"text-embedding-ada-002\",\n",
    "                    \"input\": text,\n",
    "                }\n",
    "            )\n",
    "            if response.status_code == 200:\n",
    "                return response.json()['data'][0]['embedding']\n",
    "            elif response.status_code == 429:\n",
    "                retry_count += 1\n",
    "                wait_time = 1 + (3 * retry_count * retry_count)\n",
    "                print(f\"Rate limit exceeded. Retrying in {wait_time} seconds...\")\n",
    "                print(response.text)\n",
    "                time.sleep(wait_time)\n",
    "            elif response.status_code == 500:\n",
    "                retry_count += 1\n",
    "                wait_time = 20\n",
    "                print(f\"Failed to connect to API. Status code: {response.status_code}. Retrying in {wait_time} seconds...\")\n",
    "                print(response.text)\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                print(f\"Failed to connect to API. Status code: {response.status_code}\")\n",
    "                print(response.text)\n",
    "                break\n",
    "        except requests.exceptions.RequestException as e:   \n",
    "            print(f\"Failed to connect to API: {e}\")\n",
    "            retry_count += 1\n",
    "            wait_time = 60\n",
    "            print(f\"Retrying in {wait_time} seconds...\")\n",
    "            time.sleep(wait_time)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [03:02<00:00,  3.84it/s]\n"
     ]
    }
   ],
   "source": [
    "#get ADA embeddings for posts:\n",
    "MHdatapar.loc[:, 'post_ada_embedding'] = MHdatapar.loc[:, 'text'].progress_apply(get_ada_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data to parquet\n",
    "MHdatapar.to_parquet('data/MH_BClemm_data/germany_val_all_llama.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pol_label</th>\n",
       "      <th>neg_label</th>\n",
       "      <th>neg3_label</th>\n",
       "      <th>ideo_label</th>\n",
       "      <th>GPT_Pol1</th>\n",
       "      <th>GPT_Pol2</th>\n",
       "      <th>GPT_Neg1</th>\n",
       "      <th>GPT_Neg2</th>\n",
       "      <th>GPT_Neg_3Way1</th>\n",
       "      <th>...</th>\n",
       "      <th>Llama31_political_zero</th>\n",
       "      <th>Llama31_political_GER_zero</th>\n",
       "      <th>Llama31_ideology_zero_score</th>\n",
       "      <th>Llama31_political_zero_score</th>\n",
       "      <th>Llama31_political_GER_zero_score</th>\n",
       "      <th>Llama31_political_ideology_8b</th>\n",
       "      <th>Llama31_political_post_8b</th>\n",
       "      <th>Llama31_ideology_8b_score</th>\n",
       "      <th>Llama31_political_8b_score</th>\n",
       "      <th>post_ada_embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@thatleechi17 @KlemmChr @AndiScheuer @victorpe...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>political</td>\n",
       "      <td>political</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>conservative</td>\n",
       "      <td>political</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.025982748717069626, -0.007946434430778027, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Glauben Sie nur nicht, dass Menschen die nicht...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>political</td>\n",
       "      <td>political</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>liberal</td>\n",
       "      <td>political</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-0.0044644176959991455, -0.018281370401382446...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Das ist ja das Mindeste. \\r\\n\\r\\nDass das aber...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>political</td>\n",
       "      <td>political</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>liberal</td>\n",
       "      <td>political</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.008310764096677303, -0.006543226074427366, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Challen81690499 @c_lindner @rbrinkhaus @Nowab...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>political</td>\n",
       "      <td>political</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>non-political</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.008846129290759563, -0.005247590597718954, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ich sage: #DANKE!!!\\r\\nhttps://t.co/0pVneqXwTC...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>political</td>\n",
       "      <td>political</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>conservative</td>\n",
       "      <td>political</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-0.016786759719252586, 0.0026309278327971697,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>@rehbergkk Ihr Denkfehler, in der Tat!</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>political</td>\n",
       "      <td>political</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>political</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.00166011368855834, 0.025222567841410637, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>Die Bundesregierung spricht von „Einwanderung ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>political</td>\n",
       "      <td>political</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>liberal</td>\n",
       "      <td>political</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-0.005906220525503159, -0.009432322345674038,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>Im #EU Parlament sitzen teilweise echt Verrück...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>political</td>\n",
       "      <td>political</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>conservative</td>\n",
       "      <td>political</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[-0.002412516390904784, -0.0012530875392258167...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>@StBrandner @M_HarderKuehnel Du natürlich! &lt;U+...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>non-political</td>\n",
       "      <td>political</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>non-political</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0037030696403235197, -0.007986747659742832,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>@har41637914 @Gothdad Nein. Das ist eine ganz ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>political</td>\n",
       "      <td>political</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>neutral</td>\n",
       "      <td>political</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.00026153630460612476, 0.013496157713234425,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  pol_label  neg_label  \\\n",
       "0    @thatleechi17 @KlemmChr @AndiScheuer @victorpe...          1          1   \n",
       "1    Glauben Sie nur nicht, dass Menschen die nicht...          1          0   \n",
       "2    Das ist ja das Mindeste. \\r\\n\\r\\nDass das aber...          1          1   \n",
       "3    @Challen81690499 @c_lindner @rbrinkhaus @Nowab...          0          0   \n",
       "4    Ich sage: #DANKE!!!\\r\\nhttps://t.co/0pVneqXwTC...          1          0   \n",
       "..                                                 ...        ...        ...   \n",
       "695             @rehbergkk Ihr Denkfehler, in der Tat!          0          1   \n",
       "696  Die Bundesregierung spricht von „Einwanderung ...          1          1   \n",
       "697  Im #EU Parlament sitzen teilweise echt Verrück...          1          1   \n",
       "698  @StBrandner @M_HarderKuehnel Du natürlich! <U+...          0          0   \n",
       "699  @har41637914 @Gothdad Nein. Das ist eine ganz ...          0          1   \n",
       "\n",
       "     neg3_label  ideo_label  GPT_Pol1  GPT_Pol2  GPT_Neg1  GPT_Neg2  \\\n",
       "0             0           1         1         1         1         1   \n",
       "1             1           1         1         1         0         0   \n",
       "2             0           1         1         1         1         1   \n",
       "3             1           1         1         0         0         0   \n",
       "4             2           2         1         1         0         0   \n",
       "..          ...         ...       ...       ...       ...       ...   \n",
       "695           0           1         0         0         1         1   \n",
       "696           0           0         1         1         0         1   \n",
       "697           0           1         1         1         1         1   \n",
       "698           1           1         0         0         0         0   \n",
       "699           0           1         0         0         1         1   \n",
       "\n",
       "     GPT_Neg_3Way1  ...  Llama31_political_zero  Llama31_political_GER_zero  \\\n",
       "0                0  ...               political                   political   \n",
       "1                1  ...               political                   political   \n",
       "2                0  ...               political                   political   \n",
       "3                1  ...               political                   political   \n",
       "4                2  ...               political                   political   \n",
       "..             ...  ...                     ...                         ...   \n",
       "695              0  ...               political                   political   \n",
       "696              0  ...               political                   political   \n",
       "697              0  ...               political                   political   \n",
       "698              2  ...           non-political                   political   \n",
       "699              0  ...               political                   political   \n",
       "\n",
       "     Llama31_ideology_zero_score  Llama31_political_zero_score  \\\n",
       "0                              1                             1   \n",
       "1                              1                             1   \n",
       "2                              0                             1   \n",
       "3                              1                             1   \n",
       "4                              2                             1   \n",
       "..                           ...                           ...   \n",
       "695                            1                             1   \n",
       "696                            0                             1   \n",
       "697                            2                             1   \n",
       "698                            1                             0   \n",
       "699                            1                             1   \n",
       "\n",
       "     Llama31_political_GER_zero_score  Llama31_political_ideology_8b  \\\n",
       "0                                   1                   conservative   \n",
       "1                                   1                        liberal   \n",
       "2                                   1                        liberal   \n",
       "3                                   1                        neutral   \n",
       "4                                   1                   conservative   \n",
       "..                                ...                            ...   \n",
       "695                                 1                        neutral   \n",
       "696                                 1                        liberal   \n",
       "697                                 1                   conservative   \n",
       "698                                 1                        neutral   \n",
       "699                                 1                        neutral   \n",
       "\n",
       "     Llama31_political_post_8b Llama31_ideology_8b_score  \\\n",
       "0                    political                       2.0   \n",
       "1                    political                       0.0   \n",
       "2                    political                       0.0   \n",
       "3                non-political                       1.0   \n",
       "4                    political                       2.0   \n",
       "..                         ...                       ...   \n",
       "695                  political                       1.0   \n",
       "696                  political                       0.0   \n",
       "697                  political                       2.0   \n",
       "698              non-political                       1.0   \n",
       "699                  political                       1.0   \n",
       "\n",
       "    Llama31_political_8b_score  \\\n",
       "0                          1.0   \n",
       "1                          1.0   \n",
       "2                          1.0   \n",
       "3                          0.0   \n",
       "4                          1.0   \n",
       "..                         ...   \n",
       "695                        1.0   \n",
       "696                        1.0   \n",
       "697                        1.0   \n",
       "698                        0.0   \n",
       "699                        1.0   \n",
       "\n",
       "                                    post_ada_embedding  \n",
       "0    [0.025982748717069626, -0.007946434430778027, ...  \n",
       "1    [-0.0044644176959991455, -0.018281370401382446...  \n",
       "2    [0.008310764096677303, -0.006543226074427366, ...  \n",
       "3    [0.008846129290759563, -0.005247590597718954, ...  \n",
       "4    [-0.016786759719252586, 0.0026309278327971697,...  \n",
       "..                                                 ...  \n",
       "695  [0.00166011368855834, 0.025222567841410637, 0....  \n",
       "696  [-0.005906220525503159, -0.009432322345674038,...  \n",
       "697  [-0.002412516390904784, -0.0012530875392258167...  \n",
       "698  [0.0037030696403235197, -0.007986747659742832,...  \n",
       "699  [0.00026153630460612476, 0.013496157713234425,...  \n",
       "\n",
       "[700 rows x 50 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MHdatapar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data:\n",
    "MHdatapar = pd.read_parquet('data/MH_BClemm_data/germany_val_all_llama.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'pol_label', 'neg_label', 'neg3_label', 'ideo_label',\n",
       "       'GPT_Pol1', 'GPT_Pol2', 'GPT_Neg1', 'GPT_Neg2', 'GPT_Neg_3Way1',\n",
       "       'GPT_Neg_3Way2', 'GPT_Ideo1', 'GPT_Ideo2', 'Pol_Recon', 'Neg_Recon',\n",
       "       'Neg3_Recon', 'Ideo_Recon', 'political_post_gpt4o',\n",
       "       'political_ideology_gpt4o', 'political_post_gpt4T',\n",
       "       'political_ideology_gpt4T', 'political_post_gpt4',\n",
       "       'political_ideology_gpt4', 'political_post_gpt4o_dum',\n",
       "       'political_ideology_gpt4o_score', 'political_post_gpt4T_dum',\n",
       "       'political_ideology_gpt4T_score', 'political_post_gpt4_dum',\n",
       "       'political_ideology_gpt4_score', 'Llama31_ideology_low',\n",
       "       'Llama_ideo_score_low', 'Llama31_ideo_GER_low',\n",
       "       'Llama_ideoGER_score_low', 'Llama31_ideo_GER2_low',\n",
       "       'Llama_ideoGER_score2_low', 'Llama31_ideo_GER3', 'Llama_ideoGER_score3',\n",
       "       'Llama31_ideo_EXT', 'Llama_ideoEXT_score', 'Llama31_ideology_zero',\n",
       "       'Llama31_political_zero', 'Llama31_political_GER_zero',\n",
       "       'Llama31_ideology_zero_score', 'Llama31_political_zero_score',\n",
       "       'Llama31_political_GER_zero_score', 'Llama31_political_ideology_8b',\n",
       "       'Llama31_political_post_8b', 'Llama31_ideology_8b_score',\n",
       "       'Llama31_political_8b_score', 'post_ada_embedding'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MHdatapar.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pol_label</th>\n",
       "      <th>GPT_Pol1</th>\n",
       "      <th>political_post_gpt4o_dum</th>\n",
       "      <th>political_post_gpt4T_dum</th>\n",
       "      <th>political_post_gpt4_dum</th>\n",
       "      <th>Llama31_political_zero_score</th>\n",
       "      <th>Llama31_political_8b_score</th>\n",
       "      <th>Llama31_political_GER_zero_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pol_label</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.728128</td>\n",
       "      <td>0.643356</td>\n",
       "      <td>0.699898</td>\n",
       "      <td>0.697227</td>\n",
       "      <td>0.751001</td>\n",
       "      <td>0.745813</td>\n",
       "      <td>0.587352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT_Pol1</th>\n",
       "      <td>0.728128</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.759922</td>\n",
       "      <td>0.757406</td>\n",
       "      <td>0.788814</td>\n",
       "      <td>0.679706</td>\n",
       "      <td>0.691915</td>\n",
       "      <td>0.513279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>political_post_gpt4o_dum</th>\n",
       "      <td>0.643356</td>\n",
       "      <td>0.759922</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.799530</td>\n",
       "      <td>0.831779</td>\n",
       "      <td>0.622274</td>\n",
       "      <td>0.660262</td>\n",
       "      <td>0.442959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>political_post_gpt4T_dum</th>\n",
       "      <td>0.699898</td>\n",
       "      <td>0.757406</td>\n",
       "      <td>0.799530</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.697814</td>\n",
       "      <td>0.674468</td>\n",
       "      <td>0.515174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>political_post_gpt4_dum</th>\n",
       "      <td>0.697227</td>\n",
       "      <td>0.788814</td>\n",
       "      <td>0.831779</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.690470</td>\n",
       "      <td>0.694835</td>\n",
       "      <td>0.500258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama31_political_zero_score</th>\n",
       "      <td>0.751001</td>\n",
       "      <td>0.679706</td>\n",
       "      <td>0.622274</td>\n",
       "      <td>0.697814</td>\n",
       "      <td>0.690470</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.733691</td>\n",
       "      <td>0.715535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama31_political_8b_score</th>\n",
       "      <td>0.745813</td>\n",
       "      <td>0.691915</td>\n",
       "      <td>0.660262</td>\n",
       "      <td>0.674468</td>\n",
       "      <td>0.694835</td>\n",
       "      <td>0.733691</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.562034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama31_political_GER_zero_score</th>\n",
       "      <td>0.587352</td>\n",
       "      <td>0.513279</td>\n",
       "      <td>0.442959</td>\n",
       "      <td>0.515174</td>\n",
       "      <td>0.500258</td>\n",
       "      <td>0.715535</td>\n",
       "      <td>0.562034</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  pol_label  GPT_Pol1  \\\n",
       "pol_label                          1.000000  0.728128   \n",
       "GPT_Pol1                           0.728128  1.000000   \n",
       "political_post_gpt4o_dum           0.643356  0.759922   \n",
       "political_post_gpt4T_dum           0.699898  0.757406   \n",
       "political_post_gpt4_dum            0.697227  0.788814   \n",
       "Llama31_political_zero_score       0.751001  0.679706   \n",
       "Llama31_political_8b_score         0.745813  0.691915   \n",
       "Llama31_political_GER_zero_score   0.587352  0.513279   \n",
       "\n",
       "                                  political_post_gpt4o_dum  \\\n",
       "pol_label                                         0.643356   \n",
       "GPT_Pol1                                          0.759922   \n",
       "political_post_gpt4o_dum                          1.000000   \n",
       "political_post_gpt4T_dum                          0.799530   \n",
       "political_post_gpt4_dum                           0.831779   \n",
       "Llama31_political_zero_score                      0.622274   \n",
       "Llama31_political_8b_score                        0.660262   \n",
       "Llama31_political_GER_zero_score                  0.442959   \n",
       "\n",
       "                                  political_post_gpt4T_dum  \\\n",
       "pol_label                                         0.699898   \n",
       "GPT_Pol1                                          0.757406   \n",
       "political_post_gpt4o_dum                          0.799530   \n",
       "political_post_gpt4T_dum                          1.000000   \n",
       "political_post_gpt4_dum                           0.830000   \n",
       "Llama31_political_zero_score                      0.697814   \n",
       "Llama31_political_8b_score                        0.674468   \n",
       "Llama31_political_GER_zero_score                  0.515174   \n",
       "\n",
       "                                  political_post_gpt4_dum  \\\n",
       "pol_label                                        0.697227   \n",
       "GPT_Pol1                                         0.788814   \n",
       "political_post_gpt4o_dum                         0.831779   \n",
       "political_post_gpt4T_dum                         0.830000   \n",
       "political_post_gpt4_dum                          1.000000   \n",
       "Llama31_political_zero_score                     0.690470   \n",
       "Llama31_political_8b_score                       0.694835   \n",
       "Llama31_political_GER_zero_score                 0.500258   \n",
       "\n",
       "                                  Llama31_political_zero_score  \\\n",
       "pol_label                                             0.751001   \n",
       "GPT_Pol1                                              0.679706   \n",
       "political_post_gpt4o_dum                              0.622274   \n",
       "political_post_gpt4T_dum                              0.697814   \n",
       "political_post_gpt4_dum                               0.690470   \n",
       "Llama31_political_zero_score                          1.000000   \n",
       "Llama31_political_8b_score                            0.733691   \n",
       "Llama31_political_GER_zero_score                      0.715535   \n",
       "\n",
       "                                  Llama31_political_8b_score  \\\n",
       "pol_label                                           0.745813   \n",
       "GPT_Pol1                                            0.691915   \n",
       "political_post_gpt4o_dum                            0.660262   \n",
       "political_post_gpt4T_dum                            0.674468   \n",
       "political_post_gpt4_dum                             0.694835   \n",
       "Llama31_political_zero_score                        0.733691   \n",
       "Llama31_political_8b_score                          1.000000   \n",
       "Llama31_political_GER_zero_score                    0.562034   \n",
       "\n",
       "                                  Llama31_political_GER_zero_score  \n",
       "pol_label                                                 0.587352  \n",
       "GPT_Pol1                                                  0.513279  \n",
       "political_post_gpt4o_dum                                  0.442959  \n",
       "political_post_gpt4T_dum                                  0.515174  \n",
       "political_post_gpt4_dum                                   0.500258  \n",
       "Llama31_political_zero_score                              0.715535  \n",
       "Llama31_political_8b_score                                0.562034  \n",
       "Llama31_political_GER_zero_score                          1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check correlations between different polpost classifications:\n",
    "MHdatapar.loc[:, ['pol_label', 'GPT_Pol1', 'political_post_gpt4o_dum', 'political_post_gpt4T_dum', 'political_post_gpt4_dum', 'Llama31_political_zero_score', 'Llama31_political_8b_score','Llama31_political_GER_zero_score']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>political_post_gpt4o_dum</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama31_political_GER_zero_score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>225</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "political_post_gpt4o_dum            0    1\n",
       "Llama31_political_GER_zero_score          \n",
       "0                                 108    1\n",
       "1                                 225  366"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#what is the consequence in terms of different coding for political posts?\n",
    "pd.crosstab(MHdatapar.Llama31_political_GER_zero_score, MHdatapar.political_post_gpt4o_dum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.82      0.71       115\n",
      "           1       0.92      0.85      0.88       503\n",
      "           2       0.66      0.67      0.67        82\n",
      "\n",
      "    accuracy                           0.82       700\n",
      "   macro avg       0.73      0.78      0.75       700\n",
      "weighted avg       0.84      0.82      0.83       700\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.624942207396589\n",
      "krippendorf(ideo_label): 0.6241276279497063\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.55      0.64       113\n",
      "           1       0.84      0.95      0.89       498\n",
      "           2       0.87      0.46      0.60        74\n",
      "\n",
      "    accuracy                           0.83       685\n",
      "   macro avg       0.82      0.65      0.71       685\n",
      "weighted avg       0.83      0.83      0.82       685\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.552925352296525\n",
      "krippendorf(ideo_label): 0.5490661098556129\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.79      0.71       114\n",
      "           1       0.90      0.90      0.90       486\n",
      "           2       0.86      0.53      0.65        68\n",
      "\n",
      "    accuracy                           0.84       668\n",
      "   macro avg       0.80      0.74      0.75       668\n",
      "weighted avg       0.85      0.84      0.84       668\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.6296885132732255\n",
      "krippendorf(ideo_label): 0.6293104351561764\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.56      0.59       108\n",
      "           1       0.86      0.91      0.88       475\n",
      "           2       0.73      0.55      0.63        66\n",
      "\n",
      "    accuracy                           0.81       649\n",
      "   macro avg       0.74      0.67      0.70       649\n",
      "weighted avg       0.81      0.81      0.81       649\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.5331185084334628\n",
      "krippendorf(ideo_label): 0.5325931242758986\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.81      0.70       115\n",
      "           1       0.92      0.86      0.89       503\n",
      "           2       0.70      0.68      0.69        82\n",
      "\n",
      "    accuracy                           0.83       700\n",
      "   macro avg       0.75      0.78      0.76       700\n",
      "weighted avg       0.84      0.83      0.83       700\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.6368661505196345\n",
      "krippendorf(ideo_label): 0.6362597554687432\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.55      0.55       111\n",
      "           1       0.85      0.85      0.85       499\n",
      "           2       0.46      0.44      0.45        81\n",
      "\n",
      "    accuracy                           0.76       691\n",
      "   macro avg       0.62      0.62      0.62       691\n",
      "weighted avg       0.76      0.76      0.76       691\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.4428863485847562\n",
      "krippendorf(ideo_label): 0.4432801188268013\n"
     ]
    }
   ],
   "source": [
    "#get performance of different ideology classifiers into on output:\n",
    "llm_human_column_pairs = [\n",
    "    (\"ideo_label\", \"Llama_ideo_score_low\"),\n",
    "     (\"ideo_label\", \"Llama_ideoGER_score_low\"),\n",
    "      (\"ideo_label\", \"Llama_ideoGER_score2_low\"),\n",
    "    (\"ideo_label\", \"Llama_ideoGER_score3\"),\n",
    "    (\"ideo_label\", \"Llama31_ideology_zero_score\"),\n",
    "    (\"ideo_label\", \"Llama31_ideology_8b_score\")\n",
    "]\n",
    "\n",
    "print(\"Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\")\n",
    "\n",
    "for human_col, llm_col in llm_human_column_pairs:\n",
    "    subset = MHdatapar[[human_col, llm_col]].dropna()\n",
    "    human = subset[human_col].tolist()\n",
    "    llm = subset[llm_col].tolist()\n",
    "    \n",
    "    print(\"---\")\n",
    "    print(f\"{classification_report(human, llm)}\")\n",
    "    print(f\"cohen_kappa_score({human_col}): {cohen_kappa_score(human, llm)}\")\n",
    "    print(f\"krippendorf({human_col}): {krippendorff.alpha(np.array([human, llm]), level_of_measurement=\"nominal\")}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmdiv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
