{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import config\n",
    "import src\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"sjoerdAzure.env\")  # Load environment variables from .env file\n",
    "import time\n",
    "import tqdm\n",
    "import json\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "import cltrier_lib as lib\n",
    "\n",
    "from sklearn.metrics import cohen_kappa_score, classification_report\n",
    "import krippendorff\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up helper variables and functions:\n",
    "CFG = config.Config()\n",
    "\n",
    "def load_json(path: str):\n",
    "    with open(path, encoding='utf-8') as fp:\n",
    "        return json.load(fp)\n",
    "    \n",
    "#set option variables:\n",
    "\n",
    "#set options to low temperature (0,1):\n",
    "options_low_str = \"\"\"\n",
    "seed: 42\n",
    "temperature: 0.1\n",
    "\"\"\"\n",
    "\n",
    "options_low = yaml.safe_load(options_low_str)\n",
    "\n",
    "MODELsmall: str = 'llama3.1:8b-instruct-q6_K' # options: 'gemma:7b-instruct-q6_K', 'gemma2:27b-instruct-q6_K', 'llama3.1:8b-instruct-q6_K', 'llama3.1:70b-instruct-q6_K', 'mistral:7b-instruct-v0.3-q6_K', 'mistral-large:123b-instruct-2407-q6_K', 'mixtral:8x7b-instruct-v0.1-q6_K', 'mixtral:8x22b-instruct-v0.1-q6_K', 'phi3:14b-medium-128k-instruct-q6_K' or 'qwen2:72b-instruct-q6_K'\n",
    "MODELlarge: str = 'llama3.1:70b-instruct-q6_K' # options: 'gemma:7b-instruct-q6_K', 'gemma2:27b-instruct-q6_K', 'llama3.1:8b-instruct-q6_K', 'llama3.1:70b-instruct-q6_K', 'mistral:7b-instruct-v0.3-q6_K', 'mistral-large:123b-instruct-2407-q6_K', 'mixtral:8x7b-instruct-v0.1-q6_K', 'mixtral:8x22b-instruct-v0.1-q6_K', 'phi3:14b-medium-128k-instruct-q6_K' or 'qwen2:72b-instruct-q6_K'\n",
    "MODELgpt4o = \"nf-gpt-4o-2024-08-06\" # in principe is er nu van elk model een nf (no filter) en een normale versie beschikbaar, de no filter versies zijn alleen voor onderzoekers beschikbaar voor analyze van content die niet door de filter heen zou komen.\n",
    "MODELgpt4T = \"nf-gpt-4-turbo\" # Can be gpt-35-turbo, gpt-4-turbo, gpt-4 or Meta-Llama-3-8B-Instruct.\n",
    "MODELgpt4 = \"nf-gpt-4\" # Can be gpt-35-turbo, gpt-4-turbo, gpt-4 or Meta-Llama-3-8B-Instruct.\n",
    "\n",
    "options_zero_str = \"\"\"\n",
    "seed: 42\n",
    "temperature: 0\n",
    "\"\"\"\n",
    "options_zero = yaml.safe_load(options_zero_str)\n",
    "\n",
    "temperature_0 : int = 0\n",
    "SEED: int = 42\n",
    "MAX10: int = 10\n",
    "TOPP1: int = 1\n",
    "\n",
    "\n",
    "options_large_str = \"\"\"\n",
    "seed: 42\n",
    "temperature: 0\n",
    "num_predict: 2000\n",
    "\"\"\"\n",
    "options_large = yaml.safe_load(options_large_str)\n",
    "\n",
    "#load environment variables:\n",
    "api_key = os.environ.get('sjoerd_key')\n",
    "\n",
    "#setttings:\n",
    "api_endpoint = \"https://ai-research-proxy.azurewebsites.net/chat/completions\"\n",
    "####### API REQUEST FORMATTING ######\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer \" + api_key\n",
    "}#set up helper variables and functions:\n",
    "CFG = config.Config()\n",
    "\n",
    "def load_json(path: str):\n",
    "    with open(path, encoding='utf-8') as fp:\n",
    "        return json.load(fp)\n",
    "    \n",
    "#set option variables:\n",
    "\n",
    "#set options to low temperature (0,1):\n",
    "options_low_str = \"\"\"\n",
    "seed: 42\n",
    "temperature: 0.1\n",
    "\"\"\"\n",
    "\n",
    "options_low = yaml.safe_load(options_low_str)\n",
    "\n",
    "MODELsmall: str = 'llama3.1:8b-instruct-q6_K' # options: 'gemma:7b-instruct-q6_K', 'gemma2:27b-instruct-q6_K', 'llama3.1:8b-instruct-q6_K', 'llama3.1:70b-instruct-q6_K', 'mistral:7b-instruct-v0.3-q6_K', 'mistral-large:123b-instruct-2407-q6_K', 'mixtral:8x7b-instruct-v0.1-q6_K', 'mixtral:8x22b-instruct-v0.1-q6_K', 'phi3:14b-medium-128k-instruct-q6_K' or 'qwen2:72b-instruct-q6_K'\n",
    "MODELlarge: str = 'llama3.1:70b-instruct-q6_K' # options: 'gemma:7b-instruct-q6_K', 'gemma2:27b-instruct-q6_K', 'llama3.1:8b-instruct-q6_K', 'llama3.1:70b-instruct-q6_K', 'mistral:7b-instruct-v0.3-q6_K', 'mistral-large:123b-instruct-2407-q6_K', 'mixtral:8x7b-instruct-v0.1-q6_K', 'mixtral:8x22b-instruct-v0.1-q6_K', 'phi3:14b-medium-128k-instruct-q6_K' or 'qwen2:72b-instruct-q6_K'\n",
    "MODELgpt4o = \"nf-gpt-4o-2024-08-06\" # in principe is er nu van elk model een nf (no filter) en een normale versie beschikbaar, de no filter versies zijn alleen voor onderzoekers beschikbaar voor analyze van content die niet door de filter heen zou komen.\n",
    "MODELgpt4T = \"nf-gpt-4-turbo\" # Can be gpt-35-turbo, gpt-4-turbo, gpt-4 or Meta-Llama-3-8B-Instruct.\n",
    "\n",
    "options_zero_str = \"\"\"\n",
    "seed: 42\n",
    "temperature: 0\n",
    "\"\"\"\n",
    "options_zero = yaml.safe_load(options_zero_str)\n",
    "\n",
    "temperature_0 : int = 0\n",
    "SEED: int = 42\n",
    "MAX10: int = 10\n",
    "TOPP1: int = 1\n",
    "\n",
    "\n",
    "options_large_str = \"\"\"\n",
    "seed: 42\n",
    "temperature: 0\n",
    "num_predict: 2000\n",
    "\"\"\"\n",
    "options_large = yaml.safe_load(options_large_str)\n",
    "\n",
    "#load environment variables:\n",
    "api_key = os.environ.get('sjoerd_key')\n",
    "\n",
    "#setttings:\n",
    "api_endpoint = \"https://ai-research-proxy.azurewebsites.net/chat/completions\"\n",
    "####### API REQUEST FORMATTING ######\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer \" + api_key\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('civility_jaidka', WindowsPath('data/prompts_classify/civility_jaidka.json')), ('constructiveness_jaidka', WindowsPath('data/prompts_classify/constructiveness_jaidka.json')), ('diversity_disagreement', WindowsPath('data/prompts_classify/diversity_disagreement.json')), ('diversity_disagreement_edit', WindowsPath('data/prompts_classify/diversity_disagreement_edit.json')), ('diversity_ideological_direction', WindowsPath('data/prompts_classify/diversity_ideological_direction.json')), ('diversity_positiondum', WindowsPath('data/prompts_classify/diversity_positiondum.json')), ('incivility_allcaps', WindowsPath('data/prompts_classify/incivility_allcaps.json')), ('incivility_attackreputation', WindowsPath('data/prompts_classify/incivility_attackreputation.json')), ('incivility_combine', WindowsPath('data/prompts_classify/incivility_combine.json')), ('incivility_jaidka', WindowsPath('data/prompts_classify/incivility_jaidka.json')), ('incivility_namecalling', WindowsPath('data/prompts_classify/incivility_namecalling.json')), ('incivility_namecalling_edit', WindowsPath('data/prompts_classify/incivility_namecalling_edit.json')), ('incivility_question_intelligence', WindowsPath('data/prompts_classify/incivility_question_intelligence.json')), ('incivility_sarcasm', WindowsPath('data/prompts_classify/incivility_sarcasm.json')), ('incivility_simple', WindowsPath('data/prompts_classify/incivility_simple.json')), ('incivility_simple2', WindowsPath('data/prompts_classify/incivility_simple2.json')), ('incivility_vulgarity', WindowsPath('data/prompts_classify/incivility_vulgarity.json')), ('interactivity_acknowledgement', WindowsPath('data/prompts_classify/interactivity_acknowledgement.json')), ('interactivity_acknowledgement_jaidka', WindowsPath('data/prompts_classify/interactivity_acknowledgement_jaidka.json')), ('interactivity_acknowledgement_simple', WindowsPath('data/prompts_classify/interactivity_acknowledgement_simple.json')), ('interactivity_acknowledgement_simple2', WindowsPath('data/prompts_classify/interactivity_acknowledgement_simple2.json')), ('intolerance_discrimination', WindowsPath('data/prompts_classify/intolerance_discrimination.json')), ('intolerance_rights', WindowsPath('data/prompts_classify/intolerance_rights.json')), ('intolerance_violence', WindowsPath('data/prompts_classify/intolerance_violence.json')), ('political_ideology', WindowsPath('data/prompts_classify/political_ideology.json')), ('political_ideology_ext', WindowsPath('data/prompts_classify/political_ideology_ext.json')), ('political_ideology_GER', WindowsPath('data/prompts_classify/political_ideology_GER.json')), ('political_ideology_GER2', WindowsPath('data/prompts_classify/political_ideology_GER2.json')), ('political_ideology_GER3', WindowsPath('data/prompts_classify/political_ideology_GER3.json')), ('political_ideology_US', WindowsPath('data/prompts_classify/political_ideology_US.json')), ('political_negativity', WindowsPath('data/prompts_classify/political_negativity.json')), ('political_post', WindowsPath('data/prompts_classify/political_post.json')), ('political_post_GER', WindowsPath('data/prompts_classify/political_post_GER.json')), ('political_post_jaidka', WindowsPath('data/prompts_classify/political_post_jaidka.json')), ('rationality_background_info', WindowsPath('data/prompts_classify/rationality_background_info.json')), ('rationality_background_info_edit', WindowsPath('data/prompts_classify/rationality_background_info_edit.json')), ('rationality_combine', WindowsPath('data/prompts_classify/rationality_combine.json')), ('rationality_external_evidence', WindowsPath('data/prompts_classify/rationality_external_evidence.json')), ('rationality_external_evidence_edit', WindowsPath('data/prompts_classify/rationality_external_evidence_edit.json')), ('rationality_jaidka', WindowsPath('data/prompts_classify/rationality_jaidka.json')), ('rationality_reasoning', WindowsPath('data/prompts_classify/rationality_reasoning.json')), ('rationality_reasoning_edit', WindowsPath('data/prompts_classify/rationality_reasoning_edit.json')), ('rationality_simple', WindowsPath('data/prompts_classify/rationality_simple.json')), ('rationality_simple2', WindowsPath('data/prompts_classify/rationality_simple2.json')), ('rationality_topic_relevance', WindowsPath('data/prompts_classify/rationality_topic_relevance.json'))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG.prompt_classify_files.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL: str = 'llama3.1:70b-instruct-q6_K' # options: 'gemma:7b-instruct-q6_K', 'gemma2:27b-instruct-q6_K', 'llama3.1:8b-instruct-q6_K', 'llama3.1:70b-instruct-q6_K', 'mistral:7b-instruct-v0.3-q6_K', 'mistral-large:123b-instruct-2407-q6_K', 'mixtral:8x7b-instruct-v0.1-q6_K', 'mixtral:8x22b-instruct-v0.1-q6_K', 'phi3:14b-medium-128k-instruct-q6_K' or 'qwen2:72b-instruct-q6_K'\n",
    "MODELsmall: str = 'llama3.1:8b-instruct-q6_K'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pol_label</th>\n",
       "      <th>neg_label</th>\n",
       "      <th>neg3_label</th>\n",
       "      <th>ideo_label</th>\n",
       "      <th>GPT_Pol1</th>\n",
       "      <th>GPT_Pol2</th>\n",
       "      <th>GPT_Neg1</th>\n",
       "      <th>GPT_Neg2</th>\n",
       "      <th>GPT_Neg_3Way1</th>\n",
       "      <th>GPT_Neg_3Way2</th>\n",
       "      <th>GPT_Ideo1</th>\n",
       "      <th>GPT_Ideo2</th>\n",
       "      <th>Pol_Recon</th>\n",
       "      <th>Neg_Recon</th>\n",
       "      <th>Neg3_Recon</th>\n",
       "      <th>Ideo_Recon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@thatleechi17 @KlemmChr @AndiScheuer @victorperli Ich würde sagen Sie vergleichen maximal kenntn...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Glauben Sie nur nicht, dass Menschen die nicht dem Bundestag angehören, nichts zu sagen hätten. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Das ist ja das Mindeste. \\r\\n\\r\\nDass das aber das alles möglich ist trotz der Situation der Uig...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Challen81690499 @c_lindner @rbrinkhaus @NowaboFM Na na na... TW</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ich sage: #DANKE!!!\\r\\nhttps://t.co/0pVneqXwTC\\r\\n#afd #btw #btw17 #btw2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>@rehbergkk Ihr Denkfehler, in der Tat!</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>Die Bundesregierung spricht von „Einwanderung in die Sozialsysteme“ und erteilt gleichzeitig Arb...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>Im #EU Parlament sitzen teilweise echt Verrückte https://t.co/wy2v0pYWLB</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>@StBrandner @M_HarderKuehnel Du natürlich! &lt;U+0001F60E&gt;&lt;U+0001F600&gt;</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>@har41637914 @Gothdad Nein. Das ist eine ganz falsche Wahrnehmung. Es gibt auch keine derartigen...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                    text  \\\n",
       "0    @thatleechi17 @KlemmChr @AndiScheuer @victorperli Ich würde sagen Sie vergleichen maximal kenntn...   \n",
       "1    Glauben Sie nur nicht, dass Menschen die nicht dem Bundestag angehören, nichts zu sagen hätten. ...   \n",
       "2    Das ist ja das Mindeste. \\r\\n\\r\\nDass das aber das alles möglich ist trotz der Situation der Uig...   \n",
       "3                                       @Challen81690499 @c_lindner @rbrinkhaus @NowaboFM Na na na... TW   \n",
       "4                            Ich sage: #DANKE!!!\\r\\nhttps://t.co/0pVneqXwTC\\r\\n#afd #btw #btw17 #btw2017   \n",
       "..                                                                                                   ...   \n",
       "695                                                               @rehbergkk Ihr Denkfehler, in der Tat!   \n",
       "696  Die Bundesregierung spricht von „Einwanderung in die Sozialsysteme“ und erteilt gleichzeitig Arb...   \n",
       "697                             Im #EU Parlament sitzen teilweise echt Verrückte https://t.co/wy2v0pYWLB   \n",
       "698                                  @StBrandner @M_HarderKuehnel Du natürlich! <U+0001F60E><U+0001F600>   \n",
       "699  @har41637914 @Gothdad Nein. Das ist eine ganz falsche Wahrnehmung. Es gibt auch keine derartigen...   \n",
       "\n",
       "     pol_label  neg_label  neg3_label  ideo_label  GPT_Pol1  GPT_Pol2  \\\n",
       "0            1          1           0           1         1         1   \n",
       "1            1          0           1           1         1         1   \n",
       "2            1          1           0           1         1         1   \n",
       "3            0          0           1           1         1         0   \n",
       "4            1          0           2           2         1         1   \n",
       "..         ...        ...         ...         ...       ...       ...   \n",
       "695          0          1           0           1         0         0   \n",
       "696          1          1           0           0         1         1   \n",
       "697          1          1           0           1         1         1   \n",
       "698          0          0           1           1         0         0   \n",
       "699          0          1           0           1         0         0   \n",
       "\n",
       "     GPT_Neg1  GPT_Neg2  GPT_Neg_3Way1  GPT_Neg_3Way2  GPT_Ideo1  GPT_Ideo2  \\\n",
       "0           1         1              0              0          1          1   \n",
       "1           0         0              1              1          1          1   \n",
       "2           1         1              0              0          0          0   \n",
       "3           0         0              1              1          1          1   \n",
       "4           0         0              2              2          2          2   \n",
       "..        ...       ...            ...            ...        ...        ...   \n",
       "695         1         1              0              0          1          1   \n",
       "696         0         1              0              0          0          0   \n",
       "697         1         1              0              0          1          1   \n",
       "698         0         0              2              2          1          1   \n",
       "699         1         1              0              0          1          1   \n",
       "\n",
       "     Pol_Recon  Neg_Recon  Neg3_Recon  Ideo_Recon  \n",
       "0            1          1           0           1  \n",
       "1            1          0           1           1  \n",
       "2            1          1           0           0  \n",
       "3            0          0           1           1  \n",
       "4            1          0           2           2  \n",
       "..         ...        ...         ...         ...  \n",
       "695          0          1           0           1  \n",
       "696          1          1           0           0  \n",
       "697          1          1           0           1  \n",
       "698          0          0           2           1  \n",
       "699          0          1           0           1  \n",
       "\n",
       "[700 rows x 17 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "MHdata: pd.DataFrame = pd.read_csv('data/MH_BClemm_data/germany_val_all.csv') \n",
    "MHdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change options to low temperature (0,1) and compare result:\n",
    "options_low = \"\"\"\n",
    "seed: 42\n",
    "temperature: 0.1\n",
    "\"\"\"\n",
    "\n",
    "options_low = yaml.safe_load(options_low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "classifying political_ideology: 100%|██████████| 700/700 [49:31<00:00,  4.24s/it]  \n"
     ]
    }
   ],
   "source": [
    "#the _label variables are the reconciled and definitive annotation values for the variables\n",
    "#what does Llama3.1 predict for political orientation?\n",
    "predictions: typing.Dict[str, pd.Series] = {\n",
    "    label: (\n",
    "        src.PromptClassify\n",
    "        .from_json(path)\n",
    "        (MHdata[\"text\"], MODEL, options=options_low)\n",
    "    )\n",
    "    for label, path in CFG.prompt_classify_files.items() if label == 'political_ideology'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'political_ideology': 0           neutral\n",
       " 1           neutral\n",
       " 2           liberal\n",
       " 3           neutral\n",
       " 4      conservative\n",
       "            ...     \n",
       " 695         neutral\n",
       " 696         liberal\n",
       " 697    conservative\n",
       " 698         neutral\n",
       " 699         neutral\n",
       " Name: political_ideology, Length: 700, dtype: object}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions #note that these are based on llama3.1:70b-instruct-q6_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "political_ideology\n",
      "neutral         474\n",
      "liberal         145\n",
      "conservative     81\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#join to the dataset:\n",
    "for _, preds in predictions.items():\n",
    "    print(preds.value_counts())\n",
    "    print(\"-\" * 42)\n",
    "    # Convert Series to DataFrame\n",
    "    preds_df = preds.to_frame()\n",
    "    # Rename the column in preds_df to 'Llama31_ideology'\n",
    "    preds_df = preds_df.rename(columns={preds_df.columns[0]: 'Llama31_ideology_low'})\n",
    "    MHdata = MHdata.join(preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "political_ideology\n",
      "neutral         454\n",
      "liberal         159\n",
      "conservative     87\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#join to the dataset:\n",
    "for _, preds in predictions.items():\n",
    "    print(preds.value_counts())\n",
    "    print(\"-\" * 42)\n",
    "    # Convert Series to DataFrame\n",
    "    preds_df = preds.to_frame()\n",
    "    # Rename the column in preds_df to 'Llama31_ideology'\n",
    "    preds_df = preds_df.rename(columns={preds_df.columns[0]: 'Llama31_ideology'})\n",
    "    MHdata = MHdata.join(preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#missing values in low temperature ideology:\n",
    "MHdata.Llama31_ideology_low.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MHdata.Llama31_ideology.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama31_ideology</th>\n",
       "      <th>conservative</th>\n",
       "      <th>liberal</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ideo_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>94</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>56</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama31_ideology  conservative  liberal  neutral\n",
       "ideo_label                                      \n",
       "0                            4       94       17\n",
       "1                           26       56      421\n",
       "2                           57        9       16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#does Llama political ideology differ from manual political ideology ?\n",
    "#make a crosstab to see if there are differences:\n",
    "pd.crosstab(MHdata.loc[:, 'ideo_label'], MHdata.loc[:, 'Llama31_ideology'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama31_ideology_low</th>\n",
       "      <th>conservative</th>\n",
       "      <th>liberal</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ideo_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>47</td>\n",
       "      <td>433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55</td>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama31_ideology_low  conservative  liberal  neutral\n",
       "ideo_label                                          \n",
       "0                                3       91       21\n",
       "1                               23       47      433\n",
       "2                               55        7       20"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#does Llama political ideology low differ from manual political ideology ?\n",
    "#make a crosstab to see if there are differences:\n",
    "pd.crosstab(MHdata.loc[:, 'ideo_label'], MHdata.loc[:, 'Llama31_ideology_low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the political ideology labels to numbers:\n",
    "MHdata['Llama_ideo_score'] = MHdata['Llama31_ideology'].map({'liberal': 0, 'neutral': 1, 'conservative': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "MHdata['Llama_ideo_score_low'] = MHdata['Llama31_ideology_low'].map({'liberal': 0, 'neutral': 1, 'conservative': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama_ideo_score</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ideo_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56</td>\n",
       "      <td>421</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama_ideo_score   0    1   2\n",
       "ideo_label                   \n",
       "0                 94   17   4\n",
       "1                 56  421  26\n",
       "2                  9   16  57"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(MHdata.loc[:, 'ideo_label'], MHdata.loc[:, 'Llama_ideo_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama_ideo_score</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPT_Ideo1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>115</td>\n",
       "      <td>49</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>381</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>24</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama_ideo_score    0    1   2\n",
       "GPT_Ideo1                     \n",
       "0                 115   49  11\n",
       "1                  29  381  13\n",
       "2                  15   24  63"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#and how does Llama3.1 perform compared to GPT\n",
    "#make a crosstab to see if there are differences:\n",
    "pd.crosstab(MHdata.loc[:, 'GPT_Ideo1'], MHdata.loc[:, 'Llama_ideo_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_human_column_pairs = [\n",
    "    (\"ideo_label\", \"Llama_ideo_score\"),\n",
    "    (\"ideo_label\", \"GPT_Ideo1\")\n",
    "# (\"TopicRelevance\", \"rationality_topic_relevance\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.82      0.69       115\n",
      "           1       0.93      0.84      0.88       503\n",
      "           2       0.66      0.70      0.67        82\n",
      "\n",
      "    accuracy                           0.82       700\n",
      "   macro avg       0.72      0.78      0.75       700\n",
      "weighted avg       0.84      0.82      0.82       700\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.6206909689737066\n",
      "krippendorf(ideo_label): 0.6192039671924076\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.92      0.73       115\n",
      "           1       0.96      0.81      0.88       503\n",
      "           2       0.69      0.85      0.76        82\n",
      "\n",
      "    accuracy                           0.83       700\n",
      "   macro avg       0.75      0.86      0.79       700\n",
      "weighted avg       0.87      0.83      0.84       700\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.6679290188227158\n",
      "krippendorf(ideo_label): 0.6646610493129983\n"
     ]
    }
   ],
   "source": [
    "print(\"Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\")\n",
    "\n",
    "for human_col, llm_col in llm_human_column_pairs:\n",
    "    subset = MHdata[[human_col, llm_col]].dropna()\n",
    "    human = subset[human_col].tolist()\n",
    "    llm = subset[llm_col].tolist()\n",
    "    \n",
    "    print(\"---\")\n",
    "    print(f\"{classification_report(human, llm)}\")\n",
    "    print(f\"cohen_kappa_score({human_col}): {cohen_kappa_score(human, llm)}\")\n",
    "    print(f\"krippendorf({human_col}): {krippendorff.alpha(np.array([human, llm]), level_of_measurement=\"nominal\")}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Llama did ok, but GPT4 did better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "low temperature Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.79      0.70       115\n",
      "           1       0.91      0.86      0.89       503\n",
      "           2       0.68      0.67      0.67        82\n",
      "\n",
      "    accuracy                           0.83       700\n",
      "   macro avg       0.74      0.77      0.75       700\n",
      "weighted avg       0.84      0.83      0.83       700\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.6289335453713074\n",
      "krippendorf(ideo_label): 0.6284897871397188\n"
     ]
    }
   ],
   "source": [
    "llm_human_column_pairs = [\n",
    "    (\"ideo_label\", \"Llama_ideo_score_low\"),\n",
    "#   (\"ideo_label\", \"GPT_Ideo1\")\n",
    "# (\"TopicRelevance\", \"rationality_topic_relevance\"),\n",
    "]\n",
    "print(\"low temperature Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\")\n",
    "\n",
    "for human_col, llm_col in llm_human_column_pairs:\n",
    "    subset = MHdata[[human_col, llm_col]].dropna()\n",
    "    human = subset[human_col].tolist()\n",
    "    llm = subset[llm_col].tolist()\n",
    "    \n",
    "    print(\"---\")\n",
    "    print(f\"{classification_report(human, llm)}\")\n",
    "    print(f\"cohen_kappa_score({human_col}): {cohen_kappa_score(human, llm)}\")\n",
    "    print(f\"krippendorf({human_col}): {krippendorff.alpha(np.array([human, llm]), level_of_measurement=\"nominal\")}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#very similar performance for low temperature english prompt of Llama3.1 compared to default temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "classifying political_ideology_GER: 100%|██████████| 700/700 [06:46<00:00,  1.72it/s]\n"
     ]
    }
   ],
   "source": [
    "#what if we translate the prompt first \n",
    "#what does Llama3.1 predict for political orientation?\n",
    "predictions: typing.Dict[str, pd.Series] = {\n",
    "    label: (\n",
    "        src.PromptClassify\n",
    "        .from_json(path)\n",
    "        (MHdata[\"text\"], model=MODEL, options=options_low)\n",
    "    )\n",
    "    for label, path in CFG.prompt_classify_files.items() if label == 'political_ideology_GER'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "political_ideology_GER\n",
      "Mitte     564\n",
      "Links      83\n",
      "Rechts     38\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#join to the dataset:\n",
    "for _, preds in predictions.items():\n",
    "    print(preds.value_counts())\n",
    "    print(\"-\" * 42)\n",
    "    # Convert Series to DataFrame\n",
    "    preds_df = preds.to_frame()\n",
    "    # Rename the column in preds_df to 'Llama31_ideology'\n",
    "    preds_df = preds_df.rename(columns={preds_df.columns[0]: 'Llama31_ideo_GER_low'})\n",
    "    MHdata = MHdata.join(preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "political_ideology_GER\n",
      "Mitte     505\n",
      "Links      97\n",
      "Rechts     48\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#join to the dataset:\n",
    "for _, preds in predictions.items():\n",
    "    print(preds.value_counts())\n",
    "    print(\"-\" * 42)\n",
    "    # Convert Series to DataFrame\n",
    "    preds_df = preds.to_frame()\n",
    "    # Rename the column in preds_df to 'Llama31_ideology'\n",
    "    preds_df = preds_df.rename(columns={preds_df.columns[0]: 'Llama31_ideo_GER'})\n",
    "    MHdata = MHdata.join(preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MHdata.Llama31_ideo_GER.isna().sum()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(15)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MHdata.Llama31_ideo_GER_low.isna().sum()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the political ideology labels to numbers:\n",
    "MHdata['Llama_ideoGER_score'] = MHdata['Llama31_ideo_GER'].map({'Links': 0, 'Mitte': 1, 'Rechts': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the political ideology labels to numbers:\n",
    "MHdata['Llama_ideoGER_score_low'] = MHdata['Llama31_ideo_GER_low'].map({'Links': 0, 'Mitte': 1, 'Rechts': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama_ideoGER_score</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ideo_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>421</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama_ideoGER_score  0.0  1.0  2.0\n",
       "ideo_label                        \n",
       "0                     59   51    0\n",
       "1                     32  421   11\n",
       "2                      6   33   37"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#does Llama political ideology differ from manual political ideology ?\n",
    "#make a crosstab to see if there are differences:\n",
    "pd.crosstab(MHdata.loc[:, 'ideo_label'], MHdata.loc[:, 'Llama_ideoGER_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama_ideoGER_score_low</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ideo_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>474</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama_ideoGER_score_low  0.0  1.0  2.0\n",
       "ideo_label                            \n",
       "0                         62   51    0\n",
       "1                         20  474    3\n",
       "2                          1   39   35"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#does Llama political ideology differ from manual political ideology ?\n",
    "#make a crosstab to see if there are differences:\n",
    "pd.crosstab(MHdata.loc[:, 'ideo_label'], MHdata.loc[:, 'Llama_ideoGER_score_low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.35766423357664"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#percent agreement ideoGER_low:\n",
    "100*571/685"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama31_ideo_GER</th>\n",
       "      <th>Links</th>\n",
       "      <th>Mitte</th>\n",
       "      <th>Rechts</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama31_ideology</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>conservative</th>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal</th>\n",
       "      <td>70</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>19</td>\n",
       "      <td>399</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama31_ideo_GER  Links  Mitte  Rechts\n",
       "Llama31_ideology                      \n",
       "conservative          8     26      43\n",
       "liberal              70     80       0\n",
       "neutral              19    399       5"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#and compared to the english prompt:\n",
    "pd.crosstab(MHdata.loc[:, 'Llama31_ideology'], MHdata.loc[:, 'Llama31_ideo_GER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_human_column_pairs = [\n",
    "    (\"ideo_label\", \"Llama_ideoGER_score\"),\n",
    "    (\"Llama_ideo_score\", \"Llama_ideoGER_score\")\n",
    "# (\"TopicRelevance\", \"rationality_topic_relevance\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_human_column_pairs = [\n",
    "    (\"ideo_label\", \"Llama_ideoGER_score_low\"),\n",
    "# (\"TopicRelevance\", \"rationality_topic_relevance\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Options low: Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.55      0.63       113\n",
      "           1       0.84      0.95      0.89       497\n",
      "           2       0.92      0.47      0.62        75\n",
      "\n",
      "    accuracy                           0.83       685\n",
      "   macro avg       0.84      0.66      0.72       685\n",
      "weighted avg       0.83      0.83      0.82       685\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.5580345014941591\n",
      "krippendorf(ideo_label): 0.5540933207998926\n"
     ]
    }
   ],
   "source": [
    "print(\"Options low: Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\")\n",
    "\n",
    "for human_col, llm_col in llm_human_column_pairs:\n",
    "    subset = MHdata[[human_col, llm_col]].dropna()\n",
    "    human = subset[human_col].tolist()\n",
    "    llm = subset[llm_col].tolist()\n",
    "    \n",
    "    print(\"---\")\n",
    "    print(f\"{classification_report(human, llm)}\")\n",
    "    print(f\"cohen_kappa_score({human_col}): {cohen_kappa_score(human, llm)}\")\n",
    "    print(f\"krippendorf({human_col}): {krippendorff.alpha(np.array([human, llm]), level_of_measurement=\"nominal\")}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "considerably better reliability and less missing values than without low temperature setting, but still not as good as the english prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.54      0.57       110\n",
      "           1       0.83      0.91      0.87       464\n",
      "           2       0.77      0.49      0.60        76\n",
      "\n",
      "    accuracy                           0.80       650\n",
      "   macro avg       0.74      0.64      0.68       650\n",
      "weighted avg       0.79      0.80      0.79       650\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.5027665619859429\n",
      "krippendorf(ideo_label): 0.5012600784626177\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.47      0.57       150\n",
      "           1       0.79      0.94      0.86       423\n",
      "           2       0.90      0.56      0.69        77\n",
      "\n",
      "    accuracy                           0.79       650\n",
      "   macro avg       0.80      0.66      0.70       650\n",
      "weighted avg       0.79      0.79      0.77       650\n",
      "\n",
      "cohen_kappa_score(Llama_ideo_score): 0.5294771793809241\n",
      "krippendorf(Llama_ideo_score): 0.5233547200012763\n"
     ]
    }
   ],
   "source": [
    "print(\"Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\")\n",
    "\n",
    "for human_col, llm_col in llm_human_column_pairs:\n",
    "    subset = MHdata[[human_col, llm_col]].dropna()\n",
    "    human = subset[human_col].tolist()\n",
    "    llm = subset[llm_col].tolist()\n",
    "    \n",
    "    print(\"---\")\n",
    "    print(f\"{classification_report(human, llm)}\")\n",
    "    print(f\"cohen_kappa_score({human_col}): {cohen_kappa_score(human, llm)}\")\n",
    "    print(f\"krippendorf({human_col}): {krippendorff.alpha(np.array([human, llm]), level_of_measurement=\"nominal\")}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unexpectedly, the german prompt did much worse than the english prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data to parquet\n",
    "MHdata.to_parquet('data/MH_BClemm_data/germany_val_all_llama.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "classifying political_ideology_GER: 100%|██████████| 700/700 [12:55<00:00,  1.11s/it]\n"
     ]
    }
   ],
   "source": [
    "#what if we adapt ideology labels further:\n",
    "#what does Llama3.1 predict for political orientation?\n",
    "predictions: typing.Dict[str, pd.Series] = {\n",
    "    label: (\n",
    "        src.PromptClassify\n",
    "        .from_json(path)\n",
    "        (MHdata[\"text\"], MODEL)\n",
    "    )\n",
    "    for label, path in CFG.prompt_classify_files.items() if label == 'political_ideology_GER2'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "political_ideology_GER\n",
      "Mittlere Mitte    420\n",
      "Linksliberal      148\n",
      "Konservativ        46\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#join to the dataset:\n",
    "for _, preds in predictions.items():\n",
    "    print(preds.value_counts())\n",
    "    print(\"-\" * 42)\n",
    "    # Convert Series to DataFrame\n",
    "    preds_df = preds.to_frame()\n",
    "    # Rename the column in preds_df to 'Llama31_ideology'\n",
    "    preds_df = preds_df.rename(columns={preds_df.columns[0]: 'Llama31_ideo_GER2'})\n",
    "    MHdata = MHdata.join(preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the political ideology labels to numbers:\n",
    "MHdata['Llama_ideoGER_score2'] = MHdata['Llama31_ideo_GER2'].map({'Linksliberal': 0, 'Mittlere Mitte': 1, 'Konservativ': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(86)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MHdata['Llama_ideoGER_score2'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama_ideoGER_score2</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ideo_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>370</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>21</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama_ideoGER_score2  0.0  1.0  2.0\n",
       "ideo_label                         \n",
       "0                      75   29    4\n",
       "1                      60  370   13\n",
       "2                      13   21   29"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#does Llama political ideology differ from manual political ideology ?\n",
    "#make a crosstab to see if there are differences:\n",
    "pd.crosstab(MHdata.loc[:, 'ideo_label'], MHdata.loc[:, 'Llama_ideoGER_score2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama31_ideo_GER2</th>\n",
       "      <th>Konservativ</th>\n",
       "      <th>Linksliberal</th>\n",
       "      <th>Mittlere Mitte</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama31_ideo_GER</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Links</th>\n",
       "      <td>7</td>\n",
       "      <td>63</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mitte</th>\n",
       "      <td>11</td>\n",
       "      <td>72</td>\n",
       "      <td>375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rechts</th>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama31_ideo_GER2  Konservativ  Linksliberal  Mittlere Mitte\n",
       "Llama31_ideo_GER                                            \n",
       "Links                        7            63              20\n",
       "Mitte                       11            72             375\n",
       "Rechts                      27             3               5"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#and compared to the GER1 prompt:\n",
    "pd.crosstab(MHdata.loc[:, 'Llama31_ideo_GER'], MHdata.loc[:, 'Llama31_ideo_GER2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_human_column_pairs = [\n",
    "    (\"ideo_label\", \"Llama_ideoGER_score2\"),\n",
    "    (\"Llama_ideoGER_score\", \"Llama_ideoGER_score2\")\n",
    "# (\"TopicRelevance\", \"rationality_topic_relevance\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.69      0.59       108\n",
      "           1       0.88      0.84      0.86       443\n",
      "           2       0.63      0.46      0.53        63\n",
      "\n",
      "    accuracy                           0.77       614\n",
      "   macro avg       0.67      0.66      0.66       614\n",
      "weighted avg       0.79      0.77      0.78       614\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.5003894126262686\n",
      "krippendorf(ideo_label): 0.4990361593355478\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.46      0.70      0.55        90\n",
      "         1.0       0.94      0.82      0.87       458\n",
      "         2.0       0.60      0.77      0.68        35\n",
      "\n",
      "    accuracy                           0.80       583\n",
      "   macro avg       0.66      0.76      0.70       583\n",
      "weighted avg       0.84      0.80      0.81       583\n",
      "\n",
      "cohen_kappa_score(Llama_ideoGER_score): 0.5178914320153615\n",
      "krippendorf(Llama_ideoGER_score): 0.5133874210630646\n"
     ]
    }
   ],
   "source": [
    "print(\"Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\")\n",
    "\n",
    "for human_col, llm_col in llm_human_column_pairs:\n",
    "    subset = MHdata[[human_col, llm_col]].dropna()\n",
    "    human = subset[human_col].tolist()\n",
    "    llm = subset[llm_col].tolist()\n",
    "    \n",
    "    print(\"---\")\n",
    "    print(f\"{classification_report(human, llm)}\")\n",
    "    print(f\"cohen_kappa_score({human_col}): {cohen_kappa_score(human, llm)}\")\n",
    "    print(f\"krippendorf({human_col}): {krippendorff.alpha(np.array([human, llm]), level_of_measurement=\"nominal\")}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No improvement of performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data to parquet\n",
    "MHdata.to_parquet('data/MH_BClemm_data/germany_val_all_llama.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "classifying political_ideology_GER3: 100%|██████████| 700/700 [42:05<00:00,  3.61s/it]  \n"
     ]
    }
   ],
   "source": [
    "#final try to improve German language prompt:\n",
    "#what does Llama3.1 predict for political orientation?\n",
    "predictions: typing.Dict[str, pd.Series] = {\n",
    "    label: (\n",
    "        src.PromptClassify\n",
    "        .from_json(path)\n",
    "        (MHdata[\"text\"], MODEL, options=options_low)\n",
    "    )\n",
    "    for label, path in CFG.prompt_classify_files.items() if label == 'political_ideology_GER3'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "political_ideology_GER3\n",
      "Moderate       513\n",
      "Liberal         87\n",
      "Konservativ     45\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#join to the dataset:\n",
    "for _, preds in predictions.items():\n",
    "    print(preds.value_counts())\n",
    "    print(\"-\" * 42)\n",
    "    # Convert Series to DataFrame\n",
    "    preds_df = preds.to_frame()\n",
    "    # Rename the column in preds_df to 'Llama31_ideology'\n",
    "    preds_df = preds_df.rename(columns={preds_df.columns[0]: 'Llama31_ideo_GER3'})\n",
    "    MHdata = MHdata.join(preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the political ideology labels to numbers:\n",
    "MHdata['Llama_ideoGER_score3'] = MHdata['Llama31_ideo_GER3'].map({'Liberal': 0, 'Moderate': 1, 'Konservativ': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(55)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MHdata['Llama_ideoGER_score3'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama_ideoGER_score3</th>\n",
       "      <th>0.0</th>\n",
       "      <th>1.0</th>\n",
       "      <th>2.0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ideo_label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>441</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama_ideoGER_score3  0.0  1.0  2.0\n",
       "ideo_label                         \n",
       "0                      59   46    0\n",
       "1                      23  441    9\n",
       "2                       5   26   36"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#does Llama political ideology differ from manual political ideology ?\n",
    "#make a crosstab to see if there are differences:\n",
    "pd.crosstab(MHdata.loc[:, 'ideo_label'], MHdata.loc[:, 'Llama_ideoGER_score3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.56      0.61       105\n",
      "           1       0.86      0.93      0.89       473\n",
      "           2       0.80      0.54      0.64        67\n",
      "\n",
      "    accuracy                           0.83       645\n",
      "   macro avg       0.78      0.68      0.72       645\n",
      "weighted avg       0.82      0.83      0.82       645\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.5639350973168099\n",
      "krippendorf(ideo_label): 0.562640078693097\n"
     ]
    }
   ],
   "source": [
    "llm_human_column_pairs = [\n",
    "    (\"ideo_label\", \"Llama_ideoGER_score3\"),\n",
    "#   (\"Llama_ideoGER_score\", \"Llama_ideoGER_score2\")\n",
    "# (\"TopicRelevance\", \"rationality_topic_relevance\"),\n",
    "]\n",
    "print(\"Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\")\n",
    "\n",
    "for human_col, llm_col in llm_human_column_pairs:\n",
    "    subset = MHdata[[human_col, llm_col]].dropna()\n",
    "    human = subset[human_col].tolist()\n",
    "    llm = subset[llm_col].tolist()\n",
    "    \n",
    "    print(\"---\")\n",
    "    print(f\"{classification_report(human, llm)}\")\n",
    "    print(f\"cohen_kappa_score({human_col}): {cohen_kappa_score(human, llm)}\")\n",
    "    print(f\"krippendorf({human_col}): {krippendorff.alpha(np.array([human, llm]), level_of_measurement=\"nominal\")}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best performing German Llama3.1 model so far, but did not reduce (but increased) number of missing classifications, and still performance is inferior to english language prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join to parquet data:\n",
    "#save data to parquet\n",
    "MHdatapar= pd.read_parquet('data/MH_BClemm_data/germany_val_all_llama.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pol_label</th>\n",
       "      <th>neg_label</th>\n",
       "      <th>neg3_label</th>\n",
       "      <th>ideo_label</th>\n",
       "      <th>GPT_Pol1</th>\n",
       "      <th>GPT_Pol2</th>\n",
       "      <th>GPT_Neg1</th>\n",
       "      <th>GPT_Neg2</th>\n",
       "      <th>GPT_Neg_3Way1</th>\n",
       "      <th>...</th>\n",
       "      <th>Llama31_ideo_GER</th>\n",
       "      <th>Llama_ideoGER_score</th>\n",
       "      <th>Llama31_ideo_GER2</th>\n",
       "      <th>Llama_ideoGER_score2</th>\n",
       "      <th>Llama31_ideo_GER3</th>\n",
       "      <th>Llama_ideoGER_score3</th>\n",
       "      <th>Llama31_ideology_low</th>\n",
       "      <th>Llama_ideo_score_low</th>\n",
       "      <th>Llama31_ideo_GER_low</th>\n",
       "      <th>Llama_ideoGER_score_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@thatleechi17 @KlemmChr @AndiScheuer @victorperli Ich würde sagen Sie vergleichen maximal kenntn...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mittlere Mitte</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Glauben Sie nur nicht, dass Menschen die nicht dem Bundestag angehören, nichts zu sagen hätten. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mittlere Mitte</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>liberal</td>\n",
       "      <td>0</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Das ist ja das Mindeste. \\r\\n\\r\\nDass das aber das alles möglich ist trotz der Situation der Uig...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Linksliberal</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>liberal</td>\n",
       "      <td>0</td>\n",
       "      <td>Links</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Challen81690499 @c_lindner @rbrinkhaus @NowaboFM Na na na... TW</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Mittlere Mitte</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>1.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>Mitte</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ich sage: #DANKE!!!\\r\\nhttps://t.co/0pVneqXwTC\\r\\n#afd #btw #btw17 #btw2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Rechts</td>\n",
       "      <td>2.0</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Konservativ</td>\n",
       "      <td>2.0</td>\n",
       "      <td>conservative</td>\n",
       "      <td>2</td>\n",
       "      <td>Rechts</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  text  \\\n",
       "0  @thatleechi17 @KlemmChr @AndiScheuer @victorperli Ich würde sagen Sie vergleichen maximal kenntn...   \n",
       "1  Glauben Sie nur nicht, dass Menschen die nicht dem Bundestag angehören, nichts zu sagen hätten. ...   \n",
       "2  Das ist ja das Mindeste. \\r\\n\\r\\nDass das aber das alles möglich ist trotz der Situation der Uig...   \n",
       "3                                     @Challen81690499 @c_lindner @rbrinkhaus @NowaboFM Na na na... TW   \n",
       "4                          Ich sage: #DANKE!!!\\r\\nhttps://t.co/0pVneqXwTC\\r\\n#afd #btw #btw17 #btw2017   \n",
       "\n",
       "   pol_label  neg_label  neg3_label  ideo_label  GPT_Pol1  GPT_Pol2  GPT_Neg1  \\\n",
       "0          1          1           0           1         1         1         1   \n",
       "1          1          0           1           1         1         1         0   \n",
       "2          1          1           0           1         1         1         1   \n",
       "3          0          0           1           1         1         0         0   \n",
       "4          1          0           2           2         1         1         0   \n",
       "\n",
       "   GPT_Neg2  GPT_Neg_3Way1  ...  Llama31_ideo_GER  Llama_ideoGER_score  \\\n",
       "0         1              0  ...             Mitte                  1.0   \n",
       "1         0              1  ...             Mitte                  1.0   \n",
       "2         1              0  ...             Mitte                  1.0   \n",
       "3         0              1  ...             Mitte                  1.0   \n",
       "4         0              2  ...            Rechts                  2.0   \n",
       "\n",
       "   Llama31_ideo_GER2  Llama_ideoGER_score2  Llama31_ideo_GER3  \\\n",
       "0     Mittlere Mitte                   1.0           Moderate   \n",
       "1     Mittlere Mitte                   1.0           Moderate   \n",
       "2       Linksliberal                   0.0           Moderate   \n",
       "3     Mittlere Mitte                   1.0           Moderate   \n",
       "4               None                   NaN        Konservativ   \n",
       "\n",
       "   Llama_ideoGER_score3  Llama31_ideology_low Llama_ideo_score_low  \\\n",
       "0                   1.0               neutral                    1   \n",
       "1                   1.0               liberal                    0   \n",
       "2                   1.0               liberal                    0   \n",
       "3                   1.0               neutral                    1   \n",
       "4                   2.0          conservative                    2   \n",
       "\n",
       "   Llama31_ideo_GER_low Llama_ideoGER_score_low  \n",
       "0                 Mitte                     1.0  \n",
       "1                 Mitte                     1.0  \n",
       "2                 Links                     0.0  \n",
       "3                 Mitte                     1.0  \n",
       "4                Rechts                     2.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MHdatapar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "MHdatapar = MHdatapar.join(MHdata.loc[:, ['Llama31_ideo_GER3', 'Llama_ideoGER_score3', 'Llama31_ideology_low', 'Llama_ideo_score_low', 'Llama31_ideo_GER_low' ,'Llama_ideoGER_score_low']])   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "MHdatapar.to_parquet('data/MH_BClemm_data/germany_val_all_llama.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "classifying political_ideology_ext: 100%|██████████| 700/700 [07:02<00:00,  1.66it/s]  \n"
     ]
    }
   ],
   "source": [
    "#what about Simon's more expansive english ideology prompt?\n",
    "#what does Llama3.1 predict for political orientation?\n",
    "predictions: typing.Dict[str, pd.Series] = {\n",
    "    label: (\n",
    "        src.PromptClassify\n",
    "        .from_json(path)\n",
    "        (MHdata[\"text\"], MODEL, options=options_low)\n",
    "    )\n",
    "    for label, path in CFG.prompt_classify_files.items() if label == 'political_ideology_ext'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MHdatapar=pd.read_parquet('data/MH_BClemm_data/germany_val_all_llama.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'pol_label', 'neg_label', 'neg3_label', 'ideo_label',\n",
       "       'GPT_Pol1', 'GPT_Pol2', 'GPT_Neg1', 'GPT_Neg2', 'GPT_Neg_3Way1',\n",
       "       'GPT_Neg_3Way2', 'GPT_Ideo1', 'GPT_Ideo2', 'Pol_Recon', 'Neg_Recon',\n",
       "       'Neg3_Recon', 'Ideo_Recon', 'Llama31_ideology', 'Llama_ideo_score',\n",
       "       'Llama31_ideo_GER', 'Llama_ideoGER_score', 'Llama31_ideo_GER2',\n",
       "       'Llama_ideoGER_score2', 'Llama31_ideo_GER3', 'Llama_ideoGER_score3',\n",
       "       'Llama31_ideology_low', 'Llama_ideo_score_low', 'Llama31_ideo_GER_low',\n",
       "       'Llama_ideoGER_score_low'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MHdatapar.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "political_ideology_ext\n",
      "Neutral    440\n",
      "Left       162\n",
      "Right       97\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#join to the dataset:\n",
    "for _, preds in predictions.items():\n",
    "    print(preds.value_counts())\n",
    "    print(\"-\" * 42)\n",
    "    # Convert Series to DataFrame\n",
    "    preds_df = preds.to_frame()\n",
    "    # Rename the column in preds_df to 'Llama31_ideology'\n",
    "    preds_df = preds_df.rename(columns={preds_df.columns[0]: 'Llama31_ideo_EXT'})\n",
    "    MHdata = MHdata.join(preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the political ideology labels to numbers:\n",
    "MHdata['Llama_ideoEXT_score'] = MHdata['Llama31_ideo_EXT'].map({'Left': 0, 'Neutral': 1, 'Right': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MHdata['Llama_ideoEXT_score'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.83      0.69       115\n",
      "           1       0.93      0.82      0.87       503\n",
      "           2       0.60      0.72      0.65        81\n",
      "\n",
      "    accuracy                           0.81       699\n",
      "   macro avg       0.71      0.79      0.74       699\n",
      "weighted avg       0.84      0.81      0.82       699\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.6110119022899242\n",
      "krippendorf(ideo_label): 0.6086761112191166\n"
     ]
    }
   ],
   "source": [
    "llm_human_column_pairs = [\n",
    "    (\"ideo_label\", \"Llama_ideoEXT_score\"),\n",
    "#   (\"Llama_ideoGER_score\", \"Llama_ideoGER_score2\")\n",
    "# (\"TopicRelevance\", \"rationality_topic_relevance\"),\n",
    "]\n",
    "print(\"Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\")\n",
    "\n",
    "for human_col, llm_col in llm_human_column_pairs:\n",
    "    subset = MHdata[[human_col, llm_col]].dropna()\n",
    "    human = subset[human_col].tolist()\n",
    "    llm = subset[llm_col].tolist()\n",
    "    \n",
    "    print(\"---\")\n",
    "    print(f\"{classification_report(human, llm)}\")\n",
    "    print(f\"cohen_kappa_score({human_col}): {cohen_kappa_score(human, llm)}\")\n",
    "    print(f\"krippendorf({human_col}): {krippendorff.alpha(np.array([human, llm]), level_of_measurement=\"nominal\")}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8358226037195995"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#percent agreement\n",
    "(0.59*115+0.93*503+0.60*81)/699\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#very similar (but slightly worse) than the original shorter english prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how about zero temperature?\n",
    "#change options to low temperature (0,1) and compare result:\n",
    "options_zero = \"\"\"\n",
    "seed: 42\n",
    "temperature: 0\n",
    "\"\"\"\n",
    "\n",
    "options_zero = yaml.safe_load(options_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "classifying political_post_GER: 100%|██████████| 700/700 [05:13<00:00,  2.23it/s]\n"
     ]
    }
   ],
   "source": [
    "#the _label variables are the reconciled and definitive annotation values for the variables\n",
    "#what does Llama3.1 predict for political orientation?\n",
    "predictions: typing.Dict[str, pd.Series] = {\n",
    "    label: (\n",
    "        src.PromptClassify\n",
    "        .from_json(path)\n",
    "        (MHdata[\"text\"], MODEL, options=options_zero)\n",
    "    )\n",
    "    for label, path in CFG.prompt_classify_files.items() if label in ['political_ideology', 'political_post', 'political_post_GER']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'political_post_GER': 0      political\n",
       " 1      political\n",
       " 2      political\n",
       " 3      political\n",
       " 4      political\n",
       "          ...    \n",
       " 695    political\n",
       " 696    political\n",
       " 697    political\n",
       " 698    political\n",
       " 699    political\n",
       " Name: political_post_GER, Length: 700, dtype: object}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "political_post_GER\n",
      "political        589\n",
      "non-political    111\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#join to the dataset:\n",
    "for _, preds in predictions.items():\n",
    "    print(preds.value_counts())\n",
    "    print(\"-\" * 42)\n",
    "    # Convert Series to DataFrame\n",
    "    preds_df = preds.to_frame()\n",
    "    # Rename the column in preds_df to 'Llama31_ideology'\n",
    "    preds_df = preds_df.rename(columns={preds_df.columns[0]: 'Llama31_political_GER_zero'})\n",
    "    MHdatapar = MHdatapar.join(preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the political ideology labels to numbers:\n",
    "MHdatapar['Llama31_ideology_zero_score'] = MHdatapar['Llama31_ideology_zero'].map({'liberal': 0, 'neutral': 1, 'conservative': 2})\n",
    "MHdatapar['Llama31_political_zero_score'] = MHdatapar['Llama31_political_zero'].map({'non-political': 0, 'political': 1})\n",
    "MHdatapar['Llama31_political_GER_zero_score'] = MHdatapar['Llama31_political_GER_zero'].map({'non-political': 0, 'political': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama_ideo_score_low</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama31_ideology_zero_score</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>143</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>466</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama_ideo_score_low           0    1   2\n",
       "Llama31_ideology_zero_score              \n",
       "0                            143    5   2\n",
       "1                              2  466   1\n",
       "2                              0    3  78"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#and how does Llama3.1 perform with zero compared to low temperature?\n",
    "#make a crosstab to see if there are differences:\n",
    "pd.crosstab(MHdatapar.loc[:, 'Llama31_ideology_zero_score'], MHdatapar.loc[:, 'Llama_ideo_score_low'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pol_label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama31_political_zero</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>non-political</th>\n",
       "      <td>143</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>political</th>\n",
       "      <td>59</td>\n",
       "      <td>477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pol_label                 0    1\n",
       "Llama31_political_zero          \n",
       "non-political           143   21\n",
       "political                59  477"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#and how did Llama3.1 perform in classifying political ?\n",
    "pd.crosstab(MHdatapar.loc[:, 'Llama31_political_zero'], MHdatapar.loc[:, 'pol_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama31_political_GER_zero</th>\n",
       "      <th>non-political</th>\n",
       "      <th>political</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama31_political_zero</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>non-political</th>\n",
       "      <td>110</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>political</th>\n",
       "      <td>1</td>\n",
       "      <td>535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama31_political_GER_zero  non-political  political\n",
       "Llama31_political_zero                              \n",
       "non-political                         110         54\n",
       "political                               1        535"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#does it matter whether we specify the German context in the Llama3.1 prompt when classifying political ?\n",
    "pd.crosstab(MHdatapar.loc[:, 'Llama31_political_zero'], MHdatapar.loc[:, 'Llama31_political_GER_zero'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.81      0.70       115\n",
      "           1       0.92      0.85      0.88       503\n",
      "           2       0.69      0.68      0.69        82\n",
      "\n",
      "    accuracy                           0.83       700\n",
      "   macro avg       0.74      0.78      0.76       700\n",
      "weighted avg       0.84      0.83      0.83       700\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.6320606774080042\n",
      "krippendorf(ideo_label): 0.6313698931428036\n",
      "percent_agreement(ideo_label): 82.71%\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.71      0.78       202\n",
      "           1       0.89      0.96      0.92       498\n",
      "\n",
      "    accuracy                           0.89       700\n",
      "   macro avg       0.88      0.83      0.85       700\n",
      "weighted avg       0.88      0.89      0.88       700\n",
      "\n",
      "cohen_kappa_score(pol_label): 0.7051762624773616\n",
      "krippendorf(pol_label): 0.7042627178657873\n",
      "percent_agreement(pol_label): 88.57%\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.50      0.65       202\n",
      "           1       0.83      0.98      0.90       498\n",
      "\n",
      "    accuracy                           0.84       700\n",
      "   macro avg       0.87      0.74      0.77       700\n",
      "weighted avg       0.85      0.84      0.83       700\n",
      "\n",
      "cohen_kappa_score(pol_label): 0.5541043063079607\n",
      "krippendorf(pol_label): 0.543577745708063\n",
      "percent_agreement(pol_label): 84.14%\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.97      0.80       202\n",
      "           1       0.98      0.82      0.90       498\n",
      "\n",
      "    accuracy                           0.86       700\n",
      "   macro avg       0.84      0.89      0.85       700\n",
      "weighted avg       0.90      0.86      0.87       700\n",
      "\n",
      "cohen_kappa_score(pol_label): 0.7046649612733604\n",
      "krippendorf(pol_label): 0.7005126471748071\n",
      "percent_agreement(pol_label): 86.43%\n"
     ]
    }
   ],
   "source": [
    "#evaluete respective performance :\n",
    "llm_human_column_pairs = [\n",
    "    (\"ideo_label\", \"Llama31_ideology_zero_score\"),\n",
    "    (\"pol_label\", \"Llama31_political_zero_score\"),\n",
    "    (\"pol_label\", \"Llama31_political_GER_zero_score\"),\n",
    "    (\"pol_label\", \"GPT_Pol1\")\n",
    "]\n",
    "print(\"Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\")\n",
    "\n",
    "for human_col, llm_col in llm_human_column_pairs:\n",
    "    subset = MHdatapar[[human_col, llm_col]].dropna()\n",
    "    human = subset[human_col].tolist()\n",
    "    llm = subset[llm_col].tolist()\n",
    "\n",
    "    # Calculate percent agreement\n",
    "    agreement = np.sum(np.array(human) == np.array(llm))/len(np.array(human)) * 100\n",
    "\n",
    "    print(\"---\")\n",
    "    print(f\"{classification_report(human, llm)}\")\n",
    "    print(f\"cohen_kappa_score({human_col}): {cohen_kappa_score(human, llm)}\")\n",
    "    print(f\"krippendorf({human_col}): {krippendorff.alpha(np.array([human, llm]), level_of_measurement=\"nominal\")}\")\n",
    "    print(f\"percent_agreement({human_col}): {agreement:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#llama3.1 beats GPT4 on classifying political posts, in German, even without mentioning this is German content referring to the German political system\n",
    "#in fact, when we do mention the political context, performance fall slightly below that of GPT4..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "classifying political_ideology: 100%|██████████| 700/700 [03:05<00:00,  3.77it/s]\n",
      "classifying political_post: 100%|██████████| 700/700 [03:00<00:00,  3.87it/s]\n"
     ]
    }
   ],
   "source": [
    "#what is the effect of using a smaller model?\n",
    "#what does Llama3.1 predict for political orientation and ideology?\n",
    "predictions: typing.Dict[str, pd.Series] = {\n",
    "    label: (\n",
    "        src.PromptClassify\n",
    "        .from_json(path)\n",
    "        (MHdata[\"text\"], model=MODELsmall, options=options_zero)\n",
    "    )\n",
    "    for label, path in CFG.prompt_classify_files.items() if label in ['political_ideology', 'political_post']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'political_ideology': 0      conservative\n",
       " 1           liberal\n",
       " 2           liberal\n",
       " 3           neutral\n",
       " 4      conservative\n",
       "            ...     \n",
       " 695         neutral\n",
       " 696         liberal\n",
       " 697    conservative\n",
       " 698         neutral\n",
       " 699         neutral\n",
       " Name: political_ideology, Length: 700, dtype: object,\n",
       " 'political_post': 0          political\n",
       " 1          political\n",
       " 2          political\n",
       " 3      non-political\n",
       " 4          political\n",
       "            ...      \n",
       " 695        political\n",
       " 696        political\n",
       " 697        political\n",
       " 698    non-political\n",
       " 699        political\n",
       " Name: political_post, Length: 700, dtype: object}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "political_ideology\n",
      "neutral         505\n",
      "liberal         111\n",
      "conservative     77\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------\n",
      "political_post\n",
      "political        529\n",
      "non-political    163\n",
      "Name: count, dtype: int64\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#join to the dataset:\n",
    "for label, preds in predictions.items():\n",
    "    print(preds.value_counts())\n",
    "    print(\"-\" * 42)\n",
    "    # Convert Series to DataFrame\n",
    "    preds_df = preds.to_frame()\n",
    "    # Rename the column in preds_df to include the label\n",
    "    preds_df.columns = [f'Llama31_{label}_8b']\n",
    "    MHdatapar = MHdatapar.join(preds_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Llama31_political_post_8b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>non-political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>non-political</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>political</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>700 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Llama31_political_post_8b\n",
       "0                   political\n",
       "1                   political\n",
       "2                   political\n",
       "3               non-political\n",
       "4                   political\n",
       "..                        ...\n",
       "695                 political\n",
       "696                 political\n",
       "697                 political\n",
       "698             non-political\n",
       "699                 political\n",
       "\n",
       "[700 rows x 1 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the political ideology labels to numbers:\n",
    "MHdatapar['Llama31_ideology_8b_score'] = MHdatapar['Llama31_political_ideology_8b'].map({'liberal': 0, 'neutral': 1, 'conservative': 2})\n",
    "MHdatapar['Llama31_political_8b_score'] = MHdatapar['Llama31_political_post_8b'].map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ideo_label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama31_political_ideology_8b</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>conservative</th>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal</th>\n",
       "      <td>61</td>\n",
       "      <td>37</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>42</td>\n",
       "      <td>429</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ideo_label                      0    1   2\n",
       "Llama31_political_ideology_8b             \n",
       "conservative                    9   33  35\n",
       "liberal                        61   37  13\n",
       "neutral                        42  429  34"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#and how did Llama3.1 8b perform in classifying political ?\n",
    "pd.crosstab(MHdatapar.loc[:, 'Llama31_political_ideology_8b'], MHdatapar.loc[:, 'ideo_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama31_ideology_zero</th>\n",
       "      <th>conservative</th>\n",
       "      <th>liberal</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama31_political_ideology_8b</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>conservative</th>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>liberal</th>\n",
       "      <td>11</td>\n",
       "      <td>79</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>23</td>\n",
       "      <td>57</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama31_ideology_zero          conservative  liberal  neutral\n",
       "Llama31_political_ideology_8b                                \n",
       "conservative                             46       11       20\n",
       "liberal                                  11       79       21\n",
       "neutral                                  23       57      425"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#and how did Llama3.1 8b perform in classifying political compared to large model ?\n",
    "pd.crosstab(MHdatapar.loc[:, 'Llama31_political_ideology_8b'], MHdatapar.loc[:, 'Llama31_ideology_zero'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pol_label</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama31_political_post_8b</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>non-political</th>\n",
       "      <td>147</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>political</th>\n",
       "      <td>54</td>\n",
       "      <td>475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pol_label                    0    1\n",
       "Llama31_political_post_8b          \n",
       "non-political              147   16\n",
       "political                   54  475"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#and how did Llama3.1 8b perform in classifying political ?\n",
    "pd.crosstab(MHdatapar.loc[:, 'Llama31_political_post_8b'], MHdatapar.loc[:, 'pol_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Llama31_political_zero</th>\n",
       "      <th>non-political</th>\n",
       "      <th>political</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Llama31_political_post_8b</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>non-political</th>\n",
       "      <td>126</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>political</th>\n",
       "      <td>37</td>\n",
       "      <td>492</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Llama31_political_zero     non-political  political\n",
       "Llama31_political_post_8b                          \n",
       "non-political                        126         37\n",
       "political                             37        492"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#and how did Llama3.1 8b perform in classifying political compared to large model ?\n",
    "pd.crosstab(MHdatapar.loc[:, 'Llama31_political_post_8b'], MHdatapar.loc[:, 'Llama31_political_zero'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.81      0.70       115\n",
      "           1       0.92      0.85      0.88       503\n",
      "           2       0.69      0.68      0.69        82\n",
      "\n",
      "    accuracy                           0.83       700\n",
      "   macro avg       0.74      0.78      0.76       700\n",
      "weighted avg       0.84      0.83      0.83       700\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.6320606774080042\n",
      "krippendorf(ideo_label): 0.6313698931428036\n",
      "percent_agreement(ideo_label): 82.71%\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.54      0.55       112\n",
      "           1       0.85      0.86      0.85       499\n",
      "           2       0.45      0.43      0.44        82\n",
      "\n",
      "    accuracy                           0.76       693\n",
      "   macro avg       0.62      0.61      0.61       693\n",
      "weighted avg       0.75      0.76      0.76       693\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.44429806976344577\n",
      "krippendorf(ideo_label): 0.444657923314677\n",
      "percent_agreement(ideo_label): 75.76%\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.71      0.78       202\n",
      "           1       0.89      0.96      0.92       498\n",
      "\n",
      "    accuracy                           0.89       700\n",
      "   macro avg       0.88      0.83      0.85       700\n",
      "weighted avg       0.88      0.89      0.88       700\n",
      "\n",
      "cohen_kappa_score(pol_label): 0.7051762624773616\n",
      "krippendorf(pol_label): 0.7042627178657873\n",
      "percent_agreement(pol_label): 88.57%\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.73      0.81       201\n",
      "           1       0.90      0.97      0.93       491\n",
      "\n",
      "    accuracy                           0.90       692\n",
      "   macro avg       0.90      0.85      0.87       692\n",
      "weighted avg       0.90      0.90      0.90       692\n",
      "\n",
      "cohen_kappa_score(pol_label): 0.7400757665189255\n",
      "krippendorf(pol_label): 0.7392533936651584\n",
      "percent_agreement(pol_label): 89.88%\n"
     ]
    }
   ],
   "source": [
    "#evaluete respective performance:\n",
    "llm_human_column_pairs = [\n",
    "    (\"ideo_label\", \"Llama31_ideology_zero_score\"),\n",
    "    (\"ideo_label\", \"Llama31_ideology_8b_score\"),\n",
    "    (\"pol_label\", \"Llama31_political_zero_score\"),\n",
    "    (\"pol_label\", \"Llama31_political_8b_score\")\n",
    "]\n",
    "print(\"Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\")\n",
    "\n",
    "for human_col, llm_col in llm_human_column_pairs:\n",
    "    subset = MHdatapar[[human_col, llm_col]].dropna()\n",
    "    human = subset[human_col].tolist()\n",
    "    llm = subset[llm_col].tolist()\n",
    "\n",
    "    # Calculate percent agreement\n",
    "    agreement = np.sum(np.array(human) == np.array(llm))/len(np.array(human)) * 100\n",
    "\n",
    "    print(\"---\")\n",
    "    print(f\"{classification_report(human, llm)}\")\n",
    "    print(f\"cohen_kappa_score({human_col}): {cohen_kappa_score(human, llm)}\")\n",
    "    print(f\"krippendorf({human_col}): {krippendorff.alpha(np.array([human, llm]), level_of_measurement=\"nominal\")}\")\n",
    "    print(f\"percent_agreement({human_col}): {agreement:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the 8b model did worse than the 70b model for ideology, but better for political..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:03,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [01:46, 11.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [02:08,  5.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [03:02,  7.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [04:46, 12.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [05:08,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [06:02,  7.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [07:45, 12.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [08:09,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [09:04,  7.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [10:48, 12.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [11:09,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "52it [12:03,  7.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56it [13:46, 12.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [14:09,  5.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64it [15:02,  7.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [16:45, 12.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "72it [17:07,  5.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76it [18:01,  7.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80it [19:44, 12.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "84it [20:06,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "88it [21:49, 12.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "92it [22:11,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "96it [23:05,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [24:47, 12.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "104it [25:09,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "108it [26:02,  6.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "112it [27:45, 12.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "116it [28:06,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "120it [29:00,  7.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "124it [30:43, 12.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "128it [31:04,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "132it [32:48, 12.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "136it [33:10,  5.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "140it [34:03,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "144it [35:45, 12.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "148it [36:07,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "152it [37:01,  7.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "156it [38:43, 12.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160it [39:05,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [40:50, 12.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168it [41:11,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172it [42:04,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [43:47, 12.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180it [44:09,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "184it [45:03,  7.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "188it [46:45, 12.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192it [47:07,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "196it [48:00,  6.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [49:43, 12.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "204it [50:04,  5.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "208it [51:49, 12.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "212it [52:10,  5.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "216it [53:03,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "220it [54:46, 12.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [55:07,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "228it [56:00,  6.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "232it [57:43, 12.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "236it [58:04,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "240it [59:49, 12.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "244it [1:00:10,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "248it [1:01:03,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "252it [1:02:46, 12.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "256it [1:03:07,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "260it [1:04:04,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "264it [1:05:46, 12.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "268it [1:06:08,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "272it [1:07:01,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "276it [1:08:44, 12.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "280it [1:09:05,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "284it [1:10:50, 12.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "288it [1:11:12,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "292it [1:12:05,  7.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "296it [1:13:47, 12.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [1:14:09,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "304it [1:15:03,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "308it [1:16:46, 12.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "312it [1:17:07,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "316it [1:18:03,  7.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "320it [1:19:45, 12.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "324it [1:20:08,  5.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "328it [1:21:02,  7.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "332it [1:22:44, 12.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [1:23:06,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "340it [1:24:50, 12.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "344it [1:25:12,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "348it [1:26:05,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "352it [1:27:47, 12.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "356it [1:28:09,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "360it [1:29:02,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "364it [1:30:44, 12.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "368it [1:31:06,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "372it [1:32:51, 12.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "376it [1:33:13,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "380it [1:34:06,  6.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "384it [1:35:49, 12.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "388it [1:36:10,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "392it [1:37:04,  7.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "396it [1:38:46, 12.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [1:39:08,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "404it [1:40:01,  6.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "408it [1:41:44, 12.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "412it [1:42:05,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "416it [1:43:50, 12.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "420it [1:44:11,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "424it [1:45:06,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "428it [1:46:48, 12.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "432it [1:47:09,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "436it [1:48:03,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "440it [1:49:45, 12.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "444it [1:50:08,  5.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "448it [1:51:01,  7.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "452it [1:52:44, 12.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "456it [1:53:07,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "460it [1:54:01,  7.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "464it [1:55:43, 12.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "468it [1:56:05,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "472it [1:57:49, 12.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "476it [1:58:11,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "480it [1:59:04,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "484it [2:00:47, 12.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "488it [2:01:08,  5.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "492it [2:02:05,  7.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "496it [2:03:47, 12.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [2:04:09,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "504it [2:05:02,  7.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "508it [2:06:45, 12.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "512it [2:07:08,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "516it [2:08:02,  7.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "520it [2:09:44, 12.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "524it [2:10:06,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "528it [2:11:50, 12.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "532it [2:12:11,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "536it [2:13:04,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "540it [2:14:47, 12.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "544it [2:15:09,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "548it [2:16:02,  6.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "552it [2:17:45, 12.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "556it [2:18:07,  5.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "560it [2:19:00,  7.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "564it [2:20:43, 12.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "568it [2:21:04,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "572it [2:22:49, 12.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "576it [2:23:10,  5.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "580it [2:24:04,  7.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "584it [2:25:46, 12.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "588it [2:26:08,  5.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "592it [2:27:03,  7.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "596it [2:28:45, 12.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600it [2:29:07,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "604it [2:30:01,  7.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "608it [2:31:43, 12.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "612it [2:32:05,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "616it [2:33:49, 12.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "620it [2:34:11,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "624it [2:35:04,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "628it [2:36:47, 12.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "632it [2:37:09,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "636it [2:38:03,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "640it [2:39:46, 12.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "644it [2:40:08,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "648it [2:41:01,  6.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "652it [2:42:43, 12.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "656it [2:43:07,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "660it [2:44:01,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "664it [2:45:43, 12.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "668it [2:46:07,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "672it [2:47:00,  7.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "676it [2:48:43, 12.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "680it [2:49:04,  5.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "684it [2:50:49, 12.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "688it [2:51:12,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "692it [2:52:06,  7.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "696it [2:53:48, 12.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "700it [2:54:10, 14.93s/it]\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:54,  7.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [02:37, 12.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [02:59,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [03:52,  6.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [05:34, 12.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24it [05:56,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28it [06:52,  7.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [08:35, 12.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36it [08:56,  5.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [09:50,  6.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44it [11:32, 12.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48it [11:54,  5.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "52it [13:38, 12.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "56it [14:00,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "60it [14:53,  6.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64it [16:36, 12.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "68it [16:58,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "72it [17:53,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "76it [19:36, 12.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "80it [20:01,  6.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "84it [20:54,  7.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "88it [22:37, 12.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "92it [22:59,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "96it [23:53,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100it [25:36, 12.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "104it [25:58,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "108it [26:51,  6.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "112it [28:33, 12.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "116it [28:55,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "120it [30:39, 12.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "124it [31:01,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "128it [31:54,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "132it [33:37, 12.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "136it [33:59,  5.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "140it [34:54,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "144it [36:37, 12.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "148it [36:58,  5.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "152it [37:52,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "156it [39:34, 12.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "160it [39:56,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "164it [40:51,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168it [42:34, 12.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172it [42:56,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "176it [43:50,  7.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "180it [45:32, 12.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "184it [45:54,  5.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "188it [47:39, 12.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "192it [48:00,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "196it [48:56,  7.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [50:39, 12.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "204it [51:01,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "208it [51:56,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "212it [53:39, 12.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "216it [54:01,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "220it [54:54,  7.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "224it [56:37, 12.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "228it [56:59,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "232it [57:53,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "236it [59:35, 12.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "240it [59:58,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "244it [1:00:51,  7.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "248it [1:02:34, 12.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "252it [1:02:56,  5.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "256it [1:03:50,  7.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "260it [1:05:33, 12.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "264it [1:05:55,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "268it [1:07:39, 12.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "272it [1:08:01,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "276it [1:08:54,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "280it [1:10:37, 12.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "284it [1:10:59,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "288it [1:11:54,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "292it [1:13:37, 12.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "296it [1:13:58,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "300it [1:14:54,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "304it [1:16:37, 12.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "308it [1:16:58,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "312it [1:17:52,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "316it [1:19:34, 12.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "320it [1:19:56,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "324it [1:20:49,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "328it [1:22:32, 12.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "332it [1:22:53,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "336it [1:24:38, 12.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "340it [1:25:00,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "344it [1:25:53,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "348it [1:27:36, 12.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "352it [1:27:57,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "356it [1:28:52,  7.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "360it [1:30:35, 12.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "364it [1:30:57,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "368it [1:31:50,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "372it [1:33:33, 12.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "376it [1:33:55,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "380it [1:35:39, 12.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "384it [1:36:01,  5.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "388it [1:36:55,  7.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "392it [1:38:38, 12.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "396it [1:38:59,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "400it [1:39:53,  7.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "404it [1:41:35, 12.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "408it [1:42:00,  6.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "412it [1:42:54,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "416it [1:44:38, 12.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "420it [1:44:59,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "424it [1:46:15,  9.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "428it [1:47:58, 13.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "432it [1:48:20,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "436it [1:49:13,  6.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "440it [1:50:57, 12.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "444it [1:51:19,  5.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "448it [1:52:12,  6.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "452it [1:53:55, 12.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "456it [1:54:16,  5.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "460it [1:56:00, 12.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "464it [1:56:22,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "468it [1:57:16,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "472it [1:58:58, 12.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "476it [1:59:20,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "480it [2:00:13,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "484it [2:01:56, 12.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "488it [2:02:18,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "492it [2:03:11,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "496it [2:04:53, 12.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [2:05:15,  5.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "504it [2:06:59, 12.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "508it [2:07:21,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "512it [2:08:14,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "516it [2:09:57, 12.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "520it [2:10:18,  5.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "524it [2:11:11,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "528it [2:12:53, 12.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "532it [2:13:15,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "536it [2:14:58, 12.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "540it [2:15:19,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "544it [2:16:12,  6.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "548it [2:17:54, 12.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "552it [2:18:16,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "556it [2:20:00, 12.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "560it [2:20:21,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "564it [2:21:14,  6.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "568it [2:22:58, 12.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "572it [2:23:19,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "576it [2:24:13,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "580it [2:25:58, 12.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "584it [2:26:19,  5.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "588it [2:27:12,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "592it [2:28:55, 12.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "596it [2:29:16,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "600it [2:31:02, 12.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "604it [2:31:24,  5.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "608it [2:32:17,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "612it [2:34:00, 12.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "616it [2:34:21,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "620it [2:35:14,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "624it [2:37:00, 13.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 5 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 1 second. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "628it [2:37:21,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "632it [2:38:14,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "636it [2:39:57, 12.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "640it [2:40:20,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 7 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "644it [2:41:13,  7.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "648it [2:42:55, 12.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "652it [2:43:17,  5.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "656it [2:44:13,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "660it [2:45:55, 12.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "664it [2:46:17,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "668it [2:47:10,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 3 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "672it [2:48:54, 12.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "676it [2:49:18,  5.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "680it [2:50:11,  7.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 2 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "684it [2:51:56, 12.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "688it [2:52:17,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 6 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "692it [2:53:12,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 8 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 28 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 49 seconds...\n",
      "{\"error\":{\"message\":\"No deployments available for selected model, Try again in 60 seconds. Passed model=nf-gpt-4. pre-call-checks=False, allowed_model_region=n/a, cooldown_list=[('4bc7be04-737c-4591-8be3-aa9b7101b294', {'Exception Received': 'litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.', 'Status Code': '429'})]\",\"type\":\"None\",\"param\":\"None\",\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "696it [2:54:55, 12.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rate limit exceeded. Retrying in 4 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 9 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n",
      "Rate limit exceeded. Retrying in 13 seconds...\n",
      "{\"error\":{\"message\":\"litellm.RateLimitError: AzureException RateLimitError - Requests to the ChatCompletions_Create Operation under Azure OpenAI API version 2024-02-01 have exceeded call rate limit of your current OpenAI S0 pricing tier. Please retry after 4 seconds. Please go here: https://aka.ms/oai/quotaincrease if you would like to further increase the default rate limit.\\nReceived Model Group=nf-gpt-4\\nAvailable Model Group Fallbacks=None\",\"type\":null,\"param\":null,\"code\":\"429\"}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "700it [2:55:16, 15.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      index political_ideology political_post\n",
      "0         0            neutral            NaN\n",
      "1         1            neutral            NaN\n",
      "2         2            liberal            NaN\n",
      "3         3            neutral            NaN\n",
      "4         4       conservative            NaN\n",
      "...     ...                ...            ...\n",
      "1395    695                NaN  non-political\n",
      "1396    696                NaN      political\n",
      "1397    697                NaN      political\n",
      "1398    698                NaN  non-political\n",
      "1399    699                NaN  non-political\n",
      "\n",
      "[1400 rows x 3 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#what about GPT4o, GPT4Turbo and GPT4?\n",
    "\n",
    "#classify messages using gpt4o:\n",
    "MHGPTrun1 = ['political_ideology', 'political_post']\n",
    "  \n",
    "\n",
    "chunked_result: typing.List[pd.DataFrame] = []\n",
    "\n",
    "for label, path in CFG.prompt_classify_files.items():\n",
    "    if label in MHGPTrun1: \n",
    "        template = load_json(path).get('template')\n",
    "        classes = load_json(path).get('classes')\n",
    "        for index, row in tqdm.tqdm(MHdata[\"text\"].items()):\n",
    "            retry_count = 0\n",
    "            max_retries = 10\n",
    "            \n",
    "            while retry_count < max_retries:\n",
    "                try: \n",
    "                    response = requests.post(\n",
    "                            url=api_endpoint,\n",
    "                            headers=headers,\n",
    "                            json={\n",
    "                                'model': MODELgpt4,\n",
    "                                'messages': [\n",
    "                                    {\n",
    "                                        \"role\": \"system\",\n",
    "                                        \"content\": template\n",
    "                                    },\n",
    "                                    {\n",
    "                                        \"role\": \"user\",\n",
    "                                        \"content\": template.format(text=row)\n",
    "                                    }\n",
    "                                ],\n",
    "                                'temperature': temperature_0,  \n",
    "                                'seed': SEED,\n",
    "                                \"max_tokens\": MAX10\n",
    "                            }\n",
    "                        )  \n",
    "\n",
    "                    if response.status_code == 200:\n",
    "                        data_response = response.json()\n",
    "                        chunked_result.append(\n",
    "                        pd.DataFrame(\n",
    "                            data=[[index, classes.get(data_response[\"choices\"][0][\"message\"][\"content\"], None)]],                                \n",
    "                            columns=['index', label]\n",
    "                            )\n",
    "                        )\n",
    "                        break  # Exit the retry loop on success\n",
    "                    elif response.status_code == 429:\n",
    "                        retry_count += 1\n",
    "                        wait_time = 1 + (3 * retry_count * retry_count)\n",
    "                        print(f\"Rate limit exceeded. Retrying in {wait_time} seconds...\")\n",
    "                        print(response.text)\n",
    "                        time.sleep(wait_time)\n",
    "                    elif response.status_code == 500:\n",
    "                        retry_count += 1\n",
    "                        wait_time = 20\n",
    "                        print(f\"Failed to connect to API. Status code: {response.status_code}. Retrying in {wait_time} seconds...\")\n",
    "                        print(response.text)\n",
    "                        time.sleep(wait_time)\n",
    "                    else:\n",
    "                        print(f\"Failed to connect to API. Status code: {response.status_code}\")\n",
    "                        print(response.text)\n",
    "                        break\n",
    "                except requests.exceptions.RequestException as e:   \n",
    "                    print(f\"Failed to connect to API: {e}\")\n",
    "                    retry_count += 1\n",
    "                    wait_time = 60\n",
    "                    print(f\"Retrying in {wait_time} seconds...\")\n",
    "                    time.sleep(wait_time)                 \n",
    "                \n",
    "\n",
    "\n",
    "classifications3 = pd.concat(chunked_result, ignore_index=True)\n",
    "print(classifications3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-Ahbb3pqIaEzZ3DHfv8F3dZxLZxV2D',\n",
       " 'choices': [{'finish_reason': 'stop',\n",
       "   'index': 0,\n",
       "   'message': {'content': '1',\n",
       "    'role': 'assistant',\n",
       "    'tool_calls': None,\n",
       "    'function_call': None}}],\n",
       " 'created': 1734955989,\n",
       " 'model': 'gpt-4',\n",
       " 'object': 'chat.completion',\n",
       " 'system_fingerprint': None,\n",
       " 'usage': {'prompt_tokens': 1407,\n",
       "  'completion_tokens': 1,\n",
       "  'total_tokens': 1408},\n",
       " 'service_tier': None}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "political_post_gpt4o = classifications1.loc[:, [\"index\", \"political_post\"]].dropna()\n",
    "political_post_gpt4o.set_index('index', drop=True, inplace=True)\n",
    "MHdatapar = MHdatapar.join(political_post_gpt4o, rsuffix='_gpt4o')\n",
    "political_ideology_gpt4o = classifications1.loc[:, [\"index\", \"political_ideology\"]].dropna()\n",
    "political_ideology_gpt4o.set_index('index', drop=True, inplace=True)\n",
    "MHdatapar = MHdatapar.join(political_ideology_gpt4o, rsuffix='_gpt4o')\n",
    "\n",
    "MHdatapar = MHdatapar.rename(columns={\n",
    "    'political_post': 'political_post_gpt4o',\n",
    "    'political_ideology': 'political_ideology_gpt4o'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "political_post_gpt4T = classifications2.loc[:, [\"index\", \"political_post\"]].dropna()\n",
    "political_post_gpt4T.set_index('index', drop=True, inplace=True)\n",
    "MHdatapar = MHdatapar.join(political_post_gpt4T, rsuffix='_gpt4T')\n",
    "political_ideology_gpt4T = classifications2.loc[:, [\"index\", \"political_ideology\"]].dropna()\n",
    "political_ideology_gpt4T.set_index('index', drop=True, inplace=True)\n",
    "MHdatapar = MHdatapar.join(political_ideology_gpt4T, rsuffix='_gpt4T')\n",
    "\n",
    "MHdatapar = MHdatapar.rename(columns={\n",
    "    'political_post': 'political_post_gpt4T',\n",
    "    'political_ideology': 'political_ideology_gpt4T'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "political_post_gpt4 = classifications3.loc[:, [\"index\", \"political_post\"]].dropna()\n",
    "political_post_gpt4.set_index('index', drop=True, inplace=True)\n",
    "MHdatapar = MHdatapar.join(political_post_gpt4, rsuffix='_gpt4')\n",
    "political_ideology_gpt4 = classifications3.loc[:, [\"index\", \"political_ideology\"]].dropna()\n",
    "political_ideology_gpt4.set_index('index', drop=True, inplace=True)\n",
    "MHdatapar = MHdatapar.join(political_ideology_gpt4, rsuffix='_gpt4')\n",
    "\n",
    "MHdatapar = MHdatapar.rename(columns={\n",
    "    'political_post': 'political_post_gpt4',\n",
    "    'political_ideology': 'political_ideology_gpt4'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>pol_label</th>\n",
       "      <th>neg_label</th>\n",
       "      <th>neg3_label</th>\n",
       "      <th>ideo_label</th>\n",
       "      <th>GPT_Pol1</th>\n",
       "      <th>GPT_Pol2</th>\n",
       "      <th>GPT_Neg1</th>\n",
       "      <th>GPT_Neg2</th>\n",
       "      <th>GPT_Neg_3Way1</th>\n",
       "      <th>...</th>\n",
       "      <th>political_post_gpt4o_dum</th>\n",
       "      <th>political_conservative_gpt4o_dum</th>\n",
       "      <th>political_liberal_gpt4o_dum</th>\n",
       "      <th>political_ideology_gpt4o_score</th>\n",
       "      <th>political_post_gpt4T</th>\n",
       "      <th>political_ideology_gpt4T</th>\n",
       "      <th>political_post_gpt4T_dum</th>\n",
       "      <th>political_ideology_gpt4T_score</th>\n",
       "      <th>political_post_gpt4</th>\n",
       "      <th>political_ideology_gpt4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@thatleechi17 @KlemmChr @AndiScheuer @victorperli Ich würde sagen Sie vergleichen maximal kenntn...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>political</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>political</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Glauben Sie nur nicht, dass Menschen die nicht dem Bundestag angehören, nichts zu sagen hätten. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>political</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>political</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Das ist ja das Mindeste. \\r\\n\\r\\nDass das aber das alles möglich ist trotz der Situation der Uig...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>political</td>\n",
       "      <td>liberal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>political</td>\n",
       "      <td>liberal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Challen81690499 @c_lindner @rbrinkhaus @NowaboFM Na na na... TW</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>non-political</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>non-political</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ich sage: #DANKE!!!\\r\\nhttps://t.co/0pVneqXwTC\\r\\n#afd #btw #btw17 #btw2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>political</td>\n",
       "      <td>conservative</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>political</td>\n",
       "      <td>conservative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  text  \\\n",
       "0  @thatleechi17 @KlemmChr @AndiScheuer @victorperli Ich würde sagen Sie vergleichen maximal kenntn...   \n",
       "1  Glauben Sie nur nicht, dass Menschen die nicht dem Bundestag angehören, nichts zu sagen hätten. ...   \n",
       "2  Das ist ja das Mindeste. \\r\\n\\r\\nDass das aber das alles möglich ist trotz der Situation der Uig...   \n",
       "3                                     @Challen81690499 @c_lindner @rbrinkhaus @NowaboFM Na na na... TW   \n",
       "4                          Ich sage: #DANKE!!!\\r\\nhttps://t.co/0pVneqXwTC\\r\\n#afd #btw #btw17 #btw2017   \n",
       "\n",
       "   pol_label  neg_label  neg3_label  ideo_label  GPT_Pol1  GPT_Pol2  GPT_Neg1  \\\n",
       "0          1          1           0           1         1         1         1   \n",
       "1          1          0           1           1         1         1         0   \n",
       "2          1          1           0           1         1         1         1   \n",
       "3          0          0           1           1         1         0         0   \n",
       "4          1          0           2           2         1         1         0   \n",
       "\n",
       "   GPT_Neg2  GPT_Neg_3Way1  ...  political_post_gpt4o_dum  \\\n",
       "0         1              0  ...                         1   \n",
       "1         0              1  ...                         1   \n",
       "2         1              0  ...                         1   \n",
       "3         0              1  ...                         0   \n",
       "4         0              2  ...                         1   \n",
       "\n",
       "   political_conservative_gpt4o_dum  political_liberal_gpt4o_dum  \\\n",
       "0                                 0                            0   \n",
       "1                                 0                            0   \n",
       "2                                 0                            1   \n",
       "3                                 0                            0   \n",
       "4                                 1                            0   \n",
       "\n",
       "   political_ideology_gpt4o_score  political_post_gpt4T  \\\n",
       "0                               1             political   \n",
       "1                               1             political   \n",
       "2                               0             political   \n",
       "3                               1         non-political   \n",
       "4                               2             political   \n",
       "\n",
       "   political_ideology_gpt4T  political_post_gpt4T_dum  \\\n",
       "0                   neutral                         1   \n",
       "1                   neutral                         1   \n",
       "2                   liberal                         1   \n",
       "3                   neutral                         0   \n",
       "4              conservative                         1   \n",
       "\n",
       "  political_ideology_gpt4T_score  political_post_gpt4 political_ideology_gpt4  \n",
       "0                              1            political                 neutral  \n",
       "1                              1            political                 neutral  \n",
       "2                              0            political                 liberal  \n",
       "3                              1        non-political                 neutral  \n",
       "4                              2            political            conservative  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MHdatapar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "MHdatapar.loc[:, 'political_post_gpt4o_dum'] = MHdatapar.loc[:, 'political_post_gpt4o'].map({\"political\": 1, \"non-political\":0}).fillna(0).astype(int)\n",
    "MHdatapar.loc[:, 'political_ideology_gpt4o_score'] = MHdatapar.loc[:, 'political_ideology_gpt4o'].map({'liberal': 0, 'neutral': 1, 'conservative': 2})\n",
    "MHdatapar.loc[:, 'political_post_gpt4T_dum'] = MHdatapar.loc[:, 'political_post_gpt4T'].map({\"political\": 1, \"non-political\":0}).fillna(0).astype(int)\n",
    "MHdatapar.loc[:, 'political_ideology_gpt4T_score'] = MHdatapar.loc[:, 'political_ideology_gpt4T'].map({'liberal': 0, 'neutral': 1, 'conservative': 2})\n",
    "MHdatapar.loc[:, 'political_post_gpt4_dum'] = MHdatapar.loc[:, 'political_post_gpt4'].map({\"political\": 1, \"non-political\":0}).fillna(0).astype(int)\n",
    "MHdatapar.loc[:, 'political_ideology_gpt4_score'] = MHdatapar.loc[:, 'political_ideology_gpt4'].map({'liberal': 0, 'neutral': 1, 'conservative': 2})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.88      0.74       115\n",
      "           1       0.94      0.83      0.88       503\n",
      "           2       0.63      0.76      0.69        82\n",
      "\n",
      "    accuracy                           0.83       700\n",
      "   macro avg       0.74      0.82      0.77       700\n",
      "weighted avg       0.85      0.83      0.84       700\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.6507203891972806\n",
      "krippendorf(ideo_label): 0.6489503850713998\n",
      "percent_agreement(ideo_label): 82.86%\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.86      0.64       115\n",
      "           1       0.94      0.79      0.86       503\n",
      "           2       0.66      0.70      0.68        82\n",
      "\n",
      "    accuracy                           0.79       700\n",
      "   macro avg       0.71      0.78      0.73       700\n",
      "weighted avg       0.84      0.79      0.80       700\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.5845664012062011\n",
      "krippendorf(ideo_label): 0.5793190744093153\n",
      "percent_agreement(ideo_label): 78.86%\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.88      0.70       115\n",
      "           1       0.95      0.78      0.86       503\n",
      "           2       0.57      0.78      0.66        82\n",
      "\n",
      "    accuracy                           0.80       700\n",
      "   macro avg       0.70      0.81      0.74       700\n",
      "weighted avg       0.84      0.80      0.81       700\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.605882422911157\n",
      "krippendorf(ideo_label): 0.6014412939545503\n",
      "percent_agreement(ideo_label): 79.71%\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.92      0.73       115\n",
      "           1       0.96      0.81      0.88       503\n",
      "           2       0.69      0.85      0.76        82\n",
      "\n",
      "    accuracy                           0.83       700\n",
      "   macro avg       0.75      0.86      0.79       700\n",
      "weighted avg       0.87      0.83      0.84       700\n",
      "\n",
      "cohen_kappa_score(ideo_label): 0.6679290188227158\n",
      "krippendorf(ideo_label): 0.6646610493129983\n",
      "percent_agreement(ideo_label): 83.14%\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.99      0.75       202\n",
      "           1       0.99      0.73      0.84       498\n",
      "\n",
      "    accuracy                           0.81       700\n",
      "   macro avg       0.80      0.86      0.80       700\n",
      "weighted avg       0.88      0.81      0.82       700\n",
      "\n",
      "cohen_kappa_score(pol_label): 0.6052235813114097\n",
      "krippendorf(pol_label): 0.5912994929789597\n",
      "percent_agreement(pol_label): 80.71%\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.96      0.78       202\n",
      "           1       0.98      0.80      0.88       498\n",
      "\n",
      "    accuracy                           0.85       700\n",
      "   macro avg       0.82      0.88      0.83       700\n",
      "weighted avg       0.89      0.85      0.85       700\n",
      "\n",
      "cohen_kappa_score(pol_label): 0.6708213205822375\n",
      "krippendorf(pol_label): 0.6652294191447632\n",
      "percent_agreement(pol_label): 84.71%\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.97      0.79       202\n",
      "           1       0.98      0.80      0.88       498\n",
      "\n",
      "    accuracy                           0.85       700\n",
      "   macro avg       0.82      0.88      0.83       700\n",
      "weighted avg       0.89      0.85      0.85       700\n",
      "\n",
      "cohen_kappa_score(pol_label): 0.6751654817357196\n",
      "krippendorf(pol_label): 0.6692700899229231\n",
      "percent_agreement(pol_label): 84.86%\n",
      "---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.97      0.80       202\n",
      "           1       0.98      0.82      0.90       498\n",
      "\n",
      "    accuracy                           0.86       700\n",
      "   macro avg       0.84      0.89      0.85       700\n",
      "weighted avg       0.90      0.86      0.87       700\n",
      "\n",
      "cohen_kappa_score(pol_label): 0.7046649612733604\n",
      "krippendorf(pol_label): 0.7005126471748071\n",
      "percent_agreement(pol_label): 86.43%\n"
     ]
    }
   ],
   "source": [
    "#evaluete respective performance:\n",
    "llm_human_column_pairs = [\n",
    "    (\"ideo_label\", \"political_ideology_gpt4o_score\"),\n",
    "     (\"ideo_label\", \"political_ideology_gpt4T_score\"),\n",
    "      (\"ideo_label\", \"political_ideology_gpt4_score\"),\n",
    "    (\"ideo_label\", \"GPT_Ideo1\"),\n",
    "    (\"pol_label\", \"political_post_gpt4o_dum\"),\n",
    "    (\"pol_label\", \"political_post_gpt4T_dum\"),\n",
    "    (\"pol_label\", \"political_post_gpt4_dum\"),\n",
    "    (\"pol_label\", \"GPT_Pol1\")\n",
    "]\n",
    "print(\"Inter-coder reliablity: classification_report(human as gold, llm as predicted), cohen_kappa(human, llm):\")\n",
    "\n",
    "for human_col, llm_col in llm_human_column_pairs:\n",
    "    subset = MHdatapar[[human_col, llm_col]].dropna()\n",
    "    human = subset[human_col].tolist()\n",
    "    llm = subset[llm_col].tolist()\n",
    "\n",
    "    # Calculate percent agreement\n",
    "    agreement = np.sum(np.array(human) == np.array(llm))/len(np.array(human)) * 100\n",
    "\n",
    "    print(\"---\")\n",
    "    print(f\"{classification_report(human, llm)}\")\n",
    "    print(f\"cohen_kappa_score({human_col}): {cohen_kappa_score(human, llm)}\")\n",
    "    print(f\"krippendorf({human_col}): {krippendorff.alpha(np.array([human, llm]), level_of_measurement=\"nominal\")}\")\n",
    "    print(f\"percent_agreement({human_col}): {agreement:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPT4 in MH paper outperforms GPT4o and GPT4T on both variables, but also GPT4 on Azure..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save data to parquet\n",
    "MHdata.to_parquet('data/MH_BClemm_data/germany_val_all_llama.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmdiv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
